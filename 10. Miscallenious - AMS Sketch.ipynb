{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32f7323a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import struct\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c4e06ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def float_to_int_bits(f):\n",
    "    \"\"\"Convert a floating-point number to its bit representation as an integer.\"\"\"\n",
    "    return int.from_bytes(bytearray(struct.pack('>f', f)), byteorder='big')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd42806",
   "metadata": {},
   "source": [
    "# VSAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235cae7f",
   "metadata": {},
   "source": [
    "(Refactored) code from [repository](https://github.com/vsamtuc/ddssim/blob/master/python/agms.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25f4b194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# refactor\n",
    "\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "from collections import Counter as sparse\n",
    "\n",
    "\n",
    "class hash_family:\n",
    "    def __init__(self, depth):\n",
    "        # number of hash functions\n",
    "        self.depth = depth\n",
    "        \n",
    "        # Arrays: F[0] : a1_arr , F[1] : b1_arr , F[2] : a2_arr , F[3] : b2_arr , F[4] : a3_arr , F[5] : b3_arr \n",
    "        self.F = np.random.randint(0, 1 << 63 - 1, size=(6, depth), dtype=np.int64)\n",
    "\n",
    "    @staticmethod\n",
    "    def hash31(a, b, x):\n",
    "        r = a * x + b\n",
    "        \n",
    "        # int divide by 2^31 (Shift 31) + combine higher order bits with lower\n",
    "        fold = ((r >> 31) ^ r)\n",
    "        \n",
    "        # 2147483647 = 0111...1\n",
    "        return fold & 2147483647\n",
    "\n",
    "    def hash(self, x):\n",
    "        F = self.F\n",
    "        return self.hash31(F[0], F[1], x)\n",
    "\n",
    "    def fourwise(self, x):\n",
    "        F = self.F\n",
    "        return 2*(((self.hash31(self.hash31(self.hash31(x,F[2],F[3]),x,F[4]),x,F[5])) & 32768)>>15)-1\n",
    "\n",
    "class sketch:\n",
    "    def __init__(self, width, depth, hf):\n",
    "        self.width = width\n",
    "        self.depth = depth\n",
    "        self.hf = hf\n",
    "        self.vec = np.zeros((depth, width))\n",
    "\n",
    "    def update(self, key, freq=1):\n",
    "        pos = self.hf.hash(key) % self.width\n",
    "        delta = self.hf.fourwise(key) * freq\n",
    "        self.vec[range(self.depth), pos] += delta\n",
    "\n",
    "    def inner(self, other):\n",
    "        return np.median(np.einsum('ij,ij->i', self.vec, other.vec))\n",
    "\n",
    "\n",
    "def make_stream(nkeys, length):\n",
    "    return np.random.randint(nkeys, size=length)\n",
    "\n",
    "\n",
    "def make_sparse(S):\n",
    "    return sparse(S)\n",
    "\n",
    "\n",
    "def sparse_inner(s1, s2):\n",
    "    return sum(s1[k] * s2[k] for k in s1 if k in s2)\n",
    "\n",
    "\n",
    "def create_sketch(width, depth, hf, sp):\n",
    "    sk = sketch(width, depth, hf)\n",
    "    for x in sp:\n",
    "        sk.update(x, sp[x])\n",
    "    return sk\n",
    "\n",
    "\n",
    "def create_sketch_for_vector(width, depth, hf, v):\n",
    "    sk = sketch(width, depth, hf)\n",
    "    for i, x in enumerate(v):\n",
    "        sk.update(i, x)\n",
    "    return sk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2709c9f",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c3a562f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_sketch_accuracy():\n",
    "    width = 1500\n",
    "    depth = 7\n",
    "\n",
    "    S1 = make_stream(10000, 10000)\n",
    "    S2 = make_stream(10000, 10000)\n",
    "\n",
    "    sp1 = make_sparse(S1)\n",
    "    sp2 = make_sparse(S2)\n",
    "\n",
    "    hf = hash_family(depth)\n",
    "    sk1 = create_sketch(width, depth, hf, sp1)\n",
    "    sk2 = create_sketch(width, depth, hf, sp2)\n",
    "\n",
    "    inner_product_true = sparse_inner(sp1, sp2)\n",
    "    inner_product_estimated = sk1.inner(sk2)\n",
    "\n",
    "    error = abs((inner_product_true - inner_product_estimated) / inner_product_true)\n",
    "    accuracy = 4 / np.sqrt(width)\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print()\n",
    "    print(f\"True Inner Product: {inner_product_true}, Estimated Inner Product: {inner_product_estimated}\")\n",
    "    print()\n",
    "    print(f\"Error: {error}\")\n",
    "    assert error < accuracy, \"Accuracy not sufficient\"\n",
    "    \n",
    "\n",
    "def test_sketch_accuracy_euclidian_norm(width, depth, n):\n",
    "\n",
    "    v = np.random.rand(n) # rand vector 0..1 \n",
    "\n",
    "    hf = hash_family(depth)\n",
    "    sk = create_sketch_for_vector(width, depth, hf, v)\n",
    "\n",
    "    inner_product_true = np.inner(v, v)\n",
    "    inner_product_estimated = sk.inner(sk)\n",
    "\n",
    "    error = abs((inner_product_true - inner_product_estimated) / inner_product_true)\n",
    "    accuracy = 4 / np.sqrt(width)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print()\n",
    "    print(f\"True Inner Product: {inner_product_true}, Estimated Inner Product: {inner_product_estimated}\")\n",
    "    print()\n",
    "    print(f\"Error: {error}\")\n",
    "    assert error < accuracy, \"Accuracy not sufficient\"\n",
    "\n",
    "\n",
    "def cosine_similarity(array1, array2):\n",
    "    flat_array1 = array1.flatten()\n",
    "    \n",
    "    flat_array2 = array2.flatten()\n",
    "    \n",
    "    dot_prod = np.dot(flat_array1, flat_array2)\n",
    "    \n",
    "    norm1 = np.linalg.norm(flat_array1)\n",
    "    \n",
    "    norm2 = np.linalg.norm(flat_array2)\n",
    "    \n",
    "    return dot_prod / (norm1 * norm2)\n",
    "    \n",
    "\n",
    "def test_sketch_linearity(width, depth, n):\n",
    "    v1 = np.random.rand(n) # rand vector 0..1 \n",
    "    \n",
    "    v2 = np.random.rand(n) # rand vector 0..1 \n",
    "    \n",
    "    hf = hash_family(depth)\n",
    "    \n",
    "    sk1 = create_sketch_for_vector(width, depth, hf, v1)\n",
    "    \n",
    "    sk2 = create_sketch_for_vector(width, depth, hf, v2)\n",
    "    \n",
    "    v1_plus_v2 = v1 + v2\n",
    "    \n",
    "    sk_1_plus_2 = create_sketch_for_vector(width, depth, hf, v1_plus_v2)\n",
    "    \n",
    "    cos_similarity = cosine_similarity(sk1.vec+sk2.vec, sk_1_plus_2.vec)\n",
    "    \n",
    "    print(f\"Cosine Similarity between sk(v1+v2) and sk(v1)+sk(v2) : {cos_similarity}\")\n",
    "    \n",
    "    v1_euc_norm = np.inner(v1, v1)\n",
    "    v1_euc_norm_est = sk1.inner(sk1)\n",
    "    \n",
    "    v2_euc_norm = np.inner(v2, v2)\n",
    "    v2_euc_norm_est = sk2.inner(sk2)\n",
    "    \n",
    "    print()\n",
    "    print(f\"||v1||^2 + ||v2||^2 : {v1_euc_norm+v2_euc_norm}\")\n",
    "    print(f\"M(sk(v1)) + M(sk(v2)) : {v1_euc_norm_est+v2_euc_norm_est}\")\n",
    "    \n",
    "    v1_plus_v2_euc_norm = np.inner(v1_plus_v2, v1_plus_v2)\n",
    "    \n",
    "    print()\n",
    "    print(f\"||v1 + v2||^2 : {v1_plus_v2_euc_norm}\")\n",
    "    print(f\"M(sk(v1) + sk(v2)) : {sk_1_plus_2.inner(sk_1_plus_2)}\") # sk_1_plus_2 is similar 100% to sk(v1)+sk(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df77600b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4\n",
      "\n",
      "True Inner Product: 32.83859819186468, Estimated Inner Product: 31.42268769813536\n",
      "\n",
      "Error: 0.04311726357674113\n"
     ]
    }
   ],
   "source": [
    "test_sketch_accuracy_euclidian_norm(width=100, depth=7, n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02035690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between sk(v1+v2) and sk(v1)+sk(v2) : 1.0000000000000002\n",
      "\n",
      "||v1||^2 + ||v2||^2 : 6641.120454081112\n",
      "M(sk(v1)) + M(sk(v2)) : 6376.599092318713\n",
      "\n",
      "||v1 + v2||^2 : 11624.152097238788\n",
      "M(sk(v1) + sk(v2)) : 10927.62713344412\n"
     ]
    }
   ],
   "source": [
    "test_sketch_linearity(width=100, depth=7, n=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8e7d71",
   "metadata": {},
   "source": [
    "# TFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ebbc8854",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6c661c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = 7  # number of hash functions\n",
    "width = 10  # specifies hash31 : N -> {0, 1, ..., `width`} uniformly.\n",
    "\n",
    "tf_width = tf.constant(width, dtype=tf.int32)\n",
    "tf_depth = tf.constant(depth, dtype=tf.int32)\n",
    "\n",
    "# Pool of three random tuples (A, B) corresponding to a different hash function parameters\n",
    "# We provide information about pair (F[0], F[1]) , the rest follow this \n",
    "# F[0] : shape(depth,) random `a` parameters for each row of the sketch. One row <-> One hash func <-> One `a`\n",
    "# F[1] : shape(depth,) random `b` parameters for each row of the sketch. One row <-> One hash func <-> One `b`\n",
    "tf_F = tf.random.uniform(shape=(6, depth), minval=0, maxval=(1 << 31) - 1, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "63e6f6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def sketch_for_vector(v):\n",
    "    \"\"\" Returns AGMS sketch for `v` (vector shape=(n,)). \n",
    "    Note: We serialize `F`, `width`, `depth` for efficiency \"\"\"\n",
    "    \n",
    "    F = tf.constant(tf_F)\n",
    "    width = tf.constant(tf_width)\n",
    "    depth = tf.constant(tf_depth)\n",
    "\n",
    "    @tf.function\n",
    "    def _hash31(x, a, b):\n",
    "        \"\"\" _hash31 : N -> {0, 1, ..., width} uniformly \"\"\"\n",
    "        r = a * x + b\n",
    "        fold = tf.bitwise.bitwise_xor(tf.bitwise.right_shift(r, 31), r)\n",
    "        return tf.bitwise.bitwise_and(fold, 2147483647)\n",
    "    \n",
    "    @tf.function\n",
    "    def _fourwise(x):\n",
    "        \"\"\" Fourwise independent hash of `x` (int) to {+1, -1}. \"\"\"\n",
    "        result = 2 * (tf.bitwise.right_shift(tf.bitwise.bitwise_and(_hash31(_hash31(_hash31(x, F[2], F[3]), x, F[4]), x, F[5]), 32768), 15)) - 1\n",
    "        return result\n",
    "\n",
    "    sketch = tf.zeros(shape=(depth, width), dtype=tf.float32)\n",
    "    indices = tf.range(tf.shape(v)[0], dtype=tf.int32)\n",
    "\n",
    "    for i in indices:\n",
    "        pos = _hash31(i, F[0], F[1]) % width\n",
    "        delta = tf.cast(_fourwise(i), dtype=tf.float32) * v[i]\n",
    "        indices_to_update = tf.stack([tf.range(depth, dtype=tf.int32), pos], axis=1)\n",
    "        sketch = tf.tensor_scatter_nd_add(sketch, indices_to_update, delta)\n",
    "\n",
    "    return sketch\n",
    "\n",
    "@tff.tf_computation\n",
    "def sketch_for_vector_fn(v):\n",
    "    return sketch_for_vector(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a6aa65f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tff.tf_computation\n",
    "def estimate_euc_norm_squared(sketch):\n",
    "    \n",
    "    @tf.function\n",
    "    def _median(v):\n",
    "        \"\"\" Median of tensor `v` with shape=(n,). Note: Suboptimal O(nlogn) but it's ok bcz n = `depth`\"\"\"\n",
    "        length = tf.shape(v)[0]\n",
    "        sorted_v = tf.sort(v)\n",
    "        middle = length // 2\n",
    "\n",
    "        return tf.cond(\n",
    "            tf.equal(length % 2, 0),\n",
    "            lambda: (sorted_v[middle - 1] + sorted_v[middle]) / 2.0,\n",
    "            lambda: sorted_v[middle]\n",
    "        )\n",
    "    \n",
    "    return _median(tf.reduce_sum(tf.square(sketch), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e12a12",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a184b8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bca61e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def cosine_similarity(t1, t2):\n",
    "    flat_t1 = tf.reshape(t1, shape=[-1])\n",
    "    \n",
    "    flat_t2 = tf.reshape(t2, shape=[-1])\n",
    "    \n",
    "    dot = tf.tensordot(flat_t1, flat_t2, axes=1)\n",
    "    \n",
    "    norm1 = tf.norm(flat_t1)\n",
    "    \n",
    "    norm2 = tf.norm(flat_t2)\n",
    "    \n",
    "    return dot / (norm1 * norm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c9e2e7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sketch_linearity(n):\n",
    "    v1 = tf.random.uniform(shape=(n,), minval=0, maxval=0.5, dtype=tf.float32)\n",
    "    \n",
    "    v2 = tf.random.uniform(shape=(n,), minval=0, maxval=0.5, dtype=tf.float32)\n",
    "    \n",
    "    sk1 = sketch_for_vector(v1)\n",
    "    \n",
    "    sk2 = sketch_for_vector(v2)\n",
    "    \n",
    "    v1_plus_v2 = v1 + v2\n",
    "    \n",
    "    sk_1_plus_2 = sketch_for_vector(v1_plus_v2)\n",
    "    \n",
    "    cos_similarity = cosine_similarity(sk1+sk2, sk_1_plus_2)\n",
    "    \n",
    "    print(f\"Cosine Similarity between sk(v1+v2) and sk(v1)+sk(v2) : {cos_similarity}\")\n",
    "\n",
    "    v1_euc_norm = np.inner(v1, v1)\n",
    "    v1_euc_norm_est = estimate_euc_norm_squared(sk1)\n",
    "    \n",
    "    v2_euc_norm = np.inner(v2, v2)\n",
    "    v2_euc_norm_est = estimate_euc_norm_squared(sk2)\n",
    "    \n",
    "    print()\n",
    "    print(f\"||v1||^2 + ||v2||^2 : {v1_euc_norm+v2_euc_norm}\")\n",
    "    print(f\"M(sk(v1)) + M(sk(v2)) : {v1_euc_norm_est+v2_euc_norm_est}\")\n",
    "    \n",
    "    v1_plus_v2_euc_norm = np.inner(v1_plus_v2, v1_plus_v2)\n",
    "    \n",
    "    print()\n",
    "    print(f\"||v1 + v2||^2 : {v1_plus_v2_euc_norm}\")\n",
    "    print(f\"M(sk(v1) + sk(v2)) : {estimate_euc_norm_squared(sk1+sk2)}\") # sk_1_plus_2 is similar 100% to sk(v1)+sk(v2)\n",
    "\n",
    "    \n",
    "def test_sketch_accuracy_euc_norm_squared(n):\n",
    "\n",
    "    v = tf.random.uniform(shape=(n,), minval=0, maxval=1, dtype=tf.float32)\n",
    "\n",
    "    sk = sketch_for_vector(v)\n",
    "\n",
    "    inner_product_true = np.inner(v, v)\n",
    "    inner_product_estimated = estimate_euc_norm_squared(sk)\n",
    "\n",
    "    error = abs((inner_product_true - inner_product_estimated) / inner_product_true)\n",
    "    accuracy = 4. / np.sqrt(width)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print()\n",
    "    print(f\"True Euc Norm Squared: {inner_product_true}, Estimated Euc Norm Squared: {inner_product_estimated}\")\n",
    "    print()\n",
    "    print(f\"Error: {error}\")\n",
    "    assert error < accuracy, \"Accuracy not sufficient\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b88a324a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between sk(v1+v2) and sk(v1)+sk(v2) : 0.9999998211860657\n",
      "\n",
      "||v1||^2 + ||v2||^2 : 14.457151412963867\n",
      "M(sk(v1)) + M(sk(v2)) : 16.113231658935547\n",
      "\n",
      "||v1 + v2||^2 : 24.409738540649414\n",
      "M(sk(v1) + sk(v2)) : 25.044307708740234\n"
     ]
    }
   ],
   "source": [
    "test_sketch_linearity(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5d65d3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.2649110640673518\n",
      "\n",
      "True Euc Norm Squared: 31.69739532470703, Estimated Euc Norm Squared: 30.471942901611328\n",
      "\n",
      "Error: 0.03866098076105118\n"
     ]
    }
   ],
   "source": [
    "test_sketch_accuracy_euc_norm_squared(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ee0083d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0301ddea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tff-py39] *",
   "language": "python",
   "name": "conda-env-tff-py39-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
