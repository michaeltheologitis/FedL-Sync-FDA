{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12f8f459-1a0e-4584-9a59-d0182ee9fdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079baeb4-3ff4-461c-97cd-2e033646a817",
   "metadata": {},
   "source": [
    "## Import EMNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2f5a9f2-a315-4167-b085-33c1df5961b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e1c6b01-7986-4d55-8d0e-37e2c47f60a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b19675f-ad59-4e03-91ef-d8bd949c6dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_BATCH_INPUT = (None, 28, 28) # EMNIST dataset (None is used for batch size, as it varies)\n",
    "CNN_INPUT_RESHAPE = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb30c89b-f085-4ce8-b783-ea5fb65b0d10",
   "metadata": {},
   "source": [
    "## Prepare data for Federated Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c18aaa3-647f-4eb1-b396-4c66ee9f930b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to TensorFlow Datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(256)\n",
    "\n",
    "del X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3f5543-ce86-4b35-ac58-598ff694e0d5",
   "metadata": {},
   "source": [
    "### Slice the Tensors for each Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ecdda90-668f-43cc-a247-6f25538b7cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_federated_data_for_clients(num_clients):\n",
    "    \n",
    "    # Shard the data across clients CLIENT LEVEL\n",
    "    client_datasets = [\n",
    "        train_dataset.shard(num_clients, i)\n",
    "        for i in range(num_clients)\n",
    "    ]\n",
    "    \n",
    "    return client_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d52400eb-8916-4d11-8e0c-9791962ebe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_federated_data_for_test(federated_data, batch_size, num_steps_until_rtc_check, seed=None):\n",
    "    \n",
    "    def process_client_dataset(client_dataset, batch_size, num_steps_until_rtc_check, seed, shuffle_size=512):\n",
    "        return client_dataset.shuffle(shuffle_size, seed=seed).repeat().batch(batch_size)\\\n",
    "            .take(num_steps_until_rtc_check).prefetch(tf.data.AUTOTUNE)\n",
    "        \n",
    "    federated_dataset_prepared = [\n",
    "        process_client_dataset(client_dataset, batch_size, num_steps_until_rtc_check, seed)\n",
    "        for client_dataset in federated_data\n",
    "    ]\n",
    "    return federated_dataset_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0abac82-295e-4bdd-90a1-0bf65bf8152e",
   "metadata": {},
   "source": [
    "# Miscallenious"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b51cb4-a425-4c75-a4b1-ea3b9b1bad10",
   "metadata": {},
   "source": [
    "## Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f365fb4-684c-4bc8-887a-5eb07d541ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance(server_cnn, client_cnns):\n",
    "    \n",
    "    w_t0 = server_cnn.trainable_vars_as_vector()\n",
    "    \n",
    "    squared_distances = [\n",
    "        tf.reduce_sum(tf.square(client_cnn.trainable_vars_as_vector() - w_t0)) \n",
    "        for client_cnn in client_cnns\n",
    "    ]\n",
    "    \n",
    "    var = tf.reduce_mean(squared_distances)\n",
    "    \n",
    "    return var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab51e4b2-fb82-422e-bd30-d2751e3e5902",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Neural Net weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e7d31b3-74dd-4b1d-8f96-2b24bd465664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_weights(model):\n",
    "    total_params = 0\n",
    "    for layer in model.layers:\n",
    "        total_params += np.sum([np.prod(weight.shape) for weight in layer.trainable_weights])\n",
    "    return int(total_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a29fb3-00c2-4332-99aa-8cf3d8c8e700",
   "metadata": {},
   "source": [
    "### Prepare (and restart) Client Dataset - shuffling, batching, prefetching\n",
    "\n",
    "Proper use of `.prefetch` [explained](https://stackoverflow.com/questions/63796936/what-is-the-proper-use-of-tensorflow-dataset-prefetch-and-cache-options).\n",
    "\n",
    "Proper ordering `.shuffle` and `.batch` and `.repeat` [explained](https://stackoverflow.com/questions/50437234/tensorflow-dataset-shuffle-then-batch-or-batch-then-shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64e0c33-a73f-42f2-ba2e-0c38e2ec0004",
   "metadata": {},
   "source": [
    "# Simple Convolutional Neural Net (CNN) - Medium Size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c1164e-7dde-4bf4-b518-fb59f2747f12",
   "metadata": {},
   "source": [
    "A simple Convolutional Neural Network with a single convolutional layer, followed by a max-pooling layer, and two dense layers for classification. Designed for 28x28 grayscale images. It has 692,352 weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "647bdd24-789a-4699-a1cd-02259dc067bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(tf.keras.Model):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        self.reshape = layers.Reshape(CNN_INPUT_RESHAPE)\n",
    "        self.conv1 = layers.Conv2D(32, 3, activation='relu')\n",
    "        self.max_pool = layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.dense1 = layers.Dense(128, activation='relu')\n",
    "        self.dense2 = layers.Dense(num_classes, activation='softmax')\n",
    "\n",
    "        \n",
    "    # Defines the computation from inputs to outputs\n",
    "    def call(self, inputs, training=None):\n",
    "        x = self.reshape(inputs)  # Add a channel dimension\n",
    "        x = self.conv1(x)\n",
    "        x = self.max_pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def step(self, batch):\n",
    "        \n",
    "        x_batch, y_batch = batch\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass: Compute predictions\n",
    "            y_batch_pred = self(x_batch, training=True)\n",
    "\n",
    "            # Compute the loss value\n",
    "            # (the loss function is configured in `compile()`)\n",
    "            loss = self.compiled_loss(\n",
    "                y_true=y_batch,\n",
    "                y_pred=y_batch_pred,\n",
    "                regularization_losses=self.losses\n",
    "            )\n",
    "\n",
    "        # Compute gradients\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        \n",
    "        # Apply gradients to the model's trainable variables (update weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        \n",
    "        # Update metrics (includes the metric that tracks the loss)\n",
    "        #self.compiled_metrics.update_state(y_batch, y_batch_pred)\n",
    "    \n",
    "    \n",
    "    def train(self, dataset):\n",
    "\n",
    "        for batch in dataset:\n",
    "            self.step(batch)\n",
    "            \n",
    "    \n",
    "    def set_trainable_variables(self, trainable_vars):\n",
    "        \"\"\" Given `trainable_vars` set our `self.trainable_vars` \"\"\"\n",
    "        for model_var, var in zip(self.trainable_variables, trainable_vars):\n",
    "            model_var.assign(var)\n",
    "\n",
    "            \n",
    "    def trainable_vars_as_vector(self):\n",
    "        return tf.concat([tf.reshape(var, [-1]) for var in self.trainable_variables], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb705b3-64f1-4e9b-80eb-f9ff312dd863",
   "metadata": {},
   "source": [
    "### Helper function to compile and return the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f59c4f-188f-45ef-befd-3bcf47ae7c58",
   "metadata": {},
   "source": [
    "**Important** function that returns a compiled and built `SimpleCNN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4960717e-6839-49c6-8c7f-911fc39cbd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_and_built_simple_cnn():\n",
    "    cnn = SimpleCNN()\n",
    "    \n",
    "    cnn.compile(\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False), # we have softmax\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')]\n",
    "    )\n",
    "    \n",
    "    cnn.build(CNN_BATCH_INPUT)  # EMNIST dataset (None is used for batch size, as it varies)\n",
    "    \n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c7ee4f-59da-48e6-ba78-01860ebf6ce8",
   "metadata": {},
   "source": [
    "Helper function that creates a new `AdvancedCNN` just to compute and return accuracy. Will be used in-between epochs so we keep correct metrics without synchronizing and messing up the federated training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fb96611-6114-4432-89b4-5451e4a47a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def current_accuracy_simple_cnn(client_cnns):\n",
    "    \n",
    "    tmp_cnn = get_compiled_and_built_simple_cnn()\n",
    "    tmp_cnn.set_trainable_variables(average_client_weights(client_cnns))\n",
    "    _, acc = tmp_cnn.evaluate(test_dataset, verbose=0)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a550fe5a-5268-453b-9b71-332fa67fe947",
   "metadata": {},
   "source": [
    "# Advanced Convolutional Neural Net (CNN) - Large Size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1031fcc1-6679-4c39-b140-ea707665550f",
   "metadata": {},
   "source": [
    "A more complex Convolutional Neural Network with three sets of two convolutional layers, each followed by a max-pooling layer, and two dense layers with dropout for classification. Designed for 28x28 grayscale images. It has 2,592,202 weights.\n",
    "\n",
    "Notes about `@tf.function`:\n",
    "\n",
    "1. After testing it might be worth it to wrap `.step` in `@tf.function`. More CPU usage. Be mindful of retracing (test it).\n",
    "\n",
    "2. After testing it is not worth it to wrap `.train`. Only consider `.step`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3141d998-651e-46d4-8ef1-cf359d0f7f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedCNN(tf.keras.Model):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(AdvancedCNN, self).__init__()\n",
    "        \n",
    "        self.reshape = layers.Reshape(CNN_INPUT_RESHAPE)\n",
    "        \n",
    "        self.conv1 = layers.Conv2D(64, kernel_size=3, activation='relu', padding='same')\n",
    "        self.conv2 = layers.Conv2D(64, kernel_size=3, activation='relu', padding='same')\n",
    "        self.max_pool1 = layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        \n",
    "        self.conv3 = layers.Conv2D(128, kernel_size=3, activation='relu', padding='same')\n",
    "        self.conv4 = layers.Conv2D(128, kernel_size=3, activation='relu', padding='same')\n",
    "        self.max_pool2 = layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        \n",
    "        self.conv5 = layers.Conv2D(256, kernel_size=3, activation='relu', padding='same')\n",
    "        self.conv6 = layers.Conv2D(256, kernel_size=3, activation='relu', padding='same')\n",
    "        self.max_pool3 = layers.MaxPooling2D(pool_size=(2, 2))\n",
    "\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.dense1 = layers.Dense(512, activation='relu')\n",
    "        self.dropout1 = layers.Dropout(0.5)\n",
    "        self.dense2 = layers.Dense(512, activation='relu')\n",
    "        self.dropout2 = layers.Dropout(0.5)\n",
    "        self.dense3 = layers.Dense(num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        x = self.reshape(inputs)  # Add a channel dimension\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.max_pool1(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.max_pool2(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.max_pool3(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dropout1(x, training=training)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dropout2(x, training=training)\n",
    "        x = self.dense3(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def step(self, batch):\n",
    "        \n",
    "        x_batch, y_batch = batch\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass: Compute predictions\n",
    "            y_batch_pred = self(x_batch, training=True)\n",
    "\n",
    "            # Compute the loss value\n",
    "            # (the loss function is configured in `compile()`)\n",
    "            loss = self.compiled_loss(\n",
    "                y_true=y_batch,\n",
    "                y_pred=y_batch_pred,\n",
    "                regularization_losses=self.losses\n",
    "            )\n",
    "\n",
    "        # Compute gradients\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        \n",
    "        # Apply gradients to the model's trainable variables (update weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        \n",
    "        # Update metrics (includes the metric that tracks the loss)\n",
    "        #self.compiled_metrics.update_state(y_batch, y_batch_pred)\n",
    "    \n",
    "    \n",
    "    def train(self, dataset):\n",
    "        \n",
    "        for batch in dataset:\n",
    "            self.step(batch)\n",
    "            \n",
    "    \n",
    "    def set_trainable_variables(self, trainable_vars):\n",
    "        \"\"\" Given `trainable_vars` set our `self.trainable_vars` \"\"\"\n",
    "        for model_var, var in zip(self.trainable_variables, trainable_vars):\n",
    "            model_var.assign(var)\n",
    "\n",
    "            \n",
    "    def trainable_vars_as_vector(self):\n",
    "        return tf.concat([tf.reshape(var, [-1]) for var in self.trainable_variables], axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25606540-c2a0-4e43-8ccb-d48f0bbbfcc4",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2583ec-795d-4fac-bdfe-65a9b46d4c73",
   "metadata": {},
   "source": [
    "**Important** function that returns a compiled and built `AdvancedCNN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f3a6d1d-772f-435f-8ef5-117999a85f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_and_built_advanced_cnn():\n",
    "    advanced_cnn = AdvancedCNN()\n",
    "    \n",
    "    advanced_cnn.compile(\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False), # we have softmax\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')]\n",
    "    )\n",
    "    \n",
    "    advanced_cnn.build(CNN_BATCH_INPUT)  # EMNIST dataset (None is used for batch size, as it varies)\n",
    "    \n",
    "    return advanced_cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa70171-08e0-4a13-abdd-e4522942c10f",
   "metadata": {},
   "source": [
    "Helper function that creates a new `AdvancedCNN` just to compute and return accuracy. Will be used in-between epochs so we keep correct metrics without synchronizing and messing up the federated training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36e19bd7-d6b9-4816-8c5e-79fcb1851d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def current_accuracy_advanced_cnn(client_cnns):\n",
    "    \n",
    "    tmp_cnn = get_compiled_and_built_advanced_cnn()\n",
    "    tmp_cnn.set_trainable_variables(average_client_weights(client_cnns))\n",
    "    _, acc = tmp_cnn.evaluate(test_dataset, verbose=0)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ba9905-67f5-4c59-a089-6ce27c1cf147",
   "metadata": {},
   "source": [
    "### Average NN weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1417655-5196-4954-9942-dab9d2fb3bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_client_weights(client_models):\n",
    "    # client_weights[0] the trainable variables of Client 0 (a list of tf.Variable)\n",
    "    client_weights = [model.trainable_variables for model in client_models]\n",
    "\n",
    "    # concise solution. per layer. `layer_weight_tensors` corresponds to a list of tensors of a layer\n",
    "    avg_weights = [\n",
    "        tf.reduce_mean(layer_weight_tensors, axis=0)\n",
    "        for layer_weight_tensors in zip(*client_weights)\n",
    "    ]\n",
    "\n",
    "    return avg_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f3a35c-5182-4767-a5bb-ffd35b374c81",
   "metadata": {},
   "source": [
    "### Server - Clients synchronization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9c897cb-6ee9-4f6c-bc78-78f91ac81266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synchronize_clients(server_cnn, client_cnns):\n",
    "\n",
    "    for client_cnn in client_cnns:\n",
    "        client_cnn.set_trainable_variables(server_cnn.trainable_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6fdb3e-c945-43ef-934b-97af4a8144cc",
   "metadata": {},
   "source": [
    "# Functional Dynamic Averaging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0a989e-89d0-4e71-af83-b9d6f3347070",
   "metadata": {},
   "source": [
    "We follow the Functional Dynamic Averaging (FDA) scheme. Let the mean model be\n",
    "\n",
    "$$ \\overline{w_t} = \\frac{1}{k} \\sum_{i=1}^{k} w_t^{(i)} $$\n",
    "\n",
    "where $ w_t^{(i)} $ is the model at time $ t $ in some round in the $i$-th learner.\n",
    "\n",
    "Local models are trained independently and cooperatively and we want to monitor the Round Terminating Conditon (**RTC**):\n",
    "\n",
    "$$ \\frac{1}{k} \\sum_{i=1}^{k} \\lVert w_t^{(i)} - \\overline{w_t} \\rVert_2^2  \\leq \\Theta $$\n",
    "\n",
    "where the left-hand side is the **model variance**, and threshold $\\Theta$ is a hyperparameter of the FDA, defined at the beginning of the round; it may change at each round. When the monitoring logic cannot guarantee the validity of RTC, the round terminates. All local models are pulled into `tff.SERVER`, and $\\bar{w_t}$ is set to their average. Then, another round begins."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea88e748-3b00-47a9-b128-5bbb53adfac5",
   "metadata": {},
   "source": [
    "### Monitoring the RTC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08446303-59c6-4251-9ae1-0ca859e6cf77",
   "metadata": {},
   "source": [
    "FDA monitors the RTC by applying techniques from Functionary [Functional Geometric Averaging](http://users.softnet.tuc.gr/~minos/Papers/edbt19.pdf). We first restate the problem of monitoring RTC into the standard distributed stream monitoring formulation. Let\n",
    "\n",
    "$$ S(t) =  \\frac{1}{k} \\sum_{i=1}^{k} S_i(t) $$\n",
    "\n",
    "where $ S(t) \\in \\mathbb{R}^n $ be the \"global state\" of the system and $ S_i(t) \\in \\mathbb{R}^n $ the \"local states\". The goal is to monitor the threshold condition on the global state in the form $ F(S(t)) \\leq \\Theta $ where $ F : \\mathbb{R}^n \\to \\mathbb{R} $ a non-linear function. Let\n",
    "\n",
    "$$ \\Delta_t^{(i)} = w_t^{(i)} - w_{t_0}^{(i)} $$\n",
    "\n",
    "be the update at the $ i $-th learner, that is, the change to the local model at time $t$ since the beginning of the current round at time $t_0$. Let the average update be\n",
    "\n",
    "$$ \\overline{\\Delta_t} = \\frac{1}{k} \\sum_{i=1}^{k} \\Delta_t^{(i)} $$\n",
    "\n",
    "it follows that the variance can be written as\n",
    "\n",
    "$$ \\frac{1}{k} \\sum_{i=1}^{k} \\lVert w_t^{(i)} - \\overline{w_t} \\rVert_2^2 = \\Big( \\frac{1}{k} \\sum_{i=1}^{k} \\lVert \\Delta_t^{(i)} \\rVert_2^2 \\Big) - \\lVert \\overline{\\Delta_t} \\rVert_2^2 $$\n",
    "\n",
    "So, conceptually, if we define\n",
    "$$ S_i(t) = \\begin{bmatrix}\n",
    "           \\lVert \\Delta_t^{(i)} \\rVert_2^2 \\\\\n",
    "           \\Delta_t^{(i)}\n",
    "         \\end{bmatrix} \\quad \\text{and} \\quad\n",
    "         F(\\begin{bmatrix}\n",
    "           v \\\\\n",
    "           \\bf{x}\n",
    "         \\end{bmatrix}) = v - \\lVert \\bf{x} \\rVert_2^2 $$\n",
    "\n",
    "The RTC is equivalent to condition $$ F(S(t)) \\leq \\Theta $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f8ced7-22ce-404d-bd78-55590cfdd478",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1️⃣ Naive FDA\n",
    "\n",
    "In the naive approach, we eliminate the update vector from the local state (i.e. recuce the dimension to 0). Define local state as\n",
    "\n",
    "$$ S_i(t) = \\lVert \\Delta_t^{(i)} \\rVert_2^2 \\in \\mathbb{R}$$ \n",
    "\n",
    "and the identity function\n",
    "\n",
    "$$ F(v) = v $$\n",
    "\n",
    "It is trivial that $ F(S(t)) \\leq \\Theta $ implies the RTC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ab384b-e2b3-4470-9a7b-e8f555d0245d",
   "metadata": {},
   "source": [
    "### Client Train\n",
    "\n",
    "The number of steps depends on the dataset, i.e., `.take(num)` call on `tf.data.Dataset` creation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebcfa211-c199-4f93-9b01-7ef9aeba1c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_train_naive(w_t0, client_cnn, client_dataset):\n",
    "    \"\"\"\n",
    "    :param w_t0: Vector Tensor shape=(d,). Same shape with `client_cnn.trainable_vars_as_vector()`\n",
    "    :return: Tensor shape=() dtype=tf.float32\n",
    "    \"\"\"\n",
    "    \n",
    "    # number of steps depend on `.take()` from `dataset`\n",
    "    client_cnn.train(client_dataset)\n",
    "    \n",
    "    Delta_i = client_cnn.trainable_vars_as_vector() - w_t0\n",
    "    \n",
    "    #||D(t)_i||^2 , shape = () \n",
    "    Delta_i_euc_norm_squared = tf.reduce_sum(tf.square(Delta_i)) # ||D(t)_i||^2\n",
    "    \n",
    "    return Delta_i_euc_norm_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738965e0-2852-42aa-88ee-e8f558252948",
   "metadata": {},
   "source": [
    "### Train all Clients\n",
    "\n",
    "Notes about the following potentialy general `tf.function`:\n",
    "\n",
    "1. Even though `clients_cnn` and `federated_dataset` contain `tf.Keras.Module` and `tf.data.Dataset` elements, they both are python lists (python side-effects). Take a look at [Looping Over Python data](https://www.tensorflow.org/guide/function#tracing) and afterwards [For example, the following loop is unrolled, even though the list contains ...](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/control_flow.md#while-statements) to get more insight.\n",
    "\n",
    "2. TL;DR: It is very-very bad in terms of RAM. It produces an unrolled loop. The graph becomes consequent `Delta_i_... = ... ; S_i_clients.append(...) ;` commands `len(client_cnns)` number of times. This produces a huge graph (for instance, for `NUM_CLIENTS`=8, 4GB graph is produced). Notice that each sequence of the two commands has a big (unseen) underlying graph going to the bottom, that is, `.step` in the `tf.Keras.Module` class!\n",
    "\n",
    "3. Even if we had endless RAM the usage of `tf.function` is still arguable. For instance, on testing for 16 clients the difference between the two is only 20-30ms with total execution time in the order of 200-250ms. Only if we had a huge amount of CPUs or GPU we could consider it, but still... there must be a better approach (`Dask` or a different implementation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b5e970d-f8f0-4870-80ad-f56c8d49fced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clients_train_naive(w_t0, client_cnns, federated_dataset):\n",
    "    \"\"\"\n",
    "    :param w_t0: Vector Tensor shape=(d,). Same shape with `client_cnns[i].trainable_vars_as_vector()`\n",
    "    :return: List of `Tensor shape=() dtype=tf.float32`, one for each `client_cnn` in `client_cnns`.\n",
    "    \"\"\"\n",
    "    \n",
    "    S_i_clients = []\n",
    "\n",
    "    for client_cnn, client_dataset in zip(client_cnns, federated_dataset):\n",
    "        Delta_i_euc_norm_squared = client_train_naive(w_t0, client_cnn, client_dataset)\n",
    "        S_i_clients.append(Delta_i_euc_norm_squared)\n",
    "    \n",
    "    return S_i_clients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bc0988-882c-4c7c-8ab0-27b86363c000",
   "metadata": {},
   "source": [
    "### Identity F Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da9b7c4c-da11-4e04-ba64-b035030a57b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_naive(S_i_clients):\n",
    "    \"\"\" :return: Tensor shape=() dtype=tf.float32 , Naive variance approximation \"\"\"\n",
    "    \n",
    "    S = tf.reduce_mean(S_i_clients)\n",
    "    \n",
    "    return S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d629ed-2522-4b7d-8c8c-2917e55e99ef",
   "metadata": {},
   "source": [
    "## 2️⃣ Linear FDA\n",
    "\n",
    "In the linear case, we reduce the update vector to a scalar, $ \\xi \\Delta_t^{(i)} \\in \\mathbb{R}$, where $ \\xi $ is any unit vector.\n",
    "\n",
    "Define the local state to be \n",
    "\n",
    "$$ S_i(t) = \\begin{bmatrix}\n",
    "           \\lVert \\Delta_t^{(i)} \\rVert_2^2 \\\\\n",
    "           \\xi \\Delta_t^{(i)}\n",
    "         \\end{bmatrix} \\in \\mathbb{R}^2 $$\n",
    "\n",
    "Also, define \n",
    "\n",
    "$$ F(v, x) = v - x^2 $$\n",
    "\n",
    "The RTC is equivalent to condition \n",
    "\n",
    "$$ F(S(t)) \\leq \\Theta $$\n",
    "\n",
    "A random choice of $ \\xi $ is likely to perform poorly (terminate round prematurely), as it wil likely be close to orthogonal to $ \\overline{\\Delta_t} $. A good choice would be a vector $ \\xi $ correlated to $ \\overline{\\Delta_t} $. A heuristic choice is to take $ \\overline{\\Delta_{t_0}} $ (after scaling it to norm 1), i.e., the update vector right before the current round started. All nodes can estimate this without communication, as $ \\overline{w_{t_0}} - \\overline{w_{t_{-1}}} $, the difference of the last two models pushed by the Server. Hence, \n",
    "\n",
    "$$ \\xi = \\frac{\\overline{w_{t_0}} - \\overline{w_{t_{-1}}}}{\\lVert \\overline{w_{t_0}} - \\overline{w_{t_{-1}}} \\rVert_2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f91e0af-9bfd-448d-ab43-20122b7ed1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ksi_unit(w_t0, w_tminus1):\n",
    "    \"\"\"\n",
    "    :param w_t0: Vector Tensor shape=(d,).\n",
    "    :param w_tminus1: Vector Tensor shape=(d,)\n",
    "    :return: `ξ` as defined above.\n",
    "    \"\"\"\n",
    "    if tf.reduce_all(tf.equal(w_t0, w_tminus1)):\n",
    "        # if equal then ksi becomes a random vector (will only happen in round 1)\n",
    "        ksi = tf.random.normal(shape=w_t0.shape)\n",
    "    else:\n",
    "        ksi = w_t0 - w_tminus1\n",
    "\n",
    "    # Normalize and return\n",
    "    return tf.divide(ksi, tf.norm(ksi))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0d324d-8a1b-4ac7-8c55-f8cdaf7c8e7d",
   "metadata": {},
   "source": [
    "### Client Train\n",
    "\n",
    "The number of steps depends on the dataset, i.e., `.take(num)` call on `tf.data.Dataset` creation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a6cfb66-d02e-43a4-93ea-4937434160ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_train_linear(w_t0, w_tminus1, client_cnn, client_dataset):\n",
    "    \"\"\"\n",
    "    :param w_t0: Vector Tensor shape=(d,). Same shape with `client_cnn.trainable_vars_as_vector()`\n",
    "    :param w_tminus1: Vector Tensor shape=(d,). Same shape with `client_cnn.trainable_vars_as_vector()`\n",
    "    :return: tuple ( Tensor shape=() dtype=tf.float32 , Tensor shape=() dtype=tf.float32 )\n",
    "    \"\"\"\n",
    "    \n",
    "    # number of steps depend on `.take()` from `dataset`\n",
    "    client_cnn.train(client_dataset)\n",
    "    \n",
    "    Delta_i = client_cnn.trainable_vars_as_vector() - w_t0\n",
    "    \n",
    "    #||D(t)_i||^2 , shape = () \n",
    "    Delta_i_euc_norm_squared = tf.reduce_sum(tf.square(Delta_i)) # ||D(t)_i||^2\n",
    "    \n",
    "    # heuristic unit vector ksi\n",
    "    ksi = ksi_unit(w_t0, w_tminus1)\n",
    "    \n",
    "    # ksi * Delta_i (* is dot) , shape = ()\n",
    "    ksi_Delta_i = tf.reduce_sum(tf.multiply(ksi, Delta_i))\n",
    "    \n",
    "    return Delta_i_euc_norm_squared, ksi_Delta_i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a12323-99d5-40f4-8aaf-f879dc8c80c3",
   "metadata": {},
   "source": [
    "### Train all Clients\n",
    "\n",
    "Notes about the following potentialy general `tf.function`:\n",
    "\n",
    "1. Even though `clients_cnn` and `federated_dataset` contain `tf.Keras.Module` and `tf.data.Dataset` elements, they both are python lists (python side-effects). Take a look at [Looping Over Python data](https://www.tensorflow.org/guide/function#tracing) and afterwards [For example, the following loop is unrolled, even though the list contains ...](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/control_flow.md#while-statements) to get more insight.\n",
    "\n",
    "2. TL;DR: It is very-very bad in terms of RAM. It produces an unrolled loop. The graph becomes consequent `Delta_i_... = ... ; euc_norm_squared_clients.append(...) ; ksi_delta_clients.append(...) ;` commands `len(client_cnns)` number of times. This produces a huge graph (for instance, for `NUM_CLIENTS`=8, 4GB graph is produced). Notice that each sequence of the two commands has a big (unseen) underlying graph going to the bottom, that is, `.step` in the `tf.Keras.Module` class!\n",
    "\n",
    "3. Even if we had endless RAM the usage of `tf.function` is still arguable. For instance, on testing for 16 clients the difference between the two is only 20-30ms with total execution time in the order of 200-250ms. Only if we had a huge amount of CPUs or GPU we could consider it, but still... there must be a better approach (`Dask` or a different implementation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df371cc4-530c-4a97-bd88-945c110e9b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clients_train_linear(w_t0, w_tminus1, client_cnns, federated_dataset):\n",
    "    \"\"\"\n",
    "    :param w_t0: Vector Tensor shape=(d,). Same shape with `client_cnns[i].trainable_vars_as_vector()`\n",
    "    :param w_tminus1: Vector Tensor shape=(d,). Same shape with `client_cnns[i].trainable_vars_as_vector()`\n",
    "    :return: Two Lists of `Tensor shape=() dtype=tf.float32`, one for each `client_cnn` in `client_cnns`.\n",
    "    \"\"\"\n",
    "    \n",
    "    euc_norm_squared_clients = []\n",
    "    ksi_delta_clients = []\n",
    "    \n",
    "    for client_cnn, client_dataset in zip(client_cnns, federated_dataset):\n",
    "        Delta_i_euc_norm_squared, ksi_Delta_i = client_train_linear(\n",
    "            w_t0, w_tminus1, client_cnn, client_dataset\n",
    "        )\n",
    "\n",
    "        euc_norm_squared_clients.append(Delta_i_euc_norm_squared)\n",
    "        ksi_delta_clients.append(ksi_Delta_i)\n",
    "    \n",
    "    return euc_norm_squared_clients, ksi_delta_clients\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d0ac9b-d6ba-4e87-a6ae-567f4098ccff",
   "metadata": {},
   "source": [
    "### F Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1ef87d3-60b0-44a5-a6e9-6e4e78695bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_linear(euc_norm_squared_clients, ksi_delta_clients):\n",
    "    \"\"\" :return: Tensor shape=() dtype=tf.float32 , Linear variance approximation \"\"\"\n",
    "    \n",
    "    S_1 = tf.reduce_mean(euc_norm_squared_clients)\n",
    "    S_2 = tf.reduce_mean(ksi_delta_clients)\n",
    "    \n",
    "    return S_1 - S_2**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a07ac3a-7fe3-4951-b621-7394ee42f06a",
   "metadata": {},
   "source": [
    "## 3️⃣ Sketch FDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8839471b-cab8-443f-b4c8-19dd9bbe117e",
   "metadata": {},
   "source": [
    "An optimal estimator for $ \\lVert \\overline{\\Delta_t} \\rVert_2^2  $ can be obtained by employing AMS sketches. An AMS sketch of a vector $ v \\in \\mathbb{R}^M $ is a $ d \\times m $ real matrix\n",
    "\n",
    "$$ \\Xi = \\text{sk}(v) = \\begin{bmatrix}\n",
    "           \\Xi_1 \\\\\n",
    "           \\Xi_2 \\\\\n",
    "           \\vdots \\\\\n",
    "           \\Xi_d \n",
    "         \\end{bmatrix} $$\n",
    "         \n",
    "where $ d \\cdot m \\ll M$. Operator sk($ \\cdot $) is linear, i.e., let $a, b \\in \\mathbb{R}$ and $v_1, v_2 \\in \\mathbb{R}^N$ then \n",
    "\n",
    "$$ \\text{sk}(a v_1 + b v_2) = a \\; \\text{sk}(v_1) + b \\; \\text{sk}(v_2)  $$\n",
    "\n",
    "Also, sk($ v $) can be computed in $ \\mathcal{O}(dN) $ steps.\n",
    "\n",
    "The interesting property of AMS sketches is that the function \n",
    "\n",
    "$$ M(sk(\\textbf{v})) = \\underset{i=1,...,d}{\\text{median}} \\; \\lVert \\boldsymbol{\\Xi}_i \\rVert_2^2  $$ \n",
    "\n",
    "is an excellent estimator of the Euclidean norm of **v** (within relative $\\epsilon$-error):\n",
    "\n",
    "$$ M(sk(\\textbf{v})) \\; \\in (1 \\pm \\epsilon) \\lVert \\textbf{v} \\rVert_2^2 \\; \\; \\text{with probability at least} \\; (1-\\delta) $$\n",
    "\n",
    "where $m = \\mathcal{O}(\\frac{1}{\\epsilon^2})$ and $d = \\mathcal{O}(\\log \\frac{1}{\\delta})$\n",
    "\n",
    "Let's investigate a little further on how this helps us. The $i$-th client computes $ sk(\\Delta_t^{(i)}) $ and sends it to the server. Notice\n",
    "\n",
    "$$ M\\big(sk(\\Delta_t^{(1)}) + sk(\\Delta_t^{(2)}) + ... + sk(\\Delta_t^{(k)}) \\big) = M\\Big( \\text{sk}\\big( \\sum_{i=1}^{k} \\Delta_t^{(i)} \\big) \\Big)$$\n",
    "\n",
    "Remember that\n",
    "\n",
    "$$ \\overline{\\boldsymbol{\\Delta}}_t = \\frac{1}{k} \\sum_{i=1}^{k} \\boldsymbol{\\Delta}_t^{(i)} $$\n",
    "\n",
    "Then\n",
    "            \n",
    "$$ M\\Big( \\text{sk}\\big( \\overline{\\boldsymbol{\\Delta}}_t \\big) \\Big) = M\\Big( \\text{sk}\\big( \\frac{1}{k} \\sum_{i=1}^{k} \\boldsymbol{\\Delta}_t^{(i)} \\big) \\Big) =  M\\Big( \\frac{1}{k} \\text{sk}\\big( \\sum_{i=1}^{k} \\boldsymbol{\\Delta}_t^{(i)} \\big) \\Big) $$\n",
    "\n",
    "\n",
    "Which means that \n",
    "\n",
    "$$ M\\Big( \\frac{1}{k} \\text{sk}\\big( \\sum_{i=1}^{k} \\boldsymbol{\\Delta}_t^{(i)} \\big) \\Big) \\in (1 \\pm \\epsilon) \\lVert \\overline{\\boldsymbol{\\Delta}}_t \\rVert_2^2 \\; \\; \\text{w.p. at least} \\; (1-\\delta) $$\n",
    "\n",
    "In the monitoring process it is essential that we do not overestimate $ \\lVert \\overline{\\Delta_t} \\rVert_2^2 $ because we would then underestimate the variance which would potentially result in actual varience exceeding $ \\Theta$ without us noticing it. With this in mind,\n",
    "\n",
    "$$ M\\Big( \\frac{1}{k} \\text{sk}\\big( \\sum_{i=1}^{k} \\boldsymbol{\\Delta}_t^{(i)} \\big) \\Big) \\leq (1+\\epsilon) \\lVert \\overline{\\Delta_t} \\rVert_2^2 \\quad \\text{with probability at least} \\; (1-\\delta)$$\n",
    "\n",
    "Which means\n",
    "\n",
    "$$ \\frac{1}{(1+\\epsilon)} M\\Big( \\frac{1}{k} \\text{sk}\\big( \\sum_{i=1}^{k} \\boldsymbol{\\Delta}_t^{(i)} \\big) \\Big) \\leq \\lVert \\overline{\\Delta_t} \\rVert_2^2 \\quad \\text{with probability at least} \\; (1-\\delta)$$\n",
    "\n",
    "Hence, the Server's estimation of $ \\lVert \\overline{\\Delta_t} \\rVert_2^2 $ is\n",
    "\n",
    "$$ \\frac{1}{(1+\\epsilon)} M\\Big( \\frac{1}{k} \\text{sk}\\big( \\sum_{i=1}^{k} \\boldsymbol{\\Delta}_t^{(i)} \\big) \\Big) $$\n",
    "\n",
    "Define the local state to be \n",
    "\n",
    "$$ S_i(t) = \\begin{bmatrix}\n",
    "           \\lVert \\Delta_t^{(i)} \\rVert_2^2 \\\\\n",
    "           sk(\\Delta_t^{(i)})\n",
    "         \\end{bmatrix} \\in \\mathbb{R}^{1+d \\times m} \\quad \\text{and} \\quad\n",
    "         F(\\begin{bmatrix}\n",
    "           v \\\\\n",
    "           \\Xi\n",
    "         \\end{bmatrix}) = v - \\frac{1}{(1+\\epsilon)}  M(\\Xi) \\quad \\text{where} \\quad \\Xi = \\frac{1}{k} \\sum_{i=1}^{k} sk(\\Delta_t^{(i)}) $$\n",
    "\n",
    "It follows that $ F(S(t)) \\leq \\Theta $ implies that the variance is less or equal to $ \\Theta $ with probability at least $ 1-\\delta $.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310803d6-7520-44c7-b3d1-ad5b92b82b6a",
   "metadata": {},
   "source": [
    "## AMS sketch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f351f2-1583-42e0-a788-235de316b958",
   "metadata": {},
   "source": [
    "We use `ExtensionType` which is the way to go in order to avoid unecessary graph retracing when passing around `AmsSketch` type 'objects'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f52e8196-fd98-4db6-85c2-0c5c07decf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.experimental import ExtensionType\n",
    "\n",
    "class AmsSketch(ExtensionType):\n",
    "    depth: int\n",
    "    width: int\n",
    "    F: tf.Tensor\n",
    "        \n",
    "        \n",
    "    def __init__(self, depth=7, width=1500):\n",
    "        self.depth = depth\n",
    "        self.width = width\n",
    "        self.F = tf.random.uniform(shape=(6, depth), minval=0, maxval=(1 << 31) - 1, dtype=tf.int32)\n",
    "\n",
    "        \n",
    "    def hash31(self, x, a, b):\n",
    "\n",
    "        r = a * x + b\n",
    "        fold = tf.bitwise.bitwise_xor(tf.bitwise.right_shift(r, 31), r)\n",
    "        return tf.bitwise.bitwise_and(fold, 2147483647)\n",
    "    \n",
    "    \n",
    "    def tensor_hash31(self, x, a, b): # GOOD\n",
    "        \"\"\" Assumed that x is tensor shaped (d,) , i.e., a vector (for example, indices, i.e., tf.range(d)) \"\"\"\n",
    "\n",
    "        # Reshape x to have an extra dimension, resulting in a shape of (k, 1)\n",
    "        x_reshaped = tf.expand_dims(x, axis=-1)\n",
    "\n",
    "        # shape=(`v_dim`, 7)\n",
    "        r = tf.multiply(a, x_reshaped) + b\n",
    "\n",
    "        fold = tf.bitwise.bitwise_xor(tf.bitwise.right_shift(r, 31), r)\n",
    "        \n",
    "        return tf.bitwise.bitwise_and(fold, 2147483647)\n",
    "    \n",
    "    \n",
    "    def tensor_fourwise(self, x):\n",
    "        \"\"\" Assumed that x is tensor shaped (d,) , i.e., a vector (for example, indices, i.e., tf.range(d)) \"\"\"\n",
    "        # 1st use the tensor hash31\n",
    "        in1 = self.tensor_hash31(x, self.F[2], self.F[3])  # shape = (`x_dim`,  `self.depth`)\n",
    "        \n",
    "        # 2st use the tensor hash31\n",
    "        in2 = self.tensor_hash31(x, in1, self.F[4])  # shape = (`x_dim`,  `self.depth`)\n",
    "        \n",
    "        # 3rd use the tensor hash31\n",
    "        in3 = self.tensor_hash31(x, in2, self.F[5])  # shape = (`x_dim`,  `self.depth`)\n",
    "        \n",
    "        in4 = tf.bitwise.bitwise_and(in3, 32768)  # shape = (`x_dim`,  `self.depth`)\n",
    "        \n",
    "        return 2 * (tf.bitwise.right_shift(in4, 15)) - 1  # shape = (`x_dim`,  `self.depth`)\n",
    "        \n",
    "        \n",
    "    def fourwise(self, x):\n",
    "\n",
    "        result = 2 * (tf.bitwise.right_shift(tf.bitwise.bitwise_and(self.hash31(self.hash31(self.hash31(x, self.F[2], self.F[3]), x, self.F[4]), x, self.F[5]), 32768), 15)) - 1\n",
    "        return result\n",
    "    \n",
    "\n",
    "    @tf.function\n",
    "    def sketch_for_vector(self, v):\n",
    "        \"\"\" Extremely efficient computation of sketch with only using tensors. \"\"\"\n",
    "        \n",
    "        print(\"retracing `sketch_for_vector`\")\n",
    "        \n",
    "        sketch = tf.zeros(shape=(self.depth, self.width), dtype=tf.float32)\n",
    "        \n",
    "        len_v = v.shape[0]\n",
    "        \n",
    "        pos_tensor = self.tensor_hash31(tf.range(len_v), self.F[0], self.F[1]) % self.width\n",
    "        \n",
    "        v_expand = tf.expand_dims(v, axis=-1)\n",
    "        \n",
    "        deltas_tensor = tf.multiply(tf.cast(self.tensor_fourwise(tf.range(len_v)), dtype=tf.float32), v_expand)\n",
    "        \n",
    "        range_tensor = tf.range(self.depth)\n",
    "        \n",
    "        # Expand dimensions to create a 2D tensor with shape (1, `self.depth`)\n",
    "        range_tensor_expanded = tf.expand_dims(range_tensor, 0)\n",
    "\n",
    "        # Use tf.tile to repeat the range `len_v` times\n",
    "        repeated_range_tensor = tf.tile(range_tensor_expanded, [len_v, 1])\n",
    "        \n",
    "        # shape=(`len_v`, `self.depth`, 2)\n",
    "        indices = tf.stack([repeated_range_tensor, pos_tensor], axis=-1)\n",
    "        \n",
    "        sketch = tf.tensor_scatter_nd_add(sketch, indices, deltas_tensor)\n",
    "        \n",
    "        return sketch\n",
    "    \n",
    "    \n",
    "    def sketch_for_vector2(self, v):\n",
    "        \"\"\" Bad implementation for tensorflow. \"\"\"\n",
    "\n",
    "        sketch = tf.zeros(shape=(self.depth, self.width), dtype=tf.float32)\n",
    "\n",
    "        for i in tf.range(tf.shape(v)[0], dtype=tf.int32):\n",
    "            pos = self.hash31(i, self.F[0], self.F[1]) % self.width\n",
    "            delta = tf.cast(self.fourwise(i), dtype=tf.float32) * v[i]\n",
    "            indices_to_update = tf.stack([tf.range(self.depth, dtype=tf.int32), pos], axis=1)\n",
    "            sketch = tf.tensor_scatter_nd_add(sketch, indices_to_update, delta)\n",
    "\n",
    "        return sketch\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    def estimate_euc_norm_squared(sketch):\n",
    "\n",
    "        def _median(v):\n",
    "            \"\"\" Median of tensor `v` with shape=(n,). Note: Suboptimal O(nlogn) but it's ok bcz n = `depth`\"\"\"\n",
    "            length = tf.shape(v)[0]\n",
    "            sorted_v = tf.sort(v)\n",
    "            middle = length // 2\n",
    "\n",
    "            return tf.cond(\n",
    "                tf.equal(length % 2, 0),\n",
    "                lambda: (sorted_v[middle - 1] + sorted_v[middle]) / 2.0,\n",
    "                lambda: sorted_v[middle]\n",
    "            )\n",
    "\n",
    "        return _median(tf.reduce_sum(tf.square(sketch), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89a2099-c7eb-42ac-89f9-cfe6276c8cf6",
   "metadata": {},
   "source": [
    "### Client Train\n",
    "\n",
    "The number of steps depends on the dataset, i.e., `.take(num)` call on `tf.data.Dataset` creation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed39ab84-5dee-43a5-8833-42266497ff17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_train_sketch(w_t0, client_cnn, client_dataset, ams_sketch):\n",
    "    # number of steps depend on `.take()` from `dataset`\n",
    "    client_cnn.train(client_dataset)\n",
    "    \n",
    "    Delta_i = client_cnn.trainable_vars_as_vector() - w_t0\n",
    "    \n",
    "    #||D(t)_i||^2 , shape = () \n",
    "    Delta_i_euc_norm_squared = tf.reduce_sum(tf.square(Delta_i)) # ||D(t)_i||^2 \n",
    "    \n",
    "    # sketch approx\n",
    "    sketch = ams_sketch.sketch_for_vector(Delta_i)\n",
    "    \n",
    "    return Delta_i_euc_norm_squared, sketch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc73770-0eee-421f-946d-e60002b35534",
   "metadata": {},
   "source": [
    "### Train all Clients\n",
    "\n",
    "Notes about the following potentialy general `tf.function`:\n",
    "\n",
    "1. Even though `clients_cnn` and `federated_dataset` contain `tf.Keras.Module` and `tf.data.Dataset` elements, they both are python lists (python side-effects). Take a look at [Looping Over Python data](https://www.tensorflow.org/guide/function#tracing) and afterwards [For example, the following loop is unrolled, even though the list contains ...](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/control_flow.md#while-statements) to get more insight.\n",
    "\n",
    "2. TL;DR: It is very-very bad in terms of RAM. It produces an unrolled loop. The graph becomes consequent `Delta_i_... = ... ; euc_norm_squared_clients.append(...) ; sketch_clients.append(...) ;` commands `len(client_cnns)` number of times. This produces a huge graph (for instance, for `NUM_CLIENTS`=8, 4GB graph is produced). Notice that each sequence of the two commands has a big (unseen) underlying graph going to the bottom, that is, `.step` in the `tf.Keras.Module` class!\n",
    "\n",
    "3. Even if we had endless RAM the usage of `tf.function` is still arguable. For instance, on testing for 16 clients the difference between the two is only 20-30ms with total execution time in the order of 200-250ms. Only if we had a huge amount of CPUs or GPU we could consider it, but still... there must be a better approach (`Dask` or a different implementation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e80815b8-a83e-42df-a728-dbbcde77b370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clients_train_sketch(w_t0, client_cnns, federated_dataset, ams_sketch):\n",
    "    \"\"\"\n",
    "    :param w_t0: Vector Tensor shape=(d,). Same shape with `client_cnns[i].trainable_vars_as_vector()`\n",
    "    :param ams_sketch: Instance of `AmsSketch` which is an extension type (no retrace) for Count-Min sketch approx.\n",
    "    :return: (euc_norm_squared_clients, sketch_clients) - A list of Tensor shape=() dtype=float32 and a list of sketches\n",
    "        with shape=(ams_sketch.depth, ams_sketch.width) each one corresponds to one client.\n",
    "    \"\"\"\n",
    "    \n",
    "    euc_norm_squared_clients = []\n",
    "    sketch_clients = []\n",
    "\n",
    "    # client steps (number depends on `federated_dataset`, i.e., `.take(num)`)\n",
    "    for client_cnn, client_dataset in zip(client_cnns, federated_dataset):\n",
    "        Delta_i_euc_norm_squared, sketch = client_train_sketch(\n",
    "            w_t0, client_cnn, client_dataset, ams_sketch\n",
    "        )\n",
    "\n",
    "        euc_norm_squared_clients.append(Delta_i_euc_norm_squared)\n",
    "        sketch_clients.append(sketch)\n",
    "        \n",
    "    return euc_norm_squared_clients, sketch_clients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e51698-cb10-4c7a-a8a9-20d3984d36b0",
   "metadata": {},
   "source": [
    "### F Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "56a767c4-595b-4adb-866b-de3d8589f8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_sketch(euc_norm_squared_clients, sketch_clients, epsilon):\n",
    "    \n",
    "    S_1 = tf.reduce_mean(euc_norm_squared_clients)\n",
    "    S_2 = tf.reduce_mean(sketch_clients, axis=0)  # shape=(`depth`, width`). See `Ξ` in theoretical analysis\n",
    "    \n",
    "    # See theoretical analysis above\n",
    "    return S_1 - (1. / (1. + epsilon)) * AmsSketch.estimate_euc_norm_squared(S_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b92a43b-19d3-4081-9528-3af316d640c2",
   "metadata": {},
   "source": [
    "### Metrics (early)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc208c0b-d999-4c2a-ba85-89ad51900366",
   "metadata": {},
   "source": [
    "Due to memory concerns our Metrics will consist of `namedtuple` containers which are very memory efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cb26382e-e7d1-425a-b289-50627b618575",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e0fd2ded-ccbe-4efa-8781-f8386cd18efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "RoundMetrics = namedtuple(\"RoundMetrics\", [\"epoch\", \"round\", \"total_fda_steps\", \"est_var\", \"actual_var\"])\n",
    "EpochMetrics = namedtuple(\"EpochMetrics\", [\"epoch\", \"total_rounds\", \"total_fda_steps\", \"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210307c8-a466-4211-a80d-08811139c560",
   "metadata": {},
   "source": [
    "A few notes about metrics:\n",
    "\n",
    "1. We consider the synchronization before starting training as one round, no metrics are stored we just initialize `total_rounds` to one.\n",
    "\n",
    "2. We consider the first Epoch to be indexed with one (not zero).\n",
    "\n",
    "3. `EpochMetrics` for some `epoch` correspond to final metrics of that specific epoch, that is, we store these metrics when the epoch changes to the next.\n",
    "\n",
    "4. `RoundMetrics` for some `round` (we have many such entries in one round) correspond to metrics for that specific round.\n",
    "\n",
    "5. The last round will (probably) be prematurely ended by `break` because the final Epoch ended. We store this count this round as legal without taking this premature behaviour into account. We leave\n",
    "    it for the data analysis later to deal with it. The reason why we do not catch this case is simple: Consider a case where a round takes longer than a single Epoch and reaches `break`... We would lose\n",
    "    too much information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e64dd3-40c9-4bfd-8453-b47f02b3edfb",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b2faacbc-e291-4748-a288-90c494887999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def federated_simulation(fda_name, server_cnn, client_cnns, federated_dataset, num_epochs, theta, \n",
    "                         fda_steps_in_one_epoch, ams_sketch=None, epsilon=None):\n",
    "    \"\"\" Run a federated learning simulation of one of the FDA methods. We keep general and time-series like metrics. \"\"\"\n",
    "    \n",
    "    # ---- Inits -----\n",
    "    tmp_fda_steps = 0  # helper variable to monitor when Epochs pass using `fda_steps_in_one_epoch`\n",
    "    epoch_count = 1\n",
    "    total_rounds = 1\n",
    "    total_fda_steps = 0\n",
    "    est_var = 0\n",
    "    \n",
    "    # ----- Sync ----- TODO: Count or not first sync?\n",
    "    server_cnn.set_trainable_variables(average_client_weights(client_cnns))\n",
    "    synchronize_clients(server_cnn, client_cnns)\n",
    "    w_t0 = server_cnn.trainable_vars_as_vector()\n",
    "    if fda_name == \"linear\": w_tminus1 = w_t0\n",
    "    \n",
    "    # ----- Metrics -----\n",
    "    round_metrics_list = []\n",
    "    epoch_metrics_list = []\n",
    "    \n",
    "    while epoch_count <= num_epochs:\n",
    "        \n",
    "        # We consider a `round` to be all the training until this while loop finishes and synchronization must occur\n",
    "        while est_var <= theta:\n",
    "            \n",
    "            if fda_name == \"naive\":\n",
    "                # train clients, each on some number of batches which depends on `.take` creation of dataset (Default=1)\n",
    "                Delta_i_euc_norm_squared = clients_train_naive(w_t0, client_cnns, federated_dataset)\n",
    "                \n",
    "                # Naive estimation of variance\n",
    "                est_var = F_naive(Delta_i_euc_norm_squared).numpy()\n",
    "                \n",
    "            if fda_name == \"linear\":\n",
    "                # train clients, each on some number of batches which depends on `.take` creation of dataset (Default=1)\n",
    "                euc_norm_squared_clients, ksi_delta_clients = clients_train_linear(w_t0, w_tminus1, client_cnns, federated_dataset)\n",
    "                \n",
    "                # Linear estimation of variance\n",
    "                est_var = F_linear(euc_norm_squared_clients, ksi_delta_clients).numpy()\n",
    "                \n",
    "            if fda_name == \"sketch\":\n",
    "                # train clients, each on some number of batches which depends on `.take` creation of dataset (Default=1)\n",
    "                euc_norm_squared_clients, sketch_clients = clients_train_sketch(w_t0, client_cnns, federated_dataset, ams_sketch)\n",
    "                \n",
    "                # Sketch estimation of variance\n",
    "                est_var = F_sketch(euc_norm_squared_clients, sketch_clients, epsilon).numpy()\n",
    "            \n",
    "            tmp_fda_steps += 1\n",
    "            total_fda_steps += 1\n",
    "            \n",
    "            # If Epoch has passed in this fda step\n",
    "            if tmp_fda_steps >= fda_steps_in_one_epoch:\n",
    "                \n",
    "                # Minus here and not `tmp_fda_steps = 0` because `fda_steps_in_one_epoch` is not an integer necessarily\n",
    "                # and we need to keep track of potentially more data seen in this fda step (many clients, large batch sizes)\n",
    "                tmp_fda_steps -= fda_steps_in_one_epoch\n",
    "                \n",
    "                # ---------- Metrics ------------\n",
    "                acc = current_accuracy_advanced_cnn(client_cnns)\n",
    "                epoch_metrics = EpochMetrics(epoch_count, total_rounds, total_fda_steps, acc)\n",
    "                epoch_metrics_list.append(epoch_metrics)\n",
    "                print(epoch_metrics) # remove\n",
    "                # -------------------------------\n",
    "                \n",
    "                epoch_count += 1\n",
    "                \n",
    "                if epoch_count > num_epochs: break\n",
    "        \n",
    "        # Round finished\n",
    "\n",
    "        # server average\n",
    "        server_cnn.set_trainable_variables(average_client_weights(client_cnns))\n",
    "\n",
    "        # ------------------------- Metrics --------------------------------\n",
    "        actual_var = variance(server_cnn, client_cnns).numpy()\n",
    "        round_metrics = RoundMetrics(epoch_count, total_rounds, total_fda_steps, est_var, actual_var)\n",
    "        round_metrics_list.append(round_metrics)\n",
    "        #print(round_metrics) # remove\n",
    "        # ------------------------------------------------------------------\n",
    "\n",
    "        if fda_name == \"linear\": w_tminus1 = w_t0\n",
    "        w_t0 = server_cnn.trainable_vars_as_vector()\n",
    "\n",
    "        # clients sync\n",
    "        synchronize_clients(server_cnn, client_cnns)\n",
    "        est_var = 0\n",
    "\n",
    "        total_rounds += 1\n",
    "        \n",
    "    \n",
    "    return epoch_metrics_list, round_metrics_list\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30159ba5-2b67-46d0-b176-f94932b32e61",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    "We have two types of Metrics:\n",
    "\n",
    "1. `EpochMetrics`: General metrics kept each Epoch (`total_rounds`, ..., `est_var`, etc.).\n",
    "\n",
    "2. `RoundMetrics`: Time-series type of Metrics stored in each round. This data are expected to be large in size even for small amount of tests.\n",
    "\n",
    "We need to somehow ID every entry of both of these type of metrics since they will be combined with different tests (ex. different number of clients etc.). So, we do the logical which is pass the `TestId` as defined by the distinct combination of parameters. As explained before we choose `namedtuple` for memory efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c327cd97-de74-4425-b547-314f60eab85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TestId = namedtuple(\n",
    "        'TestId',\n",
    "        [\"dataset_name\", \"fda_name\", \"num_clients\", \"batch_size\", \"num_steps_until_rtc_check\",\n",
    "         \"theta\", \"nn_num_weights\", \"sketch_width\", \"sketch_depth\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3ad59e7e-eb28-4d79-ba9e-686536678bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "EpochMetricsWithId = namedtuple('EpochMetricsWithId', TestId._fields + EpochMetrics._fields)\n",
    "RoundMetricsWithId = namedtuple('RoundMetricsWithId', TestId._fields + RoundMetrics._fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ddf63f-9968-4f97-9dd8-80b152db2b82",
   "metadata": {},
   "source": [
    "Function that takes as input an instance of `TestId` and the two metrics lists that come from a single test (one FDA synchronization) and return the two lists back ready to be used as `.extend` in the general metrics lists for all the tests (properly ID'd)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b733a0b-d8cc-403c-93fe-9b504c40d49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_metrics_with_test_id(epoch_metrics_list, round_metrics_list, test_id):\n",
    "    \n",
    "    epoch_metrics_with_test_id = [\n",
    "        EpochMetricsWithId(*test_id, *epoch_metrics)\n",
    "        for epoch_metrics in epoch_metrics_list\n",
    "    ]\n",
    "    \n",
    "    round_metrics_with_test_id = [\n",
    "        RoundMetricsWithId(*test_id, *round_metrics)\n",
    "        for round_metrics in round_metrics_list\n",
    "    ]\n",
    "    \n",
    "    return epoch_metrics_with_test_id, round_metrics_with_test_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00b5729-9811-454e-af9e-3b0b20f9f944",
   "metadata": {},
   "source": [
    "### Testing Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd37c243-6565-4126-af88-bdc4d9e6a166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_federated_simulation(num_clients, batch_size, num_steps_until_rtc_check, seed=None):\n",
    "    \n",
    "    # 1. Helper variable to count Epochs\n",
    "    fda_steps_in_one_epoch = ((n_train / batch_size) / num_clients) / num_steps_until_rtc_check\n",
    "    \n",
    "    # 2. Federated Dataset creation\n",
    "    clients_federated_data = create_federated_data_for_clients(num_clients)\n",
    "    federated_dataset = prepare_federated_data_for_test(clients_federated_data, batch_size, num_steps_until_rtc_check, seed)\n",
    "    \n",
    "    # 3. Models creation\n",
    "    server_cnn = get_compiled_and_built_advanced_cnn()\n",
    "    client_cnns = [get_compiled_and_built_advanced_cnn() for _ in range(num_clients)]\n",
    "    \n",
    "    return server_cnn, client_cnns, federated_dataset, fda_steps_in_one_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caff405-7d37-4d02-af1e-75ce1bcde603",
   "metadata": {},
   "source": [
    "### Print Current test Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "52199ae4-4a60-4eb1-813a-43f16d57480f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_current_test_info(num_clients, batch_size, num_epochs, num_steps_until_rtc_check, theta):\n",
    "    print()\n",
    "    print(f\"------------ Current Test : ------------\")\n",
    "    print(f\"Num Clients : {num_clients}\")\n",
    "    print(f\"Batch size : {batch_size}\")\n",
    "    print(f\"Num Epochs : {num_epochs}\")\n",
    "    print(f\"Number of steps until we check RTC : {num_steps_until_rtc_check}\")\n",
    "    print(f\"Theta : {theta}\")\n",
    "    print(\"-----------------------------------------\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a490850b-388c-42d6-b0f5-91c0b6ecd480",
   "metadata": {},
   "source": [
    "### Basic Test FDA\n",
    "\n",
    "Test *naive*, *linear* and *sketch* methods for fixed parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cf11b692-6fe7-4499-ad4c-38ec047fc965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_test(num_clients, batch_size, num_steps_until_rtc_check, theta, num_epochs, ams_sketch, epsilon):\n",
    "    \n",
    "    complete_epoch_metrics = []\n",
    "    complete_round_metrics = []\n",
    "    \n",
    "    for fda_name in [\"naive\", \"linear\", \"sketch\"]:\n",
    "        \n",
    "        # 1. Preparation\n",
    "        server_cnn, client_cnns, federated_dataset, fda_steps_in_one_epoch = prepare_for_federated_simulation(\n",
    "            num_clients, batch_size, num_steps_until_rtc_check\n",
    "        )\n",
    "\n",
    "        # 2. Simulation\n",
    "        epoch_metrics_list, round_metrics_list = federated_simulation(\n",
    "            fda_name, server_cnn, client_cnns, federated_dataset, num_epochs, theta, fda_steps_in_one_epoch,\n",
    "            ams_sketch if fda_name == \"sketch\" else None, epsilon if fda_name == \"sketch\" else None\n",
    "        )\n",
    "\n",
    "        # 3. Create Test ID\n",
    "        test_id = TestId(\n",
    "            \"EMNIST\", fda_name, num_clients, batch_size, num_steps_until_rtc_check, theta, count_weights(server_cnn),\n",
    "            ams_sketch.width if fda_name == \"sketch\" else -1, ams_sketch.depth if fda_name == \"sketch\" else -1\n",
    "        )\n",
    "        \n",
    "        # 4. Store ID'd Metrics\n",
    "        epoch_metrics_with_test_id_list, round_metrics_with_test_id_list = process_metrics_with_test_id(\n",
    "            epoch_metrics_list, round_metrics_list, test_id\n",
    "        )\n",
    "\n",
    "        complete_epoch_metrics.extend(epoch_metrics_with_test_id_list)\n",
    "        complete_round_metrics.extend(round_metrics_with_test_id_list)\n",
    "    \n",
    "    return complete_epoch_metrics, complete_round_metrics\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a86abe9-45c7-4c25-97ca-f92f7759b950",
   "metadata": {},
   "source": [
    "## All combinations Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bbcd1f2e-78fc-479d-b895-1f1c25257267",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "def run_tests(num_clients_list, batch_size_list, num_steps_until_rtc_check_list, theta_list, num_epochs, sketch_width, sketch_depth):\n",
    "    \n",
    "    ams_sketch = AmsSketch(width=sketch_width, depth=sketch_depth)\n",
    "    epsilon = 1. / sqrt(sketch_width)\n",
    "    \n",
    "    all_epoch_metrics = []\n",
    "    all_round_metrics = []\n",
    "    \n",
    "    for num_clients in num_clients_list:\n",
    "        for batch_size in batch_size_list:\n",
    "            for num_steps_until_rtc_check in num_steps_until_rtc_check_list:\n",
    "                for theta in theta_list:\n",
    "                    print_current_test_info(num_clients, batch_size, num_epochs, num_steps_until_rtc_check, theta)\n",
    "                    \n",
    "                    complete_epoch_metrics, complete_round_metrics = basic_test(\n",
    "                        num_clients, batch_size, num_steps_until_rtc_check, theta, num_epochs, ams_sketch, epsilon\n",
    "                    )\n",
    "                    \n",
    "                    all_epoch_metrics.extend(complete_epoch_metrics)\n",
    "                    all_round_metrics.extend(complete_round_metrics)\n",
    "                    \n",
    "    return all_epoch_metrics, all_round_metrics\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00e0e9c-8e79-4ad1-8ddb-4d5988659876",
   "metadata": {},
   "source": [
    "## Run tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c4a869-28b0-4a89-bc8c-57b5fa4449cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__' and '__file__' not in globals():\n",
    "\n",
    "    epoch_metrics_filename = '../simulation_results/epoch_metrics.parquet'\n",
    "    round_metrics_filename = '../simulation_results/round_metrics.parquet'\n",
    "    \n",
    "    all_epoch_metrics, all_round_metrics = run_tests(\n",
    "        num_clients_list=[10],\n",
    "        batch_size_list=[32],\n",
    "        num_steps_until_rtc_check_list=[1],\n",
    "        theta_list=[1.],\n",
    "        num_epochs=1,\n",
    "        sketch_width=500,\n",
    "        sketch_depth=7\n",
    "    )\n",
    "    \n",
    "    epoch_metrics_df = pd.DataFrame(all_epoch_metrics)\n",
    "    round_metrics_df = pd.DataFrame(all_round_metrics)\n",
    "    \n",
    "    epoch_metrics_df.to_parquet(epoch_metrics_filename)\n",
    "    round_metrics_df.to_parquet(round_metrics_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dask-tf-210] *",
   "language": "python",
   "name": "conda-env-dask-tf-210-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
