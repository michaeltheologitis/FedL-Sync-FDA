{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48030999",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8fbdc6-1e34-4a24-bc2c-3889b431983b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Read from `~/metrics/epoch_metrics/` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa99cded-d478-4585-a418-732835788ab3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files = glob.glob(\"../../metrics/epoch_metrics/*parquet\")\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_parquet(file)\n",
    "    \n",
    "    dataframes.append(df)\n",
    "\n",
    "df = pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae6fd06a-0b6c-4529-914c-64950e27f70f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"per_layer\"] = df['total_rounds'].apply(lambda x: not isinstance(x, int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ddbc7c5-3a74-46de-bf8a-f97cf121e4e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def per_layer_columns(row):\n",
    "    if row['per_layer']:\n",
    "        \n",
    "        tot_rounds = row['total_rounds']\n",
    "        \n",
    "        if isinstance(tot_rounds, str):\n",
    "            return ast.literal_eval(row['total_rounds'])\n",
    "        \n",
    "        elif isinstance(row['total_rounds'], np.ndarray):\n",
    "            return list(row['total_rounds'])\n",
    "            \n",
    "        else:\n",
    "            print(type(row['total_rounds']))\n",
    "            raise Exception(\"WTF\")\n",
    "    \n",
    "    return row['total_rounds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a132e0bf-b180-481d-a6a1-2138fc797f54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['total_rounds'] = df.apply(per_layer_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89ff3dd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df = pd.read_parquet(\"../../metrics/epoch_metrics/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886608af-dbca-4b76-95c2-7eab5a60ad9a",
   "metadata": {},
   "source": [
    "## For Synchronous - \"Centralized\" investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "832338a5-de23-4803-b01d-f968580c931b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_synchronous = df[(df['fda_name'] == 'synchronous') & (df['aggr_scheme'] == 'avg')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1aaface9-d871-47e5-8691-4fba83cf2c16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_synchronous['centralized_batch_size'] = df_synchronous['num_clients'] * df_synchronous['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ad6ef74-2ebf-4c6e-8bc9-04cf2f3c4b54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_synchronous = df_synchronous.sort_values(by=['centralized_batch_size'], ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2b25db-0742-4564-8e1b-bceba468b557",
   "metadata": {},
   "source": [
    "# Hyper-Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e3d30a-0336-48e7-9574-36b974c72254",
   "metadata": {},
   "source": [
    "`bias` `NaN` -> no bias\n",
    "\n",
    "`bias` $ \\in (0, 1)$ -> `bias`% of each client's dataset is biased (from sorted sequence of MNIST) - rest is good\n",
    "\n",
    "`bias` $= -1$ -> MNIST label 0 is sorted, placed at the start, and clients get assigned sequentially from this dataset. Only one label is biased to however many clients can get it assigned to them.\n",
    "\n",
    "`bias` $= -2$ -> MNIST label 8 is sorted, placed at the start, and clients get assigned sequentially from this dataset. Only one label is biased to however many clients can get it assigned to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da2bae88-a838-477f-ade3-2595e66717a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "one_label_bias = {\n",
    "    -1: 0,\n",
    "    -2: 8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "029ac0aa-49b4-4f2d-a4ab-6f7a4d80cdd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aggr = {\n",
    "    'avg': '',\n",
    "    'wavg_drifts': ' wavg'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea45453e-d536-4676-a532-9ee2faccc786",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "per_layer_dict = {\n",
    "    False: '',\n",
    "    True: ' per-layer'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc83ca7e-2d67-4138-825c-2193420208c5",
   "metadata": {},
   "source": [
    "# Helpful new Dataframe metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b67d41-76a9-461e-830f-9dccfecaf678",
   "metadata": {},
   "source": [
    "### Add Helpful model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49a43e33-b746-46ab-be9a-8a63f30a8986",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['model_bytes'] = df['nn_num_weights'] * 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c4b4b2-5b95-4f6e-bae3-389bcc45c14d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Add Helpful FDA method metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ce6b482-c726-49e4-abb7-e9daedf781d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fda_local_state_bytes(row):\n",
    "    if row['fda_name'] == \"naive\":\n",
    "        return 4\n",
    "    if row['fda_name'] == \"linear\":\n",
    "        return 8\n",
    "    if row['fda_name'] == \"sketch\":\n",
    "        return row['sketch_width'] * row['sketch_depth'] * 4 + 4\n",
    "    if row['fda_name'] == \"synchronous\":\n",
    "        return 0\n",
    "    if row['fda_name'] == 'gm':\n",
    "        return 0.125  # one bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bccd467-4482-4d0f-96c1-63625ab33531",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['local_state_bytes'] = df.apply(fda_local_state_bytes, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d63338e-b01f-4a2e-9035-56d4ccb6b5b8",
   "metadata": {},
   "source": [
    "### Add Total Steps\n",
    "\n",
    "total steps (a single fda step might have many normal SGD steps, batch steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62737054-fd40-46fe-ae01-f8774db0db91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['total_steps'] = df['total_fda_steps'] * df['num_steps_until_rtc_check']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae20d8fe-f5b6-463b-9e02-16588b178252",
   "metadata": {},
   "source": [
    "### Add communication metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "863052af-6314-4b55-86a2-163ea46f890d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-14 16:02:52.919727: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-14 16:02:53.217283: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-14 16:02:53.217441: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-14 16:02:53.261081: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-14 16:02:53.377827: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-14 16:02:53.380317: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-14 16:02:54.656012: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from fdavg.models.advanced_cnn import get_compiled_and_built_advanced_cnn\n",
    "from fdavg.models.lenet5 import get_compiled_and_built_lenet\n",
    "\n",
    "adv = get_compiled_and_built_advanced_cnn((None, 28, 28), (28, 28, 1), 10)\n",
    "\n",
    "lenet = get_compiled_and_built_lenet((None, 28, 28), (28, 28, 1), 10)\n",
    "\n",
    "adv_layer_count = [len(v) for v in adv.per_layer_trainable_vars_as_vector()]\n",
    "lenet_layer_count = [len(v) for v in lenet.per_layer_trainable_vars_as_vector()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f37407dc-7b33-465d-a4b3-b1e8ff895014",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[640, 36928, 73856, 147584, 295168, 590080, 1180160, 262656, 5130]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_layer_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bedeeb83-155c-4c65-93b3-159290367740",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[156, 2416, 48120, 10164, 850]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenet_layer_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc1ecda-66bf-4ada-8341-bc44002dd38d",
   "metadata": {},
   "source": [
    "The communication bytes exchanged for model synchronization. Remember that the Clients send their models to the Server and the Server sends the global model back. This happens at the end of every round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ac2eb6a-5878-4173-9901-1f57aec4e95e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Densenet\n",
    "\n",
    "def model_bytes_exchanged(row):\n",
    "    if row['per_layer']:\n",
    "        if row['nn_name'] == 'AdvancedCNN':\n",
    "            return sum((layer_num_weights * 4) * layer_rounds * row['num_clients'] * 2 for layer_num_weights, layer_rounds in zip(adv_layer_count, row['total_rounds']))\n",
    "        if row['nn_name'] == 'LeNet-5':\n",
    "            print(\"lenet?\")\n",
    "            return sum((layer_num_weights * 4) * layer_rounds * row['num_clients'] * 2 for layer_num_weights, layer_rounds in zip(lenet_layer_count, row['total_rounds']))\n",
    "    \n",
    "    return row['total_rounds'] * row['model_bytes'] * row['num_clients'] * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86fe348a-4beb-4805-af41-4408d78a198e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['model_bytes_exchanged'] = df.apply(model_bytes_exchanged, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de008e7-dadd-413a-98ff-1e7d94dbc8bf",
   "metadata": {},
   "source": [
    "The communication bytes exchanged for monitoring the variance. This happens at the end of every FDA step which consists of `num_steps_until_rtc_check` number of steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17eb8709-13b6-4e1b-8caa-d311d01939bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def monitoring_bytes_exchanged(row):\n",
    "    if row['per_layer']:\n",
    "        if row['nn_name'] == 'AdvancedCNN':\n",
    "            return row['local_state_bytes'] * row['total_fda_steps'] * row['num_clients'] * len(adv_layer_count)\n",
    "        if row['nn_name'] == 'LeNet-5':\n",
    "            return row['local_state_bytes'] * row['total_fda_steps'] * row['num_clients'] * len(lenet_layer_count)\n",
    "    \n",
    "    return row['local_state_bytes'] * row['total_fda_steps'] * row['num_clients']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96c0a03c-809e-4b61-b83b-73b6efa32630",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['monitoring_bytes_exchanged'] = df.apply(monitoring_bytes_exchanged, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8aa21e-1040-4794-8780-6e0283ee2d73",
   "metadata": {},
   "source": [
    "The total communication bytes exchanged in the whole Federated Learning lifecycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "84353a52-12cf-416c-9b5a-74b7658ce499",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['total_communication_bytes'] = df['model_bytes_exchanged'] + df['monitoring_bytes_exchanged']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b48e615-187c-48aa-9bbb-928e248b1040",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['total_communication_gb'] = df['total_communication_bytes'] / 10**9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9773a738-5cbd-4d87-9a7a-004fe11d6fb3",
   "metadata": {},
   "source": [
    "# HyperParameter ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42646af0-06ce-4d80-a803-9a04bbd42bb4",
   "metadata": {},
   "source": [
    "### LeNet-5 - MNIST\n",
    "On `Nvidia A10`:\n",
    "1. Batch Size = 32 -> 6.613 ms ± 0.128 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "2. *Batch Size* = 64 -> 7.509 ms ± 0.065 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "3. *Batch Size* = 128 -> 8.02 ms ± 0.099 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "4. *Batch Size* = 256 -> 9.258 ms ± 0.336 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac905fcd-cbe7-4ce6-9826-ef0f4696c14c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### AdvancedCNN - MNIST\n",
    "\n",
    "On `Nvidia A10`:\n",
    "1. *Batch Size* = 32 -> 8.853 ms ± 0.0917 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "2. *Batch Size* = 64 -> 10.325 ms ± 0.215 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "3. *Batch Size* = 128 -> 11.989 ms ± 0.134 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "4. *Batch Size* = 256 -> 16.47 ms ± 0.294 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd26782b-a565-45d7-8889-24573f7b6d95",
   "metadata": {},
   "source": [
    "### DenseNet121 - CIFAR10\n",
    "\n",
    "On `Nvidia A10`:\n",
    "1. *Batch Size* = 32 -> 8.853 ms ± 0.0917 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "2. *Batch Size* = 64 -> 10.325 ms ± 0.215 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "3. *Batch Size* = 128 -> 11.989 ms ± 0.134 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "4. *Batch Size* = 256 -> 16.47 ms ± 0.294 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83fdf5fb-18ff-4b12-ada8-5129cc7531d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "step_ms = {\n",
    "    (\"AdvancedCNN\", 32): 8.853,\n",
    "    (\"AdvancedCNN\", 64): 10.325,\n",
    "    (\"AdvancedCNN\", 128): 11.989,\n",
    "    (\"AdvancedCNN\", 256): 16.47,\n",
    "    (\"LeNet-5\", 32): 6.613,\n",
    "    (\"LeNet-5\", 64): 7.509,\n",
    "    (\"LeNet-5\", 128): 8.02,\n",
    "    (\"LeNet-5\", 256): 9.258,\n",
    "    (\"DenseNet121\", 32): 87.328,\n",
    "    (\"DenseNet121\", 64): 88.832,\n",
    "    (\"DenseNet121\", 128): 94.208,\n",
    "    (\"DenseNet121\", 256): 96.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "178b5809-8298-4666-8296-8bbec9ccda62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cpu_time_cost(row):\n",
    "    \"\"\" Total cpu time cost in (sec).\n",
    "    A single `step` means each client performed a single `step` \n",
    "    \"\"\"\n",
    "    return row['total_steps'] * step_ms[(row['nn_name'], row['batch_size'])] / 1000\n",
    "\n",
    "def communication_time_cost(num_clients, total_communication_bytes, comm_model):\n",
    "    \"\"\" Assuming channel is 1Gbps \"\"\"\n",
    "\n",
    "    total_communication_gbit = total_communication_bytes * 8e-9\n",
    "\n",
    "    if comm_model == 'common_channel':\n",
    "        \n",
    "        return ((num_clients - 1) / num_clients) * total_communication_gbit    # sec\n",
    "\n",
    "    if comm_model == 'hypercube':\n",
    "\n",
    "        return (np.ceil(np.log(num_clients)) / num_clients) * total_communication_gbit   # sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6892ee25-e1b9-4e98-b5a1-c3669d84cd93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['cpu_time_cost'] = df.apply(cpu_time_cost, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3895090-76c2-46ff-a229-30ee6142e2e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['hypercube_communication_time_cost'] = communication_time_cost(df['num_clients'], df['total_communication_bytes'], 'hypercube')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9666ef46-2574-43e9-b8e6-0c7fca3b75ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['common_channel_communication_time_cost'] = communication_time_cost(df['num_clients'], df['total_communication_bytes'], 'common_channel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8a7c286b-25a0-4eb0-a432-fded4f049071",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['hypercube_time_cost'] = df['cpu_time_cost'] + df['hypercube_communication_time_cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "efe9fa8a-d8d7-4b2a-a3a0-131eec5ce2d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['common_channel_time_cost'] = df['cpu_time_cost'] + df['common_channel_communication_time_cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b9cf2956-4729-48a5-b06c-8cd6953f6ef7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['hypercube_comm_cpu_time_ratio'] = df['hypercube_communication_time_cost'] / df['cpu_time_cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "be90d43a-e051-4445-a183-b68f329f2843",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['common_channel_comm_cpu_time_ratio'] = df['common_channel_communication_time_cost'] / df['cpu_time_cost']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270b7b80-e37e-45f6-badc-14e09ab83d8f",
   "metadata": {},
   "source": [
    "# Plots about cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "78880363-4c40-4799-9672-3218d2ec807a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define styles for each fda_name\n",
    "fda_styles = {\n",
    "    'naive': 'o-r',\n",
    "    'linear': 's-g',\n",
    "    'sketch': '^-b',\n",
    "    'synchronous': 'x-c'\n",
    "}\n",
    "fda_names = ['gm', 'naive', 'linear', 'sketch', 'synchronous']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d4fbe02f-48f4-47f4-937b-79b16e40fa5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "num_clients_values = sorted(df['num_clients'].unique())\n",
    "cmap = matplotlib.colormaps['tab20b']\n",
    "colors_dict = {\n",
    "    num_clients: color \n",
    "    for num_clients, color in zip(num_clients_values, cmap(np.linspace(0, 1, len(num_clients_values))))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6b795b-a73d-4e94-b9e4-07df61d1f0fd",
   "metadata": {},
   "source": [
    "## KDE Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f277d83f-7869-46ef-a4d6-0129553318da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "sns_params = {\n",
    "    'bw_method': 'scott',\n",
    "    'bw_adjust': 0.7,\n",
    "    'fill': True,\n",
    "    'alpha': 0.2\n",
    "}\n",
    "\"\"\"\n",
    "sns_params = {\n",
    "    'bw_method': 'scott',\n",
    "    'bw_adjust': 0.7,\n",
    "    'fill': False,\n",
    "    'alpha': 1\n",
    "}\n",
    "\n",
    "sns_params_biases = {\n",
    "    'bw_method': 'scott',\n",
    "    'bw_adjust': 0.7,\n",
    "    'fill': False,\n",
    "    'alpha': 0.8\n",
    "}\n",
    "\n",
    "base_colors = {\n",
    "    'gm': 'blue',\n",
    "    'naive': 'orange',\n",
    "    'linear': 'green',\n",
    "    'sketch': 'red',\n",
    "    'synchronous': 'purple',\n",
    "    'sketch wavg': 'black'\n",
    "}\n",
    "\n",
    "base_colors_per_layer = {\n",
    "    'gm': 'blue',\n",
    "    'naive': 'orange',\n",
    "    'linear': 'green',\n",
    "    'sketch': 'red',\n",
    "    'synchronous': 'purple',\n",
    "    'naive per-layer': 'black'\n",
    "}\n",
    "\n",
    "sync_colors = {\n",
    "    32: 'rebeccapurple',\n",
    "    64: 'darkorchid',\n",
    "    128: 'mediumorchid',\n",
    "    256: 'plum'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5a8b81fe-0fc4-4501-88a2-77cca9f24229",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['font.size'] = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ad541a-b538-4598-bc75-fb3e94362216",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Total time cost with accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fd1665-4e4b-4a86-a092-f11f7c695f8c",
   "metadata": {},
   "source": [
    "### KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cfb48896-af2d-4b62-bd6a-24a46f2eb240",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def kde_time_cost(df, filename, x_log=True):\n",
    "    \n",
    "    if x_log:\n",
    "        log_scale = (True, False)\n",
    "    else:\n",
    "        log_scale = False\n",
    "        \n",
    "    plt.rcParams['font.size'] = 20\n",
    "    plt.rcParams['legend.fontsize'] = 12\n",
    "    \n",
    "    pdf = PdfPages(filename)\n",
    "    \n",
    "    biases = sorted(df['bias'].unique(), reverse=True)[::-1]\n",
    "    \n",
    "    per_layers = [False, True]\n",
    "\n",
    "    for bias in biases:\n",
    "        \n",
    "        if pd.isna(bias):\n",
    "            mask = df['bias'].isna()\n",
    "            bias_title = f'Bias: {bias}'\n",
    "        elif bias > 0:\n",
    "            mask = df['bias'] == bias\n",
    "            bias_title = f'Bias: {bias}'\n",
    "        else:\n",
    "            mask = df['bias'] == bias\n",
    "            bias_title = f'Bias: only label {one_label_bias[bias]}'\n",
    "            \n",
    "        df_bias = df[mask]\n",
    "        \n",
    "        if len(df_bias['fda_name'].unique()) < 2:\n",
    "            continue\n",
    "    \n",
    "        fig, axs = plt.subplots(1, 2, figsize=(20, 8))\n",
    "        \n",
    "        for per_layer in per_layers:\n",
    "                    \n",
    "            per_layer_df = df_bias[df_bias['per_layer'] == per_layer]\n",
    "        \n",
    "            for fda_name in fda_names:\n",
    "                \n",
    "                name = f\"{fda_name}{per_layer_dict[per_layer]}\"\n",
    "                \n",
    "                fda_df = per_layer_df[per_layer_df['fda_name'] == fda_name]\n",
    "                \n",
    "                if fda_df.empty:\n",
    "                    continue\n",
    "\n",
    "                common_channel_df = fda_df['common_channel_time_cost']\n",
    "                sns.kdeplot(common_channel_df, label=name, ax=axs[0], color=base_colors_per_layer[name], log_scale=log_scale, **sns_params)\n",
    "\n",
    "                hypercube_df = fda_df['hypercube_time_cost']\n",
    "                sns.kdeplot(hypercube_df, label=name, ax=axs[1], color=base_colors_per_layer[name], log_scale=log_scale, **sns_params)\n",
    "\n",
    "\n",
    "        if not x_log:\n",
    "            axs[0].set_xlim(left=0)\n",
    "        axs[0].set_xlabel('Time Cost (sec)')\n",
    "        axs[0].set_ylabel('Density')\n",
    "        axs[0].legend()\n",
    "        axs[0].set_title(\"Common Channel Communication Model\")\n",
    "        axs[0].grid(True, linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "        axs[0].legend()\n",
    "\n",
    "        if not x_log:\n",
    "            axs[1].set_xlim(left=0)\n",
    "\n",
    "        axs[1].set_xlabel('Time Cost (sec)')\n",
    "        axs[1].set_ylabel('Density')\n",
    "        axs[1].legend()\n",
    "        axs[1].set_title(\"Hypercube Communication Model\")\n",
    "        axs[1].grid(True, linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "        axs[1].legend()\n",
    "        \n",
    "        fda_df = df_bias[df_bias['fda_name'] != 'synchronous']\n",
    "        sync_df = df_bias[df_bias['fda_name'] == 'synchronous']\n",
    "        info = f\"gm, naive, linear, sketch - bs : {fda_df['batch_size'].unique()}  ,  synchronous - bs: {sync_df['batch_size'].unique()}\\n\"\n",
    "        fig.suptitle(info+bias_title)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "\n",
    "        pdf.savefig(fig)\n",
    "\n",
    "        plt.close(fig)\n",
    "    \n",
    "        \n",
    "    pdf.close()\n",
    "    \n",
    "    plt.rcParams['font.size'] = 14\n",
    "    plt.rcParams['legend.fontsize'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2320ef3-66a1-4397-9b3f-6fd0c13ea5d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Total Communication cost (in gb) with accuracy (scatter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df3f1eb-20a7-4d2a-ba60-cc36708ca42a",
   "metadata": {},
   "source": [
    "### KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "83fca381-1fc0-4f35-9115-cd6effb3129f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def kde_communication_cost(df, filename, x_log=True):\n",
    "\n",
    "    if x_log:\n",
    "        log_scale = (True, False)\n",
    "    else:\n",
    "        log_scale = False\n",
    "        \n",
    "    pdf = PdfPages(filename)\n",
    "    \n",
    "    biases = sorted(df['bias'].unique(), reverse=True)[::-1]\n",
    "    \n",
    "    per_layers = [False, True]\n",
    "\n",
    "    for bias in biases:\n",
    "        \n",
    "        if pd.isna(bias):\n",
    "            mask = df['bias'].isna()\n",
    "            bias_title = f'Bias: {bias}'\n",
    "        elif bias > 0:\n",
    "            mask = df['bias'] == bias\n",
    "            bias_title = f'Bias: {bias}'\n",
    "        else:\n",
    "            mask = df['bias'] == bias\n",
    "            bias_title = f'Bias: only label {one_label_bias[bias]}'\n",
    "            \n",
    "        df_bias = df[mask]\n",
    "        \n",
    "        if len(df_bias['fda_name'].unique()) < 2:\n",
    "            continue\n",
    "    \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        avg_info = []\n",
    "        \n",
    "        for per_layer in per_layers:\n",
    "                    \n",
    "            per_layer_df = df_bias[df_bias['per_layer'] == per_layer]\n",
    "        \n",
    "            for fda_name in fda_names:\n",
    "                \n",
    "                name = f\"{fda_name}{per_layer_dict[per_layer]}\"\n",
    "                \n",
    "                fda_df = per_layer_df[per_layer_df['fda_name'] == fda_name]\n",
    "                \n",
    "                if fda_df.empty:\n",
    "                    continue\n",
    "\n",
    "                fda_data_df = fda_df['total_communication_gb']\n",
    "\n",
    "                avg_info.append(f'{name}: {fda_data_df.mean():.2f} GB')\n",
    "\n",
    "                # Plotting only the KDE using kdeplot\n",
    "                sns.kdeplot(fda_data_df, label=name, log_scale=log_scale, color=base_colors_per_layer[name], **sns_params)\n",
    "\n",
    "        text = \"Average Communication:\\n\" + '\\n'.join(avg_info)\n",
    "        # Add the text annotation inside the plot\n",
    "        plt.text(0.02, 0.97, text, transform=plt.gca().transAxes, fontsize=9, verticalalignment='top',\n",
    "                 bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.4))\n",
    "\n",
    "        if not x_log:\n",
    "            plt.xlim(left=0)\n",
    "\n",
    "        plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "        plt.xlabel('Communication (GB)')\n",
    "        plt.ylabel('Density')\n",
    "        #plt.legend()  # We'll be moving this\n",
    "        plt.gca().legend(loc='best', bbox_to_anchor=(0, 0.05, 1, 0.67))\n",
    "        \n",
    "        fda_df = df_bias[df_bias['fda_name'] != 'synchronous']\n",
    "        sync_df = df_bias[df_bias['fda_name'] == 'synchronous']\n",
    "        info = f\"gm, naive, linear, sketch - bs : {fda_df['batch_size'].unique()}  ,  synchronous - bs: {sync_df['batch_size'].unique()}\\n\"\n",
    "        plt.suptitle(info+bias_title)\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        pdf.savefig(plt.gcf()) # Save the current figure\n",
    "\n",
    "        # Close the current figure to prevent it from being displayed in the notebook\n",
    "        plt.close()\n",
    "    pdf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d35fd9-5826-4e5d-83fa-d9522eb7d2b1",
   "metadata": {},
   "source": [
    "## Total CPU time (in Seconds) with accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52af3838-5f3d-4ae6-8070-9ab446bed403",
   "metadata": {},
   "source": [
    "### KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ee28d792-6495-4ab1-a694-9cf2fb1799eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def kde_cpu_time_cost(df, filename, x_log=False):\n",
    "    \n",
    "    if x_log:\n",
    "        log_scale = (True, False)\n",
    "    else:\n",
    "        log_scale = False\n",
    "        \n",
    "    pdf = PdfPages(filename)\n",
    "    \n",
    "    biases = sorted(df['bias'].unique(), reverse=True)[::-1]\n",
    "    \n",
    "    per_layers = [False, True]\n",
    "\n",
    "    for bias in biases:\n",
    "        \n",
    "        if pd.isna(bias):\n",
    "            mask = df['bias'].isna()\n",
    "            bias_title = f'Bias: {bias}'\n",
    "        elif bias > 0:\n",
    "            mask = df['bias'] == bias\n",
    "            bias_title = f'Bias: {bias}'\n",
    "        else:\n",
    "            mask = df['bias'] == bias\n",
    "            bias_title = f'Bias: only label {one_label_bias[bias]}'\n",
    "            \n",
    "        df_bias = df[mask]\n",
    "        \n",
    "        if len(df_bias['fda_name'].unique()) < 2:\n",
    "            continue\n",
    "    \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        for per_layer in per_layers:\n",
    "                    \n",
    "            per_layer_df = df_bias[df_bias['per_layer'] == per_layer]\n",
    "        \n",
    "            for fda_name in fda_names:\n",
    "                \n",
    "                name = f\"{fda_name}{per_layer_dict[per_layer]}\"\n",
    "                \n",
    "                fda_df = per_layer_df[per_layer_df['fda_name'] == fda_name]\n",
    "                \n",
    "                if fda_df.empty:\n",
    "                    continue\n",
    "\n",
    "                fda_data_df = fda_df['cpu_time_cost']\n",
    "\n",
    "                # Plotting only the KDE using kdeplot\n",
    "                sns.kdeplot(fda_data_df, label=name, log_scale=log_scale, color=base_colors_per_layer[name], **sns_params)\n",
    "\n",
    "        if not x_log:\n",
    "            plt.xlim(left=0)\n",
    "        plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "        plt.xlabel('CPU time cost (sec)')\n",
    "        plt.ylabel('Density')\n",
    "        plt.legend()\n",
    "        \n",
    "        fda_df = df_bias[df_bias['fda_name'] != 'synchronous']\n",
    "        sync_df = df_bias[df_bias['fda_name'] == 'synchronous']\n",
    "        info = f\"gm, naive, linear, sketch - bs : {fda_df['batch_size'].unique()}  ,  synchronous - bs: {sync_df['batch_size'].unique()}\\n\"\n",
    "        plt.suptitle(info+bias_title)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "\n",
    "        pdf.savefig(plt.gcf()) # Save the current figure\n",
    "        \n",
    "        # Close the current figure to prevent it from being displayed in the notebook\n",
    "        plt.close()\n",
    "    pdf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ff1f1c-c631-4d65-acc9-7d3e48ccbb2d",
   "metadata": {},
   "source": [
    "## Total CPU cost / Comm Cost (time) - ratio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0b5fafd2-8b6e-41c2-b560-4d3b8d22289e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def kde_comm_cpu_time_cost_ratio(df, filename, x_log=True):\n",
    "    \n",
    "    if x_log:\n",
    "        log_scale = (True, False)\n",
    "    else:\n",
    "        log_scale = False\n",
    "        \n",
    "    plt.rcParams['font.size'] = 20\n",
    "    plt.rcParams['legend.fontsize'] = 12\n",
    "    \n",
    "    pdf = PdfPages(filename)\n",
    "    \n",
    "    biases = sorted(df['bias'].unique(), reverse=True)[::-1]\n",
    "    \n",
    "    per_layers = [False, True]\n",
    "\n",
    "    for bias in biases:\n",
    "        \n",
    "        if pd.isna(bias):\n",
    "            mask = df['bias'].isna()\n",
    "            bias_title = f'Bias: {bias}'\n",
    "        elif bias > 0:\n",
    "            mask = df['bias'] == bias\n",
    "            bias_title = f'Bias: {bias}'\n",
    "        else:\n",
    "            mask = df['bias'] == bias\n",
    "            bias_title = f'Bias: only label {one_label_bias[bias]}'\n",
    "            \n",
    "        df_bias = df[mask]\n",
    "        \n",
    "        if len(df_bias['fda_name'].unique()) < 2:\n",
    "            continue\n",
    "    \n",
    "        fig, axs = plt.subplots(1, 2, figsize=(20, 8))\n",
    "        \n",
    "        for per_layer in per_layers:\n",
    "                    \n",
    "            per_layer_df = df_bias[df_bias['per_layer'] == per_layer]\n",
    "        \n",
    "            for fda_name in fda_names:\n",
    "                \n",
    "                name = f\"{fda_name}{per_layer_dict[per_layer]}\"\n",
    "                \n",
    "                fda_df = per_layer_df[per_layer_df['fda_name'] == fda_name]\n",
    "                \n",
    "                if fda_df.empty:\n",
    "                    continue\n",
    "            \n",
    "                common_channel_ratio_df = fda_df['cpu_time_cost'] / fda_df['common_channel_communication_time_cost']\n",
    "                sns.kdeplot(common_channel_ratio_df, label=name, ax=axs[0], color=base_colors_per_layer[name], log_scale=log_scale, **sns_params)\n",
    "\n",
    "                hypercube_ratio_df = fda_df['cpu_time_cost'] / fda_df['hypercube_communication_time_cost']\n",
    "                sns.kdeplot(hypercube_ratio_df, label=name, ax=axs[1], color=base_colors_per_layer[name], log_scale=log_scale, **sns_params)\n",
    "\n",
    "\n",
    "        if not x_log:\n",
    "            axs[0].set_xlim(left=0)\n",
    "        axs[0].set_xlabel('CPU Time Cost / Comm. Time Cost')\n",
    "        axs[0].set_ylabel('Density')\n",
    "        axs[0].legend()\n",
    "        axs[0].set_title(\"Common Channel Communication Model\")\n",
    "        axs[0].grid(True, linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "        axs[0].legend()\n",
    "\n",
    "        if not x_log:\n",
    "            axs[1].set_xlim(left=0)\n",
    "\n",
    "        axs[1].set_xlabel('CPU Time Cost / Comm. Time Cost')\n",
    "        axs[1].set_ylabel('Density')\n",
    "        axs[1].legend()\n",
    "        axs[1].set_title(\"Hypercube Communication Model\")\n",
    "        axs[1].grid(True, linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "        axs[1].legend()\n",
    "        \n",
    "        fda_df = df_bias[df_bias['fda_name'] != 'synchronous']\n",
    "        sync_df = df_bias[df_bias['fda_name'] == 'synchronous']\n",
    "        info = f\"gm, naive, linear, sketch - bs : {fda_df['batch_size'].unique()}  ,  synchronous - bs: {sync_df['batch_size'].unique()}\\n\"\n",
    "        fig.suptitle(info+bias_title)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "\n",
    "        pdf.savefig(fig)\n",
    "\n",
    "        plt.close(fig)\n",
    "    \n",
    "        \n",
    "    pdf.close()\n",
    "    \n",
    "    plt.rcParams['font.size'] = 14\n",
    "    plt.rcParams['legend.fontsize'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb870a3a-ddbb-4e04-9f51-7745bb4c66b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "365e9052-69dd-4303-bfeb-01e116c05b35",
   "metadata": {},
   "source": [
    "## Keep Hyper-parameters fixed and plot for filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d893dadb-18b0-400d-a36f-60bd92c2970c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fda_methods_clients_time_cost(df, filename):\n",
    "    pdf = PdfPages(filename)\n",
    "    \n",
    "    batch_size_values = sorted(df['batch_size'].unique())\n",
    "    theta_values = sorted(df['theta'].unique())[1:]\n",
    "    \n",
    "    biases = sorted(df['bias'].unique(), reverse=True)[::-1]\n",
    "    \n",
    "    per_layers = [False, True]\n",
    "\n",
    "    for bias in biases:\n",
    "        \n",
    "        if pd.isna(bias):\n",
    "            mask = df['bias'].isna()\n",
    "            bias_title = f'Bias: {bias}'\n",
    "        elif bias > 0:\n",
    "            mask = df['bias'] == bias\n",
    "            bias_title = f'Bias: {bias}'\n",
    "        else:\n",
    "            mask = df['bias'] == bias\n",
    "            bias_title = f'Bias: only label {one_label_bias[bias]}'\n",
    "            \n",
    "        df_bias = df[mask]\n",
    "        \n",
    "        for batch_size in batch_size_values:\n",
    "            for theta in theta_values:\n",
    "\n",
    "                filtered_df = df_bias[(df_bias['theta'] == theta) & (df_bias['batch_size'] == batch_size)] \n",
    "\n",
    "                if filtered_df.empty:\n",
    "                    continue\n",
    "\n",
    "                fig, axs = plt.subplots(1, 2, figsize=(20, 6))\n",
    "                \n",
    "                for per_layer in per_layers:\n",
    "                    \n",
    "                    per_layer_df = filtered_df[filtered_df['per_layer'] == per_layer]\n",
    "\n",
    "                    for fda_name in fda_names:\n",
    "                        \n",
    "                        if fda_name == 'synchronous':\n",
    "                            continue\n",
    "\n",
    "                        name = f\"{fda_name}{per_layer_dict[per_layer]}\"\n",
    "\n",
    "                        fda_data = per_layer_df[per_layer_df['fda_name'] == fda_name]\n",
    "\n",
    "                        if fda_data.empty:\n",
    "                            continue\n",
    "\n",
    "                        axs[0].plot(fda_data['num_clients'], fda_data['common_channel_time_cost'], marker='o', color=base_colors_per_layer[name], label=name, markersize=3)\n",
    "                        axs[1].plot(fda_data['num_clients'], fda_data['hypercube_time_cost'], marker='o', color=base_colors_per_layer[name], label=name, markersize=3)\n",
    "\n",
    "                synchronous_data = df_bias[(df_bias['batch_size'] == batch_size) & (df_bias['fda_name'] == 'synchronous')] \n",
    "\n",
    "                if not synchronous_data.empty:\n",
    "                    axs[0].plot(synchronous_data['num_clients'], synchronous_data['common_channel_time_cost'], marker='o', label='synchronous', color=base_colors['synchronous'], markersize=3)\n",
    "                    axs[1].plot(synchronous_data['num_clients'], synchronous_data['hypercube_time_cost'], marker='o', label='synchronous', color=base_colors['synchronous'], markersize=3)\n",
    "\n",
    "                if not axs[0].has_data():\n",
    "                    plt.close(fig)\n",
    "                    continue\n",
    "\n",
    "                # Set xticks every 5 units based on available values\n",
    "                min_clients = 5\n",
    "                max_clients = 60\n",
    "\n",
    "                x_ticks = list(range(min_clients, max_clients + 1, 5))\n",
    "\n",
    "                axs[0].set_yscale('log')\n",
    "                axs[0].set_xticks(x_ticks)\n",
    "                axs[0].set_xlabel('Number of clients')\n",
    "                axs[0].legend()\n",
    "                axs[0].set_title(\"Common Channel Communication Model\")\n",
    "                axs[0].set_ylabel('Time Cost')\n",
    "                axs[0].grid(True, linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "\n",
    "                axs[1].set_yscale('log')\n",
    "                axs[1].set_xticks(x_ticks)\n",
    "                axs[1].set_xlabel('Number of clients')\n",
    "                axs[1].legend()\n",
    "                axs[1].set_title(\"Hypercube Communication Model\")\n",
    "                axs[1].set_ylabel('Time Cost')\n",
    "                axs[1].grid(True, linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "\n",
    "                title = f'Batch Size : {batch_size} , $\\Theta$ : {theta} , {bias_title}'\n",
    "                fig.suptitle(title)\n",
    "\n",
    "                plt.tight_layout()\n",
    "\n",
    "                pdf.savefig(fig)\n",
    "\n",
    "                plt.close(fig)\n",
    "    pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7dfd80c9-0fcc-4e19-828e-89fe2f9f6152",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fda_methods_clients_comm_cost(df, filename):\n",
    "    pdf = PdfPages(filename)\n",
    "    \n",
    "    batch_size_values = sorted(df['batch_size'].unique())\n",
    "    theta_values = sorted(df['theta'].unique())[1:]\n",
    "    \n",
    "    biases = sorted(df['bias'].unique(), reverse=True)[::-1]\n",
    "    \n",
    "    per_layers = [False, True]\n",
    "\n",
    "    for bias in biases:\n",
    "        \n",
    "        if pd.isna(bias):\n",
    "            mask = df['bias'].isna()\n",
    "            bias_title = f'Bias: {bias}'\n",
    "        elif bias > 0:\n",
    "            mask = df['bias'] == bias\n",
    "            bias_title = f'Bias: {bias}'\n",
    "        else:\n",
    "            mask = df['bias'] == bias\n",
    "            bias_title = f'Bias: only label {one_label_bias[bias]}'\n",
    "            \n",
    "        df_bias = df[mask]\n",
    "        \n",
    "        for batch_size in batch_size_values:\n",
    "            for theta in theta_values:\n",
    "\n",
    "                filtered_df = df_bias[(df_bias['theta'] == theta) & (df_bias['batch_size'] == batch_size)] \n",
    "\n",
    "                if filtered_df.empty:\n",
    "                    continue\n",
    "\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                \n",
    "                for per_layer in per_layers:\n",
    "                    \n",
    "                    per_layer_df = filtered_df[filtered_df['per_layer'] == per_layer]\n",
    "\n",
    "                    for fda_name in fda_names:\n",
    "                        \n",
    "                        if fda_name == 'synchronous':\n",
    "                            continue\n",
    "\n",
    "                        name = f\"{fda_name}{per_layer_dict[per_layer]}\"\n",
    "\n",
    "                        fda_data = per_layer_df[per_layer_df['fda_name'] == fda_name]\n",
    "\n",
    "                        if fda_data.empty:\n",
    "                            continue\n",
    "\n",
    "                        plt.plot(fda_data['num_clients'], fda_data['total_communication_gb'], marker='o', color=base_colors_per_layer[name], label=name, markersize=3)\n",
    "\n",
    "                synchronous_data = df_bias[(df_bias['batch_size'] == batch_size) & (df_bias['fda_name'] == 'synchronous')] \n",
    "\n",
    "                if not synchronous_data.empty:\n",
    "                    plt.plot(synchronous_data['num_clients'], synchronous_data['total_communication_gb'], marker='o', label='synchronous', color=base_colors['synchronous'], markersize=3)\n",
    "\n",
    "                # Set xticks every 5 units based on available values\n",
    "                min_clients = 5\n",
    "                max_clients = 60\n",
    "\n",
    "                x_ticks = list(range(min_clients, max_clients + 1, 5))\n",
    "\n",
    "                plt.yscale('log')\n",
    "                plt.xticks(x_ticks)\n",
    "                plt.xlabel('Number of clients')\n",
    "                plt.legend()\n",
    "                plt.ylabel('Communication (GB)')\n",
    "                plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "\n",
    "                title = f'Batch Size : {batch_size} , $\\Theta$ : {theta} , {bias_title}'\n",
    "                plt.suptitle(title)\n",
    "\n",
    "                plt.tight_layout()\n",
    "\n",
    "                pdf.savefig(plt.gcf()) # Save the current figure\n",
    "        \n",
    "                # Close the current figure to prevent it from being displayed in the notebook\n",
    "                plt.close()\n",
    "    pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046289a7-ac22-469c-a56c-2386234cf8b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37c4fad-2fdc-4ef8-ab84-04e9c0ce17b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f414682-4401-44ce-891c-8bd0ff26341a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0e72a849-b20e-497b-8ec8-80b3040ff0c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fda_methods_clients_cpu_cost(df, filename):\n",
    "    pdf = PdfPages(filename)\n",
    "    \n",
    "    batch_size_values = sorted(df['batch_size'].unique())\n",
    "    theta_values = sorted(df['theta'].unique())[1:]\n",
    "    \n",
    "    biases = sorted(df['bias'].unique(), reverse=True)[::-1]\n",
    "    \n",
    "    per_layers = [False, True]\n",
    "\n",
    "    for bias in biases:\n",
    "        \n",
    "        if pd.isna(bias):\n",
    "            mask = df['bias'].isna()\n",
    "            bias_title = f'Bias: {bias}'\n",
    "        elif bias > 0:\n",
    "            mask = df['bias'] == bias\n",
    "            bias_title = f'Bias: {bias}'\n",
    "        else:\n",
    "            mask = df['bias'] == bias\n",
    "            bias_title = f'Bias: only label {one_label_bias[bias]}'\n",
    "            \n",
    "        df_bias = df[mask]\n",
    "        \n",
    "        for batch_size in batch_size_values:\n",
    "            for theta in theta_values:\n",
    "\n",
    "                filtered_df = df_bias[(df_bias['theta'] == theta) & (df_bias['batch_size'] == batch_size)] \n",
    "                    \n",
    "                if filtered_df.empty:\n",
    "                    continue\n",
    "\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                \n",
    "                for per_layer in per_layers:\n",
    "                    \n",
    "                    per_layer_df = filtered_df[filtered_df['per_layer'] == per_layer]\n",
    "\n",
    "                    for fda_name in fda_names:\n",
    "                        \n",
    "                        if fda_name == 'synchronous':\n",
    "                            continue\n",
    "\n",
    "                        name = f\"{fda_name}{per_layer_dict[per_layer]}\"\n",
    "\n",
    "                        fda_data = per_layer_df[per_layer_df['fda_name'] == fda_name]\n",
    "\n",
    "                        if fda_data.empty:\n",
    "                            continue\n",
    "\n",
    "                        plt.plot(fda_data['num_clients'], fda_data['cpu_time_cost'], marker='o', color=base_colors_per_layer[name], label=name, markersize=3)\n",
    "\n",
    "                synchronous_data = df_bias[(df_bias['batch_size'] == batch_size) & (df_bias['fda_name'] == 'synchronous')] \n",
    "\n",
    "                if not synchronous_data.empty:\n",
    "                    plt.plot(synchronous_data['num_clients'], synchronous_data['cpu_time_cost'], marker='o', label='synchronous', color=base_colors['synchronous'], markersize=3)\n",
    "\n",
    "                # Set xticks every 5 units based on available values\n",
    "                min_clients = 5\n",
    "                max_clients = 60\n",
    "\n",
    "                x_ticks = list(range(min_clients, max_clients + 1, 5))\n",
    "\n",
    "                #plt.yscale('log')\n",
    "                plt.xticks(x_ticks)\n",
    "                plt.xlabel('Number of clients')\n",
    "                plt.legend()\n",
    "                plt.ylabel('CPU Time Cost (sec)')\n",
    "                plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "\n",
    "                title = f'Batch Size : {batch_size} , $\\Theta$ : {theta} , {bias_title}'\n",
    "                plt.suptitle(title)\n",
    "\n",
    "                plt.tight_layout()\n",
    "\n",
    "                pdf.savefig(plt.gcf()) # Save the current figure\n",
    "        \n",
    "                # Close the current figure to prevent it from being displayed in the notebook\n",
    "                plt.close()\n",
    "    pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2fe9ae-df50-490e-9211-a4304dc77c9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a76c3a-20ee-41a7-9172-fb8f41d8898c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "00863691-f2de-4026-9390-ff9b10831aaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fda_methods_theta_time_cost(df, filename):\n",
    "    pdf = PdfPages(filename)\n",
    "    \n",
    "    batch_size_values = sorted(df['batch_size'].unique())\n",
    "    num_clients_values = sorted(df['num_clients'].unique())\n",
    "    \n",
    "    biases = sorted(df['bias'].unique(), reverse=True)[::-1]\n",
    "    \n",
    "    per_layers = [False, True]\n",
    "\n",
    "    for bias in biases:\n",
    "        \n",
    "        if pd.isna(bias):\n",
    "            mask = df['bias'].isna()\n",
    "            bias_title = f'Bias: {bias}'\n",
    "        elif bias > 0:\n",
    "            mask = df['bias'] == bias\n",
    "            bias_title = f'Bias: {bias}'\n",
    "        else:\n",
    "            mask = df['bias'] == bias\n",
    "            bias_title = f'Bias: only label {one_label_bias[bias]}'\n",
    "            \n",
    "        df_bias = df[mask]\n",
    "\n",
    "        for batch_size in batch_size_values:\n",
    "            for num_clients in num_clients_values:\n",
    "\n",
    "                filtered_df = df_bias[(df_bias['batch_size'] == batch_size) & (df_bias['num_clients'] == num_clients)] \n",
    "\n",
    "                if filtered_df[filtered_df['fda_name'] != 'synchronous'].empty:\n",
    "                    continue\n",
    "\n",
    "                fig, axs = plt.subplots(1, 2, figsize=(20, 6))\n",
    "\n",
    "                for per_layer in per_layers:\n",
    "                    \n",
    "                    per_layer_df = filtered_df[filtered_df['per_layer'] == per_layer]\n",
    "\n",
    "                    for fda_name in fda_names:\n",
    "                        \n",
    "                        if fda_name == 'synchronous':\n",
    "                            continue\n",
    "\n",
    "                        name = f\"{fda_name}{per_layer_dict[per_layer]}\"\n",
    "\n",
    "                        fda_data = per_layer_df[per_layer_df['fda_name'] == fda_name]\n",
    "\n",
    "                        if fda_data.empty:\n",
    "                            continue\n",
    "\n",
    "                        axs[0].plot(fda_data['theta'], fda_data['common_channel_time_cost'], marker='o', label=name, color=base_colors_per_layer[name], markersize=3)\n",
    "                        axs[1].plot(fda_data['theta'], fda_data['hypercube_time_cost'], marker='o', label=name, color=base_colors_per_layer[name], markersize=3)\n",
    "\n",
    "                synchronous_data = df_bias[(df_bias['batch_size'] == batch_size) & (df_bias['fda_name'] == 'synchronous') & (df_bias['num_clients'] == num_clients)] \n",
    "\n",
    "                if not synchronous_data.empty:\n",
    "                    axs[0].axhline(y=synchronous_data['common_channel_time_cost'].iloc[0], label='synchronous', marker='o', color=base_colors['synchronous'], markersize=3)\n",
    "                    axs[1].axhline(y=synchronous_data['hypercube_time_cost'].iloc[0], label='synchronous', marker='o', color=base_colors['synchronous'], markersize=3)\n",
    "\n",
    "                if not axs[0].has_data():\n",
    "                    plt.close(fig)\n",
    "                    continue\n",
    "\n",
    "                axs[0].set_yscale('log')\n",
    "                axs[0].set_xlabel('Theta')\n",
    "                axs[0].legend()\n",
    "                axs[0].set_title(\"Common Channel Communication Model\")\n",
    "                axs[0].set_ylabel('Time Cost')\n",
    "                axs[0].grid(True, linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "\n",
    "                axs[1].set_yscale('log')\n",
    "                axs[1].set_xlabel('Theta')\n",
    "                axs[1].legend()\n",
    "                axs[1].set_title(\"Hypercube Communication Model\")\n",
    "                axs[1].set_ylabel('Time Cost')\n",
    "                axs[1].grid(True, linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "\n",
    "                title = f'Batch Size : {batch_size} , Num Clients : {num_clients} , {bias_title}'\n",
    "                fig.suptitle(title)\n",
    "\n",
    "                plt.tight_layout()\n",
    "\n",
    "                pdf.savefig(fig)\n",
    "\n",
    "                plt.close(fig)\n",
    "    pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "186b75fa-2fa1-42be-9c46-5dfd0072fb8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fda_methods_theta_comm_cost(df, filename):\n",
    "    pdf = PdfPages(filename)\n",
    "    \n",
    "    batch_size_values = sorted(df['batch_size'].unique())\n",
    "    num_clients_values = sorted(df['num_clients'].unique())\n",
    "    \n",
    "    biases = sorted(df['bias'].unique(), reverse=True)[::-1]\n",
    "    \n",
    "    per_layers = [False, True]\n",
    "\n",
    "    for bias in biases:\n",
    "        \n",
    "        if pd.isna(bias):\n",
    "            mask = df['bias'].isna()\n",
    "            bias_title = f'Bias: {bias}'\n",
    "        elif bias > 0:\n",
    "            mask = df['bias'] == bias\n",
    "            bias_title = f'Bias: {bias}'\n",
    "        else:\n",
    "            mask = df['bias'] == bias\n",
    "            bias_title = f'Bias: only label {one_label_bias[bias]}'\n",
    "            \n",
    "        df_bias = df[mask]\n",
    "\n",
    "        for batch_size in batch_size_values:\n",
    "            for num_clients in num_clients_values:\n",
    "\n",
    "                filtered_df = df_bias[(df_bias['batch_size'] == batch_size) & (df_bias['num_clients'] == num_clients)] \n",
    "\n",
    "                if filtered_df[filtered_df['fda_name'] != 'synchronous'].empty:\n",
    "                    continue\n",
    "\n",
    "                plt.figure(figsize=(10, 6))\n",
    "\n",
    "                for per_layer in per_layers:\n",
    "                    \n",
    "                    per_layer_df = filtered_df[filtered_df['per_layer'] == per_layer]\n",
    "\n",
    "                    for fda_name in fda_names:\n",
    "                        \n",
    "                        if fda_name == 'synchronous':\n",
    "                            continue\n",
    "\n",
    "                        name = f\"{fda_name}{per_layer_dict[per_layer]}\"\n",
    "\n",
    "                        fda_data = per_layer_df[per_layer_df['fda_name'] == fda_name]\n",
    "\n",
    "                        if fda_data.empty:\n",
    "                            continue\n",
    "\n",
    "                        plt.plot(fda_data['theta'], fda_data['total_communication_gb'], marker='o', label=name, color=base_colors_per_layer[name], markersize=3)\n",
    "\n",
    "                synchronous_data = df_bias[(df_bias['batch_size'] == batch_size) & (df_bias['fda_name'] == 'synchronous') & (df_bias['num_clients'] == num_clients)] \n",
    "\n",
    "                if not synchronous_data.empty:\n",
    "                    plt.axhline(y=synchronous_data['total_communication_gb'].iloc[0], label='synchronous', marker='o', color=base_colors['synchronous'], markersize=3)\n",
    "\n",
    "                plt.yscale('log')\n",
    "                plt.xlabel('Theta')\n",
    "                plt.legend()\n",
    "                plt.ylabel('Communication Cost (GB)')\n",
    "                plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "\n",
    "                title = f'Batch Size : {batch_size} , Num Clients : {num_clients} , {bias_title}'\n",
    "                plt.suptitle(title)\n",
    "\n",
    "                plt.tight_layout()\n",
    "\n",
    "                pdf.savefig(plt.gcf())\n",
    "\n",
    "                plt.close()\n",
    "    pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "86127ef8-3dad-4526-b837-755405050aca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fda_methods_theta_cpu_cost(df, filename):\n",
    "    pdf = PdfPages(filename)\n",
    "    \n",
    "    batch_size_values = sorted(df['batch_size'].unique())\n",
    "    num_clients_values = sorted(df['num_clients'].unique())\n",
    "    \n",
    "    biases = sorted(df['bias'].unique(), reverse=True)[::-1]\n",
    "    \n",
    "    per_layers = [False, True]\n",
    "\n",
    "    for bias in biases:\n",
    "        \n",
    "        if pd.isna(bias):\n",
    "            mask = df['bias'].isna()\n",
    "            bias_title = f'Bias: {bias}'\n",
    "        elif bias > 0:\n",
    "            mask = df['bias'] == bias\n",
    "            bias_title = f'Bias: {bias}'\n",
    "        else:\n",
    "            mask = df['bias'] == bias\n",
    "            bias_title = f'Bias: only label {one_label_bias[bias]}'\n",
    "            \n",
    "        df_bias = df[mask]\n",
    "\n",
    "        for batch_size in batch_size_values:\n",
    "            for num_clients in num_clients_values:\n",
    "\n",
    "                filtered_df = df_bias[(df_bias['batch_size'] == batch_size) & (df_bias['num_clients'] == num_clients)] \n",
    "\n",
    "                if filtered_df[filtered_df['fda_name'] != 'synchronous'].empty:\n",
    "                    continue\n",
    "\n",
    "                plt.figure(figsize=(10, 6))\n",
    "\n",
    "                for per_layer in per_layers:\n",
    "                    \n",
    "                    per_layer_df = filtered_df[filtered_df['per_layer'] == per_layer]\n",
    "\n",
    "                    for fda_name in fda_names:\n",
    "                        \n",
    "                        if fda_name == 'synchronous':\n",
    "                            continue\n",
    "\n",
    "                        name = f\"{fda_name}{per_layer_dict[per_layer]}\"\n",
    "\n",
    "                        fda_data = per_layer_df[per_layer_df['fda_name'] == fda_name]\n",
    "\n",
    "                        if fda_data.empty:\n",
    "                            continue\n",
    "\n",
    "                        plt.plot(fda_data['theta'], fda_data['cpu_time_cost'], marker='o', label=name, color=base_colors_per_layer[name], markersize=3)\n",
    "\n",
    "                synchronous_data = df_bias[(df_bias['batch_size'] == batch_size) & (df_bias['fda_name'] == 'synchronous') & (df_bias['num_clients'] == num_clients)] \n",
    "\n",
    "                if not synchronous_data.empty:\n",
    "                    plt.axhline(y=synchronous_data['cpu_time_cost'].iloc[0], label='synchronous', marker='o', color=base_colors['synchronous'], markersize=3)\n",
    "\n",
    "                #plt.yscale('log')\n",
    "                plt.xlabel('Theta')\n",
    "                plt.legend()\n",
    "                plt.ylabel('CPU Time Cost (sec)')\n",
    "                plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "\n",
    "                title = f'Batch Size : {batch_size} , Num Clients : {num_clients} , {bias_title}'\n",
    "                plt.suptitle(title)\n",
    "\n",
    "                plt.tight_layout()\n",
    "\n",
    "                pdf.savefig(plt.gcf())\n",
    "\n",
    "                plt.close()\n",
    "    pdf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35569ad5-0ead-4036-af4e-3164eb070745",
   "metadata": {},
   "source": [
    "# Per accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4e5d4cc6-9f8e-4788-adaa-c7d1215c56cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def accuracies_plots(df, filename, accuracies):\n",
    "    pdf = PdfPages(filename)\n",
    "\n",
    "    biases = sorted(df['bias'].unique(), reverse=True)[::-1]\n",
    "    \n",
    "    per_layers = [False, True]\n",
    "\n",
    "    for bias in biases:\n",
    "\n",
    "        if pd.isna(bias):\n",
    "            mask = df['bias'].isna()\n",
    "            bias_title = f'Bias: {bias}'\n",
    "        elif bias > 0:\n",
    "            mask = df['bias'] == bias\n",
    "            bias_title = f'Bias: {bias}'\n",
    "        else:\n",
    "            mask = df['bias'] == bias\n",
    "            bias_title = f'Bias: only label {one_label_bias[bias]}'\n",
    "\n",
    "        df_bias = df[mask]\n",
    "        \n",
    "        for bs in sorted(df_bias['batch_size'].unique()):\n",
    "\n",
    "            bs_df = df_bias[df_bias['batch_size'] == bs]\n",
    "                \n",
    "            for theta in sorted(bs_df['theta'].unique())[1:]:\n",
    "\n",
    "                theta_df = bs_df[bs_df['theta'] == theta]\n",
    "\n",
    "                for client in sorted(theta_df['num_clients'].unique()):\n",
    "\n",
    "                    client_df = theta_df[theta_df['num_clients'] == client]\n",
    "                    \n",
    "                    plt.figure(figsize=(10, 6))\n",
    "                    \n",
    "                    for per_layer in per_layers:\n",
    "                    \n",
    "                        per_layer_df = client_df[client_df['per_layer'] == per_layer]\n",
    "\n",
    "                        for fda_name in fda_names:\n",
    "\n",
    "                            if fda_name == 'synchronous':\n",
    "                                continue\n",
    "\n",
    "                            name = f\"{fda_name}{per_layer_dict[per_layer]}\"\n",
    "\n",
    "                            fda_df = per_layer_df[per_layer_df['fda_name'] == fda_name]\n",
    "\n",
    "                            if fda_df.empty:\n",
    "                                continue\n",
    "\n",
    "                            dataframes_for_acc = []\n",
    "                            have = False\n",
    "\n",
    "                            for acc in accuracies:\n",
    "\n",
    "                                filtered_df = fda_df[(fda_df.accuracy > acc)]\n",
    "\n",
    "                                if filtered_df.empty:\n",
    "                                    continue\n",
    "\n",
    "                                have = True\n",
    "\n",
    "                                idx = filtered_df['epoch'].idxmin()\n",
    "                                filtered_df = filtered_df.loc[idx]\n",
    "\n",
    "                                dataframes_for_acc.append(filtered_df)\n",
    "\n",
    "                            if not have:\n",
    "                                continue\n",
    "\n",
    "                            df_concat = pd.concat(dataframes_for_acc)\n",
    "\n",
    "                            plt.plot(df_concat['total_communication_gb'], df_concat['accuracy'], marker='o', color=base_colors_per_layer[name], label=name, markersize=3)\n",
    "\n",
    "                        synchronous_df = df_bias[(df_bias['num_clients'] == client) & (df_bias['fda_name'] == 'synchronous')]\n",
    "\n",
    "                    for b in sorted(synchronous_df['batch_size'].unique()):\n",
    "\n",
    "                        sync_df = synchronous_df[synchronous_df['batch_size'] == b]\n",
    "\n",
    "                        if sync_df.empty:\n",
    "                            continue\n",
    "\n",
    "                        dataframes_for_acc = []\n",
    "\n",
    "                        have = False\n",
    "\n",
    "                        for acc in accuracies:\n",
    "\n",
    "                            filtered_df = sync_df[(sync_df.accuracy > acc)]\n",
    "\n",
    "                            if filtered_df.empty:\n",
    "                                continue\n",
    "\n",
    "                            have = True\n",
    "\n",
    "                            idx = filtered_df['epoch'].idxmin()\n",
    "                            filtered_df = filtered_df.loc[idx]\n",
    "\n",
    "                            dataframes_for_acc.append(filtered_df)\n",
    "\n",
    "\n",
    "                        if not have:\n",
    "                            continue \n",
    "\n",
    "                        df_concat = pd.concat(dataframes_for_acc)\n",
    "\n",
    "                        plt.plot(df_concat['total_communication_gb'], df_concat['accuracy'], color=sync_colors[b], marker='o', label=f'synchronous b{b}', markersize=3)\n",
    "\n",
    "                    plt.xscale('log')\n",
    "                    plt.ylabel('Accuracy')\n",
    "                    plt.legend()\n",
    "                    plt.xlabel('Communication Cost (GB)')\n",
    "                    plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "\n",
    "                    title = f'$Theta$ : {theta} , Batch Size: {bs} , {bias_title} , Num Clients: {client}'\n",
    "                    plt.title(title)\n",
    "\n",
    "                    pdf.savefig(plt.gcf())\n",
    "\n",
    "                    plt.close()\n",
    "    pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13208dde-1643-4603-85bb-3df7a1d71677",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedeb5d4-3825-46e0-bc88-7f792ead34b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "948eb1bb-f061-479a-b01c-15bef5775cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def centralized_synchronous_plots(df, acc_threshold, filename):\n",
    "    pdf = PdfPages(filename)\n",
    "\n",
    "    biases = sorted(df['bias'].unique(), reverse=True)[::-1]\n",
    "    \n",
    "    acc_df = df[(df.accuracy > acc_threshold)]\n",
    "    \n",
    "    # 2. Filter out same runs. We choose the instance which first hits the `acc_threshold`\n",
    "    idx = acc_df.groupby(['centralized_batch_size', 'bias'], dropna=False)['epoch'].idxmin()\n",
    "    filtered_acc_df = acc_df.loc[idx]\n",
    "\n",
    "    for bias in biases:\n",
    "\n",
    "        if pd.isna(bias):\n",
    "            mask = filtered_acc_df['bias'].isna()\n",
    "            bias_title = f'Bias: {bias}'\n",
    "        elif bias > 0:\n",
    "            mask = filtered_acc_df['bias'] == bias\n",
    "            bias_title = f'Bias: {bias}'\n",
    "        else:\n",
    "            mask = filtered_acc_df['bias'] == bias\n",
    "            bias_title = f'Bias: only label {one_label_bias[bias]}'\n",
    "\n",
    "        df_bias = filtered_acc_df[mask]\n",
    "        \n",
    "        # ````````` here\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        plt.plot(df_bias['centralized_batch_size'], df_bias['total_fda_steps'], marker='o', markersize=3)\n",
    "        \n",
    "\n",
    "        #plt.xscale('log')\n",
    "        plt.ylabel('Steps')\n",
    "        plt.xlabel('Batch Size')\n",
    "        plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "\n",
    "        title = f'{bias_title}'\n",
    "        plt.title(title)\n",
    "        plt.suptitle(\"Synchronous Centralized\")\n",
    "\n",
    "        pdf.savefig(plt.gcf())\n",
    "\n",
    "        plt.close()\n",
    "        \n",
    "    pdf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96921ad2-3cc7-4529-843c-07ae9b3047d4",
   "metadata": {},
   "source": [
    "# Help-Stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a5cb23f7-b644-49ec-87e7-14645c70c237",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def explore_top(df, acc_thresh, nn_name, fda_name):\n",
    "    acceptable_acc_df = df[(df.accuracy > acc_thresh) & (df.nn_name == nn_name)]\n",
    "    fda_df = acceptable_acc_df[acceptable_acc_df['fda_name'] == fda_name]\n",
    "    \n",
    "    idx = fda_df.groupby(['fda_name', 'num_clients', 'bias', 'batch_size', 'theta', 'aggr_scheme', 'per_layer'], dropna=False)['epoch'].idxmin()\n",
    "    aggr_df = fda_df.loc[idx]\n",
    "    \n",
    "    print(len(aggr_df))\n",
    "    \n",
    "    aggr_df['monitoring_gb_exchanged'] = aggr_df['monitoring_bytes_exchanged'] / 10**9\n",
    "    aggr_df['model_gb_exchanged'] = aggr_df['model_bytes_exchanged'] / 10**9\n",
    "    \n",
    "    #return filtered_acceptable_acc_df\n",
    "    return aggr_df[['num_clients', 'batch_size', 'theta', 'bias', 'per_layer', 'total_rounds', 'total_fda_steps', 'epoch', 'monitoring_gb_exchanged', 'model_gb_exchanged', 'total_communication_gb', 'cpu_time_cost', 'hypercube_time_cost', 'common_channel_time_cost']].sort_values(by='common_channel_time_cost')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4916c39-2e66-494d-99fc-75150184ea09",
   "metadata": {},
   "source": [
    "## Save all those time-cost plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "da4331e9-631b-4f3c-a348-ec8e0ae31077",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def time_cost_plots(df, acc_threshold, nn_name, limit_x_axis=False, show_runs=False, params=False, kde_time_log=True, kde_comm_log=True, kde_cpu_log=False):\n",
    "    # Filter out based on `acc_threshold`\n",
    "    df_nn = df[(df.nn_name == nn_name)]\n",
    "    \n",
    "    acceptable_acc_df = df_nn[(df_nn.accuracy > acc_threshold)]\n",
    "    \n",
    "    str_thresh = str(acc_threshold).replace('.', '_')  # replace '.'\n",
    "    \n",
    "    if not os.path.exists(f\"../../metrics/plots/{nn_name}/{str_thresh}\"):\n",
    "        os.makedirs(f\"../../metrics/plots/{nn_name}/{str_thresh}\")\n",
    "        \n",
    "    # 1. Same runs not included\n",
    "    \n",
    "    # 2. Filter out same runs. We choose the instance which first hits the `acc_threshold`\n",
    "    idx = acceptable_acc_df.groupby(['fda_name', 'num_clients', 'batch_size', 'theta', 'bias', 'aggr_scheme', 'per_layer'], dropna=False)['epoch'].idxmin()\n",
    "    filtered_acceptable_acc_df = acceptable_acc_df.loc[idx]\n",
    "    \n",
    "    kde_time_cost(filtered_acceptable_acc_df, f\"../../metrics/plots/{nn_name}/{str_thresh}/time_cost.pdf\", x_log=kde_time_log)\n",
    "    \n",
    "    kde_communication_cost(filtered_acceptable_acc_df, f\"../../metrics/plots/{nn_name}/{str_thresh}/comm_cost.pdf\", x_log=kde_comm_log)\n",
    "    \n",
    "    kde_cpu_time_cost(filtered_acceptable_acc_df, f\"../../metrics/plots/{nn_name}/{str_thresh}/cpu_cost.pdf\", x_log=kde_cpu_log)\n",
    "    \n",
    "    kde_comm_cpu_time_cost_ratio(filtered_acceptable_acc_df, f\"../../metrics/plots/{nn_name}/{str_thresh}/ratio.pdf\", x_log=kde_comm_log)\n",
    "    \n",
    "    # Parameters fixed, and plot\n",
    "    if params:\n",
    "        fda_methods_clients_time_cost(filtered_acceptable_acc_df, f\"../../metrics/plots/{nn_name}/{str_thresh}/clients_time_cost.pdf\")\n",
    "        fda_methods_clients_comm_cost(filtered_acceptable_acc_df, f\"../../metrics/plots/{nn_name}/{str_thresh}/clients_comm_cost.pdf\")\n",
    "        fda_methods_clients_cpu_cost(filtered_acceptable_acc_df, f\"../../metrics/plots/{nn_name}/{str_thresh}/clients_cpu_cost.pdf\")\n",
    "        \n",
    "        fda_methods_theta_time_cost(filtered_acceptable_acc_df, f\"../../metrics/plots/{nn_name}/{str_thresh}/theta_time_cost.pdf\")\n",
    "        fda_methods_theta_comm_cost(filtered_acceptable_acc_df, f\"../../metrics/plots/{nn_name}/{str_thresh}/theta_comm_cost.pdf\")\n",
    "        fda_methods_theta_cpu_cost(filtered_acceptable_acc_df, f\"../../metrics/plots/{nn_name}/{str_thresh}/theta_cpu_cost.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27001d02-6e96-470a-8cd4-4226b2cda697",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "da05aa7a-faa6-4a26-9a01-fee0a7d5c524",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_32 = df[\n",
    "    ((df['batch_size'] == 32) | (df['fda_name'] == 'synchronous')) & (df['aggr_scheme'] == 'avg')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "10d74f00-2aef-4f19-a77f-d9af918a0f57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_theta = df[\n",
    "    ((df['theta'] >= 15.) | (df['fda_name'] == 'synchronous')) & (df['aggr_scheme'] == 'avg')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a1f1923a-a4cf-4e3e-be2f-1588080206a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_adv = df_theta\n",
    "df_lenet = df_32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c98aeb-9bde-4718-ad33-a1858e42b749",
   "metadata": {},
   "source": [
    "## AdvancedCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f86ec4-2725-491f-bbca-99f53b613b35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_cost_plots(df_adv, 0.99, 'AdvancedCNN', params=True)\n",
    "time_cost_plots(df_adv, 0.993, 'AdvancedCNN', params=True)\n",
    "time_cost_plots(df_adv, 0.995, 'AdvancedCNN', params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54939d81-7343-411e-bbca-381eeb42d16d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracies_plots(df_adv[df_adv['nn_name'] == 'AdvancedCNN'], f\"../../metrics/plots/AdvancedCNN/accuracies.pdf\", accuracies=[0.98, 0.985, 0.99, 0.991, 0.992, 0.993, 0.994, 0.995, 0.996])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cce962-b1e1-4185-b64c-4aa763d9c62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "centralized_synchronous_plots(df_synchronous[df_synchronous['nn_name'] == 'AdvncedCNN'], 0.99, f\"../../metrics/plots/AdvancedCNN/0_99/centralized_synchronous.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c535b66-eab2-4b4a-bf0c-6b60ac40e0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "centralized_synchronous_plots(df_synchronous[df_synchronous['nn_name'] == 'AdvncedCNN'], 0.993, f\"../../metrics/plots/AdvancedCNN/0_993/centralized_synchronous.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63f9016-e720-482b-ae34-bfe30c1a0acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "centralized_synchronous_plots(df_synchronous[df_synchronous['nn_name'] == 'AdvncedCNN'], 0.995, f\"../../metrics/plots/AdvancedCNN/0_995/centralized_synchronous.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e7a8e7-32cc-47f4-b0dc-1111f89669bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cea288-820e-4279-bdb2-d95a8a90fdc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#testing(df_theta, 0.99, 'AdvancedCNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ede378c-18ee-4521-9101-361614426bf3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## LeNet-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc770b7e-002f-46f4-9e00-505e0e2abb0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#explore_top(df, 0.98, 'LeNet-5', 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6c2002-4be2-4353-aed9-522ddef84eca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#time_cost_plots(df_lenet, 0.98, 'LeNet-5', params=True)\n",
    "#time_cost_plots(df_lenet, 0.975, 'LeNet-5', params=True)\n",
    "#time_cost_plots(df_lenet, 0.985, 'LeNet-5', params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d148de9-4504-448f-9773-4c78a8e39f7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#accuracies_plots(df_lenet[df_lenet['nn_name'] == 'LeNet-5'], f\"../../metrics/plots/LeNet-5/accuracies_clients.pdf\", accuracies=[0.96, 0.965, 0.96, 0.965, 0.98, 0.982, 0.984, 0.985, 0.987, 0.989])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "18c79050-3911-4d52-b9d5-eb99c803d6e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "centralized_synchronous_plots(df_synchronous[df_synchronous['nn_name'] == 'LeNet-5'], 0.975, f\"../../metrics/plots/LeNet-5/0_975/centralized_synchronous.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7d627a7e-7b20-4bee-86bb-999cbd014697",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "centralized_synchronous_plots(df_synchronous[df_synchronous['nn_name'] == 'LeNet-5'], 0.98, f\"../../metrics/plots/LeNet-5/0_98/centralized_synchronous.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2a8da963-92e2-42e8-ae7d-c51a875e99d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "centralized_synchronous_plots(df_synchronous[df_synchronous['nn_name'] == 'LeNet-5'], 0.985, f\"../../metrics/plots/LeNet-5/0_985/centralized_synchronous.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707b41dc-2c4c-4e0f-ad29-a17da520e07b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data-analysis]",
   "language": "python",
   "name": "conda-env-data-analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
