{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21ca1ae5-8b5e-4127-bd65-4203c2e83cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b9e251a6-3788-411c-9442-525935eace47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class AdvancedCNN(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Advanced Convolutional Neural Network (CNN) for image classification.\n",
    "\n",
    "    Attributes:\n",
    "    - Layers for the CNN architecture (convolutional, pooling, dense layers, dropout layers).\n",
    "\n",
    "    Methods:\n",
    "    - call: Forward pass for the model.\n",
    "    - step: Compute and apply gradients for one training batch.\n",
    "    - train: Train the model on a dataset.\n",
    "    - set_trainable_variables: Set the trainable variables of the model.\n",
    "    - trainable_vars_as_vector: Return the trainable variables as a 1D tensor.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, cnn_input_reshape, num_classes):\n",
    "        \"\"\"\n",
    "        Initialize the advanced CNN model with given input shape and number of output classes.\n",
    "\n",
    "        Args:\n",
    "        - cnn_input_reshape (tuple): The shape to which the input should be reshaped. (e.g., (28, 28, 1))\n",
    "        - num_classes (int): Number of output classes.\n",
    "        \"\"\"\n",
    "        super(AdvancedCNN, self).__init__()\n",
    "        \n",
    "        self.reshape = tf.keras.layers.Reshape(cnn_input_reshape)\n",
    "        \n",
    "        self.conv1 = tf.keras.layers.Conv2D(64, kernel_size=3, activation='relu', padding='same')\n",
    "        self.conv2 = tf.keras.layers.Conv2D(64, kernel_size=3, activation='relu', padding='same')\n",
    "        self.max_pool1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        \n",
    "        self.conv3 = tf.keras.layers.Conv2D(128, kernel_size=3, activation='relu', padding='same')\n",
    "        self.conv4 = tf.keras.layers.Conv2D(128, kernel_size=3, activation='relu', padding='same')\n",
    "        self.max_pool2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        \n",
    "        self.conv5 = tf.keras.layers.Conv2D(256, kernel_size=3, activation='relu', padding='same')\n",
    "        self.conv6 = tf.keras.layers.Conv2D(256, kernel_size=3, activation='relu', padding='same')\n",
    "        self.max_pool3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(512, activation='relu')\n",
    "        self.dropout1 = tf.keras.layers.Dropout(0.5)\n",
    "        self.dense2 = tf.keras.layers.Dense(512, activation='relu')\n",
    "        self.dropout2 = tf.keras.layers.Dropout(0.5)\n",
    "        self.dense3 = tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        \"\"\"\n",
    "        Forward pass for the model.\n",
    "\n",
    "        Args:\n",
    "        - inputs (tf.Tensor): Input tensor (batch of images).\n",
    "        - training (bool, optional): Whether the forward pass is for training or inference.\n",
    "\n",
    "        Returns:\n",
    "        - tf.Tensor: Output tensor (batch of class probabilities).\n",
    "        \"\"\"\n",
    "        x = self.reshape(inputs)  # Add a channel dimension\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.max_pool1(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.max_pool2(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.max_pool3(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dropout1(x, training=training)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dropout2(x, training=training)\n",
    "        x = self.dense3(x)\n",
    "        return x\n",
    "\n",
    "    @tf.function\n",
    "    def step(self, batch):\n",
    "        \"\"\"\n",
    "        Perform one training step on a given batch of data.\n",
    "\n",
    "        Args:\n",
    "        - batch (tuple): A tuple containing two elements:\n",
    "            - x_batch (tf.Tensor): A batch of input data.\n",
    "            - y_batch (tf.Tensor): A batch of labels.\n",
    "\n",
    "        This method computes the gradients using backpropagation and updates the model's trainable parameters.\n",
    "        \"\"\"\n",
    "        x_batch, y_batch = batch\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass: Compute predictions\n",
    "            y_batch_pred = self(x_batch, training=True)\n",
    "\n",
    "            # Compute the loss value\n",
    "            loss = self.loss(y_batch, y_batch_pred)\n",
    "\n",
    "        # Compute gradients\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        \n",
    "        # Apply gradients to the model's trainable variables (update weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "       \n",
    "    def train(self, dataset):\n",
    "        \"\"\"\n",
    "        Train the model on an entire dataset.\n",
    "\n",
    "        Args:\n",
    "        - dataset (tf.data.Dataset): The dataset on which the model will be trained. \n",
    "        \"\"\"\n",
    "        for batch in dataset:\n",
    "            self.step(batch)\n",
    "\n",
    "    def set_trainable_variables(self, trainable_vars):\n",
    "        \"\"\"\n",
    "        Set the model's trainable variables.\n",
    "\n",
    "        Args:\n",
    "        - trainable_vars (list of tf.Tensor): A list of tensors representing the trainable variables to be set.\n",
    "\n",
    "        This method sets each of the model's trainable variables to the corresponding tensor in `trainable_vars`.\n",
    "        \"\"\"\n",
    "        for model_var, var in zip(self.trainable_variables, trainable_vars):\n",
    "            model_var.assign(var)\n",
    "\n",
    "    @tf.function\n",
    "    def trainable_vars_as_vector(self):\n",
    "        \"\"\"\n",
    "        Get the model's trainable variables as a single vector.\n",
    "\n",
    "        Returns:\n",
    "        - tf.Tensor: A 1D tensor containing all of the model's trainable variables.\n",
    "        \"\"\"\n",
    "        return tf.concat([tf.reshape(var, [-1]) for var in self.trainable_variables], axis=0)\n",
    "    \n",
    "    def per_layer_trainable_vars_as_vector(self):\n",
    "        \n",
    "        layer_vectors = [\n",
    "            tf.concat([tf.reshape(var, [-1]) for var in layer.trainable_weights], axis=0)\n",
    "            for layer in self.layers\n",
    "            if layer.trainable_weights\n",
    "        ]\n",
    "        \n",
    "        return layer_vectors\n",
    "    \n",
    "    def set_layer_weights(self, layer_i, weights):\n",
    "        \n",
    "        for model_var, var in zip(self.layers[layer_i].trainable_weights, weights):\n",
    "            model_var.assign(var)\n",
    "            \n",
    "    def get_trainable_layers_indices(self):\n",
    "    \n",
    "        trainable_layers_idx = [\n",
    "            i for i, layer in enumerate(adv.layers)\n",
    "            if layer.trainable_weights\n",
    "        ]\n",
    "        \n",
    "        return trainable_layers_idx\n",
    "    \n",
    "\n",
    "def get_compiled_and_built_advanced_cnn(cnn_batch_input, cnn_input_reshape, num_classes):\n",
    "    \"\"\"\n",
    "    Compile and build an Advanced CNN model.\n",
    "\n",
    "    Args:\n",
    "    - cnn_batch_input (tuple): The shape of the input including batch size (e.g., (None, 28, 28)).\n",
    "    - cnn_input_reshape (tuple): The shape to which the input should be reshaped (e.g., (28, 28, 1)).\n",
    "    - num_classes (int): Number of output classes.\n",
    "\n",
    "    Returns:\n",
    "    - AdvancedCNN: A compiled and built Advanced CNN model.\n",
    "    \"\"\"\n",
    "    advanced_cnn = AdvancedCNN(cnn_input_reshape, num_classes)\n",
    "    \n",
    "    advanced_cnn.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),  # we have softmax\n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')]\n",
    "    )\n",
    "    \n",
    "    advanced_cnn.build(cnn_batch_input)\n",
    "    \n",
    "    return advanced_cnn\n",
    "\n",
    "\n",
    "# Sequential API - for reference\n",
    "\n",
    "def sequential_advanced_cnn(cnn_input_reshape, num_classes):\n",
    "    \"\"\"\n",
    "    Create the AdvancedCNN using the Sequential API.\n",
    "\n",
    "    Args:\n",
    "    - cnn_input_reshape (tuple): The shape to which the input should be reshaped (e.g., (28, 28, 1)).\n",
    "    - num_classes (int): Number of output classes.\n",
    "\n",
    "    Returns:\n",
    "    - tf.keras.models.Sequential: An AdvancedCNN model using the Sequential API.\n",
    "\n",
    "    Example for MNIST:\n",
    "        advanced_cnn = sequential_advanced_cnn((28, 28, 1), 10)\n",
    "        advanced_cnn.compile(...)\n",
    "        advanced_cnn.fit(...)\n",
    "    \"\"\"\n",
    "    return tf.keras.models.Sequential([\n",
    "        # Reshape layer\n",
    "        tf.keras.layers.Reshape(cnn_input_reshape, input_shape=(28, 28)),  # Example input shape, change as needed\n",
    "        # First Convolutional Block\n",
    "        tf.keras.layers.Conv2D(64, kernel_size=3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.Conv2D(64, kernel_size=3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        # Second Convolutional Block\n",
    "        tf.keras.layers.Conv2D(128, kernel_size=3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.Conv2D(128, kernel_size=3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        # Third Convolutional Block\n",
    "        tf.keras.layers.Conv2D(256, kernel_size=3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.Conv2D(256, kernel_size=3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        # Fully Connected Layers\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "eab25cd1-c6f5-4a86-aa2c-a57b09fb45c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv = get_compiled_and_built_advanced_cnn((None, 28, 28), (28, 28, 1), 10)\n",
    "adv2 = get_compiled_and_built_advanced_cnn((None, 28, 28), (28, 28, 1), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ad975551-ef8e-4cce-b66c-a1c413db5ee1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(adv.per_layer_trainable_vars_as_vector())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c2c3e050-e684-4167-8379-3ca0bf60685f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 4, 5, 7, 8, 11, 13, 15]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv.get_trainable_layers_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6799320-733c-46a1-a150-2d8ff3aa8e99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f728e315-97a2-4b2e-b270-4fa1e35589a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(73856,), dtype=float32, numpy=\n",
       "array([-0.00359674, -0.00278661,  0.00766647, ...,  0.        ,\n",
       "        0.        ,  0.        ], dtype=float32)>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv.per_layer_trainable_vars_as_vector()[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "274d3310-98b2-4ecd-8169-d945d622cf27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(73856,), dtype=float32, numpy=\n",
       "array([ 0.00152143, -0.00730704,  0.04197278, ...,  0.        ,\n",
       "        0.        ,  0.        ], dtype=float32)>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv2.per_layer_trainable_vars_as_vector()[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bfa80a-d062-46ba-a6b5-b6787014cb26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "284662a0-a7b8-4c81-9331-c8b809f9a24b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client_models = [get_compiled_and_built_advanced_cnn((None, 28, 28), (28, 28, 1), 10) for _ in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f587be2e-c18b-4df4-96c2-d9f5cdc3a1c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def avg_client_layer_weights(layer_i, client_models):\n",
    "    client_layer_weights = [model.layers[layer_i].trainable_weights for model in client_models]\n",
    "    \n",
    "    avg_layer_weights = [\n",
    "        tf.reduce_mean(layer_vars, axis=0)\n",
    "        for layer_vars in zip(*client_layer_weights)\n",
    "    ]\n",
    "    \n",
    "    return avg_layer_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "eaf6cbbc-2b9b-4eaf-9afa-d3bb879ae8a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "v = avg_client_layer_weights(4, client_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "85d987bb-f2c1-442b-b11a-cca9bfee649a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adv.set_layer_weights(4, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6f406005-98d8-49d9-9e9f-2997c33fe1c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(73856,), dtype=float32, numpy=\n",
       "array([ 0.00046246,  0.02823166, -0.02043956, ...,  0.        ,\n",
       "        0.        ,  0.        ], dtype=float32)>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv.per_layer_trainable_vars_as_vector()[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0401a8-20ac-4299-a6fc-eec06b5fdc7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e507b2-9896-4478-8ab3-0f614d9dd110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cfb33792-2a8a-4d01-a937-b4eb2d377646",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "thetas = [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4a946157-b610-406d-9351-df1ac7c2285c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "est_var = [2, 0, 0, 0, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "84d2847f-cbb4-40b8-add1-241cdcddc82c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, True, True, True, True]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[est <= var for est, var in zip(est_var, thetas)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "96d4dce9-8ff3-4b78-b800-466ea86d06fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all([est <= var for est, var in zip(est_var, thetas)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e52d2a-4840-47fb-96f8-853136063929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ae0c550b-458f-476b-8a04-7eb75bc1b2e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11, 12, 13, 14, 15, 16, 17, 18, 19]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in range(20) if x > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871930b3-f080-4006-8799-3ad89101579f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-2.13]",
   "language": "python",
   "name": "conda-env-tf-2.13-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
