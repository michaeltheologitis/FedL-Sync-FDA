{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21ca1ae5-8b5e-4127-bd65-4203c2e83cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9e251a6-3788-411c-9442-525935eace47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class AdvancedCNN(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Advanced Convolutional Neural Network (CNN) for image classification.\n",
    "\n",
    "    Attributes:\n",
    "    - Layers for the CNN architecture (convolutional, pooling, dense layers, dropout layers).\n",
    "\n",
    "    Methods:\n",
    "    - call: Forward pass for the model.\n",
    "    - step: Compute and apply gradients for one training batch.\n",
    "    - train: Train the model on a dataset.\n",
    "    - set_trainable_variables: Set the trainable variables of the model.\n",
    "    - trainable_vars_as_vector: Return the trainable variables as a 1D tensor.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, cnn_input_reshape, num_classes):\n",
    "        \"\"\"\n",
    "        Initialize the advanced CNN model with given input shape and number of output classes.\n",
    "\n",
    "        Args:\n",
    "        - cnn_input_reshape (tuple): The shape to which the input should be reshaped. (e.g., (28, 28, 1))\n",
    "        - num_classes (int): Number of output classes.\n",
    "        \"\"\"\n",
    "        super(AdvancedCNN, self).__init__()\n",
    "        \n",
    "        self.reshape = tf.keras.layers.Reshape(cnn_input_reshape)\n",
    "        \n",
    "        self.conv1 = tf.keras.layers.Conv2D(64, kernel_size=3, activation='relu', padding='same')\n",
    "        self.conv2 = tf.keras.layers.Conv2D(64, kernel_size=3, activation='relu', padding='same')\n",
    "        self.max_pool1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        \n",
    "        self.conv3 = tf.keras.layers.Conv2D(128, kernel_size=3, activation='relu', padding='same')\n",
    "        self.conv4 = tf.keras.layers.Conv2D(128, kernel_size=3, activation='relu', padding='same')\n",
    "        self.max_pool2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        \n",
    "        self.conv5 = tf.keras.layers.Conv2D(256, kernel_size=3, activation='relu', padding='same')\n",
    "        self.conv6 = tf.keras.layers.Conv2D(256, kernel_size=3, activation='relu', padding='same')\n",
    "        self.max_pool3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(512, activation='relu')\n",
    "        self.dropout1 = tf.keras.layers.Dropout(0.5)\n",
    "        self.dense2 = tf.keras.layers.Dense(512, activation='relu')\n",
    "        self.dropout2 = tf.keras.layers.Dropout(0.5)\n",
    "        self.dense3 = tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        \"\"\"\n",
    "        Forward pass for the model.\n",
    "\n",
    "        Args:\n",
    "        - inputs (tf.Tensor): Input tensor (batch of images).\n",
    "        - training (bool, optional): Whether the forward pass is for training or inference.\n",
    "\n",
    "        Returns:\n",
    "        - tf.Tensor: Output tensor (batch of class probabilities).\n",
    "        \"\"\"\n",
    "        x = self.reshape(inputs)  # Add a channel dimension\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.max_pool1(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.max_pool2(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.max_pool3(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dropout1(x, training=training)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dropout2(x, training=training)\n",
    "        x = self.dense3(x)\n",
    "        return x\n",
    "\n",
    "    @tf.function\n",
    "    def step(self, batch):\n",
    "        \"\"\"\n",
    "        Perform one training step on a given batch of data.\n",
    "\n",
    "        Args:\n",
    "        - batch (tuple): A tuple containing two elements:\n",
    "            - x_batch (tf.Tensor): A batch of input data.\n",
    "            - y_batch (tf.Tensor): A batch of labels.\n",
    "\n",
    "        This method computes the gradients using backpropagation and updates the model's trainable parameters.\n",
    "        \"\"\"\n",
    "        x_batch, y_batch = batch\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass: Compute predictions\n",
    "            y_batch_pred = self(x_batch, training=True)\n",
    "\n",
    "            # Compute the loss value\n",
    "            loss = self.loss(y_batch, y_batch_pred)\n",
    "\n",
    "        # Compute gradients\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        \n",
    "        # Apply gradients to the model's trainable variables (update weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "       \n",
    "    def train(self, dataset):\n",
    "        \"\"\"\n",
    "        Train the model on an entire dataset.\n",
    "\n",
    "        Args:\n",
    "        - dataset (tf.data.Dataset): The dataset on which the model will be trained. \n",
    "        \"\"\"\n",
    "        for batch in dataset:\n",
    "            self.step(batch)\n",
    "\n",
    "    def set_trainable_variables(self, trainable_vars):\n",
    "        \"\"\"\n",
    "        Set the model's trainable variables.\n",
    "\n",
    "        Args:\n",
    "        - trainable_vars (list of tf.Tensor): A list of tensors representing the trainable variables to be set.\n",
    "\n",
    "        This method sets each of the model's trainable variables to the corresponding tensor in `trainable_vars`.\n",
    "        \"\"\"\n",
    "        for model_var, var in zip(self.trainable_variables, trainable_vars):\n",
    "            model_var.assign(var)\n",
    "\n",
    "    @tf.function\n",
    "    def trainable_vars_as_vector(self):\n",
    "        \"\"\"\n",
    "        Get the model's trainable variables as a single vector.\n",
    "\n",
    "        Returns:\n",
    "        - tf.Tensor: A 1D tensor containing all of the model's trainable variables.\n",
    "        \"\"\"\n",
    "        return tf.concat([tf.reshape(var, [-1]) for var in self.trainable_variables], axis=0)\n",
    "    \n",
    "    def per_layer_trainable_vars_as_vector(self):\n",
    "        \n",
    "        layer_vectors = [\n",
    "            tf.concat([tf.reshape(var, [-1]) for var in layer.trainable_weights], axis=0)\n",
    "            for layer in self.layers\n",
    "            if layer.trainable_weights\n",
    "        ]\n",
    "        \n",
    "        return layer_vectors\n",
    "    \n",
    "    def set_layer_weights(self, layer_i, weights):\n",
    "        \n",
    "        for model_var, var in zip(self.layers[layer_i].trainable_weights, weights):\n",
    "            model_var.assign(var)\n",
    "            \n",
    "    def get_trainable_layers_indices(self):\n",
    "    \n",
    "        trainable_layers_idx = [\n",
    "            i for i, layer in enumerate(adv.layers)\n",
    "            if layer.trainable_weights\n",
    "        ]\n",
    "        \n",
    "        return trainable_layers_idx\n",
    "    \n",
    "\n",
    "def get_compiled_and_built_advanced_cnn(cnn_batch_input, cnn_input_reshape, num_classes):\n",
    "    \"\"\"\n",
    "    Compile and build an Advanced CNN model.\n",
    "\n",
    "    Args:\n",
    "    - cnn_batch_input (tuple): The shape of the input including batch size (e.g., (None, 28, 28)).\n",
    "    - cnn_input_reshape (tuple): The shape to which the input should be reshaped (e.g., (28, 28, 1)).\n",
    "    - num_classes (int): Number of output classes.\n",
    "\n",
    "    Returns:\n",
    "    - AdvancedCNN: A compiled and built Advanced CNN model.\n",
    "    \"\"\"\n",
    "    advanced_cnn = AdvancedCNN(cnn_input_reshape, num_classes)\n",
    "    \n",
    "    advanced_cnn.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),  # we have softmax\n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')]\n",
    "    )\n",
    "    \n",
    "    advanced_cnn.build(cnn_batch_input)\n",
    "    \n",
    "    return advanced_cnn\n",
    "\n",
    "\n",
    "# Sequential API - for reference\n",
    "\n",
    "def sequential_advanced_cnn(cnn_input_reshape, num_classes):\n",
    "    \"\"\"\n",
    "    Create the AdvancedCNN using the Sequential API.\n",
    "\n",
    "    Args:\n",
    "    - cnn_input_reshape (tuple): The shape to which the input should be reshaped (e.g., (28, 28, 1)).\n",
    "    - num_classes (int): Number of output classes.\n",
    "\n",
    "    Returns:\n",
    "    - tf.keras.models.Sequential: An AdvancedCNN model using the Sequential API.\n",
    "\n",
    "    Example for MNIST:\n",
    "        advanced_cnn = sequential_advanced_cnn((28, 28, 1), 10)\n",
    "        advanced_cnn.compile(...)\n",
    "        advanced_cnn.fit(...)\n",
    "    \"\"\"\n",
    "    return tf.keras.models.Sequential([\n",
    "        # Reshape layer\n",
    "        tf.keras.layers.Reshape(cnn_input_reshape, input_shape=(28, 28)),  # Example input shape, change as needed\n",
    "        # First Convolutional Block\n",
    "        tf.keras.layers.Conv2D(64, kernel_size=3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.Conv2D(64, kernel_size=3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        # Second Convolutional Block\n",
    "        tf.keras.layers.Conv2D(128, kernel_size=3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.Conv2D(128, kernel_size=3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        # Third Convolutional Block\n",
    "        tf.keras.layers.Conv2D(256, kernel_size=3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.Conv2D(256, kernel_size=3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        # Fully Connected Layers\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eab25cd1-c6f5-4a86-aa2c-a57b09fb45c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv = get_compiled_and_built_advanced_cnn((None, 28, 28), (28, 28, 1), 10)\n",
    "adv2 = get_compiled_and_built_advanced_cnn((None, 28, 28), (28, 28, 1), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad975551-ef8e-4cce-b66c-a1c413db5ee1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(adv.per_layer_trainable_vars_as_vector())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2c3e050-e684-4167-8379-3ca0bf60685f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 4, 5, 7, 8, 11, 13, 15]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv.get_trainable_layers_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f728e315-97a2-4b2e-b270-4fa1e35589a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(73856,), dtype=float32, numpy=\n",
       "array([-0.05227558,  0.00293674, -0.04982723, ...,  0.        ,\n",
       "        0.        ,  0.        ], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv.per_layer_trainable_vars_as_vector()[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "274d3310-98b2-4ecd-8169-d945d622cf27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(73856,), dtype=float32, numpy=\n",
       "array([ 0.04206424, -0.03129565,  0.04316866, ...,  0.        ,\n",
       "        0.        ,  0.        ], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv2.per_layer_trainable_vars_as_vector()[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "59bfa80a-d062-46ba-a6b5-b6787014cb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_layers_indices = adv.get_trainable_layers_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "284662a0-a7b8-4c81-9331-c8b809f9a24b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client_models = [get_compiled_and_built_advanced_cnn((None, 28, 28), (28, 28, 1), 10) for _ in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f587be2e-c18b-4df4-96c2-d9f5cdc3a1c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def avg_client_layer_weights(layer_i, client_models):\n",
    "    client_layer_weights = [model.layers[layer_i].trainable_weights for model in client_models]\n",
    "    \n",
    "    avg_layer_weights = [\n",
    "        tf.reduce_mean(layer_vars, axis=0)\n",
    "        for layer_vars in zip(*client_layer_weights)\n",
    "    ]\n",
    "    \n",
    "    return avg_layer_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eaf6cbbc-2b9b-4eaf-9afa-d3bb879ae8a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "avg_weights = [avg_client_layer_weights(layer_i, client_models) for layer_i in trainable_layers_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "871930b3-f080-4006-8799-3ad89101579f",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_weights_vecs = [\n",
    "    tf.concat([tf.reshape(var, [-1]) for var in trainable_weights], axis=0)\n",
    "    for trainable_weights in avg_weights\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0bf3fd7c-7e31-42bd-9d5a-189048c9787a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(avg_weights_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1b2be4cd-4f93-448d-a87f-8525f98bdf82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client_layer_vecs = [client_cnn.per_layer_trainable_vars_as_vector() for client_cnn in client_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d6b3f2b9-ac05-4ab2-9d36-f8b96c49fc2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "avg_weights_vecs2 = [\n",
    "    tf.reduce_mean(vecs, axis=0) for vecs in zip(*client_layer_vecs)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "86a864d5-83ed-44b6-818a-bde122db153f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for avg1, avg2 in zip(avg_weights_vecs, avg_weights_vecs2):\n",
    "    print(tf.reduce_sum(avg1-avg2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb03a409-6031-4f85-be8c-9c72e3a04b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-2.13]",
   "language": "python",
   "name": "conda-env-tf-2.13-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
