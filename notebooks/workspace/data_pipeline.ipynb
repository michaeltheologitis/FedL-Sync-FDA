{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6b821bc9-703e-4a3d-ab6c-514c9517510b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    Load the MNIST dataset and normalize the pixel values.\n",
    "\n",
    "    This function loads the MNIST dataset using Keras's built-in dataset API.\n",
    "    It normalizes the pixel values of the images by dividing them by 255.0.\n",
    "    \n",
    "    Returns:\n",
    "    - X_train (numpy.ndarray): The training data, a 3D array of shape (num_samples, 28, 28).\n",
    "    - y_train (numpy.ndarray): The labels for the training data, a 1D array of shape (num_samples,).\n",
    "    - X_test (numpy.ndarray): The test data, a 3D array of shape (num_samples, 28, 28).\n",
    "    - y_test (numpy.ndarray): The labels for the test data, a 1D array of shape (num_samples,).\n",
    "    \"\"\"\n",
    "    (X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "    X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "def convert_to_tf_dataset(X_train, y_train, X_test, y_test):\n",
    "    # Convert to TensorFlow Datasets\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(256)\n",
    "\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "\n",
    "class LeNet5(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    LeNet-5 model for image classification.\n",
    "\n",
    "    Attributes:\n",
    "    - Layers for the LeNet-5 architecture (convolutional, pooling, dense layers).\n",
    "\n",
    "    Methods:\n",
    "    - call: Forward pass for the model.\n",
    "    - step: Compute and apply gradients for one training batch.\n",
    "    - train: Train the model on a dataset.\n",
    "    - set_trainable_variables: Set the trainable variables of the model.\n",
    "    - trainable_vars_as_vector: Return the trainable variables as a 1D tensor.\n",
    "    \"\"\"\n",
    "    def __init__(self, cnn_input_reshape, num_classes):\n",
    "        \"\"\"\n",
    "        Initialize the LeNet-5 model with given input shape and number of output classes.\n",
    "\n",
    "        Args:\n",
    "        - cnn_input_reshape (tuple): The shape to which the input should be reshaped. (e.g., (28, 28, 1))\n",
    "        - num_classes (int): Number of output classes.\n",
    "        \"\"\"\n",
    "        \n",
    "        super(LeNet5, self).__init__()\n",
    "        \n",
    "        self.reshape = layers.Reshape(cnn_input_reshape)\n",
    "        \n",
    "        # Layer 1 Conv2D\n",
    "        self.conv1 = layers.Conv2D(filters=6, kernel_size=(5, 5), strides=(1, 1), activation='tanh', padding='same')\n",
    "        # Layer 2 Pooling Layer\n",
    "        self.avgpool1 = layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid')\n",
    "        # Layer 3 Conv2D\n",
    "        self.conv2 = layers.Conv2D(filters=16, kernel_size=(5, 5), strides=(1, 1), activation='tanh', padding='valid')\n",
    "        # Layer 4 Pooling Layer\n",
    "        self.avgpool2 = layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid')\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.dense1 = layers.Dense(units=120, activation='tanh')\n",
    "        self.dense2 = layers.Dense(units=84, activation='tanh')\n",
    "        self.dense3 = layers.Dense(units=num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        \"\"\"\n",
    "        Forward pass for the model.\n",
    "\n",
    "        Args:\n",
    "        - inputs (tf.Tensor): Input tensor (batch of images).\n",
    "        - training (bool, optional): Whether the forward pass is for training.\n",
    "\n",
    "        Returns:\n",
    "        - x (tf.Tensor): Output tensor (batch of class probabilities).\n",
    "        \"\"\"\n",
    "        x = self.reshape(inputs)\n",
    "        x = self.conv1(x)\n",
    "        x = self.avgpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.avgpool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    #@tf.function\n",
    "    def step(self, batch):\n",
    "        #print(\"Retrace\")\n",
    "        \"\"\"\n",
    "        Perform one training step on a given batch of data.\n",
    "\n",
    "        Args:\n",
    "        - batch (tuple): A tuple containing two elements:\n",
    "            - x_batch (tf.Tensor): A batch of input data.\n",
    "            - y_batch (tf.Tensor): A batch of labels.\n",
    "\n",
    "        This method computes the gradients using backpropagation and updates the model's trainable parameters.\n",
    "        \"\"\"\n",
    "        \n",
    "        x_batch, y_batch = batch\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass: Compute predictions\n",
    "            y_batch_pred = self(x_batch, training=True)\n",
    "\n",
    "            # Compute the loss value\n",
    "            loss = self.loss(y_batch, y_batch_pred)\n",
    "\n",
    "        # Compute gradients\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        \n",
    "        # Apply gradients to the model's trainable variables (update weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "\n",
    "    def train(self, dataset):\n",
    "        \"\"\"\n",
    "        Train the model on an entire dataset.\n",
    "\n",
    "        Args:\n",
    "        - dataset (tf.data.Dataset): The dataset on which the model will be trained. \n",
    "        \"\"\"\n",
    "        for batch in dataset:\n",
    "            self.step(batch)\n",
    "\n",
    "    def set_trainable_variables(self, trainable_vars):\n",
    "        \"\"\"\n",
    "        Set the model's trainable variables.\n",
    "\n",
    "        Args:\n",
    "        - trainable_vars (list of tf.Tensor): A list of tensors representing the trainable variables to be set.\n",
    "\n",
    "        This method sets each of the model's trainable variables to the corresponding tensor in `trainable_vars`.\n",
    "        \"\"\"\n",
    "        for model_var, var in zip(self.trainable_variables, trainable_vars):\n",
    "            model_var.assign(var)\n",
    "\n",
    "    def trainable_vars_as_vector(self):\n",
    "        \"\"\"\n",
    "        Get the model's trainable variables as a single vector.\n",
    "\n",
    "        Returns:\n",
    "        - tf.Tensor: A 1D tensor containing all of the model's trainable variables.\n",
    "        \"\"\"\n",
    "        return tf.concat([tf.reshape(var, [-1]) for var in self.trainable_variables], axis=0)\n",
    "\n",
    "\n",
    "def get_compiled_and_built_lenet(cnn_batch_input, cnn_input_reshape, num_classes):\n",
    "    \"\"\"\n",
    "    Compile and build a LeNet-5 model.\n",
    "\n",
    "    Args:\n",
    "    - cnn_batch_input (tuple): The shape of the input including batch size (e.g., (None, 28, 28)).\n",
    "    - cnn_input_reshape (tuple): The shape to which the input should be reshaped (e.g., (28, 28, 1)).\n",
    "    - num_classes (int): Number of output classes.\n",
    "\n",
    "    Returns:\n",
    "    - cnn (LeNet5): A compiled and built LeNet-5 model.\n",
    "    \"\"\"\n",
    "    cnn = LeNet5(cnn_input_reshape, num_classes)\n",
    "    \n",
    "    cnn.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),  # we have softmax\n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')]\n",
    "    )\n",
    "    \n",
    "    cnn.build(cnn_batch_input)\n",
    "    \n",
    "    return cnn\n",
    "\n",
    "\n",
    "X_train, y_train, X_test, y_test = load_data()\n",
    "train_dataset, test_dataset = convert_to_tf_dataset(X_train, y_train, X_test, y_test)        \n",
    "        \n",
    "lenet = get_compiled_and_built_lenet((None, 28, 28), (28, 28, 1), 10)\n",
    "\n",
    "batch_size = 256\n",
    "num_steps_until_rtc_check = 1\n",
    "shuffle_size = train_dataset.cardinality()  # Uniform shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a223258e-ec63-4aa9-9f3a-cc71b72c84f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = train_dataset.shuffle(shuffle_size).repeat().batch(batch_size).take(1).prefetch(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9deb5b05-a43d-4f51-be7c-0ccaa62072d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.86 s ± 16.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "for _ in range(25):\n",
    "    for batch in ds:\n",
    "        lenet.step(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "60a4cf96-62a3-48ef-abd6-93f274f38657",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = train_dataset.shuffle(shuffle_size).repeat().batch(batch_size).prefetch(10).take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3a6b30e7-fa1c-41b7-81f6-c221ef6437c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.91 s ± 41.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "for _ in range(25):\n",
    "    for batch in ds:\n",
    "        lenet.step(batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-2.13]",
   "language": "python",
   "name": "conda-env-tf-2.13-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
