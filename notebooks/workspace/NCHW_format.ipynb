{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c155a9a-b99e-4574-b9a6-71e6597bea1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "for gpu in tf.config.experimental.list_physical_devices('GPU'):\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "from tensorflow.keras import datasets\n",
    "\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57557a70-601f-4851-b237-4299f1e860bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4110b3d-a6a8-40f5-b021-30222a7ce89f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fdavg.models import count_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2be50278-4b9c-40a0-afc7-3d17fb4a5a82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "#X_train, X_test = X_train / 255.0, X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f23383bc-9ea4-4d38-9cf2-93a1afaa2e70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "265139c7-4d7c-42b7-b63b-c47347a23575",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb5ee097-6d27-47c1-bce3-212e85e7bb22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train = np.squeeze(y_train)\n",
    "y_test = np.squeeze(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea489543-667b-4843-ab90-f8edd823fb38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd74294-5711-42e0-8026-2bbcc2450bc3",
   "metadata": {},
   "source": [
    "# DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ca36795-ab90-4253-8279-39c85b516d21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "\"\"\" \n",
    "Implementation from https://github.com/keras-team/keras-applications/blob/master/keras_applications/densenet.py\n",
    "\n",
    "DenseNet, not pre-trained, specifically for the CIFAR-10 datasets. \n",
    "\n",
    "Note:\n",
    "    - Preprocessing on input is assumed using `tensorflow.keras.applications.densenet.preprocess_input`.\n",
    "\n",
    "Deviations from original keras implementation:\n",
    "    1) We add dropout layers with rate=0.2 as suggested by Huang et. al, 2016 for training on CIFAR-10\n",
    "    2) We adopt `he normal` weight-initialization He et al., 2015 as suggested by Huang et. al., 2016\n",
    "\"\"\"\n",
    "\n",
    "def dense_block(x, blocks, name):\n",
    "    for i in range(blocks):\n",
    "        x = conv_block(x, 32, name=name + '_block' + str(i + 1))\n",
    "    return x\n",
    "\n",
    "\n",
    "def transition_block(x, reduction, name):\n",
    "    bn_axis = 1  # For NCHW format : (batch_size, channels, height, width)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=name + '_bn')(x)\n",
    "    x = layers.Activation('relu', name=name + '_relu')(x)\n",
    "    x = layers.Conv2D(int(x.shape[bn_axis] * reduction), 1, kernel_initializer='he_normal', use_bias=False, name=name + '_conv', data_format='channels_first')(x)\n",
    "    x = layers.AveragePooling2D(2, strides=2, name=name + '_pool', data_format='channels_first')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv_block(x, growth_rate, name):\n",
    "    bn_axis = 1  # For NCHW format : (batch_size, channels, height, width)\n",
    "    x1 = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=name + '_0_bn')(x)\n",
    "    x1 = layers.Activation('relu', name=name + '_0_relu')(x1)\n",
    "    x1 = layers.Conv2D(4 * growth_rate, 1, use_bias=False, kernel_initializer='he_normal', name=name + '_1_conv', data_format='channels_first')(x1)\n",
    "    x1 = layers.Dropout(0.2, name=name + '_1_dropout')(x1)  # Add dropout 0.2 after convolution as Huang et. al suggest for Cifar-10\n",
    "    x1 = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=name + '_1_bn')(x1)\n",
    "    x1 = layers.Activation('relu', name=name + '_1_relu')(x1)\n",
    "    x1 = layers.Conv2D(growth_rate, 3, padding='same', use_bias=False, kernel_initializer='he_normal', name=name + '_2_conv', data_format='channels_first')(x1)\n",
    "    x1 = layers.Dropout(0.2, name=name + '_2_dropout')(x1)  # Add dropout 0.2 after convolution as Huang et. al suggest for Cifar-10\n",
    "    x = layers.Concatenate(axis=bn_axis, name=name + '_concat')([x, x1])\n",
    "    return x\n",
    "\n",
    "\n",
    "def dense_net_fn(blocks, input_shape, classes):\n",
    "\n",
    "    # Determine proper input shape\n",
    "    img_input = layers.Input(shape=input_shape)\n",
    "\n",
    "    bn_axis = 1  # For NCHW format : (batch_size, channels, height, width)\n",
    "    \n",
    "    x_nchw = tf.transpose(img_input, [0, 3, 1, 2])  # Tranform to NCHW format\n",
    "    #x_nchw = img_input\n",
    "\n",
    "    x = layers.ZeroPadding2D(padding=((3, 3), (3, 3)), data_format='channels_first')(x_nchw)\n",
    "    x = layers.Conv2D(64, 7, strides=2, use_bias=False, kernel_initializer='he_normal', name='conv1/conv', data_format='channels_first')(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name='conv1/bn')(x)\n",
    "    x = layers.Activation('relu', name='conv1/relu')(x)\n",
    "    x = layers.ZeroPadding2D(padding=((1, 1), (1, 1)), data_format='channels_first')(x)\n",
    "    x = layers.MaxPooling2D(3, strides=2, name='pool1', data_format='channels_first')(x)\n",
    "\n",
    "    x = dense_block(x, blocks[0], name='conv2')\n",
    "    x = transition_block(x, 0.5, name='pool2')\n",
    "    x = dense_block(x, blocks[1], name='conv3')\n",
    "    x = transition_block(x, 0.5, name='pool3')\n",
    "    x = dense_block(x, blocks[2], name='conv4')\n",
    "    x = transition_block(x, 0.5, name='pool4')\n",
    "    x = dense_block(x, blocks[3], name='conv5')\n",
    "\n",
    "    x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name='bn')(x)\n",
    "    x = layers.Activation('relu', name='relu')(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D(name='avg_pool', data_format='channels_first')(x)\n",
    "    x = layers.Dense(classes, kernel_initializer='he_normal', activation='softmax', name='fc10')(x)\n",
    "\n",
    "    inputs = img_input\n",
    "\n",
    "    # Create model.\n",
    "    if blocks == [6, 12, 24, 16]:\n",
    "        model = models.Model(inputs, x, name='densenet121')\n",
    "    elif blocks == [6, 12, 32, 32]:\n",
    "        model = models.Model(inputs, x, name='densenet169')\n",
    "    elif blocks == [6, 12, 48, 32]:\n",
    "        model = models.Model(inputs, x, name='densenet201')\n",
    "    else:\n",
    "        model = models.Model(inputs, x, name='densenet')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "class DenseNet:\n",
    "    def __init__(self, name, input_shape=(32, 32, 3), classes=10):\n",
    "        \n",
    "        self.model = None\n",
    "        \n",
    "        if name == 'DenseNet121':\n",
    "            self.model = dense_net_fn([6, 12, 24, 16], input_shape, classes)\n",
    "        if name == 'DenseNet169':\n",
    "            self.model = dense_net_fn([6, 12, 32, 32], input_shape, classes)\n",
    "        if name == 'DenseNet201':\n",
    "            self.model = dense_net_fn([6, 12, 48, 32], input_shape, classes)\n",
    "            \n",
    "    def __getattr__(self, name):\n",
    "        # Automatically delegate method calls to the underlying Keras model. \n",
    "        # This ensures that the custom class supports all methods of the \n",
    "        # Keras model without having to define each one explicitly.\n",
    "        return getattr(self.model, name)\n",
    "\n",
    "    def step(self, batch):\n",
    "        x_batch, y_batch = batch\n",
    "        return self.train_on_batch(x=x_batch, y=y_batch)\n",
    "        \n",
    "    def train(self, dataset):\n",
    "        for batch in dataset:\n",
    "            self.step(batch)\n",
    "            \n",
    "    def set_trainable_variables(self, trainable_vars):\n",
    "        for model_var, var in zip(self.trainable_variables, trainable_vars):\n",
    "            model_var.assign(var)\n",
    "        \n",
    "    def set_non_trainable_variables(self, non_trainable_vars):\n",
    "        for model_var, var in zip(self.non_trainable_variables, non_trainable_vars):\n",
    "            model_var.assign(var)\n",
    "\n",
    "    @tf.function\n",
    "    def trainable_vars_as_vector(self):\n",
    "        return tf.concat([tf.reshape(var, [-1]) for var in self.trainable_variables], axis=0)\n",
    "\n",
    "    def per_layer_trainable_vars_as_vector(self):\n",
    "        layer_vectors = [\n",
    "            tf.concat([tf.reshape(var, [-1]) for var in layer.trainable_weights], axis=0)\n",
    "            for layer in self.layers\n",
    "            if layer.trainable_weights\n",
    "        ]\n",
    "\n",
    "        return layer_vectorsdd\n",
    "\n",
    "    def set_layer_weights(self, layer_i, weights):\n",
    "        for model_var, var in zip(self.layers[layer_i].trainable_weights, weights):\n",
    "            model_var.assign(var)\n",
    "\n",
    "    def get_trainable_layers_indices(self):\n",
    "        trainable_layers_idx = [\n",
    "            i for i, layer in enumerate(self.layers)\n",
    "            if layer.trainable_weights\n",
    "        ]\n",
    "\n",
    "        return trainable_layers_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8868c223-dce9-4611-8b8f-9c309d7932bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd0af3b-4a55-4a51-988d-8e25b0656b67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1acd8a55-31c5-4181-8af4-83fd56b18455",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_compiled_and_built_densenet(name, cnn_batch_input, learning_rate_schedule):\n",
    "    densenet = DenseNet(name)\n",
    "\n",
    "    densenet.compile(\n",
    "        optimizer=tf.keras.optimizers.SGD(\n",
    "            learning_rate=learning_rate_schedule,\n",
    "            momentum=0.9,\n",
    "            weight_decay=1e-4,\n",
    "            nesterov=True\n",
    "        ),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),  # we have softmax\n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')]\n",
    "    )\n",
    "\n",
    "    densenet.build(cnn_batch_input)\n",
    "\n",
    "    return densenet\n",
    "\n",
    "\n",
    "def create_learning_rate_schedule(total_epochs, steps_per_epoch):\n",
    "    \"\"\"\n",
    "    DenseNet paper, where the learning rate changes at specific epochs (50% and 75% of total training epochs).\n",
    "    Starts at 0.1, goes to 0.01 at 50% of epochs, and finally after 75% goes to 0.001\n",
    "\n",
    "    Ref: https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/PiecewiseConstantDecay\n",
    "    \"\"\"\n",
    "\n",
    "    total_steps = total_epochs * steps_per_epoch\n",
    "\n",
    "    steps_at_50_percent = 0.5 * total_steps\n",
    "    steps_at_75_percent = 0.75 * total_steps\n",
    "\n",
    "    boundaries = [steps_at_50_percent, steps_at_75_percent]\n",
    "    values = [0.1, 0.01, 0.001]\n",
    "\n",
    "    learning_rate_schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(boundaries, values)\n",
    "\n",
    "    return learning_rate_schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e8f9f1-9a90-45e0-9974-1b63d3c438c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8fb1000-210e-4261-826e-a34d42bfae4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_clients = 2\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ce8ac47-872d-43b1-b06e-b85d3bc84666",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_unbiased_federated_data(X_train, y_train, num_clients):\n",
    "    X_train_unbiased_lst = np.array_split(X_train, num_clients)\n",
    "    y_train_unbiased_lst = np.array_split(y_train, num_clients)\n",
    "\n",
    "    unbiased_federated_dataset = [\n",
    "        tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "        for X_train, y_train in zip(X_train_unbiased_lst, y_train_unbiased_lst)\n",
    "    ]\n",
    "\n",
    "    return unbiased_federated_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e53e3efc-d1dd-448e-b63d-5b98bc7b5bbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_federated_data(federated_dataset, batch_size, num_steps_until_rtc_check, seed=None):\n",
    "    \n",
    "    def process_client_dataset(_client_dataset, _batch_size, _num_steps_until_rtc_check, _seed):\n",
    "        shuffle_size = _client_dataset.cardinality()  # Uniform shuffling\n",
    "        return _client_dataset.shuffle(shuffle_size, seed=_seed).repeat().batch(_batch_size) \\\n",
    "            .take(_num_steps_until_rtc_check)\n",
    "\n",
    "    federated_dataset_prepared = [\n",
    "        process_client_dataset(client_dataset, batch_size, num_steps_until_rtc_check, seed)\n",
    "        for client_dataset in federated_dataset\n",
    "    ]\n",
    "    return federated_dataset_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a593e82-5d3a-4eaf-aefd-02edec483acb",
   "metadata": {},
   "source": [
    "# New paradigm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57da9660-e351-4784-bb49-e4d4a395f7b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_weights2(model):\n",
    "    total_params = 0\n",
    "    for layer in model.layers:\n",
    "        total_params += np.sum([np.prod(weight.shape) for weight in layer.trainable_weights])\n",
    "        total_params += np.sum([np.prod(weight.shape) for weight in layer.non_trainable_weights])\n",
    "    return int(total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "436bb18d-dec3-4a52-b443-922662e0ee9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def average_client_weights2(client_models):\n",
    "    # Retrieve the trainable variables from each client model\n",
    "    client_trainable_weights = [model.trainable_variables for model in client_models]\n",
    "    client_non_trainable_weights = [model.non_trainable_variables for model in client_models]\n",
    "\n",
    "    # Compute the average weights for each layer\n",
    "    avg_trainable_weights = [\n",
    "        tf.reduce_mean(layer_weight_tensors, axis=0)\n",
    "        for layer_weight_tensors in zip(*client_trainable_weights)\n",
    "    ]\n",
    "    \n",
    "    avg_non_trainable_weights = [\n",
    "        tf.reduce_mean(layer_weight_tensors, axis=0)\n",
    "        for layer_weight_tensors in zip(*client_non_trainable_weights)\n",
    "    ]\n",
    "    \n",
    "    return avg_trainable_weights, avg_non_trainable_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7b89eee-d91f-4924-94d8-b2be803e5465",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def synchronize_clients2(server_model, client_models):\n",
    "    for client_model in client_models:\n",
    "        client_model.set_trainable_variables(server_model.trainable_variables)\n",
    "    \n",
    "    for client_model in client_models:\n",
    "        client_model.set_non_trainable_variables(server_model.non_trainable_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dd7a2c-3a41-452d-b1e2-2f5bf8ca6a82",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15e06a85-3d20-4e47-b35a-0d281994f3e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clients_train_synchronous(client_cnns, federated_dataset):\n",
    "    for client_cnn, client_dataset in zip(client_cnns, federated_dataset):\n",
    "        client_cnn.train(client_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ad95ae-4afb-498b-a791-7fa7eff244b4",
   "metadata": {},
   "source": [
    "# Data - models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d329d2e6-22b5-4f06-91a2-64485cabc350",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.densenet import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d13862ac-7521-4755-a436-780d2c3db7ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocess the input data\n",
    "X_train_dense = preprocess_input(X_train)\n",
    "X_test_dense = preprocess_input(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1649278e-b9f5-46ac-9d2f-cf2d172eebd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test_dense, y_test)).batch(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab23355f-dd98-4bc5-8cbf-a4f8c89f27a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fed_ds = prepare_federated_data(\n",
    "    create_unbiased_federated_data(X_train_dense, y_train, num_clients), batch_size, 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e6cf592-fcee-455e-b524-eabb9b5c61dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "server_cnn = DenseNet('DenseNet121')\n",
    "\n",
    "server_cnn.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(weight_decay=1e-4),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),  # we have softmax\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')]\n",
    ")\n",
    "\n",
    "server_cnn.build((None, 32, 32, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76446970-6aa6-4ab7-acc2-db651d6f990c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "server_cnn = DenseNet('DenseNet121')\n",
    "\n",
    "server_cnn.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(weight_decay=1e-4),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),  # we have softmax\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')]\n",
    ")\n",
    "\n",
    "server_cnn.build((None, 32, 32, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f48975b-bef8-4407-bf43-ffeef229947a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6964106"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_weights(server_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a173ae1-0bd4-4a54-8a39-c08dfddb1b25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "5c4ba208-dbff-4b1c-ab7c-3780a4ec4a68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the model\n",
    "client_cnns = [DenseNet('DenseNet121') for _ in range(num_clients)]\n",
    "server_cnn = DenseNet('DenseNet121')\n",
    "\n",
    "for cnn in client_cnns:\n",
    "    cnn.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(weight_decay=1e-4),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),  # we have softmax\n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')]\n",
    "    )\n",
    "    \n",
    "    cnn.build((None, 32, 32, 3))\n",
    "\n",
    "server_cnn.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(weight_decay=1e-4),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),  # we have softmax\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')]\n",
    ")\n",
    "\n",
    "server_cnn.build((None, 32, 32, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "81940ef6-b307-41c9-9f3a-fef854224c6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "steps_per_epoch = 50_000 / batch_size\n",
    "num_epochs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "bd93d911-2dfd-48ab-8249-272ddae0e882",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr_schedule = create_learning_rate_schedule(num_epochs, steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "1ce7fd58-a9c2-4ea5-82bc-aee792461b6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "server_cnn = get_compiled_and_built_densenet('DenseNet121', (None, 32, 32, 3), lr_schedule) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "4d23f510-7c02-416f-95de-8cff92336b3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1702379568.063747  312111 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 157s 368ms/step - loss: 2.0154 - accuracy: 0.3593 - val_loss: 31.3817 - val_accuracy: 0.3065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f25c1fd0c90>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server_cnn.fit(X_train_dense, y_train, batch_size=batch_size, validation_data=(X_test_dense, y_test), epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26acbdb8-45f6-4d96-9f9f-e72be4730d63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "server_cnn.optimizer.learning_rate.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e60c3e6-7cc9-42ab-84e6-d85009fcb153",
   "metadata": {},
   "source": [
    "# Train ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2476a3a-2e73-495c-b133-a9fc7e6d9dd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fdavg.models.miscellaneous import average_client_weights, synchronize_clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1239f0c0-f97d-410a-b375-3c7a50bc6da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cnn in client_cnns:\n",
    "    cnn.metrics[1].reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714b28ef-efd6-4585-a3e6-dbc4d49d3d9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "synchronize_clients2(server_cnn, client_cnns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fe8125-a365-4a64-a97b-79e2abd6ceab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for step in range(500):\n",
    "    \n",
    "    clients_train_synchronous(client_cnns, fed_ds)\n",
    "    \n",
    "    avg_trainable_weights = average_client_weights(client_cnns)\n",
    "    server_cnn.set_trainable_variables(avg_trainable_weights)\n",
    "    synchronize_clients(server_cnn, client_cnns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84d24e7-cce2-4231-9edb-d2222af394e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889ac2d9-da02-4c12-8c61-76b64e15df28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for var in server_cnn.non_trainable_variables:\n",
    "    if not 'bn' in var.name:\n",
    "        print(var.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f32982a-7b36-42e3-bb9a-fd66d5e11f05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client_cnns[1].evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27f5f00-01d0-46f7-a6c4-e24d659e8ba8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client_cnns[0].evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ae5f8f-861a-4efe-9fcb-a8803d3489ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "avg_trainable_weights, avg_non_trainable_weights = average_client_weights2(client_cnns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f31fadb-2106-4ad7-8fa5-54aa7f47bd7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "server_cnn.set_non_trainable_variables(avg_non_trainable_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5de03d-2e49-4e85-b026-e644d0b7a367",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdfacd6-158c-4b0a-8e6d-4fdca9e3c499",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "server_cnn.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20091f8-0817-4a7f-ad8a-3789b2f33a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e646698-daf5-4786-917b-8d2be9c11a7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16de36b0-bb73-4d50-8373-a49156df9a26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5546f6a7-bc6b-4932-9a51-9b6a6d0e82c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.reduce_mean([cnn.metrics[1].result() for cnn in client_cnns]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08118513-b169-436d-95a3-e1b2a60a7985",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.reduce_mean([cnn.metrics[0].result() for cnn in client_cnns]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f463a606-a5a8-4197-9035-d65b1113cccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cd22a6-fdfa-4810-9691-87e3246204bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843eff51-0844-465e-b038-fd2defad6152",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "server_cnn.evaluate(X_train_dense, y_train, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bc3638-ca93-4673-9b75-ca45dbd47c3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c755e2-87f1-4f1f-92f4-a4980a37ef87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "server_cnn.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc5b232-c668-4f05-a017-cdfbbc4dfd05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client_cnns[0].evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f151a81f-fdad-4f3d-aa9f-a7f36e019184",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client_cnns[1].evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef8d27b-ddda-4211-9266-02acef601308",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111c428f-450e-4526-8f7f-78e61d3f7284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb3492c-49a3-44a5-bd64-aa8932d5d278",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp = DenseNet('DenseNet121')\n",
    "\n",
    "tmp.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(weight_decay=1e-4),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),  # we have softmax\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')]\n",
    ")\n",
    "\n",
    "tmp.build((None, 32, 32, 3))\n",
    "\n",
    "avg_trainable_weights, avg_non_trainable_weights = average_client_weights2(client_cnns)\n",
    "tmp.set_trainable_variables(avg_trainable_weights)\n",
    "tmp.set_non_trainable_variables(avg_non_trainable_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233aef92-b9fc-4cb5-bdfb-484eb04c5fc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7bd2d3-c77a-4704-b853-6d2537f1cfc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4df91a-8003-4703-9d47-562471a97518",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def current_accuracy2(client_models, test_dataset, tmp_model):\n",
    "    avg_trainable_weights, avg_non_trainable_weights = average_client_weights2(client_models)\n",
    "    tmp_model.set_trainable_variables(avg_trainable_weights)\n",
    "    tmp_model.set_non_trainable_variables(avg_non_trainable_weights)\n",
    "    # Evaluate the temporary model on the test dataset\n",
    "    _, acc = tmp_model.evaluate(test_dataset, verbose=0)\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c803250c-ce02-45a6-b5a6-d8ba8f4e2e52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.prod([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aebb07c-2a4a-4ca1-b433-784aab1ca843",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "server_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06f35f4-495e-460f-8f35-b88badc8dc05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad36c59-8efe-4a42-85d2-722341d2b4e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84490eef-4e02-4d3b-9852-cd96bc09d1b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AdvancedCNN(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Advanced Convolutional Neural Network (CNN) for image classification.\n",
    "\n",
    "    Attributes:\n",
    "    - Layers for the CNN architecture (convolutional, pooling, dense layers, dropout layers).\n",
    "\n",
    "    Methods:\n",
    "    - call: Forward pass for the model.\n",
    "    - step: Compute and apply gradients for one training batch.\n",
    "    - train: Train the model on a dataset.\n",
    "    - set_trainable_variables: Set the trainable variables of the model.\n",
    "    - trainable_vars_as_vector: Return the trainable variables as a 1D tensor.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, cnn_input_reshape, num_classes):\n",
    "        \"\"\"\n",
    "        Initialize the advanced CNN model with given input shape and number of output classes.\n",
    "\n",
    "        Args:\n",
    "        - cnn_input_reshape (tuple): The shape to which the input should be reshaped. (e.g., (28, 28, 1))\n",
    "        - num_classes (int): Number of output classes.\n",
    "        \"\"\"\n",
    "        super(AdvancedCNN, self).__init__()\n",
    "        \n",
    "        self.reshape = tf.keras.layers.Reshape(cnn_input_reshape)\n",
    "        \n",
    "        self.conv1 = tf.keras.layers.Conv2D(64, kernel_size=3, activation='relu', padding='same')\n",
    "        self.conv2 = tf.keras.layers.Conv2D(64, kernel_size=3, activation='relu', padding='same')\n",
    "        self.max_pool1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        \n",
    "        self.conv3 = tf.keras.layers.Conv2D(128, kernel_size=3, activation='relu', padding='same')\n",
    "        self.conv4 = tf.keras.layers.Conv2D(128, kernel_size=3, activation='relu', padding='same')\n",
    "        self.max_pool2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        \n",
    "        self.conv5 = tf.keras.layers.Conv2D(256, kernel_size=3, activation='relu', padding='same')\n",
    "        self.conv6 = tf.keras.layers.Conv2D(256, kernel_size=3, activation='relu', padding='same')\n",
    "        self.max_pool3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(512, activation='relu')\n",
    "        self.dropout1 = tf.keras.layers.Dropout(0.5)\n",
    "        self.dense2 = tf.keras.layers.Dense(512, activation='relu')\n",
    "        self.dropout2 = tf.keras.layers.Dropout(0.5)\n",
    "        self.dense3 = tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        x = self.reshape(inputs)  # Add a channel dimension\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.max_pool1(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.max_pool2(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.max_pool3(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dropout1(x, training=training)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dropout2(x, training=training)\n",
    "        x = self.dense3(x)\n",
    "        return x\n",
    "        \n",
    "    def step(self, batch):\n",
    "        x_batch, y_batch = batch\n",
    "        return self.train_on_batch(x=x_batch, y=y_batch)\n",
    "       \n",
    "    def train(self, dataset):\n",
    "        for batch in dataset:\n",
    "            self.step(batch)\n",
    "\n",
    "    def set_trainable_variables(self, trainable_vars):\n",
    "        for model_var, var in zip(self.trainable_variables, trainable_vars):\n",
    "            model_var.assign(var)\n",
    "\n",
    "    def set_non_trainable_variables(self, non_trainable_vars):\n",
    "        for model_var, var in zip(self.non_trainable_variables, non_trainable_vars):\n",
    "            model_var.assign(var)\n",
    "\n",
    "    @tf.function\n",
    "    def trainable_vars_as_vector(self):\n",
    "        return tf.concat([tf.reshape(var, [-1]) for var in self.trainable_variables], axis=0)\n",
    "\n",
    "    def per_layer_trainable_vars_as_vector(self):\n",
    "\n",
    "        layer_vectors = [\n",
    "            tf.concat([tf.reshape(var, [-1]) for var in layer.trainable_weights], axis=0)\n",
    "            for layer in self.layers\n",
    "            if layer.trainable_weights\n",
    "        ]\n",
    "\n",
    "        return layer_vectors\n",
    "\n",
    "    def set_layer_weights(self, layer_i, weights):\n",
    "\n",
    "        for model_var, var in zip(self.layers[layer_i].trainable_weights, weights):\n",
    "            model_var.assign(var)\n",
    "\n",
    "    def get_trainable_layers_indices(self):\n",
    "\n",
    "        trainable_layers_idx = [\n",
    "            i for i, layer in enumerate(self.layers)\n",
    "            if layer.trainable_weights\n",
    "        ]\n",
    "\n",
    "        return trainable_layers_idx\n",
    "    \n",
    "\n",
    "def get_compiled_and_built_advanced_cnn(cnn_batch_input, cnn_input_reshape, num_classes):\n",
    "    advanced_cnn = AdvancedCNN(cnn_input_reshape, num_classes)\n",
    "    \n",
    "    advanced_cnn.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),  # we have softmax\n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')]\n",
    "    )\n",
    "    \n",
    "    advanced_cnn.build(cnn_batch_input)\n",
    "    \n",
    "    return advanced_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bbad5f-4eb5-4357-b3c9-b33bd3bf6702",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adv = get_compiled_and_built_advanced_cnn((None, 28, 28), (28, 28, 1), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e3b245-75d9-4b9c-9cdb-e784859a3868",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adv.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0d54c2-43f4-449c-bd53-7ed6c583fd3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64034576-9faf-4f59-afd6-fc08ebf1fd33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test = X_train / 255.0, X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11c7e93-3263-49af-ba8a-2bf81c38b915",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b49c8f0-476d-4f98-a985-ef2758bb9938",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(256).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2299fb8-c2d4-454f-adbc-e484d6ea2f15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adv.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9a5699-0c4c-4669-8a45-776d000e7b02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "it = iter(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed879bf5-f43d-4698-ad33-ab305a4da58b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "\n",
    "adv.step(next(it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d02917-2aff-44cd-996b-9cb4287848ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adv.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebb6871-e1b8-453f-9e17-d56e53417abb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d33a487-097b-4df3-a7c4-70c146c6ab02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "for _ in range(100):\n",
    "    adv.step(next(it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8555790c-86e0-4dd0-80cc-ed5ef3e6fbdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adv.metrics[1].reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617fc0ee-d568-4634-9aef-80f87c08a29f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adv.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491eeefb-aeec-4732-8c1e-3a86ed7ca32e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-2.14-gpu]",
   "language": "python",
   "name": "conda-env-tf-2.14-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
