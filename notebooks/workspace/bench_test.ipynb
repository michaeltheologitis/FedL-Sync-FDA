{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34977906-c342-427c-b7f9-974ba119f5ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "\n",
    "import tensorflow as tf\n",
    "        \n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "586ef3aa-cb2d-405d-859b-a1b66ef10376",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#os.environ['CUDA_VISIBLE_DEVICES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81ca8c26-b8cd-4873-a2fa-f4dc63958428",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class AdvancedCNN(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Advanced Convolutional Neural Network (CNN) for image classification.\n",
    "\n",
    "    Attributes:\n",
    "    - Layers for the CNN architecture (convolutional, pooling, dense layers, dropout layers).\n",
    "\n",
    "    Methods:\n",
    "    - call: Forward pass for the model.\n",
    "    - step: Compute and apply gradients for one training batch.\n",
    "    - train: Train the model on a dataset.\n",
    "    - set_trainable_variables: Set the trainable variables of the model.\n",
    "    - trainable_vars_as_vector: Return the trainable variables as a 1D tensor.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, cnn_input_reshape, num_classes):\n",
    "        \"\"\"\n",
    "        Initialize the advanced CNN model with given input shape and number of output classes.\n",
    "\n",
    "        Args:\n",
    "        - cnn_input_reshape (tuple): The shape to which the input should be reshaped. (e.g., (28, 28, 1))\n",
    "        - num_classes (int): Number of output classes.\n",
    "        \"\"\"\n",
    "        super(AdvancedCNN, self).__init__()\n",
    "        \n",
    "        self.reshape = tf.keras.layers.Reshape(cnn_input_reshape)\n",
    "        \n",
    "        self.conv1 = tf.keras.layers.Conv2D(64, kernel_size=3, activation='relu', padding='same')\n",
    "        self.conv2 = tf.keras.layers.Conv2D(64, kernel_size=3, activation='relu', padding='same')\n",
    "        self.max_pool1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        \n",
    "        self.conv3 = tf.keras.layers.Conv2D(128, kernel_size=3, activation='relu', padding='same')\n",
    "        self.conv4 = tf.keras.layers.Conv2D(128, kernel_size=3, activation='relu', padding='same')\n",
    "        self.max_pool2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        \n",
    "        self.conv5 = tf.keras.layers.Conv2D(256, kernel_size=3, activation='relu', padding='same')\n",
    "        self.conv6 = tf.keras.layers.Conv2D(256, kernel_size=3, activation='relu', padding='same')\n",
    "        self.max_pool3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(512, activation='relu')\n",
    "        self.dropout1 = tf.keras.layers.Dropout(0.5)\n",
    "        self.dense2 = tf.keras.layers.Dense(512, activation='relu')\n",
    "        self.dropout2 = tf.keras.layers.Dropout(0.5)\n",
    "        self.dense3 = tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        \"\"\"\n",
    "        Forward pass for the model.\n",
    "\n",
    "        Args:\n",
    "        - inputs (tf.Tensor): Input tensor (batch of images).\n",
    "        - training (bool, optional): Whether the forward pass is for training or inference.\n",
    "\n",
    "        Returns:\n",
    "        - tf.Tensor: Output tensor (batch of class probabilities).\n",
    "        \"\"\"\n",
    "        x = self.reshape(inputs)  # Add a channel dimension\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.max_pool1(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.max_pool2(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.max_pool3(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dropout1(x, training=training)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dropout2(x, training=training)\n",
    "        x = self.dense3(x)\n",
    "        return x\n",
    "\n",
    "    @tf.function\n",
    "    def step(self, batch):\n",
    "        \"\"\"\n",
    "        Perform one training step on a given batch of data.\n",
    "\n",
    "        Args:\n",
    "        - batch (tuple): A tuple containing two elements:\n",
    "            - x_batch (tf.Tensor): A batch of input data.\n",
    "            - y_batch (tf.Tensor): A batch of labels.\n",
    "\n",
    "        This method computes the gradients using backpropagation and updates the model's trainable parameters.\n",
    "        \"\"\"\n",
    "        x_batch, y_batch = batch\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass: Compute predictions\n",
    "            y_batch_pred = self(x_batch, training=True)\n",
    "\n",
    "            # Compute the loss value\n",
    "            loss = self.loss(y_batch, y_batch_pred)\n",
    "\n",
    "        # Compute gradients\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        \n",
    "        # Apply gradients to the model's trainable variables (update weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "       \n",
    "    def train(self, dataset):\n",
    "        \"\"\"\n",
    "        Train the model on an entire dataset.\n",
    "\n",
    "        Args:\n",
    "        - dataset (tf.data.Dataset): The dataset on which the model will be trained. \n",
    "        \"\"\"\n",
    "        for batch in dataset:\n",
    "            self.step(batch)\n",
    "            \n",
    "    def set_trainable_variables(self, trainable_vars):\n",
    "        \"\"\"\n",
    "        Set the model's trainable variables.\n",
    "\n",
    "        Args:\n",
    "        - trainable_vars (list of tf.Tensor): A list of tensors representing the trainable variables to be set.\n",
    "\n",
    "        This method sets each of the model's trainable variables to the corresponding tensor in `trainable_vars`.\n",
    "        \"\"\"\n",
    "        for model_var, var in zip(self.trainable_variables, trainable_vars):\n",
    "            model_var.assign(var)\n",
    "\n",
    "    def trainable_vars_as_vector(self):\n",
    "        \"\"\"\n",
    "        Get the model's trainable variables as a single vector.\n",
    "\n",
    "        Returns:\n",
    "        - tf.Tensor: A 1D tensor containing all of the model's trainable variables.\n",
    "        \"\"\"\n",
    "        return tf.concat([tf.reshape(var, [-1]) for var in self.trainable_variables], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class LeNet5(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    LeNet-5 model for image classification.\n",
    "\n",
    "    Attributes:\n",
    "    - Layers for the LeNet-5 architecture (convolutional, pooling, dense layers).\n",
    "\n",
    "    Methods:\n",
    "    - call: Forward pass for the model.\n",
    "    - step: Compute and apply gradients for one training batch.\n",
    "    - train: Train the model on a dataset.\n",
    "    - set_trainable_variables: Set the trainable variables of the model.\n",
    "    - trainable_vars_as_vector: Return the trainable variables as a 1D tensor.\n",
    "    \"\"\"\n",
    "    def __init__(self, cnn_input_reshape, num_classes):\n",
    "        \"\"\"\n",
    "        Initialize the LeNet-5 model with given input shape and number of output classes.\n",
    "\n",
    "        Args:\n",
    "        - cnn_input_reshape (tuple): The shape to which the input should be reshaped. (e.g., (28, 28, 1))\n",
    "        - num_classes (int): Number of output classes.\n",
    "        \"\"\"\n",
    "        \n",
    "        super(LeNet5, self).__init__()\n",
    "        \n",
    "        self.reshape = tf.keras.layers.Reshape(cnn_input_reshape)\n",
    "        \n",
    "        # Layer 1 Conv2D\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=6, kernel_size=(5, 5), strides=(1, 1), activation='tanh', padding='same')\n",
    "        # Layer 2 Pooling Layer\n",
    "        self.avgpool1 = tf.keras.layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid')\n",
    "        # Layer 3 Conv2D\n",
    "        self.conv2 = tf.keras.layers.Conv2D(filters=16, kernel_size=(5, 5), strides=(1, 1), activation='tanh', padding='valid')\n",
    "        # Layer 4 Pooling Layer\n",
    "        self.avgpool2 = tf.keras.layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid')\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(units=120, activation='tanh')\n",
    "        self.dense2 = tf.keras.layers.Dense(units=84, activation='tanh')\n",
    "        self.dense3 = tf.keras.layers.Dense(units=num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        \"\"\"\n",
    "        Forward pass for the model.\n",
    "\n",
    "        Args:\n",
    "        - inputs (tf.Tensor): Input tensor (batch of images).\n",
    "        - training (bool, optional): Whether the forward pass is for training.\n",
    "\n",
    "        Returns:\n",
    "        - x (tf.Tensor): Output tensor (batch of class probabilities).\n",
    "        \"\"\"\n",
    "        x = self.reshape(inputs)\n",
    "        x = self.conv1(x)\n",
    "        x = self.avgpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.avgpool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    @tf.function\n",
    "    def step(self, batch):\n",
    "        \"\"\"\n",
    "        Perform one training step on a given batch of data.\n",
    "\n",
    "        Args:\n",
    "        - batch (tuple): A tuple containing two elements:\n",
    "            - x_batch (tf.Tensor): A batch of input data.\n",
    "            - y_batch (tf.Tensor): A batch of labels.\n",
    "\n",
    "        This method computes the gradients using backpropagation and updates the model's trainable parameters.\n",
    "        \"\"\"\n",
    "\n",
    "        x_batch, y_batch = batch\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass: Compute predictions\n",
    "            y_batch_pred = self(x_batch, training=True)\n",
    "\n",
    "            # Compute the loss value\n",
    "            loss = self.loss(y_batch, y_batch_pred)\n",
    "\n",
    "        # Compute gradients\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        \n",
    "        # Apply gradients to the model's trainable variables (update weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "\n",
    "    def train(self, dataset):\n",
    "        \"\"\"\n",
    "        Train the model on an entire dataset.\n",
    "\n",
    "        Args:\n",
    "        - dataset (tf.data.Dataset): The dataset on which the model will be trained. \n",
    "        \"\"\"\n",
    "        for batch in dataset:\n",
    "            self.step(batch)\n",
    "\n",
    "    def set_trainable_variables(self, trainable_vars):\n",
    "        \"\"\"\n",
    "        Set the model's trainable variables.\n",
    "\n",
    "        Args:\n",
    "        - trainable_vars (list of tf.Tensor): A list of tensors representing the trainable variables to be set.\n",
    "\n",
    "        This method sets each of the model's trainable variables to the corresponding tensor in `trainable_vars`.\n",
    "        \"\"\"\n",
    "        for model_var, var in zip(self.trainable_variables, trainable_vars):\n",
    "            model_var.assign(var)\n",
    "\n",
    "    def trainable_vars_as_vector(self):\n",
    "        \"\"\"\n",
    "        Get the model's trainable variables as a single vector.\n",
    "\n",
    "        Returns:\n",
    "        - tf.Tensor: A 1D tensor containing all of the model's trainable variables.\n",
    "        \"\"\"\n",
    "        return tf.concat([tf.reshape(var, [-1]) for var in self.trainable_variables], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fb6a999-b5c3-4fb8-9d88-a7342ac9707f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MNIST_CNN_BATCH_INPUT = (None, 28, 28)  # EMNIST dataset (None is used for batch size, as it varies)\n",
    "MNIST_CNN_INPUT_RESHAPE = (28, 28, 1)\n",
    "MNIST_N_TRAIN = 60_000\n",
    "\n",
    "\n",
    "def mnist_load_data():\n",
    "    (X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "    X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98c2e163-2ccc-4e28-980a-8bd3e005f1c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For MNIST\n",
    "advanced_cnn = AdvancedCNN(\n",
    "    cnn_input_reshape=(28, 28, 1), \n",
    "    num_classes=10\n",
    ")\n",
    "\n",
    "advanced_cnn.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),  # we have softmax\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')]\n",
    ")\n",
    "\n",
    "# For MNIST\n",
    "lenet5 = LeNet5(\n",
    "    cnn_input_reshape=(28, 28, 1), \n",
    "    num_classes=10\n",
    ")\n",
    "\n",
    "lenet5.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),  # we have softmax\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6eac9f-24a4-4357-aebe-f1fdd527ddf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b03152-fa9c-473f-857d-42e83f5032fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66a82cdb-4644-4905-bbef-fc7352a93764",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "793f57c9-3b9f-432f-a2bc-5632d015809b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def norma(bs, time_sec, n_train=60_000):\n",
    "    return time_sec * 1000 / (n_train / bs) # ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "279e0e2f-84b5-45fc-bdac-94629d0c9653",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = mnist_load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82697224",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f78180e6c50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advanced_cnn.fit(x=X_train, y=y_train, batch_size=32, epochs=1, verbose=0)\n",
    "advanced_cnn.fit(x=X_train, y=y_train, batch_size=64, epochs=1, verbose=0)\n",
    "advanced_cnn.fit(x=X_train, y=y_train, batch_size=128, epochs=1, verbose=0)\n",
    "advanced_cnn.fit(x=X_train, y=y_train, batch_size=256, epochs=1, verbose=0)\n",
    "lenet5.fit(x=X_train, y=y_train, batch_size=32, epochs=1, verbose=0)\n",
    "lenet5.fit(x=X_train, y=y_train, batch_size=64, epochs=1, verbose=0)\n",
    "lenet5.fit(x=X_train, y=y_train, batch_size=128, epochs=1, verbose=0)\n",
    "lenet5.fit(x=X_train, y=y_train, batch_size=256, epochs=1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608ec257",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226ae2fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9127a8d5-64c0-4076-a34e-e56da9dacca2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5min 18s ± 3.37 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "advanced_cnn.fit(x=X_train, y=y_train, batch_size=32, epochs=20, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce2ec5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "318"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5 * 60 + 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4951a94-5dcf-4bac-b1ac-c457eff9e614",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.48"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norma(bs=32, time_sec=318, n_train=20*60_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80f1a2b8-7d60-450e-918a-d1b0a84cb4a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08986666666666666"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norma(bs=32, time_sec=3.37, n_train=20*60_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7ef8119-b844-4bb1-b205-853aa49371c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3min 2s ± 840 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "advanced_cnn.fit(x=X_train, y=y_train, batch_size=64, epochs=20, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03f944f5-5dbc-432f-896d-a6430a20b18d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3 * 60 + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84328780-b412-4130-ac7b-513a22458981",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.706666666666667"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norma(bs=64, time_sec=182, n_train=20*60_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71ff7950-de56-4799-bcf9-049fa2f6b98f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0448"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norma(bs=64, time_sec=0.84, n_train=20*60_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21989e3f-d623-4765-b018-d131688efabe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 40s ± 296 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "advanced_cnn.fit(x=X_train, y=y_train, batch_size=128, epochs=20, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60dadcc8-49f6-45bd-a03e-73486d2e4629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.666666666666666"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norma(bs=128, time_sec=100, n_train=20*60_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e772e9d-ca32-4d99-b505-784adde819a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.031573333333333335"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norma(bs=128, time_sec=0.296, n_train=20*60_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "444e2764-a494-4eaf-8e0e-fc55c5ebc6fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 10s ± 249 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "advanced_cnn.fit(x=X_train, y=y_train, batch_size=256, epochs=20, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb5e5765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.933333333333334"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norma(bs=256, time_sec=70, n_train=20*60_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc933044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05312"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norma(bs=256, time_sec=0.249, n_train=20*60_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ce31d6-8619-4dfd-9e02-9305c40f3f00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50a9ded-a5bd-4529-9f74-453037f6e2f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81ad2ed-3248-42eb-87d5-3958a480673e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d0641d-6535-44b4-9932-78fb2481111c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb9fbc26-ab21-4658-a842-ac424de0787c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3min 50s ± 1.51 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "lenet5.fit(x=X_train, y=y_train, batch_size=32, epochs=20, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb512dda-2442-48fb-940c-75c9541c2ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "230"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3 * 60 + 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e75d7971-60ed-4442-8456-aca7e97e172e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.133333333333334"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norma(bs=32, time_sec=230, n_train=20*60_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ffdbd0c-d17c-491c-8bf0-c2b183238f78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.040266666666666666"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norma(bs=32, time_sec=1.51, n_train=20*60_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9603a47b-350e-4b96-9a46-9a9d3ac1254e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefde4e3-42e6-49bc-94e5-4988ffb35b28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "538bb6b5-7792-4f0e-8a50-4c619d1cc144",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2min 10s ± 765 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "lenet5.fit(x=X_train, y=y_train, batch_size=64, epochs=20, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1be772c8-9ce3-427c-9f75-2c3d7a56647c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.933333333333334"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norma(bs=64, time_sec=130, n_train=20*60_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e6cc0c6-36c3-49bd-9b3c-7c9cbaa5fec0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0408"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norma(bs=64, time_sec=0.765, n_train=20*60_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf73b6e6-cf76-42f8-a2df-5fee2ccd379b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd20763e-e844-4eb7-8a64-a5af3d1f2350",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171ac9dc-b26e-488b-9379-37e9dc96906f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c44db50a-e207-4ce8-be19-10d64594ab58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 6s ± 447 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "lenet5.fit(x=X_train, y=y_train, batch_size=128, epochs=20, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7abc8174-f249-4fd1-884b-0d596d37ed55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.04"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norma(bs=128, time_sec=66, n_train=20*60_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7062a661-4070-47c8-9273-e86f59054597",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04768"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norma(bs=128, time_sec=0.447, n_train=20*60_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7734c900-5238-46a2-b01a-ceaaadab9a22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d603ab2-a29e-43e6-881f-e4566e25d9f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.1 s ± 399 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "lenet5.fit(x=X_train, y=y_train, batch_size=256, epochs=20, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2ab09691-fa16-46c5-b697-132b0489d295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.274666666666667"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norma(bs=256, time_sec=34.1, n_train=20*60_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "278d8568-436c-4645-9bd2-1c9fc615671e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08512"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norma(bs=256, time_sec=0.399, n_train=20*60_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0906f2-41cb-4f8e-83ea-9d8717dda62f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-2.13-gpu]",
   "language": "python",
   "name": "conda-env-tf-2.13-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
