{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb14bd07-1ed9-48b8-b555-f273d9b94262",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b7ca59-4fed-437b-9b1f-88410e5227a0",
   "metadata": {},
   "source": [
    "## Load EMNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "934bad8d-9fd1-4f3c-89a7-764afea7bf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    (X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "    X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "888e05f9-a0d9-4a14-ad41-d3bf95983a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_BATCH_INPUT = (None, 28, 28) # EMNIST dataset (None is used for batch size, as it varies)\n",
    "CNN_INPUT_RESHAPE = (28, 28, 1)\n",
    "n_train = 60_000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2c674a-86f0-439a-acac-5b7361cb1bb3",
   "metadata": {},
   "source": [
    "## Prepare data for Federated Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc922c51-3415-47d2-89aa-20917d7a7e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tf_dataset(X_train, y_train, X_test, y_test):\n",
    "    # Convert to TensorFlow Datasets\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(256)\n",
    "\n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542046e6-8dce-46e8-8b37-89be77a65714",
   "metadata": {},
   "source": [
    "### Slice the Tensors for each Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbad50b0-6a74-40f2-90ff-ddbfca571052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_federated_data_for_clients(num_clients, train_dataset):\n",
    "    \n",
    "    # Shard the data across clients CLIENT LEVEL\n",
    "    client_datasets = [\n",
    "        train_dataset.shard(num_clients, i)\n",
    "        for i in range(num_clients)\n",
    "    ]\n",
    "    \n",
    "    return client_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85eecedc-e51d-462f-ab03-92c0131a4ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_federated_data_for_test(federated_data, batch_size, num_steps_until_rtc_check=1, seed=None):\n",
    "    \n",
    "    def process_client_dataset(client_dataset, batch_size, num_steps_until_rtc_check, seed, shuffle_size=512):\n",
    "        return client_dataset.shuffle(shuffle_size, seed=seed).repeat().batch(batch_size)\\\n",
    "            .take(num_steps_until_rtc_check).prefetch(tf.data.AUTOTUNE)\n",
    "        \n",
    "    federated_dataset_prepared = [\n",
    "        process_client_dataset(client_dataset, batch_size, num_steps_until_rtc_check, seed)\n",
    "        for client_dataset in federated_data\n",
    "    ]\n",
    "    return federated_dataset_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d68e84-955d-4b12-9058-b7442632132f",
   "metadata": {},
   "source": [
    "# Simple Convolutional Neural Net (CNN) - Medium Size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53997727-a02d-4bb9-9074-961db9fffc14",
   "metadata": {},
   "source": [
    "A simple Convolutional Neural Network with a single convolutional layer, followed by a max-pooling layer, and two dense layers for classification. Designed for 28x28 grayscale images. It has 692,352 weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c86044de-7ece-47a3-82b1-068df850e73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(tf.keras.Model):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.reshape = layers.Reshape(CNN_INPUT_RESHAPE)\n",
    "        self.conv1 = layers.Conv2D(32, 3, activation='relu')\n",
    "        self.max_pool = layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.dense1 = layers.Dense(128, activation='relu')\n",
    "        self.dense2 = layers.Dense(num_classes, activation='softmax')\n",
    "\n",
    "        \n",
    "    # Defines the computation from inputs to outputs\n",
    "    def call(self, inputs, training=None):\n",
    "        x = self.reshape(inputs)  # Add a channel dimension\n",
    "        x = self.conv1(x)\n",
    "        x = self.max_pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def step(self, batch):\n",
    "        \n",
    "        x_batch, y_batch = batch\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass: Compute predictions\n",
    "            y_batch_pred = self(x_batch, training=True)\n",
    "\n",
    "            # Compute the loss value\n",
    "            # (the loss function is configured in `compile()`)\n",
    "            loss = self.compiled_loss(\n",
    "                y_true=y_batch,\n",
    "                y_pred=y_batch_pred,\n",
    "                regularization_losses=self.losses\n",
    "            )\n",
    "\n",
    "        # Compute gradients\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        \n",
    "        # Apply gradients to the model's trainable variables (update weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        \n",
    "        # Update metrics (includes the metric that tracks the loss)\n",
    "        #self.compiled_metrics.update_state(y_batch, y_batch_pred)\n",
    "    \n",
    "    \n",
    "    def train(self, dataset):\n",
    "\n",
    "        for batch in dataset:\n",
    "            self.step(batch)\n",
    "            \n",
    "    \n",
    "    def set_trainable_variables(self, trainable_vars):\n",
    "        \"\"\" Given `trainable_vars` set our `self.trainable_vars` \"\"\"\n",
    "        for model_var, var in zip(self.trainable_variables, trainable_vars):\n",
    "            model_var.assign(var)\n",
    "\n",
    "            \n",
    "    def trainable_vars_as_vector(self):\n",
    "        return tf.concat([tf.reshape(var, [-1]) for var in self.trainable_variables], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87edfc16-7cd2-4096-83fb-cc7c662acc03",
   "metadata": {},
   "source": [
    "### Helper function to compile and return the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0e87f0-0102-499c-9f29-807489153e6f",
   "metadata": {},
   "source": [
    "**Important** function that returns a compiled and built `SimpleCNN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "96fc99a5-8dbb-4bef-9a0f-2325e8a11171",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_and_built_simple_cnn():\n",
    "    cnn = SimpleCNN()\n",
    "    \n",
    "    cnn.compile(\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False), # we have softmax\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')]\n",
    "    )\n",
    "    \n",
    "    cnn.build(CNN_BATCH_INPUT)  # EMNIST dataset (None is used for batch size, as it varies)\n",
    "    \n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a3dafe-6ee7-41dc-8ebf-ffc3806c2229",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ace19942-c3f6-41eb-afb3-2233f1dcf17d",
   "metadata": {},
   "source": [
    "Helper function that creates a new `AdvancedCNN` just to compute and return accuracy. Will be used in-between epochs so we keep correct metrics without synchronizing and messing up the federated training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9e2ec63-d0fe-4fb0-9d7f-bcd834cb9d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def current_accuracy_simple_cnn(client_cnns, test_dataset):\n",
    "    \n",
    "    tmp_cnn = get_compiled_and_built_simple_cnn()\n",
    "    tmp_cnn.set_trainable_variables(average_client_weights(client_cnns))\n",
    "    _, acc = tmp_cnn.evaluate(test_dataset, verbose=0)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3cfd3d-e4bc-4457-bcb9-7469779c5437",
   "metadata": {},
   "source": [
    "### Client Train\n",
    "\n",
    "The number of steps depends on the dataset, i.e., `.take(num)` call on `tf.data.Dataset` creation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37a0acbe-9afb-4c79-897c-fbcae06a4f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_train_naive(w_t0, client_cnn, client_dataset):\n",
    "    \"\"\"\n",
    "    :param w_t0: Vector Tensor shape=(d,). Same shape with `client_cnn.trainable_vars_as_vector()`\n",
    "    :return: Tensor shape=() dtype=tf.float32\n",
    "    \"\"\"\n",
    "    \n",
    "    # number of steps depend on `.take()` from `dataset`\n",
    "    client_cnn.train(client_dataset)\n",
    "    \n",
    "    Delta_i = client_cnn.trainable_vars_as_vector() - w_t0\n",
    "    \n",
    "    #||D(t)_i||^2 , shape = () \n",
    "    Delta_i_euc_norm_squared = tf.reduce_sum(tf.square(Delta_i)) # ||D(t)_i||^2\n",
    "    \n",
    "    return Delta_i_euc_norm_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ba997e-94a7-47e1-afaa-4eca1679194c",
   "metadata": {},
   "source": [
    "### Train all Clients\n",
    "\n",
    "Notes about the following potentialy general `tf.function`:\n",
    "\n",
    "1. Even though `clients_cnn` and `federated_dataset` contain `tf.Keras.Module` and `tf.data.Dataset` elements, they both are python lists (python side-effects). Take a look at [Looping Over Python data](https://www.tensorflow.org/guide/function#tracing) and afterwards [For example, the following loop is unrolled, even though the list contains ...](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/control_flow.md#while-statements) to get more insight.\n",
    "\n",
    "2. TL;DR: It is very-very bad in terms of RAM. It produces an unrolled loop. The graph becomes consequent `Delta_i_... = ... ; S_i_clients.append(...) ;` commands `len(client_cnns)` number of times. This produces a huge graph (for instance, for `NUM_CLIENTS`=8, 4GB graph is produced). Notice that each sequence of the two commands has a big (unseen) underlying graph going to the bottom, that is, `.step` in the `tf.Keras.Module` class!\n",
    "\n",
    "3. Even if we had endless RAM the usage of `tf.function` is still arguable. For instance, on testing for 16 clients the difference between the two is only 20-30ms with total execution time in the order of 200-250ms. Only if we had a huge amount of CPUs or GPU we could consider it, but still... there must be a better approach (`Dask` or a different implementation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6122a3d-2c6a-4fd9-91bf-d27c31903983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clients_train_naive(w_t0, client_cnns, federated_dataset):\n",
    "    \"\"\"\n",
    "    :param w_t0: Vector Tensor shape=(d,). Same shape with `client_cnns[i].trainable_vars_as_vector()`\n",
    "    :return: List of `Tensor shape=() dtype=tf.float32`, one for each `client_cnn` in `client_cnns`.\n",
    "    \"\"\"\n",
    "    \n",
    "    S_i_clients = []\n",
    "\n",
    "    for client_cnn, client_dataset in zip(client_cnns, federated_dataset):\n",
    "        Delta_i_euc_norm_squared = client_train_naive(w_t0, client_cnn, client_dataset)\n",
    "        S_i_clients.append(Delta_i_euc_norm_squared)\n",
    "    \n",
    "    return S_i_clients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2ef20f-3bf0-4da3-a541-8ff496b696be",
   "metadata": {},
   "source": [
    "### Identity F Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a358a8b7-a84a-4a26-a919-d346c59455ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_naive(S_i_clients):\n",
    "    \"\"\" :return: Tensor shape=() dtype=tf.float32 , Naive variance approximation \"\"\"\n",
    "    \n",
    "    S = tf.reduce_mean(S_i_clients)\n",
    "    \n",
    "    return S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47847b6-236d-4b44-b124-ea9da7934f16",
   "metadata": {},
   "source": [
    "### Testing Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e247843e-2d7a-466a-a75c-2f5fd85c5388",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_for_federated_simulation(num_clients, train_dataset, batch_size, num_steps_until_rtc_check=1, seed=None, bench_test=False):\n",
    "    \n",
    "    # 1. Helper variable to count Epochs\n",
    "    if bench_test:\n",
    "        fda_steps_in_one_epoch = 10\n",
    "    else:\n",
    "        fda_steps_in_one_epoch = ((n_train / batch_size) / num_clients) / num_steps_until_rtc_check\n",
    "    \n",
    "    # 2. Federated Dataset creation\n",
    "    clients_federated_data = create_federated_data_for_clients(num_clients, train_dataset)\n",
    "    federated_dataset = prepare_federated_data_for_test(clients_federated_data, batch_size)\n",
    "    \n",
    "    # 3. Models creation\n",
    "    server_cnn = get_compiled_and_built_simple_cnn()\n",
    "    client_cnns = [get_compiled_and_built_simple_cnn() for _ in range(num_clients)]\n",
    "    \n",
    "    return server_cnn, client_cnns, federated_dataset, fda_steps_in_one_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae89a0c-5d08-41e6-83fd-ac72977ac473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1b686ec-893c-4677-8aae-58ab8bea66c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = convert_to_tf_dataset(*load_data())\n",
    "\n",
    "server_cnn, client_cnns, federated_dataset, fda_steps_in_one_epoch = prepare_for_federated_simulation(\n",
    "    num_clients=5, \n",
    "    train_dataset=train_dataset, \n",
    "    batch_size=32\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d45e78-df1b-43d4-970b-f20cf8453805",
   "metadata": {},
   "source": [
    "This function provides the most importand functionality to achieve high parallelism. Given a list of client NN weights\n",
    "and a list of client datasets (1-1 correspondance) we store each client's information (the weights and the batch) inside\n",
    "a unifying `tf.data.Dataset` and return it.\n",
    "    \n",
    "This is extremely importand because, quoting [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/control_flow.md#while-statements), \"`for` statements that iterate over a `tf.data.Dataset` and which do not contain `break` or `return` statements are executed as TensorFlow loops by converting them to `tf.data.Dataset.reduce` ops\"!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad26dcb8-44c0-4363-9168-28a03e822db3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transform_to_single_ds(weights_of_clients, federated_dataset):\n",
    "    \"\"\" \n",
    "    :param: weights_of_clients: A list where the i-th element is client_cnn[i].get_weights()\n",
    "    :param: federated_dataset: A list where the i-th element is a `_PrefetchDataset` (`.take(1)`) of the sharded\n",
    "        i-th client's dataset.\n",
    "    :returns: A single `tf.data.Dataset` with k elements, where k the number of clients, where each element is\n",
    "        (client_weights, client_batch). \n",
    "    \"\"\"\n",
    "    weights_batches_ds = None\n",
    "    \n",
    "    for client_weights, client_batch in zip(weights_of_clients, federated_dataset):\n",
    "    \n",
    "        if weights_batches_ds is None:\n",
    "\n",
    "            client_weights_ds = tf.data.Dataset.from_tensors((*client_weights, ))\n",
    "            weights_batches_ds = tf.data.Dataset.zip((client_weights_ds, client_batch))\n",
    "\n",
    "        else:\n",
    "\n",
    "            # Create a `Dataset` with a single element comprising of the client cnn layers' weights\n",
    "            client_weights_ds = tf.data.Dataset.from_tensors((*client_weights, ))\n",
    "\n",
    "            # Zip together the information of the client weights along with its dataset (_Prefetch)\n",
    "            client_weights_batch_ds = tf.data.Dataset.zip((client_weights_ds, client_batch))\n",
    "\n",
    "            # Concatenate the above with the rest of the clients\n",
    "            weights_batches_ds = weights_batches_ds.concatenate(client_weights_batch_ds)\n",
    "    \n",
    "    return weights_batches_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e82d232-43d3-4fbe-a3e0-a35e8912c811",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fa044c7-ae70-4181-813d-2da90d84b180",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weights_of_clients = [client_cnn.get_weights() for client_cnn in client_cnns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d4bec2d-65ea-4fa7-b687-a85d0f255e1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weights_batches_ds = transform_to_single_ds(weights_of_clients, federated_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386e89d6-585b-481b-9b4f-d247b6b7458b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e3952484-3268-4705-ab1a-e3b98b7bac99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def client_step(client_weights, client_batch):\n",
    "    \n",
    "    cnn = get_compiled_and_built_simple_cnn()\n",
    "    \n",
    "    weights = [w for w in client_weights]\n",
    "    \n",
    "    cnn.set_weights(weights)\n",
    "    \n",
    "    \n",
    "    return client_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b50762bb-5ed1-40ff-9e8a-246b5bddd899",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "in user code:\n\n    File \"/tmp/ipykernel_47754/2618185590.py\", line 7, in client_step  *\n        cnn.set_weights(weights)\n    File \"/home/miketheologitis/anaconda3/envs/tf-2.12/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1835, in set_weights  **\n        backend.batch_set_value(weight_value_tuples)\n    File \"/home/miketheologitis/anaconda3/envs/tf-2.12/lib/python3.9/site-packages/keras/backend.py\", line 4311, in batch_set_value\n        value = np.asarray(value, dtype=dtype_numpy(x))\n\n    NotImplementedError: Cannot convert a symbolic tf.Tensor (args_0:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m updated_weights_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mweights_batches_ds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_step\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-2.12/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:2240\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2236\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops -> map_op ->\u001b[39;00m\n\u001b[1;32m   2237\u001b[0m \u001b[38;5;66;03m# dataset_ops).\u001b[39;00m\n\u001b[1;32m   2238\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[1;32m   2239\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m map_op\n\u001b[0;32m-> 2240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmap_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2241\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2242\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2243\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2245\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-2.12/lib/python3.9/site-packages/tensorflow/python/data/ops/map_op.py:37\u001b[0m, in \u001b[0;36m_map_v2\u001b[0;34m(input_dataset, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m debug_mode\u001b[38;5;241m.\u001b[39mDEBUG_MODE:\n\u001b[1;32m     35\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     36\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`num_parallel_calls` argument is specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MapDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_cardinality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _ParallelMapDataset(\n\u001b[1;32m     41\u001b[0m       input_dataset,\n\u001b[1;32m     42\u001b[0m       map_func,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m       preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     46\u001b[0m       name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-2.12/lib/python3.9/site-packages/tensorflow/python/data/ops/map_op.py:107\u001b[0m, in \u001b[0;36m_MapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_inter_op_parallelism \u001b[38;5;241m=\u001b[39m use_inter_op_parallelism\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality \u001b[38;5;241m=\u001b[39m preserve_cardinality\n\u001b[0;32m--> 107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_legacy_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_legacy_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m    113\u001b[0m variant_tensor \u001b[38;5;241m=\u001b[39m gen_dataset_ops\u001b[38;5;241m.\u001b[39mmap_dataset(\n\u001b[1;32m    114\u001b[0m     input_dataset\u001b[38;5;241m.\u001b[39m_variant_tensor,  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    118\u001b[0m     preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality,\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_common_args)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-2.12/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:261\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    255\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    256\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    257\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    258\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    259\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m--> 261\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m    263\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-2.12/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:232\u001b[0m, in \u001b[0;36mTracingCompiler.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    224\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \n\u001b[1;32m    226\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;124;03m      `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    235\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-2.12/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:202\u001b[0m, in \u001b[0;36mTracingCompiler._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_spec\u001b[38;5;241m.\u001b[39mmake_canonicalized_monomorphic_type(args, kwargs)\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 202\u001b[0m   concrete_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_concrete_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m   seen_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m    204\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_arg_keywords \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-2.12/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:166\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_concrete_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m   args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    164\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-2.12/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:396\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m   args \u001b[38;5;241m=\u001b[39m placeholder_bound_args\u001b[38;5;241m.\u001b[39margs\n\u001b[1;32m    394\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m placeholder_bound_args\u001b[38;5;241m.\u001b[39mkwargs\n\u001b[0;32m--> 396\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;66;03m# TODO(b/263520817): Remove access to private attribute.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m concrete_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39m_function_captures  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-2.12/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:300\u001b[0m, in \u001b[0;36mTracingCompiler._create_concrete_function\u001b[0;34m(self, args, kwargs, func_graph)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m   arg_names \u001b[38;5;241m=\u001b[39m base_arg_names\n\u001b[1;32m    299\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m monomorphic_function\u001b[38;5;241m.\u001b[39mConcreteFunction(\n\u001b[0;32m--> 300\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m,\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[1;32m    313\u001b[0m     spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m    318\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-2.12/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1214\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1212\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1214\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-2.12/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:238\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;129m@eager_function\u001b[39m\u001b[38;5;241m.\u001b[39mdefun_with_attributes(\n\u001b[1;32m    233\u001b[0m     input_signature\u001b[38;5;241m=\u001b[39mstructure\u001b[38;5;241m.\u001b[39mget_flat_tensor_specs(\n\u001b[1;32m    234\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_structure),\n\u001b[1;32m    235\u001b[0m     autograph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    236\u001b[0m     attributes\u001b[38;5;241m=\u001b[39mdefun_kwargs)\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[0;32m--> 238\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mwrapper_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m   ret \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_structure, ret)\n\u001b[1;32m    240\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ret]\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-2.12/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:169\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[1;32m    168\u001b[0m   nested_args \u001b[38;5;241m=\u001b[39m (nested_args,)\n\u001b[0;32m--> 169\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_ctx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnested_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m ret \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(ret)\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_pack(ret):\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-2.12/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:692\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 692\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m    693\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    694\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-2.12/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-2.12/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filevvaddprg.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__client_step\u001b[0;34m(client_weights, client_batch)\u001b[0m\n\u001b[1;32m     10\u001b[0m cnn \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(get_compiled_and_built_simple_cnn), (), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     11\u001b[0m weights \u001b[38;5;241m=\u001b[39m [ag__\u001b[38;5;241m.\u001b[39mld(w) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mld(client_weights)]\n\u001b[0;32m---> 12\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcnn\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-2.12/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[1;32m    330\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: from cache\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n\u001b[0;32m--> 331\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx()\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m ag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDISABLED:\n\u001b[1;32m    334\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: AutoGraph is disabled in context\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-2.12/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-2.12/lib/python3.9/site-packages/keras/engine/base_layer.py:1835\u001b[0m, in \u001b[0;36mLayer.set_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m   1832\u001b[0m         weight_value_tuples\u001b[38;5;241m.\u001b[39mappend((param, weight))\n\u001b[1;32m   1833\u001b[0m         weight_index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1835\u001b[0m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_set_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight_value_tuples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1837\u001b[0m \u001b[38;5;66;03m# Perform any layer defined finalization of the layer state.\u001b[39;00m\n\u001b[1;32m   1838\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flatten_layers():\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-2.12/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-2.12/lib/python3.9/site-packages/keras/backend.py:4311\u001b[0m, in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   4309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mor\u001b[39;00m tf\u001b[38;5;241m.\u001b[39minside_function():\n\u001b[1;32m   4310\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x, value \u001b[38;5;129;01min\u001b[39;00m tuples:\n\u001b[0;32m-> 4311\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4312\u001b[0m         _assign_value_to_variable(x, value)\n\u001b[1;32m   4313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: in user code:\n\n    File \"/tmp/ipykernel_47754/2618185590.py\", line 7, in client_step  *\n        cnn.set_weights(weights)\n    File \"/home/miketheologitis/anaconda3/envs/tf-2.12/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1835, in set_weights  **\n        backend.batch_set_value(weight_value_tuples)\n    File \"/home/miketheologitis/anaconda3/envs/tf-2.12/lib/python3.9/site-packages/keras/backend.py\", line 4311, in batch_set_value\n        value = np.asarray(value, dtype=dtype_numpy(x))\n\n    NotImplementedError: Cannot convert a symbolic tf.Tensor (args_0:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported.\n"
     ]
    }
   ],
   "source": [
    "updated_weights_dataset = weights_batches_ds.map(\n",
    "    client_step\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "99998015-129f-46a2-8ba2-61146c530d7e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[-0.09867188,  0.14038436,  0.04368007,  0.10912751,\n",
       "           -0.13217494,  0.12761752,  0.11392225, -0.14094844,\n",
       "            0.05158406, -0.02202985, -0.03674391,  0.00636083,\n",
       "            0.08236691, -0.00184546, -0.06704932,  0.06318627,\n",
       "           -0.09771751, -0.03474028,  0.05229424, -0.08579065,\n",
       "           -0.03078154,  0.08751979, -0.03356294,  0.11475404,\n",
       "            0.12217663,  0.13530181,  0.04078162,  0.02428082,\n",
       "            0.04578532,  0.13023688, -0.12828481,  0.07579209]],\n",
       " \n",
       "         [[ 0.12486617, -0.05201104,  0.06867196,  0.1381575 ,\n",
       "           -0.07834218,  0.02061407, -0.06158811, -0.06629313,\n",
       "            0.06348149, -0.1225654 , -0.0386292 , -0.06996137,\n",
       "            0.09493688,  0.05410103, -0.13650358,  0.0615605 ,\n",
       "           -0.10308299,  0.03784294, -0.09747477,  0.06917003,\n",
       "            0.1345068 ,  0.0225428 ,  0.01310159, -0.11230831,\n",
       "            0.03261822,  0.08617488, -0.03707909, -0.06101545,\n",
       "           -0.07096687, -0.01604684, -0.13965279,  0.06104001]],\n",
       " \n",
       "         [[-0.08185064, -0.05892314, -0.02915921,  0.11688964,\n",
       "            0.08007522, -0.07208329,  0.06539789, -0.03750952,\n",
       "            0.029882  ,  0.05825268,  0.01138268,  0.12338962,\n",
       "            0.11824541, -0.05369195, -0.12404425, -0.00395428,\n",
       "            0.13196601,  0.03397799,  0.07811484, -0.13946427,\n",
       "           -0.0684625 ,  0.00888655, -0.1088638 , -0.14212422,\n",
       "           -0.03272772, -0.01403174,  0.01278691,  0.04512066,\n",
       "           -0.13662045, -0.00253728, -0.08298041,  0.11062478]]],\n",
       " \n",
       " \n",
       "        [[[-0.04544736, -0.11192352,  0.14010192,  0.11051609,\n",
       "           -0.09611362, -0.12257756,  0.10069235,  0.10894768,\n",
       "            0.11114706,  0.13719802,  0.10552494, -0.11070137,\n",
       "           -0.00165915, -0.04558569, -0.11003369, -0.0996885 ,\n",
       "           -0.06765713, -0.0770973 , -0.05417752, -0.00786009,\n",
       "           -0.10088716, -0.05413523, -0.12906337, -0.08319972,\n",
       "            0.01818748,  0.03966941,  0.07036005, -0.01733606,\n",
       "           -0.04001305,  0.06157954,  0.05291516, -0.10049729]],\n",
       " \n",
       "         [[ 0.06662187,  0.12577273,  0.08838835, -0.00632016,\n",
       "            0.13346781, -0.04176039, -0.10430934, -0.10953148,\n",
       "           -0.04217063,  0.03963877, -0.06087811, -0.04575327,\n",
       "           -0.06813162, -0.05825471,  0.03453371, -0.04880445,\n",
       "            0.11284967,  0.0497376 ,  0.07300892,  0.03491664,\n",
       "            0.1305844 ,  0.13393585,  0.02415036,  0.02707049,\n",
       "            0.12667768,  0.1181315 , -0.06988875,  0.00248143,\n",
       "           -0.0168848 , -0.05265836, -0.04439693,  0.13361065]],\n",
       " \n",
       "         [[-0.12353159, -0.10879081,  0.10322735, -0.14098369,\n",
       "           -0.13633993, -0.07448313,  0.08177589, -0.14075172,\n",
       "            0.02142429,  0.07368776,  0.03372218, -0.1282641 ,\n",
       "           -0.05750082, -0.05740496,  0.14011718,  0.05527365,\n",
       "           -0.05871599, -0.11455345, -0.05403002, -0.04003695,\n",
       "           -0.12088716, -0.12157911,  0.01340292, -0.09093709,\n",
       "           -0.13396242,  0.02171941,  0.04312934,  0.07295813,\n",
       "            0.00820071,  0.10198054, -0.11017714, -0.1099647 ]]],\n",
       " \n",
       " \n",
       "        [[[ 0.10659857,  0.10874395, -0.01082754,  0.10506687,\n",
       "            0.04455639,  0.08046187, -0.11040001, -0.04905522,\n",
       "           -0.10614698, -0.11225775,  0.07506883, -0.05429129,\n",
       "            0.12642579, -0.06297261,  0.06294638,  0.10196061,\n",
       "            0.09571941,  0.13422225,  0.08555171, -0.11217141,\n",
       "            0.10456963,  0.00426885,  0.08773419,  0.11130439,\n",
       "           -0.01866075,  0.06716241,  0.03901142, -0.10422574,\n",
       "           -0.1167545 ,  0.11515455,  0.00968108, -0.06247745]],\n",
       " \n",
       "         [[-0.06578679,  0.05344814,  0.11489902,  0.03013954,\n",
       "           -0.12692155, -0.07004307, -0.12413825,  0.13518886,\n",
       "            0.01321138, -0.01391539,  0.04522978,  0.06259339,\n",
       "           -0.00298981,  0.08306506, -0.11415084,  0.08377723,\n",
       "           -0.09126861, -0.00870833,  0.0971709 , -0.05868156,\n",
       "           -0.05478336, -0.12304708,  0.09486762,  0.04509927,\n",
       "           -0.10607528, -0.05730851,  0.07136525, -0.04764804,\n",
       "            0.10776107,  0.12818812, -0.10548265,  0.09156716]],\n",
       " \n",
       "         [[-0.08157375,  0.01641449, -0.07183561,  0.03198664,\n",
       "           -0.04780057,  0.01852821, -0.06556676,  0.08490908,\n",
       "            0.06091788,  0.12554334,  0.10876091,  0.13181095,\n",
       "           -0.04651421, -0.11762971, -0.11013688,  0.12107854,\n",
       "            0.07313956, -0.01878145, -0.09369898, -0.00460652,\n",
       "            0.01766388, -0.06417266, -0.11869936, -0.01437287,\n",
       "           -0.05358168,  0.13004376, -0.1071635 ,  0.06379706,\n",
       "           -0.0560966 ,  0.09507646,  0.09352514, -0.08584006]]]],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32),\n",
       " array([[-0.00542803,  0.01275189,  0.02688493, ..., -0.0107996 ,\n",
       "         -0.01617493, -0.03177783],\n",
       "        [-0.02122626, -0.00693242, -0.02552073, ..., -0.00553488,\n",
       "          0.00127525, -0.01673451],\n",
       "        [-0.01914527, -0.00840815,  0.03178795, ..., -0.01318795,\n",
       "         -0.01611821,  0.00956959],\n",
       "        ...,\n",
       "        [-0.023999  , -0.02615152,  0.00992411, ...,  0.02389846,\n",
       "          0.02692182,  0.02178384],\n",
       "        [-0.00062492, -0.01989922, -0.02429282, ..., -0.00820384,\n",
       "          0.00542826,  0.02985391],\n",
       "        [ 0.01810579,  0.01981548, -0.01235343, ..., -0.02982334,\n",
       "         -0.0094665 , -0.01901765]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[-0.18517804,  0.09679304,  0.03862566, ...,  0.08461188,\n",
       "         -0.04320921,  0.1836402 ],\n",
       "        [ 0.13512485,  0.18224873, -0.01855464, ..., -0.01018569,\n",
       "          0.00206153,  0.08354534],\n",
       "        [ 0.0198829 ,  0.0371601 , -0.18398511, ...,  0.05223818,\n",
       "         -0.01174973,  0.07565184],\n",
       "        ...,\n",
       "        [ 0.15031128, -0.06599037,  0.00905401, ..., -0.10328207,\n",
       "         -0.06790406,  0.09532453],\n",
       "        [ 0.0975789 , -0.09238865, -0.0939777 , ...,  0.09166516,\n",
       "         -0.05705766,  0.17301287],\n",
       "        [-0.08428054, -0.18588343, -0.04298252, ..., -0.07568465,\n",
       "          0.02910221, -0.0141688 ]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server_cnn.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ba65d1d6-0611-459f-abaa-2f2be7fabef1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for client_weights in updated_weights_dataset:\n",
    "    cnn = get_compiled_and_built_simple_cnn()\n",
    "    \n",
    "    weights = [w for w in client_weights]\n",
    "    \n",
    "    cnn.set_weights(weights)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d126d11e-e183-4491-b95e-62f55ea03d82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d226db-f624-478a-b872-970826da737c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5659930a-6d46-4acc-9f3a-4d94814d71fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41159614-3b26-41cb-ba20-de0d34e5630c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-2.12]",
   "language": "python",
   "name": "conda-env-tf-2.12-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
