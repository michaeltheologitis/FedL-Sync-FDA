2023-05-07 11:02:50,497 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.0.0.104:36749'
2023-05-07 11:02:54,385 - distributed.worker - INFO -       Start worker at:     tcp://10.0.0.104:45029
2023-05-07 11:02:54,385 - distributed.worker - INFO -          Listening to:     tcp://10.0.0.104:45029
2023-05-07 11:02:54,385 - distributed.worker - INFO -           Worker name:             SLURMCluster-6
2023-05-07 11:02:54,385 - distributed.worker - INFO -          dashboard at:           10.0.0.104:37113
2023-05-07 11:02:54,385 - distributed.worker - INFO - Waiting to connect to:     tcp://10.0.0.100:40503
2023-05-07 11:02:54,385 - distributed.worker - INFO - -------------------------------------------------
2023-05-07 11:02:54,385 - distributed.worker - INFO -               Threads:                          4
2023-05-07 11:02:54,386 - distributed.worker - INFO -                Memory:                   2.79 GiB
2023-05-07 11:02:54,386 - distributed.worker - INFO -       Local Directory: /storage/tuclocal/mtheologitis/dask-worker-space/worker-c7wa7nls
2023-05-07 11:02:54,386 - distributed.worker - INFO - -------------------------------------------------
2023-05-07 11:02:56,328 - distributed.worker - INFO -         Registered to:     tcp://10.0.0.100:40503
2023-05-07 11:02:56,330 - distributed.worker - INFO - -------------------------------------------------
2023-05-07 11:02:56,332 - distributed.core - INFO - Starting established connection to tcp://10.0.0.100:40503
2023-05-07 11:04:01,851 - distributed.worker - INFO - Starting Worker plugin TF_Simulation_FDA_CNN.py061be514-ec83-4204-948e-29ac2e27ccc0
2023-05-07 11:04:01,961 - distributed.utils - INFO - Reload module TF_Simulation_FDA_CNN from .py file
2023-05-07 11:04:26,750 - distributed.core - INFO - Event loop was unresponsive in Worker for 24.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
