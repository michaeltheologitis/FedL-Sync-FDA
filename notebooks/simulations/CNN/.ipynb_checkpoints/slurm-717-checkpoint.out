2023-05-07 11:17:21,208 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.0.0.105:44093'
2023-05-07 11:17:25,412 - distributed.worker - INFO -       Start worker at:     tcp://10.0.0.105:39831
2023-05-07 11:17:25,412 - distributed.worker - INFO -          Listening to:     tcp://10.0.0.105:39831
2023-05-07 11:17:25,412 - distributed.worker - INFO -           Worker name:             SLURMCluster-1
2023-05-07 11:17:25,412 - distributed.worker - INFO -          dashboard at:           10.0.0.105:37297
2023-05-07 11:17:25,412 - distributed.worker - INFO - Waiting to connect to:     tcp://10.0.0.100:46559
2023-05-07 11:17:25,413 - distributed.worker - INFO - -------------------------------------------------
2023-05-07 11:17:25,413 - distributed.worker - INFO -               Threads:                          4
2023-05-07 11:17:25,413 - distributed.worker - INFO -                Memory:                   2.79 GiB
2023-05-07 11:17:25,413 - distributed.worker - INFO -       Local Directory: /storage/tuclocal/mtheologitis/dask-worker-space/worker-13uq091_
2023-05-07 11:17:25,413 - distributed.worker - INFO - -------------------------------------------------
2023-05-07 11:17:27,324 - distributed.worker - INFO -         Registered to:     tcp://10.0.0.100:46559
2023-05-07 11:17:27,326 - distributed.worker - INFO - -------------------------------------------------
2023-05-07 11:17:27,327 - distributed.core - INFO - Starting established connection to tcp://10.0.0.100:46559
2023-05-07 11:17:52,484 - distributed.worker - INFO - Starting Worker plugin TF_Simulation_FDA_CNN.pyb3244740-9ce7-4d2a-8d1a-9fed036b873a
2023-05-07 11:17:52,632 - distributed.utils - INFO - Reload module TF_Simulation_FDA_CNN from .py file
2023-05-07 11:18:03.205488: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE3, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-07 11:18:17,305 - distributed.core - INFO - Event loop was unresponsive in Worker for 24.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
