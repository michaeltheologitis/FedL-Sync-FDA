{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12f8f459-1a0e-4584-9a59-d0182ee9fdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079baeb4-3ff4-461c-97cd-2e033646a817",
   "metadata": {},
   "source": [
    "## Load EMNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02d71e6c-10cf-47df-9c1f-ac924e399bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    (X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "    X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b19675f-ad59-4e03-91ef-d8bd949c6dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_BATCH_INPUT = (None, 28, 28) # EMNIST dataset (None is used for batch size, as it varies)\n",
    "CNN_INPUT_RESHAPE = (28, 28, 1)\n",
    "n_train = 60_000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb30c89b-f085-4ce8-b783-ea5fb65b0d10",
   "metadata": {},
   "source": [
    "## Prepare data for Federated Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7381f169-8fc3-4dc3-b7a2-feed3ea4b4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tf_dataset(X_train, y_train, X_test, y_test):\n",
    "    # Convert to TensorFlow Datasets\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(256)\n",
    "\n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3f5543-ce86-4b35-ac58-598ff694e0d5",
   "metadata": {},
   "source": [
    "### Slice the Tensors for each Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ecdda90-668f-43cc-a247-6f25538b7cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_federated_data_for_clients(num_clients, train_dataset):\n",
    "    \n",
    "    # Shard the data across clients CLIENT LEVEL\n",
    "    client_datasets = [\n",
    "        train_dataset.shard(num_clients, i)\n",
    "        for i in range(num_clients)\n",
    "    ]\n",
    "    \n",
    "    return client_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d52400eb-8916-4d11-8e0c-9791962ebe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_federated_data_for_test(federated_data, batch_size, num_steps_until_rtc_check, seed=None):\n",
    "    \n",
    "    def process_client_dataset(client_dataset, batch_size, num_steps_until_rtc_check, seed, shuffle_size=512):\n",
    "        return client_dataset.shuffle(shuffle_size, seed=seed).repeat().batch(batch_size)\\\n",
    "            .take(num_steps_until_rtc_check).prefetch(tf.data.AUTOTUNE)\n",
    "        \n",
    "    federated_dataset_prepared = [\n",
    "        process_client_dataset(client_dataset, batch_size, num_steps_until_rtc_check, seed)\n",
    "        for client_dataset in federated_data\n",
    "    ]\n",
    "    return federated_dataset_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0abac82-295e-4bdd-90a1-0bf65bf8152e",
   "metadata": {},
   "source": [
    "# Miscallenious"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b51cb4-a425-4c75-a4b1-ea3b9b1bad10",
   "metadata": {},
   "source": [
    "## Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f365fb4-684c-4bc8-887a-5eb07d541ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance(server_cnn, client_cnns):\n",
    "    \n",
    "    w_t0 = server_cnn.trainable_vars_as_vector()\n",
    "    \n",
    "    squared_distances = [\n",
    "        tf.reduce_sum(tf.square(client_cnn.trainable_vars_as_vector() - w_t0)) \n",
    "        for client_cnn in client_cnns\n",
    "    ]\n",
    "    \n",
    "    var = tf.reduce_mean(squared_distances)\n",
    "    \n",
    "    return var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab51e4b2-fb82-422e-bd30-d2751e3e5902",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Neural Net weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e7d31b3-74dd-4b1d-8f96-2b24bd465664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_weights(model):\n",
    "    total_params = 0\n",
    "    for layer in model.layers:\n",
    "        total_params += np.sum([np.prod(weight.shape) for weight in layer.trainable_weights])\n",
    "    return int(total_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aae2fab-4c19-48a7-948b-f0f52a0e663f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Find accuracy based on some arbitrary `compile_and_build_model_func`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d627861c-4a75-4ad3-8e6c-26210ebbf7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def current_accuracy(client_models, test_dataset, compile_and_build_model_func):\n",
    "    \n",
    "    tmp_model = compile_and_build_model_func()\n",
    "    tmp_model.set_trainable_variables(average_client_weights(client_models))\n",
    "    _, acc = tmp_model.evaluate(test_dataset, verbose=0)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f097113-9940-4be8-a1a7-7151374b43db",
   "metadata": {},
   "source": [
    "### Average NN weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1417655-5196-4954-9942-dab9d2fb3bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_client_weights(client_models):\n",
    "    # client_weights[0] the trainable variables of Client 0 (a list of tf.Variable)\n",
    "    client_weights = [model.trainable_variables for model in client_models]\n",
    "\n",
    "    # concise solution. per layer. `layer_weight_tensors` corresponds to a list of tensors of a layer\n",
    "    avg_weights = [\n",
    "        tf.reduce_mean(layer_weight_tensors, axis=0)\n",
    "        for layer_weight_tensors in zip(*client_weights)\n",
    "    ]\n",
    "\n",
    "    return avg_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0518ecd2-6963-47b1-b1f5-8ba633ca6d43",
   "metadata": {},
   "source": [
    "## Server - Clients synchronization\n",
    "\n",
    "The assumption here is that the models have `set_trainable_variables` function implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9c897cb-6ee9-4f6c-bc78-78f91ac81266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synchronize_clients(server_model, client_models):\n",
    "\n",
    "    for client_model in client_models:\n",
    "        client_model.set_trainable_variables(server_model.trainable_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a29fb3-00c2-4332-99aa-8cf3d8c8e700",
   "metadata": {},
   "source": [
    "### Prepare (and restart) Client Dataset - shuffling, batching, prefetching\n",
    "\n",
    "Proper use of `.prefetch` [explained](https://stackoverflow.com/questions/63796936/what-is-the-proper-use-of-tensorflow-dataset-prefetch-and-cache-options).\n",
    "\n",
    "Proper ordering `.shuffle` and `.batch` and `.repeat` [explained](https://stackoverflow.com/questions/50437234/tensorflow-dataset-shuffle-then-batch-or-batch-then-shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64e0c33-a73f-42f2-ba2e-0c38e2ec0004",
   "metadata": {},
   "source": [
    "# LeNet-5 - Small Size (61,706 params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c1164e-7dde-4bf4-b518-fb59f2747f12",
   "metadata": {},
   "source": [
    "The `LeNet-5` [LeCun et al. paper from 1998](http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "647bdd24-789a-4699-a1cd-02259dc067bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, num_classes=10):\n",
    "        super(LeNet5, self).__init__()\n",
    "        \n",
    "        self.reshape = layers.Reshape(CNN_INPUT_RESHAPE)\n",
    "        \n",
    "        # Layer 1 Conv2D\n",
    "        self.conv1 = layers.Conv2D(filters=6, kernel_size=(5, 5), strides=(1, 1), activation='tanh', padding='same')\n",
    "        # Layer 2 Pooling Layer\n",
    "        self.avgpool1 = layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid')\n",
    "        # Layer 3 Conv2D\n",
    "        self.conv2 = layers.Conv2D(filters=16, kernel_size=(5, 5), strides=(1, 1), activation='tanh', padding='valid')\n",
    "        # Layer 4 Pooling Layer\n",
    "        self.avgpool2 = layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid')\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.dense1 = layers.Dense(units=120, activation='tanh')\n",
    "        self.dense2 = layers.Dense(units=84, activation='tanh')\n",
    "        self.dense3 = layers.Dense(units=num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        x = self.reshape(inputs)\n",
    "        x = self.conv1(x)\n",
    "        x = self.avgpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.avgpool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    @tf.function\n",
    "    def step(self, batch):\n",
    "        \n",
    "        print(\"Retrace LeNet5.step()\")\n",
    "        \n",
    "        x_batch, y_batch = batch\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass: Compute predictions\n",
    "            y_batch_pred = self(x_batch, training=True)\n",
    "\n",
    "            # Compute the loss value\n",
    "            # (the loss function is configured in `compile()`)\n",
    "            loss = self.compiled_loss(\n",
    "                y_true=y_batch,\n",
    "                y_pred=y_batch_pred,\n",
    "                regularization_losses=self.losses\n",
    "            )\n",
    "\n",
    "        # Compute gradients\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        \n",
    "        # Apply gradients to the model's trainable variables (update weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        \n",
    "        # Update metrics (includes the metric that tracks the loss)\n",
    "        #self.compiled_metrics.update_state(y_batch, y_batch_pred)\n",
    "    \n",
    "    \n",
    "    def train(self, dataset):\n",
    "\n",
    "        for batch in dataset:\n",
    "            self.step(batch)\n",
    "            \n",
    "    \n",
    "    def set_trainable_variables(self, trainable_vars):\n",
    "        \"\"\" Given `trainable_vars` set our `self.trainable_vars` \"\"\"\n",
    "        for model_var, var in zip(self.trainable_variables, trainable_vars):\n",
    "            model_var.assign(var)\n",
    "\n",
    "            \n",
    "    def trainable_vars_as_vector(self):\n",
    "        return tf.concat([tf.reshape(var, [-1]) for var in self.trainable_variables], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb705b3-64f1-4e9b-80eb-f9ff312dd863",
   "metadata": {},
   "source": [
    "### Helper function to compile and return the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f59c4f-188f-45ef-befd-3bcf47ae7c58",
   "metadata": {},
   "source": [
    "**Important** function that returns a compiled and built `SimpleCNN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4960717e-6839-49c6-8c7f-911fc39cbd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_and_built_lenet():\n",
    "    cnn = LeNet5()\n",
    "    \n",
    "    cnn.compile(\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False), # we have softmax\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')]\n",
    "    )\n",
    "    \n",
    "    cnn.build(CNN_BATCH_INPUT)  # EMNIST dataset (None is used for batch size, as it varies)\n",
    "    \n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a550fe5a-5268-453b-9b71-332fa67fe947",
   "metadata": {},
   "source": [
    "# Advanced Convolutional Neural Net (CNN) - Large Size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1031fcc1-6679-4c39-b140-ea707665550f",
   "metadata": {},
   "source": [
    "A more complex Convolutional Neural Network with three sets of two convolutional layers, each followed by a max-pooling layer, and two dense layers with dropout for classification. Designed for 28x28 grayscale images. It has 2,592,202 weights.\n",
    "\n",
    "Notes about `@tf.function`:\n",
    "\n",
    "1. After testing it might be worth it to wrap `.step` in `@tf.function`. More CPU usage. Be mindful of retracing (test it).\n",
    "\n",
    "2. After testing it is not worth it to wrap `.train`. Only consider `.step`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3141d998-651e-46d4-8ef1-cf359d0f7f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedCNN(tf.keras.Model):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(AdvancedCNN, self).__init__()\n",
    "        \n",
    "        self.reshape = layers.Reshape(CNN_INPUT_RESHAPE)\n",
    "        \n",
    "        self.conv1 = layers.Conv2D(64, kernel_size=3, activation='relu', padding='same')\n",
    "        self.conv2 = layers.Conv2D(64, kernel_size=3, activation='relu', padding='same')\n",
    "        self.max_pool1 = layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        \n",
    "        self.conv3 = layers.Conv2D(128, kernel_size=3, activation='relu', padding='same')\n",
    "        self.conv4 = layers.Conv2D(128, kernel_size=3, activation='relu', padding='same')\n",
    "        self.max_pool2 = layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        \n",
    "        self.conv5 = layers.Conv2D(256, kernel_size=3, activation='relu', padding='same')\n",
    "        self.conv6 = layers.Conv2D(256, kernel_size=3, activation='relu', padding='same')\n",
    "        self.max_pool3 = layers.MaxPooling2D(pool_size=(2, 2))\n",
    "\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.dense1 = layers.Dense(512, activation='relu')\n",
    "        self.dropout1 = layers.Dropout(0.5)\n",
    "        self.dense2 = layers.Dense(512, activation='relu')\n",
    "        self.dropout2 = layers.Dropout(0.5)\n",
    "        self.dense3 = layers.Dense(num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        x = self.reshape(inputs)  # Add a channel dimension\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.max_pool1(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.max_pool2(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.max_pool3(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dropout1(x, training=training)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dropout2(x, training=training)\n",
    "        x = self.dense3(x)\n",
    "        return x\n",
    "    \n",
    "    @tf.function\n",
    "    def step(self, batch):\n",
    "        \n",
    "        print(\"Retrace AdvancedCNN.step()\")\n",
    "        \n",
    "        x_batch, y_batch = batch\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass: Compute predictions\n",
    "            y_batch_pred = self(x_batch, training=True)\n",
    "\n",
    "            # Compute the loss value\n",
    "            # (the loss function is configured in `compile()`)\n",
    "            loss = self.compiled_loss(\n",
    "                y_true=y_batch,\n",
    "                y_pred=y_batch_pred,\n",
    "                regularization_losses=self.losses\n",
    "            )\n",
    "\n",
    "        # Compute gradients\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        \n",
    "        # Apply gradients to the model's trainable variables (update weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        \n",
    "        # Update metrics (includes the metric that tracks the loss)\n",
    "        #self.compiled_metrics.update_state(y_batch, y_batch_pred)\n",
    "    \n",
    "    \n",
    "    def train(self, dataset):\n",
    "        \n",
    "        for batch in dataset:\n",
    "            self.step(batch)\n",
    "            \n",
    "    \n",
    "    def set_trainable_variables(self, trainable_vars):\n",
    "        \"\"\" Given `trainable_vars` set our `self.trainable_vars` \"\"\"\n",
    "        for model_var, var in zip(self.trainable_variables, trainable_vars):\n",
    "            model_var.assign(var)\n",
    "\n",
    "            \n",
    "    def trainable_vars_as_vector(self):\n",
    "        return tf.concat([tf.reshape(var, [-1]) for var in self.trainable_variables], axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25606540-c2a0-4e43-8ccb-d48f0bbbfcc4",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2583ec-795d-4fac-bdfe-65a9b46d4c73",
   "metadata": {},
   "source": [
    "**Important** function that returns a compiled and built `AdvancedCNN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f3a6d1d-772f-435f-8ef5-117999a85f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_and_built_advanced_cnn():\n",
    "    advanced_cnn = AdvancedCNN()\n",
    "    \n",
    "    advanced_cnn.compile(\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False), # we have softmax\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')]\n",
    "    )\n",
    "    \n",
    "    advanced_cnn.build(CNN_BATCH_INPUT)  # EMNIST dataset (None is used for batch size, as it varies)\n",
    "    \n",
    "    return advanced_cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6fdb3e-c945-43ef-934b-97af4a8144cc",
   "metadata": {},
   "source": [
    "# Functional Dynamic Averaging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0a989e-89d0-4e71-af83-b9d6f3347070",
   "metadata": {},
   "source": [
    "We follow the Functional Dynamic Averaging (FDA) scheme. Let the mean model be\n",
    "\n",
    "$$ \\overline{w_t} = \\frac{1}{k} \\sum_{i=1}^{k} w_t^{(i)} $$\n",
    "\n",
    "where $ w_t^{(i)} $ is the model at time $ t $ in some round in the $i$-th learner.\n",
    "\n",
    "Local models are trained independently and cooperatively and we want to monitor the Round Terminating Conditon (**RTC**):\n",
    "\n",
    "$$ \\frac{1}{k} \\sum_{i=1}^{k} \\lVert w_t^{(i)} - \\overline{w_t} \\rVert_2^2  \\leq \\Theta $$\n",
    "\n",
    "where the left-hand side is the **model variance**, and threshold $\\Theta$ is a hyperparameter of the FDA, defined at the beginning of the round; it may change at each round. When the monitoring logic cannot guarantee the validity of RTC, the round terminates. All local models are pulled into `tff.SERVER`, and $\\bar{w_t}$ is set to their average. Then, another round begins."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea88e748-3b00-47a9-b128-5bbb53adfac5",
   "metadata": {},
   "source": [
    "### Monitoring the RTC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08446303-59c6-4251-9ae1-0ca859e6cf77",
   "metadata": {},
   "source": [
    "FDA monitors the RTC by applying techniques from Functionary [Functional Geometric Averaging](http://users.softnet.tuc.gr/~minos/Papers/edbt19.pdf). We first restate the problem of monitoring RTC into the standard distributed stream monitoring formulation. Let\n",
    "\n",
    "$$ S(t) =  \\frac{1}{k} \\sum_{i=1}^{k} S_i(t) $$\n",
    "\n",
    "where $ S(t) \\in \\mathbb{R}^n $ be the \"global state\" of the system and $ S_i(t) \\in \\mathbb{R}^n $ the \"local states\". The goal is to monitor the threshold condition on the global state in the form $ F(S(t)) \\leq \\Theta $ where $ F : \\mathbb{R}^n \\to \\mathbb{R} $ a non-linear function. Let\n",
    "\n",
    "$$ \\Delta_t^{(i)} = w_t^{(i)} - w_{t_0}^{(i)} $$\n",
    "\n",
    "be the update at the $ i $-th learner, that is, the change to the local model at time $t$ since the beginning of the current round at time $t_0$. Let the average update be\n",
    "\n",
    "$$ \\overline{\\Delta_t} = \\frac{1}{k} \\sum_{i=1}^{k} \\Delta_t^{(i)} $$\n",
    "\n",
    "it follows that the variance can be written as\n",
    "\n",
    "$$ \\frac{1}{k} \\sum_{i=1}^{k} \\lVert w_t^{(i)} - \\overline{w_t} \\rVert_2^2 = \\Big( \\frac{1}{k} \\sum_{i=1}^{k} \\lVert \\Delta_t^{(i)} \\rVert_2^2 \\Big) - \\lVert \\overline{\\Delta_t} \\rVert_2^2 $$\n",
    "\n",
    "So, conceptually, if we define\n",
    "$$ S_i(t) = \\begin{bmatrix}\n",
    "           \\lVert \\Delta_t^{(i)} \\rVert_2^2 \\\\\n",
    "           \\Delta_t^{(i)}\n",
    "         \\end{bmatrix} \\quad \\text{and} \\quad\n",
    "         F(\\begin{bmatrix}\n",
    "           v \\\\\n",
    "           \\bf{x}\n",
    "         \\end{bmatrix}) = v - \\lVert \\bf{x} \\rVert_2^2 $$\n",
    "\n",
    "The RTC is equivalent to condition $$ F(S(t)) \\leq \\Theta $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f8ced7-22ce-404d-bd78-55590cfdd478",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1️⃣ Naive FDA\n",
    "\n",
    "In the naive approach, we eliminate the update vector from the local state (i.e. recuce the dimension to 0). Define local state as\n",
    "\n",
    "$$ S_i(t) = \\lVert \\Delta_t^{(i)} \\rVert_2^2 \\in \\mathbb{R}$$ \n",
    "\n",
    "and the identity function\n",
    "\n",
    "$$ F(v) = v $$\n",
    "\n",
    "It is trivial that $ F(S(t)) \\leq \\Theta $ implies the RTC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ab384b-e2b3-4470-9a7b-e8f555d0245d",
   "metadata": {},
   "source": [
    "### Client Train\n",
    "\n",
    "The number of steps depends on the dataset, i.e., `.take(num)` call on `tf.data.Dataset` creation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebcfa211-c199-4f93-9b01-7ef9aeba1c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_train_naive(w_t0, client_cnn, client_dataset):\n",
    "    \"\"\"\n",
    "    :param w_t0: Vector Tensor shape=(d,). Same shape with `client_cnn.trainable_vars_as_vector()`\n",
    "    :return: Tensor shape=() dtype=tf.float32\n",
    "    \"\"\"\n",
    "    \n",
    "    # number of steps depend on `.take()` from `dataset`\n",
    "    client_cnn.train(client_dataset)\n",
    "    \n",
    "    Delta_i = client_cnn.trainable_vars_as_vector() - w_t0\n",
    "    \n",
    "    #||D(t)_i||^2 , shape = () \n",
    "    Delta_i_euc_norm_squared = tf.reduce_sum(tf.square(Delta_i)) # ||D(t)_i||^2\n",
    "    \n",
    "    return Delta_i_euc_norm_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738965e0-2852-42aa-88ee-e8f558252948",
   "metadata": {},
   "source": [
    "### Train all Clients\n",
    "\n",
    "Notes about the following potentialy general `tf.function`:\n",
    "\n",
    "1. Even though `clients_cnn` and `federated_dataset` contain `tf.Keras.Module` and `tf.data.Dataset` elements, they both are python lists (python side-effects). Take a look at [Looping Over Python data](https://www.tensorflow.org/guide/function#tracing) and afterwards [For example, the following loop is unrolled, even though the list contains ...](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/control_flow.md#while-statements) to get more insight.\n",
    "\n",
    "2. TL;DR: It is very-very bad in terms of RAM. It produces an unrolled loop. The graph becomes consequent `Delta_i_... = ... ; S_i_clients.append(...) ;` commands `len(client_cnns)` number of times. This produces a huge graph (for instance, for `NUM_CLIENTS`=8, 4GB graph is produced). Notice that each sequence of the two commands has a big (unseen) underlying graph going to the bottom, that is, `.step` in the `tf.Keras.Module` class!\n",
    "\n",
    "3. Even if we had endless RAM the usage of `tf.function` is still arguable. For instance, on testing for 16 clients the difference between the two is only 20-30ms with total execution time in the order of 200-250ms. Only if we had a huge amount of CPUs or GPU we could consider it, but still... there must be a better approach (`Dask` or a different implementation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b5e970d-f8f0-4870-80ad-f56c8d49fced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clients_train_naive(w_t0, client_cnns, federated_dataset):\n",
    "    \"\"\"\n",
    "    :param w_t0: Vector Tensor shape=(d,). Same shape with `client_cnns[i].trainable_vars_as_vector()`\n",
    "    :return: List of `Tensor shape=() dtype=tf.float32`, one for each `client_cnn` in `client_cnns`.\n",
    "    \"\"\"\n",
    "    \n",
    "    S_i_clients = []\n",
    "\n",
    "    for client_cnn, client_dataset in zip(client_cnns, federated_dataset):\n",
    "        Delta_i_euc_norm_squared = client_train_naive(w_t0, client_cnn, client_dataset)\n",
    "        S_i_clients.append(Delta_i_euc_norm_squared)\n",
    "    \n",
    "    return S_i_clients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bc0988-882c-4c7c-8ab0-27b86363c000",
   "metadata": {},
   "source": [
    "### Identity F Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da9b7c4c-da11-4e04-ba64-b035030a57b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_naive(S_i_clients):\n",
    "    \"\"\" :return: Tensor shape=() dtype=tf.float32 , Naive variance approximation \"\"\"\n",
    "    \n",
    "    S = tf.reduce_mean(S_i_clients)\n",
    "    \n",
    "    return S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d629ed-2522-4b7d-8c8c-2917e55e99ef",
   "metadata": {},
   "source": [
    "## 2️⃣ Linear FDA\n",
    "\n",
    "In the linear case, we reduce the update vector to a scalar, $ \\xi \\Delta_t^{(i)} \\in \\mathbb{R}$, where $ \\xi $ is any unit vector.\n",
    "\n",
    "Define the local state to be \n",
    "\n",
    "$$ S_i(t) = \\begin{bmatrix}\n",
    "           \\lVert \\Delta_t^{(i)} \\rVert_2^2 \\\\\n",
    "           \\xi \\Delta_t^{(i)}\n",
    "         \\end{bmatrix} \\in \\mathbb{R}^2 $$\n",
    "\n",
    "Also, define \n",
    "\n",
    "$$ F(v, x) = v - x^2 $$\n",
    "\n",
    "The RTC is equivalent to condition \n",
    "\n",
    "$$ F(S(t)) \\leq \\Theta $$\n",
    "\n",
    "A random choice of $ \\xi $ is likely to perform poorly (terminate round prematurely), as it wil likely be close to orthogonal to $ \\overline{\\Delta_t} $. A good choice would be a vector $ \\xi $ correlated to $ \\overline{\\Delta_t} $. A heuristic choice is to take $ \\overline{\\Delta_{t_0}} $ (after scaling it to norm 1), i.e., the update vector right before the current round started. All nodes can estimate this without communication, as $ \\overline{w_{t_0}} - \\overline{w_{t_{-1}}} $, the difference of the last two models pushed by the Server. Hence, \n",
    "\n",
    "$$ \\xi = \\frac{\\overline{w_{t_0}} - \\overline{w_{t_{-1}}}}{\\lVert \\overline{w_{t_0}} - \\overline{w_{t_{-1}}} \\rVert_2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f91e0af-9bfd-448d-ab43-20122b7ed1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ksi_unit(w_t0, w_tminus1):\n",
    "    \"\"\"\n",
    "    :param w_t0: Vector Tensor shape=(d,).\n",
    "    :param w_tminus1: Vector Tensor shape=(d,)\n",
    "    :return: `ξ` as defined above.\n",
    "    \"\"\"\n",
    "    if tf.reduce_all(tf.equal(w_t0, w_tminus1)):\n",
    "        # if equal then ksi becomes a random vector (will only happen in round 1)\n",
    "        ksi = tf.random.normal(shape=w_t0.shape)\n",
    "    else:\n",
    "        ksi = w_t0 - w_tminus1\n",
    "\n",
    "    # Normalize and return\n",
    "    return tf.divide(ksi, tf.norm(ksi))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0d324d-8a1b-4ac7-8c55-f8cdaf7c8e7d",
   "metadata": {},
   "source": [
    "### Client Train\n",
    "\n",
    "The number of steps depends on the dataset, i.e., `.take(num)` call on `tf.data.Dataset` creation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a6cfb66-d02e-43a4-93ea-4937434160ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_train_linear(w_t0, w_tminus1, client_cnn, client_dataset):\n",
    "    \"\"\"\n",
    "    :param w_t0: Vector Tensor shape=(d,). Same shape with `client_cnn.trainable_vars_as_vector()`\n",
    "    :param w_tminus1: Vector Tensor shape=(d,). Same shape with `client_cnn.trainable_vars_as_vector()`\n",
    "    :return: tuple ( Tensor shape=() dtype=tf.float32 , Tensor shape=() dtype=tf.float32 )\n",
    "    \"\"\"\n",
    "    \n",
    "    # number of steps depend on `.take()` from `dataset`\n",
    "    client_cnn.train(client_dataset)\n",
    "    \n",
    "    Delta_i = client_cnn.trainable_vars_as_vector() - w_t0\n",
    "    \n",
    "    #||D(t)_i||^2 , shape = () \n",
    "    Delta_i_euc_norm_squared = tf.reduce_sum(tf.square(Delta_i)) # ||D(t)_i||^2\n",
    "    \n",
    "    # heuristic unit vector ksi\n",
    "    ksi = ksi_unit(w_t0, w_tminus1)\n",
    "    \n",
    "    # ksi * Delta_i (* is dot) , shape = ()\n",
    "    ksi_Delta_i = tf.reduce_sum(tf.multiply(ksi, Delta_i))\n",
    "    \n",
    "    return Delta_i_euc_norm_squared, ksi_Delta_i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a12323-99d5-40f4-8aaf-f879dc8c80c3",
   "metadata": {},
   "source": [
    "### Train all Clients\n",
    "\n",
    "Notes about the following potentialy general `tf.function`:\n",
    "\n",
    "1. Even though `clients_cnn` and `federated_dataset` contain `tf.Keras.Module` and `tf.data.Dataset` elements, they both are python lists (python side-effects). Take a look at [Looping Over Python data](https://www.tensorflow.org/guide/function#tracing) and afterwards [For example, the following loop is unrolled, even though the list contains ...](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/control_flow.md#while-statements) to get more insight.\n",
    "\n",
    "2. TL;DR: It is very-very bad in terms of RAM. It produces an unrolled loop. The graph becomes consequent `Delta_i_... = ... ; euc_norm_squared_clients.append(...) ; ksi_delta_clients.append(...) ;` commands `len(client_cnns)` number of times. This produces a huge graph (for instance, for `NUM_CLIENTS`=8, 4GB graph is produced). Notice that each sequence of the two commands has a big (unseen) underlying graph going to the bottom, that is, `.step` in the `tf.Keras.Module` class!\n",
    "\n",
    "3. Even if we had endless RAM the usage of `tf.function` is still arguable. For instance, on testing for 16 clients the difference between the two is only 20-30ms with total execution time in the order of 200-250ms. Only if we had a huge amount of CPUs or GPU we could consider it, but still... there must be a better approach (`Dask` or a different implementation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df371cc4-530c-4a97-bd88-945c110e9b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clients_train_linear(w_t0, w_tminus1, client_cnns, federated_dataset):\n",
    "    \"\"\"\n",
    "    :param w_t0: Vector Tensor shape=(d,). Same shape with `client_cnns[i].trainable_vars_as_vector()`\n",
    "    :param w_tminus1: Vector Tensor shape=(d,). Same shape with `client_cnns[i].trainable_vars_as_vector()`\n",
    "    :return: Two Lists of `Tensor shape=() dtype=tf.float32`, one for each `client_cnn` in `client_cnns`.\n",
    "    \"\"\"\n",
    "    \n",
    "    euc_norm_squared_clients = []\n",
    "    ksi_delta_clients = []\n",
    "    \n",
    "    for client_cnn, client_dataset in zip(client_cnns, federated_dataset):\n",
    "        Delta_i_euc_norm_squared, ksi_Delta_i = client_train_linear(\n",
    "            w_t0, w_tminus1, client_cnn, client_dataset\n",
    "        )\n",
    "\n",
    "        euc_norm_squared_clients.append(Delta_i_euc_norm_squared)\n",
    "        ksi_delta_clients.append(ksi_Delta_i)\n",
    "    \n",
    "    return euc_norm_squared_clients, ksi_delta_clients\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d0ac9b-d6ba-4e87-a6ae-567f4098ccff",
   "metadata": {},
   "source": [
    "### F Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1ef87d3-60b0-44a5-a6e9-6e4e78695bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_linear(euc_norm_squared_clients, ksi_delta_clients):\n",
    "    \"\"\" :return: Tensor shape=() dtype=tf.float32 , Linear variance approximation \"\"\"\n",
    "    \n",
    "    S_1 = tf.reduce_mean(euc_norm_squared_clients)\n",
    "    S_2 = tf.reduce_mean(ksi_delta_clients)\n",
    "    \n",
    "    return S_1 - S_2**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a07ac3a-7fe3-4951-b621-7394ee42f06a",
   "metadata": {},
   "source": [
    "## 3️⃣ Sketch FDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8839471b-cab8-443f-b4c8-19dd9bbe117e",
   "metadata": {},
   "source": [
    "An optimal estimator for $ \\lVert \\overline{\\Delta_t} \\rVert_2^2  $ can be obtained by employing AMS sketches. An AMS sketch of a vector $ v \\in \\mathbb{R}^M $ is a $ d \\times m $ real matrix\n",
    "\n",
    "$$ \\Xi = \\text{sk}(v) = \\begin{bmatrix}\n",
    "           \\Xi_1 \\\\\n",
    "           \\Xi_2 \\\\\n",
    "           \\vdots \\\\\n",
    "           \\Xi_d \n",
    "         \\end{bmatrix} $$\n",
    "         \n",
    "where $ d \\cdot m \\ll M$. Operator sk($ \\cdot $) is linear, i.e., let $a, b \\in \\mathbb{R}$ and $v_1, v_2 \\in \\mathbb{R}^N$ then \n",
    "\n",
    "$$ \\text{sk}(a v_1 + b v_2) = a \\; \\text{sk}(v_1) + b \\; \\text{sk}(v_2)  $$\n",
    "\n",
    "Also, sk($ v $) can be computed in $ \\mathcal{O}(dN) $ steps.\n",
    "\n",
    "The interesting property of AMS sketches is that the function \n",
    "\n",
    "$$ M(sk(\\textbf{v})) = \\underset{i=1,...,d}{\\text{median}} \\; \\lVert \\boldsymbol{\\Xi}_i \\rVert_2^2  $$ \n",
    "\n",
    "is an excellent estimator of the Euclidean norm of **v** (within relative $\\epsilon$-error):\n",
    "\n",
    "$$ M(sk(\\textbf{v})) \\; \\in (1 \\pm \\epsilon) \\lVert \\textbf{v} \\rVert_2^2 \\; \\; \\text{with probability at least} \\; (1-\\delta) $$\n",
    "\n",
    "where $m = \\mathcal{O}(\\frac{1}{\\epsilon^2})$ and $d = \\mathcal{O}(\\log \\frac{1}{\\delta})$\n",
    "\n",
    "Let's investigate a little further on how this helps us. The $i$-th client computes $ sk(\\Delta_t^{(i)}) $ and sends it to the server. Notice\n",
    "\n",
    "$$ M\\big(sk(\\Delta_t^{(1)}) + sk(\\Delta_t^{(2)}) + ... + sk(\\Delta_t^{(k)}) \\big) = M\\Big( \\text{sk}\\big( \\sum_{i=1}^{k} \\Delta_t^{(i)} \\big) \\Big)$$\n",
    "\n",
    "Remember that\n",
    "\n",
    "$$ \\overline{\\boldsymbol{\\Delta}}_t = \\frac{1}{k} \\sum_{i=1}^{k} \\boldsymbol{\\Delta}_t^{(i)} $$\n",
    "\n",
    "Then\n",
    "            \n",
    "$$ M\\Big( \\text{sk}\\big( \\overline{\\boldsymbol{\\Delta}}_t \\big) \\Big) = M\\Big( \\text{sk}\\big( \\frac{1}{k} \\sum_{i=1}^{k} \\boldsymbol{\\Delta}_t^{(i)} \\big) \\Big) =  M\\Big( \\frac{1}{k} \\text{sk}\\big( \\sum_{i=1}^{k} \\boldsymbol{\\Delta}_t^{(i)} \\big) \\Big) $$\n",
    "\n",
    "\n",
    "Which means that \n",
    "\n",
    "$$ M\\Big( \\frac{1}{k} \\text{sk}\\big( \\sum_{i=1}^{k} \\boldsymbol{\\Delta}_t^{(i)} \\big) \\Big) \\in (1 \\pm \\epsilon) \\lVert \\overline{\\boldsymbol{\\Delta}}_t \\rVert_2^2 \\; \\; \\text{w.p. at least} \\; (1-\\delta) $$\n",
    "\n",
    "In the monitoring process it is essential that we do not overestimate $ \\lVert \\overline{\\Delta_t} \\rVert_2^2 $ because we would then underestimate the variance which would potentially result in actual varience exceeding $ \\Theta$ without us noticing it. With this in mind,\n",
    "\n",
    "$$ M\\Big( \\frac{1}{k} \\text{sk}\\big( \\sum_{i=1}^{k} \\boldsymbol{\\Delta}_t^{(i)} \\big) \\Big) \\leq (1+\\epsilon) \\lVert \\overline{\\Delta_t} \\rVert_2^2 \\quad \\text{with probability at least} \\; (1-\\delta)$$\n",
    "\n",
    "Which means\n",
    "\n",
    "$$ \\frac{1}{(1+\\epsilon)} M\\Big( \\frac{1}{k} \\text{sk}\\big( \\sum_{i=1}^{k} \\boldsymbol{\\Delta}_t^{(i)} \\big) \\Big) \\leq \\lVert \\overline{\\Delta_t} \\rVert_2^2 \\quad \\text{with probability at least} \\; (1-\\delta)$$\n",
    "\n",
    "Hence, the Server's estimation of $ \\lVert \\overline{\\Delta_t} \\rVert_2^2 $ is\n",
    "\n",
    "$$ \\frac{1}{(1+\\epsilon)} M\\Big( \\frac{1}{k} \\text{sk}\\big( \\sum_{i=1}^{k} \\boldsymbol{\\Delta}_t^{(i)} \\big) \\Big) $$\n",
    "\n",
    "Define the local state to be \n",
    "\n",
    "$$ S_i(t) = \\begin{bmatrix}\n",
    "           \\lVert \\Delta_t^{(i)} \\rVert_2^2 \\\\\n",
    "           sk(\\Delta_t^{(i)})\n",
    "         \\end{bmatrix} \\in \\mathbb{R}^{1+d \\times m} \\quad \\text{and} \\quad\n",
    "         F(\\begin{bmatrix}\n",
    "           v \\\\\n",
    "           \\Xi\n",
    "         \\end{bmatrix}) = v - \\frac{1}{(1+\\epsilon)}  M(\\Xi) \\quad \\text{where} \\quad \\Xi = \\frac{1}{k} \\sum_{i=1}^{k} sk(\\Delta_t^{(i)}) $$\n",
    "\n",
    "It follows that $ F(S(t)) \\leq \\Theta $ implies that the variance is less or equal to $ \\Theta $ with probability at least $ 1-\\delta $.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310803d6-7520-44c7-b3d1-ad5b92b82b6a",
   "metadata": {},
   "source": [
    "## AMS sketch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f351f2-1583-42e0-a788-235de316b958",
   "metadata": {},
   "source": [
    "We use `ExtensionType` which is the way to go in order to avoid unecessary graph retracing when passing around `AmsSketch` type 'objects'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f52e8196-fd98-4db6-85c2-0c5c07decf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmsSketch:\n",
    "        \n",
    "    def __init__(self, depth=7, width=1500):\n",
    "        self.depth = depth\n",
    "        self.width = width\n",
    "        self.F = tf.random.uniform(shape=(6, depth), minval=0, maxval=(1 << 31) - 1, dtype=tf.int32)\n",
    "\n",
    "        \n",
    "    def hash31(self, x, a, b):\n",
    "\n",
    "        r = a * x + b\n",
    "        fold = tf.bitwise.bitwise_xor(tf.bitwise.right_shift(r, 31), r)\n",
    "        return tf.bitwise.bitwise_and(fold, 2147483647)\n",
    "    \n",
    "    \n",
    "    def tensor_hash31(self, x, a, b): # GOOD\n",
    "        \"\"\" Assumed that x is tensor shaped (d,) , i.e., a vector (for example, indices, i.e., tf.range(d)) \"\"\"\n",
    "\n",
    "        # Reshape x to have an extra dimension, resulting in a shape of (k, 1)\n",
    "        x_reshaped = tf.expand_dims(x, axis=-1)\n",
    "\n",
    "        # shape=(`v_dim`, 7)\n",
    "        r = tf.multiply(a, x_reshaped) + b\n",
    "\n",
    "        fold = tf.bitwise.bitwise_xor(tf.bitwise.right_shift(r, 31), r)\n",
    "        \n",
    "        return tf.bitwise.bitwise_and(fold, 2147483647)\n",
    "    \n",
    "    \n",
    "    def tensor_fourwise(self, x):\n",
    "        \"\"\" Assumed that x is tensor shaped (d,) , i.e., a vector (for example, indices, i.e., tf.range(d)) \"\"\"\n",
    "        # 1st use the tensor hash31\n",
    "        in1 = self.tensor_hash31(x, self.F[2], self.F[3])  # shape = (`x_dim`,  `self.depth`)\n",
    "        \n",
    "        # 2st use the tensor hash31\n",
    "        in2 = self.tensor_hash31(x, in1, self.F[4])  # shape = (`x_dim`,  `self.depth`)\n",
    "        \n",
    "        # 3rd use the tensor hash31\n",
    "        in3 = self.tensor_hash31(x, in2, self.F[5])  # shape = (`x_dim`,  `self.depth`)\n",
    "        \n",
    "        in4 = tf.bitwise.bitwise_and(in3, 32768)  # shape = (`x_dim`,  `self.depth`)\n",
    "        \n",
    "        return 2 * (tf.bitwise.right_shift(in4, 15)) - 1  # shape = (`x_dim`,  `self.depth`)\n",
    "        \n",
    "        \n",
    "    def fourwise(self, x):\n",
    "\n",
    "        result = 2 * (tf.bitwise.right_shift(tf.bitwise.bitwise_and(self.hash31(self.hash31(self.hash31(x, self.F[2], self.F[3]), x, self.F[4]), x, self.F[5]), 32768), 15)) - 1\n",
    "        return result\n",
    "    \n",
    "\n",
    "    @tf.function\n",
    "    def sketch_for_vector(self, v):\n",
    "        \"\"\" Extremely efficient computation of sketch with only using tensors. \"\"\"\n",
    "        \n",
    "        print(\"retracing `sketch_for_vector`\")\n",
    "        \n",
    "        sketch = tf.zeros(shape=(self.depth, self.width), dtype=tf.float32)\n",
    "        \n",
    "        len_v = v.shape[0]\n",
    "        \n",
    "        pos_tensor = self.tensor_hash31(tf.range(len_v), self.F[0], self.F[1]) % self.width\n",
    "        \n",
    "        v_expand = tf.expand_dims(v, axis=-1)\n",
    "        \n",
    "        deltas_tensor = tf.multiply(tf.cast(self.tensor_fourwise(tf.range(len_v)), dtype=tf.float32), v_expand)\n",
    "        \n",
    "        range_tensor = tf.range(self.depth)\n",
    "        \n",
    "        # Expand dimensions to create a 2D tensor with shape (1, `self.depth`)\n",
    "        range_tensor_expanded = tf.expand_dims(range_tensor, 0)\n",
    "\n",
    "        # Use tf.tile to repeat the range `len_v` times\n",
    "        repeated_range_tensor = tf.tile(range_tensor_expanded, [len_v, 1])\n",
    "        \n",
    "        # shape=(`len_v`, `self.depth`, 2)\n",
    "        indices = tf.stack([repeated_range_tensor, pos_tensor], axis=-1)\n",
    "        \n",
    "        sketch = tf.tensor_scatter_nd_add(sketch, indices, deltas_tensor)\n",
    "        \n",
    "        return sketch\n",
    "    \n",
    "    \n",
    "    def sketch_for_vector2(self, v):\n",
    "        \"\"\" Bad implementation for tensorflow. \"\"\"\n",
    "\n",
    "        sketch = tf.zeros(shape=(self.depth, self.width), dtype=tf.float32)\n",
    "\n",
    "        for i in tf.range(tf.shape(v)[0], dtype=tf.int32):\n",
    "            pos = self.hash31(i, self.F[0], self.F[1]) % self.width\n",
    "            delta = tf.cast(self.fourwise(i), dtype=tf.float32) * v[i]\n",
    "            indices_to_update = tf.stack([tf.range(self.depth, dtype=tf.int32), pos], axis=1)\n",
    "            sketch = tf.tensor_scatter_nd_add(sketch, indices_to_update, delta)\n",
    "\n",
    "        return sketch\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    def estimate_euc_norm_squared(sketch):\n",
    "\n",
    "        def _median(v):\n",
    "            \"\"\" Median of tensor `v` with shape=(n,). Note: Suboptimal O(nlogn) but it's ok bcz n = `depth`\"\"\"\n",
    "            length = tf.shape(v)[0]\n",
    "            sorted_v = tf.sort(v)\n",
    "            middle = length // 2\n",
    "\n",
    "            return tf.cond(\n",
    "                tf.equal(length % 2, 0),\n",
    "                lambda: (sorted_v[middle - 1] + sorted_v[middle]) / 2.0,\n",
    "                lambda: sorted_v[middle]\n",
    "            )\n",
    "\n",
    "        return _median(tf.reduce_sum(tf.square(sketch), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89a2099-c7eb-42ac-89f9-cfe6276c8cf6",
   "metadata": {},
   "source": [
    "### Client Train\n",
    "\n",
    "The number of steps depends on the dataset, i.e., `.take(num)` call on `tf.data.Dataset` creation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed39ab84-5dee-43a5-8833-42266497ff17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_train_sketch(w_t0, client_cnn, client_dataset, ams_sketch):\n",
    "    # number of steps depend on `.take()` from `dataset`\n",
    "    client_cnn.train(client_dataset)\n",
    "    \n",
    "    Delta_i = client_cnn.trainable_vars_as_vector() - w_t0\n",
    "    \n",
    "    #||D(t)_i||^2 , shape = () \n",
    "    Delta_i_euc_norm_squared = tf.reduce_sum(tf.square(Delta_i)) # ||D(t)_i||^2 \n",
    "    \n",
    "    # sketch approx\n",
    "    sketch = ams_sketch.sketch_for_vector(Delta_i)\n",
    "    \n",
    "    return Delta_i_euc_norm_squared, sketch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc73770-0eee-421f-946d-e60002b35534",
   "metadata": {},
   "source": [
    "### Train all Clients\n",
    "\n",
    "Notes about the following potentialy general `tf.function`:\n",
    "\n",
    "1. Even though `clients_cnn` and `federated_dataset` contain `tf.Keras.Module` and `tf.data.Dataset` elements, they both are python lists (python side-effects). Take a look at [Looping Over Python data](https://www.tensorflow.org/guide/function#tracing) and afterwards [For example, the following loop is unrolled, even though the list contains ...](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/control_flow.md#while-statements) to get more insight.\n",
    "\n",
    "2. TL;DR: It is very-very bad in terms of RAM. It produces an unrolled loop. The graph becomes consequent `Delta_i_... = ... ; euc_norm_squared_clients.append(...) ; sketch_clients.append(...) ;` commands `len(client_cnns)` number of times. This produces a huge graph (for instance, for `NUM_CLIENTS`=8, 4GB graph is produced). Notice that each sequence of the two commands has a big (unseen) underlying graph going to the bottom, that is, `.step` in the `tf.Keras.Module` class!\n",
    "\n",
    "3. Even if we had endless RAM the usage of `tf.function` is still arguable. For instance, on testing for 16 clients the difference between the two is only 20-30ms with total execution time in the order of 200-250ms. Only if we had a huge amount of CPUs or GPU we could consider it, but still... there must be a better approach (`Dask` or a different implementation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e80815b8-a83e-42df-a728-dbbcde77b370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clients_train_sketch(w_t0, client_cnns, federated_dataset, ams_sketch):\n",
    "    \"\"\"\n",
    "    :param w_t0: Vector Tensor shape=(d,). Same shape with `client_cnns[i].trainable_vars_as_vector()`\n",
    "    :param ams_sketch: Instance of `AmsSketch` which is an extension type (no retrace) for Count-Min sketch approx.\n",
    "    :return: (euc_norm_squared_clients, sketch_clients) - A list of Tensor shape=() dtype=float32 and a list of sketches\n",
    "        with shape=(ams_sketch.depth, ams_sketch.width) each one corresponds to one client.\n",
    "    \"\"\"\n",
    "    \n",
    "    euc_norm_squared_clients = []\n",
    "    sketch_clients = []\n",
    "\n",
    "    # client steps (number depends on `federated_dataset`, i.e., `.take(num)`)\n",
    "    for client_cnn, client_dataset in zip(client_cnns, federated_dataset):\n",
    "        Delta_i_euc_norm_squared, sketch = client_train_sketch(\n",
    "            w_t0, client_cnn, client_dataset, ams_sketch\n",
    "        )\n",
    "\n",
    "        euc_norm_squared_clients.append(Delta_i_euc_norm_squared)\n",
    "        sketch_clients.append(sketch)\n",
    "        \n",
    "    return euc_norm_squared_clients, sketch_clients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e51698-cb10-4c7a-a8a9-20d3984d36b0",
   "metadata": {},
   "source": [
    "### F Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56a767c4-595b-4adb-866b-de3d8589f8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_sketch(euc_norm_squared_clients, sketch_clients, epsilon):\n",
    "    \n",
    "    S_1 = tf.reduce_mean(euc_norm_squared_clients)\n",
    "    S_2 = tf.reduce_mean(sketch_clients, axis=0)  # shape=(`depth`, width`). See `Ξ` in theoretical analysis\n",
    "    \n",
    "    # See theoretical analysis above\n",
    "    return S_1 - (1. / (1. + epsilon)) * AmsSketch.estimate_euc_norm_squared(S_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37661782-3943-4729-9f1d-bb34209a5a90",
   "metadata": {},
   "source": [
    "# 4️⃣. Synchronous (synchronize in every step!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d974b469-7a21-4309-b3fa-5d2d7bc6b64f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clients_train_synchronous(client_cnns, federated_dataset): # NEW\n",
    "    for client_cnn, client_dataset in zip(client_cnns, federated_dataset):\n",
    "        client_cnn.train(client_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b92a43b-19d3-4081-9528-3af316d640c2",
   "metadata": {},
   "source": [
    "### Metrics (early)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc208c0b-d999-4c2a-ba85-89ad51900366",
   "metadata": {},
   "source": [
    "Due to memory concerns our Metrics will consist of `namedtuple` containers which are very memory efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb26382e-e7d1-425a-b289-50627b618575",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e0fd2ded-ccbe-4efa-8781-f8386cd18efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "RoundMetrics = namedtuple(\"RoundMetrics\", [\"epoch\", \"round\", \"total_fda_steps\", \"est_var\", \"actual_var\"])\n",
    "EpochMetrics = namedtuple(\"EpochMetrics\", [\"epoch\", \"total_rounds\", \"total_fda_steps\", \"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210307c8-a466-4211-a80d-08811139c560",
   "metadata": {},
   "source": [
    "A few notes about metrics:\n",
    "\n",
    "1. We consider the synchronization before starting training as one round, no metrics are stored we just initialize `total_rounds` to one.\n",
    "\n",
    "2. We consider the first Epoch to be indexed with one (not zero).\n",
    "\n",
    "3. `EpochMetrics` for some `epoch` correspond to final metrics of that specific epoch, that is, we store these metrics when the epoch changes to the next.\n",
    "\n",
    "4. In `RoundMetrics`, the column `epoch` corresponds to the epoch that this round ended at. (We can always find when it began by the previous entry).\n",
    "\n",
    "4. The last round will (probably) be prematurely ended by `break` because the final Epoch ended. We store this and leave it to the data analysis part to deal with it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e64dd3-40c9-4bfd-8453-b47f02b3edfb",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2faacbc-e291-4748-a288-90c494887999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def federated_simulation(test_dataset, federated_dataset, fda_name, server_cnn, client_cnns, num_epochs, theta, \n",
    "                         fda_steps_in_one_epoch, compile_and_build_model_func, ams_sketch=None, epsilon=None):\n",
    "    \"\"\" Run a federated learning simulation of one of the FDA methods. We keep general and time-series-like metrics. \"\"\"\n",
    "    \n",
    "    # ---- Inits -----\n",
    "    tmp_fda_steps = 0  # helper variable to monitor when Epochs pass using `fda_steps_in_one_epoch`\n",
    "    epoch_count = 1\n",
    "    total_rounds = 1\n",
    "    total_fda_steps = 0\n",
    "    est_var = 0\n",
    "    \n",
    "    # ----- Sync ----- TODO: Count or not first sync?\n",
    "    server_cnn.set_trainable_variables(average_client_weights(client_cnns))\n",
    "    synchronize_clients(server_cnn, client_cnns)\n",
    "    w_t0 = server_cnn.trainable_vars_as_vector()\n",
    "    if fda_name == \"linear\": w_tminus1 = w_t0\n",
    "    \n",
    "    # ----- Metrics -----\n",
    "    round_metrics_list = []\n",
    "    epoch_metrics_list = []\n",
    "    \n",
    "    while epoch_count <= num_epochs:\n",
    "        \n",
    "        # We consider a `round` to be all the training until this while loop finishes and synchronization must occur\n",
    "        while est_var <= theta:\n",
    "            \n",
    "            if fda_name == \"naive\":\n",
    "                # train clients, each on some number of batches which depends on `.take` creation of dataset (Default=1)\n",
    "                Delta_i_euc_norm_squared = clients_train_naive(w_t0, client_cnns, federated_dataset)\n",
    "                \n",
    "                # Naive estimation of variance\n",
    "                est_var = F_naive(Delta_i_euc_norm_squared).numpy()\n",
    "                \n",
    "            if fda_name == \"linear\":\n",
    "                # train clients, each on some number of batches which depends on `.take` creation of dataset (Default=1)\n",
    "                euc_norm_squared_clients, ksi_delta_clients = clients_train_linear(w_t0, w_tminus1, client_cnns, federated_dataset)\n",
    "                \n",
    "                # Linear estimation of variance\n",
    "                est_var = F_linear(euc_norm_squared_clients, ksi_delta_clients).numpy()\n",
    "                \n",
    "            if fda_name == \"sketch\":\n",
    "                # train clients, each on some number of batches which depends on `.take` creation of dataset (Default=1)\n",
    "                euc_norm_squared_clients, sketch_clients = clients_train_sketch(w_t0, client_cnns, federated_dataset, ams_sketch)\n",
    "                \n",
    "                # Sketch estimation of variance\n",
    "                est_var = F_sketch(euc_norm_squared_clients, sketch_clients, epsilon).numpy()\n",
    "            \n",
    "            if fda_name == \"synchronous\":  # NEW\n",
    "                # train clients, each on some number of batches which depends on `.take` creation of dataset (Default=1)\n",
    "                clients_train_synchronous(client_cnns, federated_dataset)\n",
    "                \n",
    "                # Force synchronization in every round, `synchronous` method\n",
    "                est_var = theta + 1\n",
    "            \n",
    "            tmp_fda_steps += 1\n",
    "            total_fda_steps += 1\n",
    "            \n",
    "            # If Epoch has passed in this fda step\n",
    "            if tmp_fda_steps >= fda_steps_in_one_epoch:\n",
    "                \n",
    "                # Minus here and not `tmp_fda_steps = 0` because `fda_steps_in_one_epoch` is not an integer necessarily\n",
    "                # and we need to keep track of potentially more data seen in this fda step (many clients, large batch sizes)\n",
    "                tmp_fda_steps -= fda_steps_in_one_epoch\n",
    "                \n",
    "                # ---------- Metrics ------------\n",
    "                acc = current_accuracy(client_cnns, test_dataset, compile_and_build_model_func)\n",
    "                epoch_metrics = EpochMetrics(epoch_count, total_rounds, total_fda_steps, acc)\n",
    "                epoch_metrics_list.append(epoch_metrics)\n",
    "                print(epoch_metrics) # remove\n",
    "                # -------------------------------\n",
    "                \n",
    "                epoch_count += 1\n",
    "                \n",
    "                if epoch_count > num_epochs: break\n",
    "        \n",
    "        # Round finished\n",
    "\n",
    "        # server average\n",
    "        server_cnn.set_trainable_variables(average_client_weights(client_cnns))\n",
    "        \n",
    "        if fda_name == \"synchronous\":  # NEW\n",
    "            synchronize_clients(server_cnn, client_cnns)\n",
    "            est_var = 0\n",
    "            total_rounds += 1\n",
    "            continue\n",
    "\n",
    "        # ------------------------- Metrics --------------------------------\n",
    "        actual_var = variance(server_cnn, client_cnns).numpy()\n",
    "        round_metrics = RoundMetrics(epoch_count, total_rounds, total_fda_steps, est_var, actual_var)\n",
    "        round_metrics_list.append(round_metrics)\n",
    "        print(round_metrics)\n",
    "        # ------------------------------------------------------------------\n",
    "\n",
    "        if fda_name == \"linear\": w_tminus1 = w_t0\n",
    "        w_t0 = server_cnn.trainable_vars_as_vector()\n",
    "\n",
    "        # clients sync\n",
    "        synchronize_clients(server_cnn, client_cnns)\n",
    "        est_var = 0\n",
    "\n",
    "        total_rounds += 1\n",
    "        \n",
    "    \n",
    "    return epoch_metrics_list, round_metrics_list\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30159ba5-2b67-46d0-b176-f94932b32e61",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    "We have two types of Metrics:\n",
    "\n",
    "1. `EpochMetrics`: General metrics kept each Epoch (`total_rounds`, ..., `est_var`, etc.).\n",
    "\n",
    "2. `RoundMetrics`: Time-series type of Metrics stored in each round. This data are expected to be large in size even for small amount of tests.\n",
    "\n",
    "We need to somehow ID every entry of both of these type of metrics since they will be combined with different tests (ex. different number of clients etc.). So, we do the logical which is pass the `TestId` as defined by the distinct combination of parameters. As explained before we choose `namedtuple` for memory efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c327cd97-de74-4425-b547-314f60eab85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TestId = namedtuple(\n",
    "        'TestId',\n",
    "        [\"dataset_name\", \"fda_name\", \"num_clients\", \"batch_size\", \"num_steps_until_rtc_check\",\n",
    "         \"theta\", \"nn_num_weights\", \"sketch_width\", \"sketch_depth\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ad59e7e-eb28-4d79-ba9e-686536678bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "EpochMetricsWithId = namedtuple('EpochMetricsWithId', TestId._fields + EpochMetrics._fields)\n",
    "RoundMetricsWithId = namedtuple('RoundMetricsWithId', TestId._fields + RoundMetrics._fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ddf63f-9968-4f97-9dd8-80b152db2b82",
   "metadata": {},
   "source": [
    "Function that takes as input an instance of `TestId` and the two metrics lists that come from a single test (one FDA synchronization) and return the two lists back ready to be used as `.extend` in the general metrics lists for all the tests (properly ID'd)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b733a0b-d8cc-403c-93fe-9b504c40d49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_metrics_with_test_id(epoch_metrics_list, round_metrics_list, test_id):\n",
    "    \n",
    "    epoch_metrics_with_test_id = [\n",
    "        EpochMetricsWithId(*test_id, *epoch_metrics)\n",
    "        for epoch_metrics in epoch_metrics_list\n",
    "    ]\n",
    "    \n",
    "    round_metrics_with_test_id = [\n",
    "        RoundMetricsWithId(*test_id, *round_metrics)\n",
    "        for round_metrics in round_metrics_list\n",
    "    ]\n",
    "    \n",
    "    return epoch_metrics_with_test_id, round_metrics_with_test_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00b5729-9811-454e-af9e-3b0b20f9f944",
   "metadata": {},
   "source": [
    "### Testing Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd37c243-6565-4126-af88-bdc4d9e6a166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_federated_simulation(num_clients, train_dataset, batch_size, num_steps_until_rtc_check, compile_and_build_model_func, seed=None, bench_test=False):\n",
    "    \n",
    "    # 1. Helper variable to count Epochs\n",
    "    if bench_test:\n",
    "        fda_steps_in_one_epoch = 10\n",
    "    else:\n",
    "        fda_steps_in_one_epoch = ((n_train / batch_size) / num_clients) / num_steps_until_rtc_check\n",
    "    \n",
    "    # 2. Federated Dataset creation\n",
    "    clients_federated_data = create_federated_data_for_clients(num_clients, train_dataset)\n",
    "    federated_dataset = prepare_federated_data_for_test(clients_federated_data, batch_size, num_steps_until_rtc_check, seed)\n",
    "    \n",
    "    # 3. Models creation\n",
    "    server_cnn = compile_and_build_model_func()\n",
    "    client_cnns = [compile_and_build_model_func() for _ in range(num_clients)]\n",
    "    \n",
    "    return server_cnn, client_cnns, federated_dataset, fda_steps_in_one_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a129b2-2d0f-4a85-a433-8ce95e2c6947",
   "metadata": {},
   "source": [
    "### Single FDA method simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "43168637-4f32-4167-96b5-1764f937b918",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "def single_simulation(fda_name, num_clients, train_dataset, test_dataset, batch_size, num_steps_until_rtc_check,\n",
    "                     theta, num_epochs, sketch_width, sketch_depth, compile_and_build_model_func, bench_test=False):\n",
    "    \n",
    "     # 1. Preparation\n",
    "    server_cnn, client_cnns, federated_dataset, fda_steps_in_one_epoch = prepare_for_federated_simulation(\n",
    "        num_clients, train_dataset, batch_size, num_steps_until_rtc_check, compile_and_build_model_func, bench_test=bench_test\n",
    "    )\n",
    "\n",
    "    # 2. Simulation\n",
    "    epoch_metrics_list, round_metrics_list = federated_simulation(\n",
    "        test_dataset, federated_dataset, fda_name, server_cnn, client_cnns, num_epochs, theta, fda_steps_in_one_epoch,\n",
    "        compile_and_build_model_func, ams_sketch = AmsSketch(width=sketch_width, depth=sketch_depth) if fda_name == \"sketch\" else None,\n",
    "        epsilon = 1. / sqrt(sketch_width) if fda_name == \"sketch\" else None\n",
    "    )\n",
    "\n",
    "    # 3. Create Test ID\n",
    "    test_id = TestId(\n",
    "        \"EMNIST\", fda_name, num_clients, batch_size, num_steps_until_rtc_check, theta, \n",
    "        count_weights(server_cnn), sketch_width, sketch_depth\n",
    "    )\n",
    "\n",
    "    # 4. Store ID'd Metrics\n",
    "    epoch_metrics_with_test_id_list, round_metrics_with_test_id_list = process_metrics_with_test_id(\n",
    "        epoch_metrics_list, round_metrics_list, test_id\n",
    "    )\n",
    "    \n",
    "    # Not needed, but we are proactive because `Dask` uses this\n",
    "    del server_cnn, client_cnns, federated_dataset\n",
    "    \n",
    "    return epoch_metrics_with_test_id_list, round_metrics_with_test_id_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caff405-7d37-4d02-af1e-75ce1bcde603",
   "metadata": {},
   "source": [
    "### Print Current test Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "52199ae4-4a60-4eb1-813a-43f16d57480f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_current_test_info(fda_name, num_clients, batch_size, num_epochs, num_steps_until_rtc_check, theta):\n",
    "    print()\n",
    "    print(f\"------------ Current Test : ------------\")\n",
    "    print(f\"FDA name : {fda_name}\")\n",
    "    print(f\"Num Clients : {num_clients}\")\n",
    "    print(f\"Batch size : {batch_size}\")\n",
    "    print(f\"Num Epochs : {num_epochs}\")\n",
    "    print(f\"Number of steps until we check RTC : {num_steps_until_rtc_check}\")\n",
    "    print(f\"Theta : {theta}\")\n",
    "    print(\"-----------------------------------------\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bd6942-cad1-4bc9-bba7-486542104eb5",
   "metadata": {},
   "source": [
    "# FDA-methods simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fb23d36a-11c6-4d90-8a3e-521f332da2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fda_simulation(num_clients, train_dataset, test_dataset, batch_size, num_steps_until_rtc_check,\n",
    "                   theta, num_epochs, sketch_width, sketch_depth, compile_and_build_model_func, bench_test=False):\n",
    "    \n",
    "    complete_epoch_metrics = []\n",
    "    complete_round_metrics = []\n",
    "    \n",
    "    for fda_name in [\"naive\", \"linear\", \"sketch\"]:\n",
    "        \n",
    "        print_current_test_info(fda_name, num_clients, batch_size, num_epochs, num_steps_until_rtc_check, theta)\n",
    "\n",
    "        # 4. Store ID'd Metrics\n",
    "        epoch_metrics_with_test_id_list, round_metrics_with_test_id_list = single_simulation(\n",
    "            fda_name, num_clients, train_dataset, test_dataset, batch_size, num_steps_until_rtc_check, theta, num_epochs,\n",
    "            sketch_width if fda_name == \"sketch\" else -1, sketch_depth if fda_name == \"sketch\" else -1, \n",
    "            compile_and_build_model_func, bench_test=bench_test\n",
    "        )\n",
    "\n",
    "        complete_epoch_metrics.extend(epoch_metrics_with_test_id_list)\n",
    "        complete_round_metrics.extend(round_metrics_with_test_id_list)\n",
    "    \n",
    "    return complete_epoch_metrics, complete_round_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb34edc-2792-4afb-991b-6dc3913b5086",
   "metadata": {},
   "source": [
    "# Synchronous simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b17bf0d3-5385-435c-9acf-c09ae868828d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def synchronous_simulation(num_clients, train_dataset, test_dataset, batch_size, num_steps_until_rtc_check,\n",
    "                           theta, num_epochs, compile_and_build_model_func, bench_test=False):\n",
    "    \n",
    "    print_current_test_info('synchronous', num_clients, batch_size, num_epochs, num_steps_until_rtc_check, theta)\n",
    "    \n",
    "    return single_simulation(\n",
    "            'synchronous', num_clients, train_dataset, test_dataset, batch_size, num_steps_until_rtc_check, theta, num_epochs,\n",
    "             -1, -1, compile_and_build_model_func, bench_test=bench_test\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7bfd0d-af24-47d7-a30b-b57fa2b904c7",
   "metadata": {},
   "source": [
    "# Run tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e1b1f5eb-adfd-4ade-9866-815f10c9f788",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------ Current Test : ------------\n",
      "FDA name : naive\n",
      "Num Clients : 5\n",
      "Batch size : 32\n",
      "Num Epochs : 2\n",
      "Number of steps until we check RTC : 1\n",
      "Theta : 1.0\n",
      "-----------------------------------------\n",
      "\n",
      "Retrace LeNet5.step()\n",
      "Retrace LeNet5.step()\n",
      "Retrace LeNet5.step()\n",
      "Retrace LeNet5.step()\n",
      "Retrace LeNet5.step()\n",
      "Retrace LeNet5.step()\n",
      "Retrace LeNet5.step()\n",
      "Retrace LeNet5.step()\n",
      "Retrace LeNet5.step()\n",
      "Retrace LeNet5.step()\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function LeNet5.step at 0x7f4965bf34c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "RoundMetrics(epoch=1, round=1, total_fda_steps=7, est_var=1.1616861, actual_var=0.4159701)\n",
      "RoundMetrics(epoch=1, round=2, total_fda_steps=14, est_var=1.0678132, actual_var=0.16751987)\n",
      "RoundMetrics(epoch=1, round=3, total_fda_steps=21, est_var=1.3096124, actual_var=0.16894269)\n",
      "RoundMetrics(epoch=1, round=4, total_fda_steps=27, est_var=1.0553515, actual_var=0.14087683)\n",
      "RoundMetrics(epoch=1, round=5, total_fda_steps=34, est_var=1.2343023, actual_var=0.15487087)\n",
      "RoundMetrics(epoch=1, round=6, total_fda_steps=42, est_var=1.1546633, actual_var=0.15783347)\n",
      "RoundMetrics(epoch=1, round=7, total_fda_steps=52, est_var=1.0806792, actual_var=0.24347949)\n",
      "RoundMetrics(epoch=1, round=8, total_fda_steps=64, est_var=1.1077757, actual_var=0.37528357)\n",
      "RoundMetrics(epoch=1, round=9, total_fda_steps=78, est_var=1.0042992, actual_var=0.38578877)\n",
      "RoundMetrics(epoch=1, round=10, total_fda_steps=93, est_var=1.0003111, actual_var=0.4608162)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 29\u001b[0m\n\u001b[1;32m     24\u001b[0m     all_epoch_metrics, all_round_metrics \u001b[38;5;241m=\u001b[39m synchronous_simulation(\n\u001b[1;32m     25\u001b[0m         num_clients, train_dataset, test_dataset, batch_size, num_steps_until_rtc_check,\n\u001b[1;32m     26\u001b[0m         theta, num_epochs, compile_and_build_model_func, bench_test\u001b[38;5;241m=\u001b[39mbench_test\n\u001b[1;32m     27\u001b[0m     )\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 29\u001b[0m     all_epoch_metrics, all_round_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mfda_simulation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_clients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_steps_until_rtc_check\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msketch_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msketch_depth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompile_and_build_model_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbench_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbench_test\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m#epoch_metrics_df = pd.DataFrame(all_epoch_metrics)\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m#round_metrics_df = pd.DataFrame(all_round_metrics)\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m#epoch_metrics_df.to_parquet(epoch_metrics_filename)\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m#round_metrics_df.to_parquet(round_metrics_filename)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[37], line 12\u001b[0m, in \u001b[0;36mfda_simulation\u001b[0;34m(num_clients, train_dataset, test_dataset, batch_size, num_steps_until_rtc_check, theta, num_epochs, sketch_width, sketch_depth, compile_and_build_model_func, bench_test)\u001b[0m\n\u001b[1;32m      9\u001b[0m print_current_test_info(fda_name, num_clients, batch_size, num_epochs, num_steps_until_rtc_check, theta)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# 4. Store ID'd Metrics\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m epoch_metrics_with_test_id_list, round_metrics_with_test_id_list \u001b[38;5;241m=\u001b[39m \u001b[43msingle_simulation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfda_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_clients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_steps_until_rtc_check\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43msketch_width\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfda_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msketch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msketch_depth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfda_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msketch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompile_and_build_model_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbench_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbench_test\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m complete_epoch_metrics\u001b[38;5;241m.\u001b[39mextend(epoch_metrics_with_test_id_list)\n\u001b[1;32m     19\u001b[0m complete_round_metrics\u001b[38;5;241m.\u001b[39mextend(round_metrics_with_test_id_list)\n",
      "Cell \u001b[0;32mIn[35], line 12\u001b[0m, in \u001b[0;36msingle_simulation\u001b[0;34m(fda_name, num_clients, train_dataset, test_dataset, batch_size, num_steps_until_rtc_check, theta, num_epochs, sketch_width, sketch_depth, compile_and_build_model_func, bench_test)\u001b[0m\n\u001b[1;32m      7\u001b[0m server_cnn, client_cnns, federated_dataset, fda_steps_in_one_epoch \u001b[38;5;241m=\u001b[39m prepare_for_federated_simulation(\n\u001b[1;32m      8\u001b[0m     num_clients, train_dataset, batch_size, num_steps_until_rtc_check, compile_and_build_model_func, bench_test\u001b[38;5;241m=\u001b[39mbench_test\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# 2. Simulation\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m epoch_metrics_list, round_metrics_list \u001b[38;5;241m=\u001b[39m \u001b[43mfederated_simulation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfederated_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfda_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_cnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient_cnns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfda_steps_in_one_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompile_and_build_model_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mams_sketch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mAmsSketch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msketch_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msketch_depth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfda_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msketch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43msketch_width\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfda_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msketch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# 3. Create Test ID\u001b[39;00m\n\u001b[1;32m     19\u001b[0m test_id \u001b[38;5;241m=\u001b[39m TestId(\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEMNIST\u001b[39m\u001b[38;5;124m\"\u001b[39m, fda_name, num_clients, batch_size, num_steps_until_rtc_check, theta, \n\u001b[1;32m     21\u001b[0m     count_weights(server_cnn), sketch_width, sketch_depth\n\u001b[1;32m     22\u001b[0m )\n",
      "Cell \u001b[0;32mIn[30], line 29\u001b[0m, in \u001b[0;36mfederated_simulation\u001b[0;34m(test_dataset, federated_dataset, fda_name, server_cnn, client_cnns, num_epochs, theta, fda_steps_in_one_epoch, compile_and_build_model_func, ams_sketch, epsilon)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m est_var \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m theta:\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fda_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnaive\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;66;03m# train clients, each on some number of batches which depends on `.take` creation of dataset (Default=1)\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m         Delta_i_euc_norm_squared \u001b[38;5;241m=\u001b[39m \u001b[43mclients_train_naive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw_t0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient_cnns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfederated_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;66;03m# Naive estimation of variance\u001b[39;00m\n\u001b[1;32m     32\u001b[0m         est_var \u001b[38;5;241m=\u001b[39m F_naive(Delta_i_euc_norm_squared)\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "Cell \u001b[0;32mIn[17], line 10\u001b[0m, in \u001b[0;36mclients_train_naive\u001b[0;34m(w_t0, client_cnns, federated_dataset)\u001b[0m\n\u001b[1;32m      7\u001b[0m S_i_clients \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m client_cnn, client_dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(client_cnns, federated_dataset):\n\u001b[0;32m---> 10\u001b[0m     Delta_i_euc_norm_squared \u001b[38;5;241m=\u001b[39m \u001b[43mclient_train_naive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw_t0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient_cnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     S_i_clients\u001b[38;5;241m.\u001b[39mappend(Delta_i_euc_norm_squared)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m S_i_clients\n",
      "Cell \u001b[0;32mIn[16], line 8\u001b[0m, in \u001b[0;36mclient_train_naive\u001b[0;34m(w_t0, client_cnn, client_dataset)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m:param w_t0: Vector Tensor shape=(d,). Same shape with `client_cnn.trainable_vars_as_vector()`\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m:return: Tensor shape=() dtype=tf.float32\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# number of steps depend on `.take()` from `dataset`\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mclient_cnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m Delta_i \u001b[38;5;241m=\u001b[39m client_cnn\u001b[38;5;241m.\u001b[39mtrainable_vars_as_vector() \u001b[38;5;241m-\u001b[39m w_t0\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#||D(t)_i||^2 , shape = () \u001b[39;00m\n",
      "Cell \u001b[0;32mIn[12], line 65\u001b[0m, in \u001b[0;36mLeNet5.train\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset):\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep(batch)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-2.4.0/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:422\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mor\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minside_function():\n\u001b[1;32m    421\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[0;32m--> 422\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43miterator_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOwnedIterator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    424\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__iter__() is only supported inside of tf.function \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    425\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor when eager execution is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-2.4.0/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py:682\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m element_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    681\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(error_message)\n\u001b[0;32m--> 682\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-2.4.0/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py:686\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_iterator\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset):\n\u001b[1;32m    685\u001b[0m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 686\u001b[0m   dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_options\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    688\u001b[0m   \u001b[38;5;66;03m# Store dataset reference to ensure that dataset is alive when this iterator\u001b[39;00m\n\u001b[1;32m    689\u001b[0m   \u001b[38;5;66;03m# is being used. For example, `tf.data.Dataset.from_generator` registers\u001b[39;00m\n\u001b[1;32m    690\u001b[0m   \u001b[38;5;66;03m# a few py_funcs that are needed in `self._next_internal`.  If the dataset\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[38;5;66;03m# is deleted, this iterator crashes on `self.__next__(...)` call.\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset \u001b[38;5;241m=\u001b[39m dataset\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-2.4.0/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:397\u001b[0m, in \u001b[0;36mDatasetV2._apply_options\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    388\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.data graph rewrites are not compatible with tf.Variable. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    390\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following rewrites will be disabled: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m. To enable \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    391\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrewrites, use resource variables instead by calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    392\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.enable_resource_variables()` at the start of the program.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m    393\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(graph_rewrites\u001b[38;5;241m.\u001b[39menabled \u001b[38;5;241m+\u001b[39m graph_rewrites\u001b[38;5;241m.\u001b[39mdefault))\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (graph_rewrites\u001b[38;5;241m.\u001b[39menabled \u001b[38;5;129;01mor\u001b[39;00m graph_rewrites\u001b[38;5;241m.\u001b[39mdefault \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    395\u001b[0m       (options\u001b[38;5;241m.\u001b[39mexperimental_optimization\u001b[38;5;241m.\u001b[39mapply_default_optimizations  \u001b[38;5;66;03m# pylint: disable=g-bool-id-comparison\u001b[39;00m\n\u001b[1;32m    396\u001b[0m        \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m)):\n\u001b[0;32m--> 397\u001b[0m   dataset \u001b[38;5;241m=\u001b[39m \u001b[43m_OptimizeDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph_rewrites\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mgraph_rewrites\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mgraph_rewrites\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph_rewrite_configs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;66;03m# (4) Apply stats aggregator options\u001b[39;00m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m options\u001b[38;5;241m.\u001b[39mexperimental_stats \u001b[38;5;129;01mand\u001b[39;00m options\u001b[38;5;241m.\u001b[39mexperimental_stats\u001b[38;5;241m.\u001b[39maggregator:  \u001b[38;5;66;03m# pylint: disable=line-too-long\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-2.4.0/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:4577\u001b[0m, in \u001b[0;36m_OptimizeDataset.__init__\u001b[0;34m(self, input_dataset, optimizations_enabled, optimizations_disabled, optimizations_default, optimization_configs)\u001b[0m\n\u001b[1;32m   4566\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizations_disabled \u001b[38;5;241m=\u001b[39m convert\u001b[38;5;241m.\u001b[39moptional_param_to_tensor(\n\u001b[1;32m   4567\u001b[0m     argument_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizations_disabled\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   4568\u001b[0m     argument_value\u001b[38;5;241m=\u001b[39moptimizations_disabled,\n\u001b[1;32m   4569\u001b[0m     argument_default\u001b[38;5;241m=\u001b[39m[],\n\u001b[1;32m   4570\u001b[0m     argument_dtype\u001b[38;5;241m=\u001b[39mdtypes\u001b[38;5;241m.\u001b[39mstring)\n\u001b[1;32m   4571\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizations_default \u001b[38;5;241m=\u001b[39m convert\u001b[38;5;241m.\u001b[39moptional_param_to_tensor(\n\u001b[1;32m   4572\u001b[0m     argument_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizations_default\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   4573\u001b[0m     argument_value\u001b[38;5;241m=\u001b[39moptimizations_default,\n\u001b[1;32m   4574\u001b[0m     argument_default\u001b[38;5;241m=\u001b[39m[],\n\u001b[1;32m   4575\u001b[0m     argument_dtype\u001b[38;5;241m=\u001b[39mdtypes\u001b[38;5;241m.\u001b[39mstring)\n\u001b[0;32m-> 4577\u001b[0m variant_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize_dataset_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4578\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variant_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m   4579\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizations_enabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4580\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizations_disabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4581\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizations_default\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4582\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimization_configs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimization_configs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4583\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_structure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4585\u001b[0m \u001b[38;5;28msuper\u001b[39m(_OptimizeDataset, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(input_dataset, variant_tensor)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-2.4.0/lib/python3.8/site-packages/tensorflow/python/ops/gen_dataset_ops.py:4021\u001b[0m, in \u001b[0;36moptimize_dataset_v2\u001b[0;34m(input_dataset, optimizations_enabled, optimizations_disabled, optimizations_default, output_types, output_shapes, optimization_configs, name)\u001b[0m\n\u001b[1;32m   4019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m   4020\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 4021\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4022\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOptimizeDatasetV2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizations_enabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4023\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptimizations_disabled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizations_default\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_types\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4024\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_shapes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimization_configs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4025\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptimization_configs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4026\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   4027\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    #import pandas as pd\n",
    "    \n",
    "    train_dataset, test_dataset = convert_to_tf_dataset(*load_data())\n",
    "\n",
    "    epoch_metrics_filename = 'epoch_metrics.parquet'\n",
    "    round_metrics_filename = 'round_metrics.parquet'\n",
    "    \n",
    "    num_clients = 5\n",
    "    batch_size = 32\n",
    "    theta = 1.\n",
    "    bench_test = False\n",
    "    synchronous = False\n",
    "    \n",
    "    num_epochs = 2\n",
    "    num_steps_until_rtc_check = 1\n",
    "    sketch_width = 250\n",
    "    sketch_depth = 5\n",
    "    \n",
    "    compile_and_build_model_func = get_compiled_and_built_lenet\n",
    "    \n",
    "    if synchronous:\n",
    "        all_epoch_metrics, all_round_metrics = synchronous_simulation(\n",
    "            num_clients, train_dataset, test_dataset, batch_size, num_steps_until_rtc_check,\n",
    "            theta, num_epochs, compile_and_build_model_func, bench_test=bench_test\n",
    "        )\n",
    "    else:\n",
    "        all_epoch_metrics, all_round_metrics = fda_simulation(\n",
    "            num_clients, train_dataset, test_dataset, batch_size, num_steps_until_rtc_check,\n",
    "            theta, num_epochs, sketch_width, sketch_depth, compile_and_build_model_func, bench_test=bench_test\n",
    "        )\n",
    "    \n",
    "    #epoch_metrics_df = pd.DataFrame(all_epoch_metrics)\n",
    "    #round_metrics_df = pd.DataFrame(all_round_metrics)\n",
    "    \n",
    "    #epoch_metrics_df.to_parquet(epoch_metrics_filename)\n",
    "    #round_metrics_df.to_parquet(round_metrics_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0e3c10-9de2-4473-9d2c-35c32fc57fc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epoch_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59798cc2-09bb-4a40-a1ec-938776d04162",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-2.4.0]",
   "language": "python",
   "name": "conda-env-tf-2.4.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
