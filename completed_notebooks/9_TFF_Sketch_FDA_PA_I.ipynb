{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16945920",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5666e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.50.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tff.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70db373c",
   "metadata": {},
   "source": [
    "## Create Binary Classification data with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8936c1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "n = 100_000\n",
    "d = 100\n",
    "\n",
    "\n",
    "noise_factor = 0.01 # % of the labels are randomly flipped, DEFAULT=0.01\n",
    "test_size = 0.1 # % of n\n",
    "# The factor multiplying the hypercube size. Larger values spread out the \n",
    "# clusters/classes and make the classification task easier. DEFAULT=1\n",
    "class_sep = -1\n",
    "seed = 7\n",
    "\n",
    "# Create (noisy) testing data for binary classification.\n",
    "X, y = make_classification(\n",
    "    n_samples=n, \n",
    "    n_features=d,\n",
    "    n_informative=d,\n",
    "    n_redundant=0, \n",
    "    n_classes=2,\n",
    "    class_sep=class_sep,\n",
    "    flip_y=noise_factor,\n",
    "    random_state=seed\n",
    ")\n",
    "\n",
    "# We will work with label values -1, +1 and not 0, +1 (convert)\n",
    "y[y == 0] = -1\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5cf2729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7658"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# PA-I regressor from sklearn\n",
    "pa1 = PassiveAggressiveClassifier(C=0.01, loss=\"hinge\", n_jobs=-1)\n",
    "pa1.fit(X_train, y_train)\n",
    "\n",
    "accuracy_score(y_test, pa1.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b180164a",
   "metadata": {},
   "source": [
    "## Convert to Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29d1b71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert the data to TensorFlow tensors\n",
    "X_train_tensor = tf.constant(X_train, dtype=tf.float32)\n",
    "y_train_tensor = tf.constant(y_train, dtype=tf.float32)\n",
    "X_test_tensor = tf.constant(X_test, dtype=tf.float32)\n",
    "y_test_tensor = tf.constant(y_test, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69cdcfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X, y, X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc001d5",
   "metadata": {},
   "source": [
    "## Prepare data for Tensorflow Federated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2921d7d",
   "metadata": {},
   "source": [
    "We have the training and testing Tensors holding our data. TFF expects for each client an `OrderedDict` containing `y` and `x` data. Hence, we preprocess our Tensors to follow this convention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53e2091a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NUM_CLIENTS = 20\n",
    "\n",
    "# https://www.tensorflow.org/api_docs/python/tf/data/Dataset#batch\n",
    "BATCH_SIZE = 32\n",
    "SHUFFLE_BUFFER = int(n / NUM_CLIENTS)\n",
    "NUM_STEPS_UNTIL_SYNC_CHECK = 1 # Steps until sync check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb39a4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of batches per client: 156\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of batches per client: {int((1-test_size)*n / (NUM_CLIENTS*BATCH_SIZE))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b5c09a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "# Create a dictionary with the slices for each client\n",
    "client_slices_train = {}\n",
    "slices_test = {}\n",
    "\n",
    "n_test = int(n - n*test_size)\n",
    "\n",
    "for i in range(NUM_CLIENTS):\n",
    "    # Compute the indices for this client's slice\n",
    "    start_idx = int(i * n_test / NUM_CLIENTS)\n",
    "    end_idx = int((i + 1) * n_test / NUM_CLIENTS)\n",
    "\n",
    "    # Get the slice for this client\n",
    "    X_client_train = X_train_tensor[start_idx:end_idx]\n",
    "    y_client_train = y_train_tensor[start_idx:end_idx]\n",
    "    \n",
    "    client_data_train = collections.OrderedDict([('y', y_client_train), ('x', X_client_train)])\n",
    "    \n",
    "    # Combine the slices into a single dataset\n",
    "    client_slices_train[f'client_{i}'] = client_data_train\n",
    "\n",
    "slices_test = collections.OrderedDict([('y', y_test_tensor), ('x', X_test_tensor)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c178a1f",
   "metadata": {},
   "source": [
    "For a sanity check let's see inside `client_slices_train` for the first x,y tuple of the 'first' client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f169ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100,), dtype=float32, numpy=\n",
       "array([ -0.43840492,  -8.602735  ,  -2.5706942 ,  -4.9137297 ,\n",
       "        -6.5534873 ,  -1.493107  ,   1.5496199 ,  -3.7241213 ,\n",
       "        -1.3533349 ,   6.419472  ,   9.5305    ,  -4.3068776 ,\n",
       "         1.8209226 ,   3.843456  ,  -6.099927  ,  -2.0994277 ,\n",
       "         5.0526834 ,   5.215126  ,   0.31975892,  -3.7441716 ,\n",
       "         6.497558  ,   1.8366643 ,  -2.1913083 ,   9.370149  ,\n",
       "        -3.4765773 ,  -1.4791905 ,  -6.209484  ,  -9.619827  ,\n",
       "        12.635862  ,   2.6724894 ,   7.8316813 ,  -4.6290493 ,\n",
       "         2.1394951 ,   4.2733474 ,   2.9170232 ,   2.5974233 ,\n",
       "        -0.99408895,   3.4114075 ,   2.2466993 ,   4.0714283 ,\n",
       "        -3.4346006 , -10.980129  ,   9.790514  ,   4.8795867 ,\n",
       "        -5.8626986 ,   6.1965513 ,   3.0575798 ,   9.065236  ,\n",
       "         1.9486036 ,  -9.105302  ,  -0.06869748,  -1.3184999 ,\n",
       "         4.211022  ,  -3.5095856 ,  -1.2642521 ,  -7.6088433 ,\n",
       "         4.582711  , -11.008443  ,   0.5270276 ,   3.9419043 ,\n",
       "        -5.483259  ,   4.303941  ,  -3.7320702 ,  -7.459744  ,\n",
       "         0.9873421 ,  -3.0163593 ,   1.2761813 ,   5.7072163 ,\n",
       "        -0.60984117,  -2.8034127 ,   1.0121217 ,   7.0424304 ,\n",
       "        -4.4048014 ,   5.43      ,  -4.0908318 ,  -5.516724  ,\n",
       "         5.168792  ,  -7.5033817 ,  -1.7357826 ,  -0.3198306 ,\n",
       "         0.25918704,   1.296209  ,  -5.3040895 ,   2.4852474 ,\n",
       "        -0.88268167,  -3.717105  ,  -4.6772604 ,  -1.0271661 ,\n",
       "         0.9102276 , -12.090892  ,   5.4819736 ,  -6.496595  ,\n",
       "         3.3641524 ,  -1.2723552 ,   2.9576976 ,   7.7134476 ,\n",
       "        -8.583975  ,   7.0026207 ,   1.1277165 ,  -9.168984  ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_slices_train['client_0']['x'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49e19090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_slices_train['client_0']['y'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2192acbc",
   "metadata": {},
   "source": [
    "Now, a client with `client_id` has it's single Tensor holding instances in`client_slices_train[client_id]['x']` and labels in `client_slices_train[client_id]['y']`. Let's take a step back from TFF. Having this data scheme, we can create a client's Tensorflow dataset using `from_tensor_slices` function passing the client's id as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c683cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/api_docs/python/tf/data/Dataset#batch\n",
    "\n",
    "def create_tf_dataset_for_client(client_id):\n",
    "    return tf.data.Dataset.from_tensor_slices(client_slices_train[client_id]) \\\n",
    "        .shuffle(SHUFFLE_BUFFER).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE) \\\n",
    "        .take(NUM_STEPS_UNTIL_SYNC_CHECK)\n",
    "\n",
    "def create_tf_dataset_for_test():\n",
    "    return tf.data.Dataset.from_tensor_slices(slices_test).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef737537",
   "metadata": {},
   "source": [
    "For TFF we need to construct Federated data for clients, i.e., `tff.simulation.datasets.ClientData`. We can use the `from_clients_and_tf_fn` function that takes as argument the `client_ids` : a list of strings corresponding to client ids, and a `serializable_dataset_fn` : a function that takes a `client_id` from the above list, and returns a `tf.data.Dataset`. It's obvious how we proceed with the code (using the above function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86b6c7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preprocessed_train_federated_dataset = tff.simulation.datasets.ClientData.from_clients_and_tf_fn(\n",
    "    client_ids=list(client_slices_train.keys()),\n",
    "    serializable_dataset_fn=lambda client_id: create_tf_dataset_for_client(client_id)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1acb22b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['client_0',\n",
       " 'client_1',\n",
       " 'client_2',\n",
       " 'client_3',\n",
       " 'client_4',\n",
       " 'client_5',\n",
       " 'client_6',\n",
       " 'client_7',\n",
       " 'client_8',\n",
       " 'client_9',\n",
       " 'client_10',\n",
       " 'client_11',\n",
       " 'client_12',\n",
       " 'client_13',\n",
       " 'client_14',\n",
       " 'client_15',\n",
       " 'client_16',\n",
       " 'client_17',\n",
       " 'client_18',\n",
       " 'client_19']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_train_federated_dataset.client_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1a74b7",
   "metadata": {},
   "source": [
    "**Note**: Cross-device federated learning does not use client IDs or perform any tracking of clients. However in simulation experiments using centralized test data the experimenter may select specific clients to be processed per round. The concept of a client ID is only available at the preprocessing stage when preparing input data for the simulation and is not part of the TensorFlow Federated core APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bde8820",
   "metadata": {},
   "source": [
    "Now, `preprocessed_train_federated_dataset` holds logic on how each client constructs its dataset. Note that so `client_slices_train` has already been materialized and lies in this context's memory.\n",
    "\n",
    "One way (the simplest) to feed federated data to TFF in a simulation is simply as a Python list, with each element of the list holds the data of an individual client, whether as a list or preferably as a `tf.data.Dataset`. Since we already created an interface that provides the latter we will use it. Here is a helper function that will construct a list of datasets from the set of users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c68b681",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_federated_data():    \n",
    "    return [\n",
    "        preprocessed_train_federated_dataset.create_tf_dataset_for_client(client)\n",
    "        for client in preprocessed_train_federated_dataset.client_ids\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1f39ef",
   "metadata": {},
   "source": [
    "**Important Note**: Firstly, we used `sklearn` to create the binary classification data eagerly, i.e., we were forced to materialize it into memory. In simulation, in general it is more sound to push preprocessing logic into each client, i.e., each client constructs its own dataset (from the same underlying distribution) or reads from a file or something else and he, himself processes the data as needed. This is the best approach and uses the TFF distributed engine the best way. But in our case this was illogical to happen since we are forced to construct the dataset in memory anyway. For example, we could have stored each client's data inside some serialized file (`client_0.tfrecord` for the first client and so on) and push logic where each clients diserializes and processes its own data but this would be silly and slower when testing. For a small example that showcases this scenario see *TFF - Introduction - Federated Core API - Part 3(examples).ipynb*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2b3cc5",
   "metadata": {},
   "source": [
    "## TFF Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114f51dd",
   "metadata": {},
   "source": [
    "Let's start with a simple float32 type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3016a9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLOAT32_TYPE = tff.TensorType(dtype=tf.float32, shape=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86f60f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'float32'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(FLOAT32_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "090749e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_FLOAT32 = tff.FederatedType(FLOAT32_TYPE, tff.CLIENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72cbef65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{float32}@CLIENTS'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(CLIENT_FLOAT32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "796f1d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVER_FLOAT32 = tff.FederatedType(FLOAT32_TYPE, tff.SERVER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0e6abe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'float32@SERVER'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(SERVER_FLOAT32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48c4bf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "INT32_TYPE = tff.TensorType(dtype=tf.int32, shape=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b735a318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'int32'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(INT32_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5f689f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVER_INT32_TYPE = tff.type_at_server(INT32_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62241ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'int32@SERVER'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(SERVER_INT32_TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3efd34",
   "metadata": {},
   "source": [
    "Create a TFF type representing a float32 tensor of shape (1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7844a47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLOAT32_1_TYPE = tff.TensorType(dtype=tf.float32, shape=(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa1bd80e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'float32[1]'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(FLOAT32_1_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f9aa834c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_FLOAT32_1_TYPE = tff.type_at_clients(FLOAT32_1_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "08586e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{float32[1]}@CLIENTS'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(CLIENT_FLOAT32_1_TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387f7d8f",
   "metadata": {},
   "source": [
    "1-dimensional tensor (vector) of length 1 with elements of type float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b813ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE_TYPE = tff.TensorType(dtype=tf.float32, shape=(2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "96b08b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'float32[2,1]'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(STATE_TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fdf9a8",
   "metadata": {},
   "source": [
    "The local client state $ S_i(t) $ as defined in the unpublished paper for Linear FDA (read theoretical analysis bellow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "168f7ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_STATE = tff.FederatedType(STATE_TYPE, tff.CLIENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1e006455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{float32[2,1]}@CLIENTS'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(CLIENT_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d3c683",
   "metadata": {},
   "source": [
    "First, let's define the type of input as a TFF named tuple. Since the size of data batches may vary, we set the batch dimension to None to indicate that the size of this dimension is unknown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "47b88ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BATCH_SPEC = collections.OrderedDict(\n",
    "    y=tf.TensorSpec(shape=[None], dtype=tf.float32),\n",
    "    x=tf.TensorSpec(shape=[None, d], dtype=tf.float32)\n",
    ")\n",
    "BATCH_TYPE = tff.to_type(BATCH_SPEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5d69a37d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<y=float32[?],x=float32[?,100]>'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(BATCH_TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a844eba",
   "metadata": {},
   "source": [
    "Every client holds a sequence of batches so the we define the client data type as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3bd7c409",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LOCAL_DATA_TYPE = tff.SequenceType(BATCH_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1f9890c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<y=float32[?],x=float32[?,100]>*'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(LOCAL_DATA_TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dedbfb",
   "metadata": {},
   "source": [
    "Let's now define the TFF type of the model which is simply a `tf.Variable` with shape (d, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1625384b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODEL_TYPE = tff.TensorType(dtype=tf.float32, shape=(d, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4db97c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'float32[100,1]'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bbc608",
   "metadata": {},
   "source": [
    "Since the server holds the 'global' model we need to create the Federated Type, defined as the tuple of a member: An instance of `tff.Type`, and a placement: The specification of placement of the member comonents (where this type is hosted at, for example, at `tff.SERVER` or `tff.CLIENTS`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "93453747",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SERVER_MODEL_TYPE = tff.type_at_server(MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "424c7703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'float32[100,1]@SERVER'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(SERVER_MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dd0413",
   "metadata": {},
   "source": [
    "Following, the same logic, we create the Federated Type of each client's data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d5a56be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CLIENT_DATA_TYPE = tff.type_at_clients(LOCAL_DATA_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7cc37383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{<y=float32[?],x=float32[?,100]>*}@CLIENTS'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(CLIENT_DATA_TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fe9341",
   "metadata": {},
   "source": [
    "We will also need to define the client models at the CLIENTS (for FDA later, to be cont...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9dd51ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_MODEL_TYPE = tff.type_at_clients(MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "47df0ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{float32[100,1]}@CLIENTS'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(CLIENT_MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af966b0",
   "metadata": {},
   "source": [
    "## Accuracy Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2427e37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tf.function\n",
    "def accuracy(model, dataset):\n",
    "    \n",
    "    @tf.function\n",
    "    def _batch_accuracy(model, batch):\n",
    "        x_batch, y_batch = batch['x'], tf.expand_dims(batch['y'], axis=1)\n",
    "\n",
    "        # dot(w, x) for the batch (each instance of x in x_batch) with with shape=(batchsize, 1)\n",
    "        weights_dot_x_batch = tf.matmul(x_batch, model)\n",
    "\n",
    "        # Prediction batch with shape=(batchsize, 1)\n",
    "        y_pred_batch = tf.sign(weights_dot_x_batch)\n",
    "\n",
    "        accuracy = tf.reduce_mean(tf.cast(tf.equal(y_pred_batch, y_batch), tf.float32))\n",
    "\n",
    "        return accuracy\n",
    "    \n",
    "    # We take advantage of AutoGraph (convert Python code to TensorFlow-compatible graph code automatically)\n",
    "    acc, num_batches = 0., 0.\n",
    "    for batch in dataset:\n",
    "        acc += _batch_accuracy(model, batch)\n",
    "        num_batches += 1\n",
    "        \n",
    "    acc = acc / num_batches\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7db2f5a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/miketheologitis/anaconda3/envs/tff-py39/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/miketheologitis/anaconda3/envs/tff-py39/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "\n",
    "@tff.tf_computation(MODEL_TYPE, LOCAL_DATA_TYPE)\n",
    "def accuracy_fn(model, dataset):\n",
    "    model = tf.Variable(initial_value=model)\n",
    "    return accuracy(model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ecea1204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(<model=float32[100,1],dataset=<y=float32[?],x=float32[?,100]>*> -> float32)'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(accuracy_fn.type_signature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5791b516",
   "metadata": {},
   "source": [
    "# Federated Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a379134b",
   "metadata": {},
   "source": [
    "### Server Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8b4f4816",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tff.tf_computation(MODEL_TYPE)\n",
    "def server_update_fn(clients_aggr_model):\n",
    "    model = tf.Variable(initial_value=clients_aggr_model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74689db",
   "metadata": {},
   "source": [
    "**Note**: This abstraction for this simple jupyter (where the model is a `tf.Variable`) is not necessary. We create this abstraction since it is common practice generally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9e2160",
   "metadata": {},
   "source": [
    "### Client train - PA-I Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642f3b8a",
   "metadata": {},
   "source": [
    "![PA](images/PA_binary_classifiers.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b5a9fb",
   "metadata": {},
   "source": [
    "Each client trains on its own dataset (which is a sequence of batches). Hence, we create the training process, currently a PA-1 Classifier. The input of `client_train` is the client model materialized inside its client and its dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "32494451",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tf.function\n",
    "def client_train(model, C, dataset):\n",
    "    \n",
    "    @tf.function\n",
    "    def _train_on_batch(model, C, batch):\n",
    "\n",
    "        x_batch, y_batch = batch['x'], tf.expand_dims(batch['y'], axis=1)\n",
    "\n",
    "        # dot(w, x) for the batch (each instance of x in x_batch) with with shape=(batchsize, 1)\n",
    "        weights_dot_x_batch = tf.matmul(x_batch, model)\n",
    "\n",
    "        # Prediction batch with shape=(batchsize, 1)\n",
    "        y_pred_batch = tf.sign(weights_dot_x_batch)\n",
    "\n",
    "        # Suffer loss for each prediction (of instance) in the batch with shape=(batchsize,1)\n",
    "        loss_batch = tf.maximum(0., 1. - tf.multiply(y_batch, weights_dot_x_batch))\n",
    "\n",
    "        # shape=(batchsize,1) where each instance is ||x||^2, x in x_batch\n",
    "        norm_batch = tf.expand_dims(tf.reduce_sum(tf.square(x_batch), axis=1), axis=1)\n",
    "        \n",
    "        # PA-1 : Learning rate t for each instance x, with shape=(batchsize,1)\n",
    "        t_batch = tf.maximum(C, tf.divide(loss_batch, norm_batch))\n",
    "\n",
    "        # each instance is y*t*x, where y,t scalars and x in x_batch. shape=(batchsize,d)\n",
    "        t_y_x_batch = tf.multiply(t_batch, tf.multiply(y_batch, x_batch))\n",
    "\n",
    "        # !!!! Update with mean t*y*x\n",
    "        t_y_x_update = tf.expand_dims(tf.reduce_mean(t_y_x_batch, axis=0) ,axis=1)\n",
    "\n",
    "        # Update\n",
    "        model.assign_add(t_y_x_update)\n",
    "    \n",
    "    for batch in dataset:\n",
    "        _train_on_batch(model, C, batch)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32448c2f",
   "metadata": {},
   "source": [
    "# Functional Dynamic Averaging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35e6a7f",
   "metadata": {},
   "source": [
    "We follow the Functional Dynamic Averaging (FDA) scheme. Let the mean model be\n",
    "\n",
    "$$ \\overline{w_t} = \\frac{1}{k} \\sum_{i=1}^{k} w_t^{(i)} $$\n",
    "\n",
    "where $ w_t^{(i)} $ is the model at time $ t $ in some round in the $i$-th learner.\n",
    "\n",
    "Local models are trained independently and cooperatively and we want to monitor the Round Terminating Conditon (**RTC**):\n",
    "\n",
    "$$ \\frac{1}{k} \\sum_{i=1}^{k} \\lVert w_t^{(i)} - \\overline{w_t} \\rVert_2^2  \\leq \\Theta $$\n",
    "\n",
    "where the left-hand side is the **model variance**, and threshold $\\Theta$ is a hyperparameter of the FDA, defined at the beginning of the round; it may change at each round. When the monitoring logic cannot guarantee the validity of RTC, the round terminates. All local models are pulled into `tff.SERVER`, and $\\bar{w_t}$ is set to their average. Then, another round begins.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaca834",
   "metadata": {},
   "source": [
    "### Monitoring the RTC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a62f59b",
   "metadata": {},
   "source": [
    "FDA monitors the RTC by applying techniques from Functionary [Functional Geometric Averaging](http://users.softnet.tuc.gr/~minos/Papers/edbt19.pdf). We first restate the problem of monitoring RTC into the standard distributed stream monitoring formulation. Let\n",
    "\n",
    "$$ S(t) =  \\frac{1}{k} \\sum_{i=1}^{k} S_i(t) $$\n",
    "\n",
    "where $ S(t) \\in \\mathbb{R}^n $ be the \"global state\", **variance approximation**, of the system and $ S_i(t) \\in \\mathbb{R}^n $ the \"local states\". The goal is to monitor the threshold condition on the global state in the form $ F(S(t)) \\leq \\Theta $ where $ F : \\mathbb{R}^n \\to \\mathbb{R} $ a non-linear function. Let\n",
    "\n",
    "$$ \\Delta_t^{(i)} = w_t^{(i)} - w_{t_0}^{(i)} $$\n",
    "\n",
    "be the update at the $ i $-th learner, that is, the change to the local model at time $t$ since the beginning of the current round at time $t_0$. Let the average update be\n",
    "\n",
    "$$ \\overline{\\Delta_t} = \\frac{1}{k} \\sum_{i=1}^{k} \\Delta_t^{(i)} $$\n",
    "\n",
    "it follows that the variance can be written as\n",
    "\n",
    "$$ \\frac{1}{k} \\sum_{i=1}^{k} \\lVert w_t^{(i)} - \\overline{w_t} \\rVert_2^2 = \\Big( \\frac{1}{k} \\sum_{i=1}^{k} \\lVert \\Delta_t^{(i)} \\rVert_2^2 \\Big) - \\lVert \\overline{\\Delta_t} \\rVert_2^2 $$\n",
    "\n",
    "So, conceptually, if we define\n",
    "$$ S_i(t) = \\begin{bmatrix}\n",
    "           \\lVert \\Delta_t^{(i)} \\rVert_2^2 \\\\\n",
    "           \\Delta_t^{(i)}\n",
    "         \\end{bmatrix} \\quad \\text{and} \\quad\n",
    "         F(\\begin{bmatrix}\n",
    "           v \\\\\n",
    "           \\bf{x}\n",
    "         \\end{bmatrix}) = v - \\lVert \\bf{x} \\rVert_2^2 $$\n",
    "\n",
    "The RTC is equivalent to condition $$ F(S(t)) \\leq \\Theta $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e3a4a9",
   "metadata": {},
   "source": [
    "## 3️⃣ Sketch FDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1660b12",
   "metadata": {},
   "source": [
    "An optimal estimator for $ \\lVert \\overline{\\Delta_t} \\rVert_2^2  $ can be obtained by employing AMS sketches. An AMS sketch of a vector $ v \\in \\mathbb{R}^M $ is a $ d \\times m $ real matrix\n",
    "\n",
    "$$ \\Xi = \\text{sk}(v) = \\begin{bmatrix}\n",
    "           \\Xi_1 \\\\\n",
    "           \\Xi_2 \\\\\n",
    "           \\vdots \\\\\n",
    "           \\Xi_d \n",
    "         \\end{bmatrix} $$\n",
    "         \n",
    "where $ d \\cdot m \\ll M$. Operator sk($ \\cdot $) is linear, i.e., let $a, b \\in \\mathbb{R}$ and $v_1, v_2 \\in \\mathbb{R}^N$ then \n",
    "\n",
    "$$ \\text{sk}(a v_1 + b v_2) = a \\; \\text{sk}(v_1) + b \\; \\text{sk}(v_2)  $$\n",
    "\n",
    "Also, sk($ v $) can be computed in $ \\mathcal{O}(dN) $ steps.\n",
    "\n",
    "The interesting property of AMS sketches is that\n",
    "\n",
    "$$ M(sk(v)) = \\underset{i=1,...,d}{\\text{median}} \\; \\lVert \\Xi_i \\rVert_2^2 \\; \\in (1 \\pm \\epsilon) \\lVert v \\rVert_2^2 \\; \\; \\text{with probability at least} \\; (1-\\delta)$$ \n",
    "\n",
    "Let's investigate a little further on how this helps us. The $i$-th client computes $ sk(\\Delta_t^{(i)}) $ and sends it to the server. Notice\n",
    "\n",
    "$$ M\\big(sk(\\Delta_t^{(1)}) + sk(\\Delta_t^{(2)}) + ... + sk(\\Delta_t^{(k)}) \\big) = M\\Big( \\text{sk}\\big( \\sum_{i=1}^{k} \\Delta_t^{(i)} \\big) \\Big)$$\n",
    "\n",
    "Moreover, we want to approximate\n",
    "\n",
    "$$ \\lVert \\overline{\\Delta_t} \\rVert_2^2 = \\frac{1}{k^2} \\Big\\lVert \\sum_{i=1}^{k} \\Delta_t^{(i)} \\Big\\rVert_2^2 $$\n",
    "\n",
    "Which means that \n",
    "\n",
    "$$ \\frac{1}{k^2} M\\Big( \\text{sk}\\big( \\sum_{i=1}^{k} \\Delta_t^{(i)} \\big) \\Big) \\in (1 \\pm \\epsilon) \\lVert \\overline{\\Delta_t} \\rVert_2^2 \\; \\; \\text{with probability at least} \\; (1-\\delta) $$ \n",
    "\n",
    "In the monitoring process it is essential that we do not overestimate $ \\lVert \\overline{\\Delta_t} \\rVert_2^2 $ because we would then underestimate the variance which would potentially result in actual varience exceeding $ \\Theta$ without us noticing it. With this in mind,\n",
    "\n",
    "$$ \\frac{1}{k^2} M\\Big( \\text{sk}\\big( \\sum_{i=1}^{k} \\Delta_t^{(i)} \\big) \\Big) \\leq (1+\\epsilon) \\lVert \\overline{\\Delta_t} \\rVert_2^2 \\quad \\text{with probability at least} \\; (1-\\delta)$$\n",
    "\n",
    "Which means\n",
    "\n",
    "$$ \\frac{1}{(1+\\epsilon)} \\frac{1}{k^2} M\\Big( \\text{sk}\\big( \\sum_{i=1}^{k} \\Delta_t^{(i)} \\big) \\Big) \\leq \\lVert \\overline{\\Delta_t} \\rVert_2^2 \\quad \\text{with probability at least} \\; (1-\\delta)$$\n",
    "\n",
    "Hence, the Server's estimation of $ \\lVert \\overline{\\Delta_t} \\rVert_2^2 $ is\n",
    "\n",
    "$$ \\frac{1}{(1+\\epsilon)} \\frac{1}{k^2} M\\Big( sk(\\Delta_t^{(1)}) + sk(\\Delta_t^{(2)}) + ... + sk(\\Delta_t^{(k)}) \\big) \\Big) $$\n",
    "\n",
    "Define the local state to be \n",
    "\n",
    "$$ S_i(t) = \\begin{bmatrix}\n",
    "           \\lVert \\Delta_t^{(i)} \\rVert_2^2 \\\\\n",
    "           sk(\\Delta_t^{(i)})\n",
    "         \\end{bmatrix} \\in \\mathbb{R}^{1+d \\times m} \\quad \\text{and} \\quad\n",
    "         F(\\begin{bmatrix}\n",
    "           v \\\\\n",
    "           \\Xi\n",
    "         \\end{bmatrix}) = v - \\frac{1}{(1+\\epsilon)} \\frac{1}{k^2} M(\\Xi) \\quad \\text{where} \\quad \\Xi = \\sum_{i=1}^{k} sk(\\Delta_t^{(i)}) $$\n",
    "\n",
    "It follows that $ F(S(t)) \\leq \\Theta $ implies that the variance is less or equal to $ \\Theta $ with probability at least $ 1-\\delta $.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d50277c",
   "metadata": {},
   "source": [
    "## AMS sketch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0bca12",
   "metadata": {},
   "source": [
    "First we define the `depth` ($ d $) and `width` ($ m $) of the sketch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "72f71eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = 7  # number of hash functions\n",
    "width = 1500  # specifies hash31 : N -> {0, 1, ..., `width`} uniformly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1aca0e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "c = 1. # big O constant. Just an estimation (potentially way off)\n",
    "\n",
    "epsilon = c/np.sqrt(width)\n",
    "delta = c/np.exp(depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e0829826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ε = 0.02582  ,  δ = 0.00091188\n"
     ]
    }
   ],
   "source": [
    "print(f\"ε = {epsilon:<.5}  ,  δ = {delta:<.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "259895a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promise: M(sk(v)) in [0.97418*||v||^2, 1.0258*||v||^2]  w.p. at least 0.99909\n"
     ]
    }
   ],
   "source": [
    "print(f\"Promise: M(sk(v)) in [{1-epsilon:<.5}*||v||^2, {1+epsilon:<.5}*||v||^2]  w.p. at least {1-delta:<.5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e0f88c",
   "metadata": {},
   "source": [
    "### Define TFF types "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1aef79d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SKETCH_TYPE = tff.TensorType(tf.float32, shape=[depth, width])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6ca7dbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32[7,1500]\n"
     ]
    }
   ],
   "source": [
    "print(SKETCH_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "02b38219",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_SKETCH_TYPE = tff.type_at_clients(SKETCH_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "896a7fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{float32[7,1500]}@CLIENTS'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(CLIENT_SKETCH_TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d76cbd",
   "metadata": {},
   "source": [
    "### Initialize hash functions and Pre-serialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6b07d4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_width = tf.constant(width, dtype=tf.int32)\n",
    "tf_depth = tf.constant(depth, dtype=tf.int32)\n",
    "\n",
    "# Pool of three random tuples (A, B) corresponding to a different hash function parameters\n",
    "# We provide information about pair (F[0], F[1]) , the rest follow this \n",
    "# F[0] : shape(depth,) random `a` parameters for each row of the sketch. One row <-> One hash func <-> One `a`\n",
    "# F[1] : shape(depth,) random `b` parameters for each row of the sketch. One row <-> One hash func <-> One `b`\n",
    "tf_F = tf.random.uniform(shape=(6, depth), minval=0, maxval=(1 << 31) - 1, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611f045e",
   "metadata": {},
   "source": [
    "### Sketch (Deprecated). See next Jupyters TODO: fix this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7c19cb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def sketch_for_vector(v):\n",
    "    \"\"\" Returns AGMS sketch for `v` (vector shape=(n,)). \n",
    "    Note: We serialize `F`, `width`, `depth` for efficiency \"\"\"\n",
    "    \n",
    "    F = tf.constant(tf_F)\n",
    "    width = tf.constant(tf_width)\n",
    "    depth = tf.constant(tf_depth)\n",
    "\n",
    "    @tf.function\n",
    "    def _hash31(x, a, b):\n",
    "        \"\"\" _hash31 : N -> {0, 1, ..., width} uniformly \"\"\"\n",
    "        r = a * x + b\n",
    "        fold = tf.bitwise.bitwise_xor(tf.bitwise.right_shift(r, 31), r)\n",
    "        return tf.bitwise.bitwise_and(fold, 2147483647)\n",
    "    \n",
    "    @tf.function\n",
    "    def _fourwise(x):\n",
    "        \"\"\" Fourwise independent hash of `x` (int) to {+1, -1}. \"\"\"\n",
    "        result = 2 * (tf.bitwise.right_shift(tf.bitwise.bitwise_and(_hash31(_hash31(_hash31(x, F[2], F[3]), x, F[4]), x, F[5]), 32768), 15)) - 1\n",
    "        return result\n",
    "\n",
    "    sketch = tf.zeros(shape=(depth, width), dtype=tf.float32)\n",
    "    indices = tf.range(tf.shape(v)[0], dtype=tf.int32)\n",
    "\n",
    "    for i in indices:\n",
    "        pos = _hash31(i, F[0], F[1]) % width\n",
    "        delta = tf.cast(_fourwise(i), dtype=tf.float32) * v[i]\n",
    "        indices_to_update = tf.stack([tf.range(depth, dtype=tf.int32), pos], axis=1)\n",
    "        sketch = tf.tensor_scatter_nd_add(sketch, indices_to_update, delta)\n",
    "\n",
    "    return sketch\n",
    "\n",
    "\n",
    "@tff.tf_computation(MODEL_TYPE)\n",
    "def sketch_for_vector_fn(v):\n",
    "    # we use `.squeeze` to reshape from (n,1) to (n,)\n",
    "    return sketch_for_vector(tf.squeeze(v, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0069b1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(float32[100,1] -> float32[7,1500])'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(sketch_for_vector_fn.type_signature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1944184a",
   "metadata": {},
   "source": [
    "### Euclidean Norm Squared estimation given Sketch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d3345e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def estimate_euc_norm_squared(sketch):\n",
    "    \n",
    "    @tf.function\n",
    "    def _median(v):\n",
    "        \"\"\" Median of tensor `v` with shape=(n,). Note: Suboptimal O(nlogn) but it's ok bcz n = `depth`\"\"\"\n",
    "        length = tf.shape(v)[0]\n",
    "        sorted_v = tf.sort(v)\n",
    "        middle = length // 2\n",
    "\n",
    "        return tf.cond(\n",
    "            tf.equal(length % 2, 0),\n",
    "            lambda: (sorted_v[middle - 1] + sorted_v[middle]) / 2.0,\n",
    "            lambda: sorted_v[middle]\n",
    "        )\n",
    "    \n",
    "    return _median(tf.reduce_sum(tf.square(sketch), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e386998a",
   "metadata": {},
   "source": [
    "### Client train and Local State"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89be9c24",
   "metadata": {},
   "source": [
    "As explained clients return\n",
    "\n",
    "$$ S_i(t) = \\begin{bmatrix}\n",
    "           \\lVert \\Delta_t^{(i)} \\rVert_2^2 \\\\\n",
    "           sk(\\Delta_t^{(i)})\n",
    "         \\end{bmatrix} \\in \\mathbb{R}^{1+d \\times m} \\quad \\text{and} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb4743f",
   "metadata": {},
   "source": [
    "Using the functions decorated with `tf.function` (context inside Tensorflow) we create the `client_train_fn` with context inside TFF. \n",
    "\n",
    "`initial_model` is the model currently inside each `tff.CLIENT`. This model is different in each CLIENT with the exception in the first step after synchronization, and `last_sync_model` is the synchronized model at the start of the current round. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "888be5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tff.tf_computation(MODEL_TYPE, MODEL_TYPE, FLOAT32_TYPE, LOCAL_DATA_TYPE)\n",
    "def client_train_fn(last_sync_model, initial_model, C, dataset):\n",
    "    \n",
    "    model = client_train(\n",
    "        tf.Variable(initial_value=initial_model), C, dataset\n",
    "    )\n",
    "    \n",
    "    Delta_i = model - last_sync_model # AutoGraph\n",
    "    \n",
    "    #||D(t)_i||^2 , shape = (1,) \n",
    "    Delta_i_norm_squared = tf.reduce_sum(tf.square(Delta_i), axis=0) \n",
    "    \n",
    "    # sk(D(t)_i) \n",
    "    sketch = sketch_for_vector_fn(Delta_i)\n",
    "\n",
    "    return model, Delta_i_norm_squared, sketch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "349b9ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(<last_sync_model=float32[100,1],initial_model=float32[100,1],C=float32,dataset=<y=float32[?],x=float32[?,100]>*> -> <float32[100,1],float32[1],float32[7,1500]>)'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(client_train_fn.type_signature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d317f2",
   "metadata": {},
   "source": [
    "### Server Average Client Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54e18e0",
   "metadata": {},
   "source": [
    "When it is time to synchronize the Clients, the Server averages the Client weights and computes the global model. This is what this function does. Moreover, remember that the Client updates its model using `server_update_fn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fc7bdbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tff.federated_computation(CLIENT_MODEL_TYPE)\n",
    "def server_update(client_models):\n",
    "    # 4. Compute the mean of the client weights\n",
    "    mean_client_model = tff.federated_mean(client_models)\n",
    "    \n",
    "    # 4. Update the server model\n",
    "    server_model = tff.federated_map(server_update_fn, mean_client_model)\n",
    "    \n",
    "    return server_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "61a2a0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'({float32[100,1]}@CLIENTS -> float32[100,1]@SERVER)'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(server_update.type_signature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e6455e",
   "metadata": {},
   "source": [
    "### Client Learning Step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556998dc",
   "metadata": {},
   "source": [
    "A Client learning step is an update of the model based on one or more batches. The following `federated_computation` describes the step operation over all the clients. We pass a `federated_dataset` which could be thought as a stream of one or more batches for each client and some more parameters, namely, the last synchronized global model, the current client models, and the parameter `C` of the **PA-I** classifier.\n",
    "\n",
    "Notice that each of those parameters is placed in `tff.CLIENTS`. \n",
    "\n",
    "Moreover, we return the updated Client models `client_models` (think of this as the new state of the distributed system) placed in `tff.CLIENTS` aswell which is logical, each Client updates its own model. Lastly, we return the $S_i(t)$ as described in the unpublished manuscript ('local state') of each Client, again placed in `tff.CLIENTS`.\n",
    "\n",
    "Note: Do not think of the `return` as a normal programming `return` statement. Here, we describe the change in state in the distributed system, in this case, solely in `tff.CLIENTS`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b758bda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tff.federated_computation(CLIENT_MODEL_TYPE, CLIENT_MODEL_TYPE, CLIENT_FLOAT32, CLIENT_DATA_TYPE)\n",
    "def step(last_sync_client_models, client_models, client_C, federated_dataset):\n",
    "    # 2. 3. Train the client models on their respective datasets\n",
    "    client_models, client_Delta_i_norm_squared, client_sketches = tff.federated_map(\n",
    "        client_train_fn, \n",
    "        (last_sync_client_models, client_models, client_C, federated_dataset)\n",
    "    )\n",
    "    \n",
    "    return client_models, client_Delta_i_norm_squared, client_sketches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "08b11ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(<last_sync_client_models={float32[100,1]}@CLIENTS,client_models={float32[100,1]}@CLIENTS,client_C={float32}@CLIENTS,federated_dataset={<y=float32[?],x=float32[?,100]>*}@CLIENTS> -> <{float32[100,1]}@CLIENTS,{float32[1]}@CLIENTS,{float32[7,1500]}@CLIENTS>)'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(step.type_signature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541c0b3b",
   "metadata": {},
   "source": [
    "### Server Computation of 'Global State', i.e, Variance Approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6787e99a",
   "metadata": {},
   "source": [
    "For more simplicity in the computations we differ a bit from the theoretical analysis.\n",
    "\n",
    "Let `server_S_1` = $ \\frac{1}{k} \\sum_{i=1}^{k} \\lVert \\Delta_t^{(i)} \\rVert_2^2 $ , and `server_M_S_2` = $ \\frac{1}{(1+\\epsilon)} \\frac{1}{k^2} M\\Big( sk(\\Delta_t^{(1)}) + sk(\\Delta_t^{(2)}) + ... + sk(\\Delta_t^{(k)}) \\big) \\Big) $\n",
    "\n",
    "Then `server_S_1` - `server_M_S_2` $ \\leq \\Theta$ implies that the variance is $ \\leq \\Theta $ with probability at least $ 1-\\delta $ (already proven in **FDA Sketch** section)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0f818b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tff.federated_computation(CLIENT_FLOAT32_1_TYPE, CLIENT_SKETCH_TYPE, SERVER_INT32_TYPE, SERVER_FLOAT32)\n",
    "def server_global_state(client_Delta_i_norm_squared, client_sketches, num_clients, epsilon):\n",
    "    \n",
    "    @tff.tf_computation(SKETCH_TYPE, INT32_TYPE, FLOAT32_TYPE)\n",
    "    def var_est(sketch_sum, num_clients, epsilon):\n",
    "        return (1/(1+epsilon))*tf.cast((1/num_clients**2), dtype=tf.float32) * estimate_euc_norm_squared(sketch_sum)\n",
    "    \n",
    "    server_S_1 = tff.federated_mean(client_Delta_i_norm_squared)\n",
    "    \n",
    "    server_M_S_2 = tff.federated_map(\n",
    "        var_est,\n",
    "        (tff.federated_sum(client_sketches), num_clients, epsilon)\n",
    "    )\n",
    "    \n",
    "    return server_S_1, server_M_S_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1ecb75f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(<client_Delta_i_norm_squared={float32[1]}@CLIENTS,client_sketches={float32[7,1500]}@CLIENTS,num_clients=int32@SERVER,epsilon=float32@SERVER> -> <float32[1]@SERVER,float32@SERVER>)'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(server_global_state.type_signature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80f9f7e",
   "metadata": {},
   "source": [
    "### Round Terminating Condition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d158204",
   "metadata": {},
   "source": [
    "We check whether we guarantee that the **RTC** holds (`True`) or not (`False`).\n",
    "\n",
    "Follows from above..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a06e446b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same for all FDA. (bool)\n",
    "@tff.tf_computation(FLOAT32_1_TYPE, FLOAT32_TYPE, FLOAT32_TYPE)\n",
    "def RTC_holds(S_1, M_S_2, THETA):\n",
    "    \"\"\" Returns True if RTC holds (has not been defied). False otherwise (sync must happen)\"\"\"\n",
    "    \n",
    "    @tf.function\n",
    "    def _F(S_1, M_S_2, THETA):\n",
    "        \"\"\" Sketch FDA \"\"\"\n",
    "        return S_1 - M_S_2 <= THETA\n",
    "    \n",
    "    return _F(S_1, M_S_2, THETA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cb04701e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(<S_1=float32[1],M_S_2=float32,THETA=float32> -> bool[1])'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(RTC_holds.type_signature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698c5f35",
   "metadata": {},
   "source": [
    "### Help variance function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e382606",
   "metadata": {},
   "source": [
    "A helper function that computes the **Actual Variance** when the approximate **RTC** condition does not hold. We want to see how far off the approximation is from reality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "eec4adef",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_spec = tf.TensorSpec(shape=(NUM_CLIENTS, d, 1), dtype=tf.float32)\n",
    "\n",
    "@tf.function(input_signature=[w_spec, w_spec])\n",
    "def variance(w_t, w_sync):\n",
    "    # w_t , w_sync tensors with shape=(NUM_CLIENTS, d, 1)\n",
    "    \n",
    "    # tensor with shape=(NUM_CLIENTS, d, 1)\n",
    "    diff = w_t - w_sync\n",
    "    \n",
    "    # tensor with shape=(NUM_CLIENTS, 1) , For each client ||w_i_t - w_t||^2\n",
    "    dot = tf.reduce_sum(tf.square(diff), axis=1)\n",
    "    \n",
    "    # Variance shape=() , scalar\n",
    "    var = tf.reduce_mean(dot)\n",
    "    \n",
    "    return var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe51953c",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491a75dc",
   "metadata": {},
   "source": [
    "A very ugly looking `Metrics` class that helps us with printing and storing the round metrics.\n",
    "\n",
    "Skip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dc049cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unentangle num_rounds\n",
    "\n",
    "class Metrics:\n",
    "    def __init__(self, name, num_rounds, theta,\n",
    "                 num_clients, num_steps_until_sync_check, batch_size,\n",
    "                 n, d, test_size, width, depth):\n",
    "        \n",
    "        self.num_rounds = num_rounds\n",
    "        self.theta = theta\n",
    "        self.num_clients = num_clients\n",
    "        self.num_steps_until_sync_check = num_steps_until_sync_check\n",
    "        self.batch_size = batch_size\n",
    "        self.n = n\n",
    "        self.d = d\n",
    "        self.test_size = test_size\n",
    "        self.sketch_bytes = width*depth*4\n",
    "        self.S_i_bytes = self.sketch_bytes + 4\n",
    "        self.name = name\n",
    "        \n",
    "        self.model_bytes = self.d * 4\n",
    "        \n",
    "        self.total_batches_per_client = int((1-self.test_size)*self.n / (self.num_clients*self.batch_size))\n",
    "        \n",
    "        self.one_sample_size_b = (self.d+1)*4 # bytes\n",
    "        \n",
    "        self.training_dataset_size_mb = self.one_sample_size_b * (n * (1-test_size)) / 1_000_000 # In mb\n",
    "        \n",
    "        \n",
    "        self.samples = int(self.n * (1-self.test_size))\n",
    "        \n",
    "        self.all_metrics = []\n",
    "        \n",
    "    \n",
    "    def print_initial_information(self):\n",
    "        print(\"FEDERATED SETTING INFO:\")\n",
    "        print(\"------------------------------------------------------------\")\n",
    "\n",
    "        print(\"CLIENTS:\")\n",
    "        print(f'{\"Clients\":<10} {\"Batches per Client\":<20} {\"Number of steps until Sync check\":<25}')\n",
    "        print(f'{self.num_clients:<10} {self.total_batches_per_client:<20} {self.num_steps_until_sync_check:<20}')\n",
    "        print()\n",
    "\n",
    "        print(\"TRAIN DATASET:\")\n",
    "        print(f'{\"x-Dim\":<6} {\"y-classes\":<10} {\"Samples\":<12} {\"Dataset size (MB)\":<20} {\"Samples per Batch\":<20}')\n",
    "        print(f'{d:<6} {2:<10} {self.samples:<12} {self.training_dataset_size_mb:<20} {self.batch_size:<20}')\n",
    "        print()\n",
    "\n",
    "        print(\"ALGORITHM:\")\n",
    "        print(f'{\"Name\":<5} {\"Model Bytes\":<10}')\n",
    "        print(f'{\"PA-I\":<5} {self.model_bytes:<10}')\n",
    "        print()\n",
    "\n",
    "        print(\"SYNCHRONIZATION:\")\n",
    "        print(f'{self.name} FDA monitoring model Variance bellow {self.theta}')\n",
    "        print(f'Sketch bytes: {self.sketch_bytes}')\n",
    "        print(\"------------------------------------------------------------\")\n",
    "        print()\n",
    "        print()   \n",
    "    \n",
    "    def store_and_print_metrics(self, num_round, num_steps, global_state, accuracy, C, var):\n",
    "        metrics = {}\n",
    "\n",
    "        metrics['Round'] = num_round\n",
    "        metrics['Steps'] = num_steps\n",
    "        metrics['Accuracy'] = accuracy\n",
    "        metrics['Global State'] = global_state[0]\n",
    "        metrics['C'] = C\n",
    "        metrics['Actual Variance'] = var\n",
    "\n",
    "        # Total samples seen by all clients. batch_size = samples per batch\n",
    "        metrics['Samples'] = self.batch_size * num_steps * self.num_clients\n",
    "\n",
    "        assert num_steps % self.num_steps_until_sync_check == 0\n",
    "        # FDA Every `NUM_STEPS_UNTIL_SYNC_CHECK` clients return their S_i (`width`*`depth`*4+4 bytes)\n",
    "        local_states_bytes = int(num_steps/self.num_steps_until_sync_check) * self.num_clients * self.S_i_bytes\n",
    "        # Synchronization: Receive models from clients AND Send model to all clients\n",
    "        sync_bytes = 2 * self.model_bytes * self.num_clients\n",
    "\n",
    "        metrics['Bytes Exchanged'] = local_states_bytes + sync_bytes\n",
    "\n",
    "        self.all_metrics.append(metrics)\n",
    "\n",
    "        # Print the metrics for the current round\n",
    "        self.print_round_metrics()\n",
    "        \n",
    "    def print_round_metrics(self):\n",
    "        metrics = self.all_metrics[-1]\n",
    "        # Print the metric values in a nicely formatted table\n",
    "        print((\n",
    "            f'{\"Round\":<6} {\"Steps\":<6} {\"C\":<5} {\"Accuracy\":<13} '\n",
    "            f'{\"Bytes Exchanged\":<20} {\"Samples\":<15} {\"Var Approx\":<15} '\n",
    "            f'{\"Var (Actual)\":<15}'\n",
    "        ))\n",
    "\n",
    "        print((\n",
    "            f\"{metrics['Round']:<6} {metrics['Steps']:<6} {metrics['C']:<5} \"\n",
    "            f\"{metrics['Accuracy']:<13.5f} {metrics['Bytes Exchanged']:<20} \"\n",
    "            f\"{metrics['Samples']:<15} {metrics['Global State']:<15.6f} \"\n",
    "            f\"{metrics['Actual Variance']:<15.6f}\"\n",
    "        ))\n",
    "\n",
    "        print()\n",
    "    \n",
    "    def print_aggregate_metrics(self):\n",
    "\n",
    "        total_bytes_exchanged = sum(metrics['Bytes Exchanged'] for metrics in self.all_metrics)\n",
    "        total_mb_exchanged = total_bytes_exchanged/1_000_000\n",
    "        \n",
    "        total_steps = sum(metrics['Steps'] for metrics in self.all_metrics)\n",
    "        total_samples = sum(metrics['Samples'] for metrics in self.all_metrics)\n",
    "        final_accuracy = self.all_metrics[-1]['Accuracy']\n",
    "\n",
    "        # Remember we pass the dataset many times at random (random batches)\n",
    "        trained_in_bytes = self.one_sample_size_b * total_samples \n",
    "        trained_in_mb = trained_in_bytes / 1_000_000 # MB\n",
    "        \n",
    "        # total communication due to model synchronization\n",
    "        model_sync_bytes_exchanged = self.num_rounds * (2 * self.model_bytes * self.num_clients)\n",
    "        model_sync_mb_exchanged = model_sync_bytes_exchanged / 1_000_000\n",
    "        \n",
    "        # total communication due to monitoring\n",
    "        monitoring_bytes_exchanged = total_bytes_exchanged - model_sync_bytes_exchanged\n",
    "        monitoring_mb_exchanged = monitoring_bytes_exchanged / 1_000_000\n",
    "        \n",
    "        print(\"------------------------------------------------------------\")\n",
    "\n",
    "        print()\n",
    "        print('FINAL METRICS:')\n",
    "        print(\"------------------------------------------------------------\")\n",
    "        print()\n",
    "\n",
    "        print('TRAINING:')\n",
    "        print((\n",
    "            f'{\"Rounds\":<7} {\"Steps\":<9} {\"Samples\":<13} {\"Trained MB\":<20}'\n",
    "            f'{\"Final Accuracy\":<25}'\n",
    "        ))\n",
    "        print((\n",
    "            f'{self.num_rounds:<7} {total_steps:<9} {total_samples:<13} {trained_in_mb:<20.5f}'\n",
    "            f'{final_accuracy:<25.6}'\n",
    "        ))\n",
    "        print()\n",
    "        \n",
    "        print('COMMUNICATION:')\n",
    "        print(f'{\"Total MB Exchanged\":<25} {\"Model Sync MB Exchanged\":<25} {\"Monitoring MB Exchanged\":<25}')\n",
    "        print(f'{total_mb_exchanged:<25} {model_sync_mb_exchanged:<25} {monitoring_mb_exchanged:<25}')\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e05037e",
   "metadata": {},
   "source": [
    "## Training Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09197d61",
   "metadata": {},
   "source": [
    "Create the federated datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "933033bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_federated_data = create_federated_data()\n",
    "test_dataset = create_tf_dataset_for_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9949269",
   "metadata": {},
   "source": [
    "Initial conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5e2b3758",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ROUNDS = 15\n",
    "THETA = 2.\n",
    "C = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdec3b1e",
   "metadata": {},
   "source": [
    "We assume that all Clients start in synchronization, i.e., Server model is zeros and Client models are also zeros.\n",
    "\n",
    "Moreover, notice that `client_models`, `last_sync_client_models`, `client_C` are all defined as lists containing `NUM_CLIENTS` elements. This is the simulation approach of TFF and following the already defined functions above, each element in those lists is assumed to lie in one `tff.CLIENT`. For example, each `tff.CLIENT` has a `C` hyperparameter to be used by **PA-I** classifier on its own model etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9cb526fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial model of zeros\n",
    "model = tf.Variable(tf.zeros(shape=(d, 1)), trainable=True, name='weights', dtype=tf.float32)\n",
    "\n",
    "# Assume client models are synchronized at the start (Obviously S_t = 0)\n",
    "client_models = [model]*NUM_CLIENTS\n",
    "last_sync_client_models = [model]*NUM_CLIENTS\n",
    "client_C = [C]*NUM_CLIENTS\n",
    "S_1 = tf.zeros(shape=(1,), dtype=tf.float32)\n",
    "S_2 = tf.zeros(shape=(), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a7248d",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "769dd10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEDERATED SETTING INFO:\n",
      "------------------------------------------------------------\n",
      "CLIENTS:\n",
      "Clients    Batches per Client   Number of steps until Sync check\n",
      "20         156                  10                  \n",
      "\n",
      "TRAIN DATASET:\n",
      "x-Dim  y-classes  Samples      Dataset size (MB)    Samples per Batch   \n",
      "100    2          90000        36.36                32                  \n",
      "\n",
      "ALGORITHM:\n",
      "Name  Model Bytes\n",
      "PA-I  400       \n",
      "\n",
      "SYNCHRONIZATION:\n",
      "Sketch FDA monitoring model Variance bellow 2.0\n",
      "Sketch bytes: 42000\n",
      "------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = Metrics('Sketch', NUM_ROUNDS, THETA, NUM_CLIENTS, NUM_STEPS_UNTIL_SYNC_CHECK, BATCH_SIZE, n, d, test_size, width, depth)\n",
    "metrics.print_initial_information()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bb61660c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEDERATED SETTING INFO:\n",
      "------------------------------------------------------------\n",
      "CLIENTS:\n",
      "Clients    Batches per Client   Number of steps until Sync check\n",
      "20         156                  10                  \n",
      "\n",
      "TRAIN DATASET:\n",
      "x-Dim  y-classes  Samples      Dataset size (MB)    Samples per Batch   \n",
      "100    2          90000        36.36                32                  \n",
      "\n",
      "ALGORITHM:\n",
      "Name  Model Bytes\n",
      "PA-I  400       \n",
      "\n",
      "SYNCHRONIZATION:\n",
      "Sketch FDA monitoring model Variance bellow 2.0\n",
      "Sketch bytes: 42000\n",
      "------------------------------------------------------------\n",
      "\n",
      "\n",
      "Round  Steps  C     Accuracy      Bytes Exchanged      Samples         Var Approx      Var (Actual)   \n",
      "1      90     0.01  0.81540       7576720              57600           2.048988        1.425875       \n",
      "\n",
      "Round  Steps  C     Accuracy      Bytes Exchanged      Samples         Var Approx      Var (Actual)   \n",
      "2      90     0.01  0.81749       7576720              57600           2.022470        1.453180       \n",
      "\n",
      "Round  Steps  C     Accuracy      Bytes Exchanged      Samples         Var Approx      Var (Actual)   \n",
      "3      90     0.01  0.81919       7576720              57600           2.248756        1.755310       \n",
      "\n",
      "Round  Steps  C     Accuracy      Bytes Exchanged      Samples         Var Approx      Var (Actual)   \n",
      "4      80     0.01  0.82069       6736640              51200           2.181031        1.855824       \n",
      "\n",
      "Round  Steps  C     Accuracy      Bytes Exchanged      Samples         Var Approx      Var (Actual)   \n",
      "5      80     0.01  0.82298       6736640              51200           2.335855        2.058414       \n",
      "\n",
      "Round  Steps  C     Accuracy      Bytes Exchanged      Samples         Var Approx      Var (Actual)   \n",
      "6      70     0.01  0.82398       5896560              44800           2.298385        2.109297       \n",
      "\n",
      "Round  Steps  C     Accuracy      Bytes Exchanged      Samples         Var Approx      Var (Actual)   \n",
      "7      60     0.01  0.82598       5056480              38400           2.198117        2.070584       \n",
      "\n",
      "Round  Steps  C     Accuracy      Bytes Exchanged      Samples         Var Approx      Var (Actual)   \n",
      "8      60     0.01  0.82718       5056480              38400           2.271489        2.149604       \n",
      "\n",
      "Round  Steps  C     Accuracy      Bytes Exchanged      Samples         Var Approx      Var (Actual)   \n",
      "9      50     0.01  0.82847       4216400              32000           2.010376        1.932123       \n",
      "\n",
      "Round  Steps  C     Accuracy      Bytes Exchanged      Samples         Var Approx      Var (Actual)   \n",
      "10     50     0.01  0.82897       4216400              32000           2.130766        2.061736       \n",
      "\n",
      "Round  Steps  C     Accuracy      Bytes Exchanged      Samples         Var Approx      Var (Actual)   \n",
      "11     50     0.01  0.82997       4216400              32000           2.100415        2.031009       \n",
      "\n",
      "Round  Steps  C     Accuracy      Bytes Exchanged      Samples         Var Approx      Var (Actual)   \n",
      "12     50     0.01  0.83177       4216400              32000           2.360999        2.297480       \n",
      "\n",
      "Round  Steps  C     Accuracy      Bytes Exchanged      Samples         Var Approx      Var (Actual)   \n",
      "13     50     0.01  0.83167       4216400              32000           2.566023        2.507746       \n",
      "\n",
      "Round  Steps  C     Accuracy      Bytes Exchanged      Samples         Var Approx      Var (Actual)   \n",
      "14     50     0.01  0.83257       4216400              32000           2.610741        2.553171       \n",
      "\n",
      "Round  Steps  C     Accuracy      Bytes Exchanged      Samples         Var Approx      Var (Actual)   \n",
      "15     50     0.01  0.83227       4216400              32000           2.613210        2.555816       \n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "FINAL METRICS:\n",
      "------------------------------------------------------------\n",
      "\n",
      "TRAINING:\n",
      "Rounds  Steps     Samples       Trained MB          Final Accuracy           \n",
      "15      970       620800        250.80320           0.832268                 \n",
      "\n",
      "COMMUNICATION:\n",
      "Total MB Exchanged        Model Sync MB Exchanged   Monitoring MB Exchanged  \n",
      "81.72776                  0.24                      81.48776                 \n"
     ]
    }
   ],
   "source": [
    "metrics.print_initial_information()\n",
    "\n",
    "for r in range(1, NUM_ROUNDS+1):\n",
    "    \n",
    "    num_steps = 0 # Each step() invocation is `NUM_STEPS_UNTIL_SYNC_CHECK` number of theoretical steps\n",
    "    \n",
    "    while RTC_holds(S_1, S_2, THETA): # RTC holds, no sync needed\n",
    "        \n",
    "        # Perform a training step with the current client_models (no sync yet)\n",
    "        # Note: We train for `NUM_STEPS_UNTIL_SYNC_CHECK` batches inside `step` in order to let TF optimize.\n",
    "        #       It is the same to `step` for one batch `NUM_STEPS_UNTIL_SYNC_CHECK` number of times.\n",
    "        client_models, client_Delta_i_norm_squared, client_sketches = step(\n",
    "            last_sync_client_models, client_models, client_C, train_federated_data\n",
    "        )\n",
    "        \n",
    "        # Compute 'global state' Approx Variance as defined in the manuscript\n",
    "        S_1, S_2 = server_global_state(client_Delta_i_norm_squared, client_sketches, NUM_CLIENTS, epsilon)\n",
    "        \n",
    "        # because we train for `NUM_STEPS_UNTIL_SYNC_CHECK` batches inside `step`\n",
    "        num_steps += 1*NUM_STEPS_UNTIL_SYNC_CHECK\n",
    "    \n",
    "    # RTC defied, sync must happen\n",
    "    \n",
    "    # Update the server model from the client models.\n",
    "    model = server_update(client_models)\n",
    "    \n",
    "    metrics.store_and_print_metrics(r, num_steps, S_1 - S_2, accuracy_fn(model, test_dataset), client_C[0], variance(client_models, [model]*NUM_CLIENTS))\n",
    "    \n",
    "    client_models, last_sync_client_models, S_1, S_2 = [model]*NUM_CLIENTS, [model]*NUM_CLIENTS, tf.zeros(shape=(1,), dtype=tf.float32), tf.zeros(shape=(), dtype=tf.float32)\n",
    "    \n",
    "    \n",
    "metrics.print_aggregate_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f49d3a",
   "metadata": {},
   "source": [
    "# TODO: \n",
    "1. Metrics class becomes .py imported\n",
    "1. unused types\n",
    "3. types consistency. *_TYPE @SERVER/CLIENTS\n",
    "4. show initial metrics before training loop\n",
    "5. beamer presentation\n",
    "6. plots think about it. (maybe first create relationship between hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f090b5d",
   "metadata": {},
   "source": [
    "# training loop (testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9c8bd59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uncomment\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "metrics = Metrics('Sketch', NUM_ROUNDS, THETA, NUM_CLIENTS, NUM_STEPS_UNTIL_SYNC_CHECK, BATCH_SIZE, n, d, test_size, width*depth*4)\n",
    "metrics.print_initial_information()\n",
    "\n",
    "for r in range(1, NUM_ROUNDS+1):\n",
    "    \n",
    "    num_steps = 0 # Each step() invocation is a step\n",
    "    \n",
    "    while RTC_holds(S_1, S_2, THETA): # RTC holds, no sync needed\n",
    "        \n",
    "        # Perform a training step with the current client_models (no sync yet)\n",
    "        client_models, client_Delta_i_norm_squared, client_sketches, client_D_i = step(\n",
    "            last_sync_client_models, client_models, client_C, train_federated_data\n",
    "        )\n",
    "        \n",
    "        # Compute 'global state' Approx Variance as defined in the manuscript\n",
    "        S_1, S_2 = server_global_state(client_Delta_i_norm_squared, client_sketches, NUM_CLIENTS, epsilon)\n",
    "        \n",
    "        client_D_i_tf = tf.constant(client_D_i, shape=(NUM_CLIENTS, d)) # CORR shape=(NUM_CLIENTS, d)\n",
    "        D_i_mean_tf = tf.reduce_mean(client_D_i_tf, axis=0) # CORR shape=(d,)\n",
    "        D_i_mean_euc_sq = tf.reduce_sum(tf.square(D_i_mean_tf)) # CORR (right-hand-side)\n",
    "        \n",
    "        D_i_mean_euc_sq_est = S_2\n",
    "        \n",
    "        sum_D_i_k = tf.reduce_mean(tf.reduce_sum(tf.square(client_D_i_tf), axis=1)) # CORR (left-hand-side)\n",
    "        \n",
    "        print(f\"Actual sketch val: {D_i_mean_euc_sq} ,  Sketch est: {D_i_mean_euc_sq_est}\")\n",
    "        print(f\"Overestimate: {D_i_mean_euc_sq <= D_i_mean_euc_sq_est}\")\n",
    "        print(f\"Left-hand-side: {sum_D_i_k}\")\n",
    "        print(f\"Actual Var: {sum_D_i_k-D_i_mean_euc_sq} , Sketch var: {sum_D_i_k-D_i_mean_euc_sq_est}\")\n",
    "        print()\n",
    "        \n",
    "        num_steps += 1\n",
    "    \n",
    "    # RTC defied, sync must happen\n",
    "    \n",
    "        \n",
    "    # Update the server model from the client models.\n",
    "    model = server_update(client_models)\n",
    "    \n",
    "    metrics.store_and_print_metrics(r, num_steps, S_1 - S_2, accuracy_fn(model, test_dataset), client_C[0], variance(client_models, [model]*NUM_CLIENTS))\n",
    "    \n",
    "    client_models, last_sync_client_models, S_1, S_2 = [model]*NUM_CLIENTS, [model]*NUM_CLIENTS, tf.zeros(shape=(1,), dtype=tf.float32), tf.zeros(shape=(), dtype=tf.float32)\n",
    "\n",
    "    \n",
    "metrics.print_aggregate_metrics()\n",
    "\"\"\"\n",
    "print(\"uncomment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6948c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tff-py39] *",
   "language": "python",
   "name": "conda-env-tff-py39-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
