{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32f7323a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import struct\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c4e06ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def float_to_int_bits(f):\n",
    "    \"\"\"Convert a floating-point number to its bit representation as an integer.\"\"\"\n",
    "    return int.from_bytes(bytearray(struct.pack('>f', f)), byteorder='big')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd42806",
   "metadata": {},
   "source": [
    "# VSAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235cae7f",
   "metadata": {},
   "source": [
    "(Refactored) code from [repository](https://github.com/vsamtuc/ddssim/blob/master/python/agms.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25f4b194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# refactor\n",
    "\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "from collections import Counter as sparse\n",
    "\n",
    "\n",
    "class hash_family:\n",
    "    def __init__(self, depth):\n",
    "        # number of hash functions\n",
    "        self.depth = depth\n",
    "        \n",
    "        # Arrays: F[0] : a1_arr , F[1] : b1_arr , F[2] : a2_arr , F[3] : b2_arr , F[4] : a3_arr , F[5] : b3_arr \n",
    "        self.F = np.random.randint(0, 1 << 63 - 1, size=(6, depth), dtype=np.int64)\n",
    "\n",
    "    @staticmethod\n",
    "    def hash31(a, b, x):\n",
    "        r = a * x + b\n",
    "        \n",
    "        # int divide by 2^31 (Shift 31) + combine higher order bits with lower\n",
    "        fold = ((r >> 31) ^ r)\n",
    "        \n",
    "        # 2147483647 = 0111...1\n",
    "        return fold & 2147483647\n",
    "\n",
    "    def hash(self, x):\n",
    "        F = self.F\n",
    "        return self.hash31(F[0], F[1], x)\n",
    "\n",
    "    def fourwise(self, x):\n",
    "        F = self.F\n",
    "        return 2*(((self.hash31(self.hash31(self.hash31(x,F[2],F[3]),x,F[4]),x,F[5])) & 32768)>>15)-1\n",
    "\n",
    "class sketch:\n",
    "    def __init__(self, width, depth, hf):\n",
    "        self.width = width\n",
    "        self.depth = depth\n",
    "        self.hf = hf\n",
    "        self.vec = np.zeros((depth, width))\n",
    "\n",
    "    def update(self, key, freq=1):\n",
    "        pos = self.hf.hash(key) % self.width\n",
    "        delta = self.hf.fourwise(key) * freq\n",
    "        self.vec[range(self.depth), pos] += delta\n",
    "\n",
    "    def inner(self, other):\n",
    "        return np.median(np.einsum('ij,ij->i', self.vec, other.vec))\n",
    "\n",
    "\n",
    "def make_stream(nkeys, length):\n",
    "    return np.random.randint(nkeys, size=length)\n",
    "\n",
    "\n",
    "def make_sparse(S):\n",
    "    return sparse(S)\n",
    "\n",
    "\n",
    "def sparse_inner(s1, s2):\n",
    "    return sum(s1[k] * s2[k] for k in s1 if k in s2)\n",
    "\n",
    "\n",
    "def create_sketch(width, depth, hf, sp):\n",
    "    sk = sketch(width, depth, hf)\n",
    "    for x in sp:\n",
    "        sk.update(x, sp[x])\n",
    "    return sk\n",
    "\n",
    "\n",
    "def create_sketch_for_vector(width, depth, hf, v):\n",
    "    sk = sketch(width, depth, hf)\n",
    "    for i, x in enumerate(v):\n",
    "        sk.update(i, x)\n",
    "    return sk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2709c9f",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c3a562f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_sketch_accuracy():\n",
    "    width = 1500\n",
    "    depth = 7\n",
    "\n",
    "    S1 = make_stream(10000, 10000)\n",
    "    S2 = make_stream(10000, 10000)\n",
    "\n",
    "    sp1 = make_sparse(S1)\n",
    "    sp2 = make_sparse(S2)\n",
    "\n",
    "    hf = hash_family(depth)\n",
    "    sk1 = create_sketch(width, depth, hf, sp1)\n",
    "    sk2 = create_sketch(width, depth, hf, sp2)\n",
    "\n",
    "    inner_product_true = sparse_inner(sp1, sp2)\n",
    "    inner_product_estimated = sk1.inner(sk2)\n",
    "\n",
    "    error = abs((inner_product_true - inner_product_estimated) / inner_product_true)\n",
    "    accuracy = 4 / np.sqrt(width)\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print()\n",
    "    print(f\"True Inner Product: {inner_product_true}, Estimated Inner Product: {inner_product_estimated}\")\n",
    "    print()\n",
    "    print(f\"Error: {error}\")\n",
    "    assert error < accuracy, \"Accuracy not sufficient\"\n",
    "    \n",
    "\n",
    "def test_sketch_accuracy_euclidian_norm(width, depth, n):\n",
    "\n",
    "    v = np.random.rand(n) # rand vector 0..1 \n",
    "\n",
    "    hf = hash_family(depth)\n",
    "    sk = create_sketch_for_vector(width, depth, hf, v)\n",
    "\n",
    "    inner_product_true = np.inner(v, v)\n",
    "    inner_product_estimated = sk.inner(sk)\n",
    "\n",
    "    error = abs((inner_product_true - inner_product_estimated) / inner_product_true)\n",
    "    accuracy = 4 / np.sqrt(width)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print()\n",
    "    print(f\"True Inner Product: {inner_product_true}, Estimated Inner Product: {inner_product_estimated}\")\n",
    "    print()\n",
    "    print(f\"Error: {error}\")\n",
    "    assert error < accuracy, \"Accuracy not sufficient\"\n",
    "\n",
    "\n",
    "def cosine_similarity(array1, array2):\n",
    "    flat_array1 = array1.flatten()\n",
    "    \n",
    "    flat_array2 = array2.flatten()\n",
    "    \n",
    "    dot_prod = np.dot(flat_array1, flat_array2)\n",
    "    \n",
    "    norm1 = np.linalg.norm(flat_array1)\n",
    "    \n",
    "    norm2 = np.linalg.norm(flat_array2)\n",
    "    \n",
    "    return dot_prod / (norm1 * norm2)\n",
    "    \n",
    "\n",
    "def test_sketch_linearity(width, depth, n):\n",
    "    v1 = np.random.rand(n) # rand vector 0..1 \n",
    "    \n",
    "    v2 = np.random.rand(n) # rand vector 0..1 \n",
    "    \n",
    "    hf = hash_family(depth)\n",
    "    \n",
    "    sk1 = create_sketch_for_vector(width, depth, hf, v1)\n",
    "    \n",
    "    sk2 = create_sketch_for_vector(width, depth, hf, v2)\n",
    "    \n",
    "    v1_plus_v2 = v1 + v2\n",
    "    \n",
    "    sk_1_plus_2 = create_sketch_for_vector(width, depth, hf, v1_plus_v2)\n",
    "    \n",
    "    cos_similarity = cosine_similarity(sk1.vec+sk2.vec, sk_1_plus_2.vec)\n",
    "    \n",
    "    print(f\"Cosine Similarity between sk(v1+v2) and sk(v1)+sk(v2) : {cos_similarity}\")\n",
    "    \n",
    "    v1_euc_norm = np.inner(v1, v1)\n",
    "    v1_euc_norm_est = sk1.inner(sk1)\n",
    "    \n",
    "    v2_euc_norm = np.inner(v2, v2)\n",
    "    v2_euc_norm_est = sk2.inner(sk2)\n",
    "    \n",
    "    print()\n",
    "    print(f\"||v1||^2 + ||v2||^2 : {v1_euc_norm+v2_euc_norm}\")\n",
    "    print(f\"M(sk(v1)) + M(sk(v2)) : {v1_euc_norm_est+v2_euc_norm_est}\")\n",
    "    \n",
    "    v1_plus_v2_euc_norm = np.inner(v1_plus_v2, v1_plus_v2)\n",
    "    \n",
    "    print()\n",
    "    print(f\"||v1 + v2||^2 : {v1_plus_v2_euc_norm}\")\n",
    "    print(f\"M(sk(v1) + sk(v2)) : {sk_1_plus_2.inner(sk_1_plus_2)}\") # sk_1_plus_2 is similar 100% to sk(v1)+sk(v2)\n",
    "    \n",
    "    \n",
    "def test_speed(width, depth, n):\n",
    "    v1 = np.random.rand(n) # rand vector 0..1 \n",
    "    \n",
    "    hf = hash_family(depth)\n",
    "    \n",
    "    sk1 = create_sketch_for_vector(width, depth, hf, v1)\n",
    "    \n",
    "    sketch = create_sketch_for_vector(width, depth, hf, v1)\n",
    "    \n",
    "    return sketch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56309f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206.80811142921448\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "test_speed(1700, 7, 2_700_000)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df77600b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4\n",
      "\n",
      "True Inner Product: 32.83859819186468, Estimated Inner Product: 31.42268769813536\n",
      "\n",
      "Error: 0.04311726357674113\n"
     ]
    }
   ],
   "source": [
    "test_sketch_accuracy_euclidian_norm(width=100, depth=7, n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02035690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between sk(v1+v2) and sk(v1)+sk(v2) : 1.0000000000000002\n",
      "\n",
      "||v1||^2 + ||v2||^2 : 6641.120454081112\n",
      "M(sk(v1)) + M(sk(v2)) : 6376.599092318713\n",
      "\n",
      "||v1 + v2||^2 : 11624.152097238788\n",
      "M(sk(v1) + sk(v2)) : 10927.62713344412\n"
     ]
    }
   ],
   "source": [
    "test_sketch_linearity(width=100, depth=7, n=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8e7d71",
   "metadata": {},
   "source": [
    "# TFF (Deprecated) go down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebbc8854",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c661c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = 7  # number of hash functions\n",
    "width = 50  # specifies hash31 : N -> {0, 1, ..., `width`} uniformly.\n",
    "\n",
    "tf_width = tf.constant(width, dtype=tf.int32)\n",
    "tf_depth = tf.constant(depth, dtype=tf.int32)\n",
    "\n",
    "# Pool of three random tuples (A, B) corresponding to a different hash function parameters\n",
    "# We provide information about pair (F[0], F[1]) , the rest follow this \n",
    "# F[0] : shape(depth,) random `a` parameters for each row of the sketch. One row <-> One hash func <-> One `a`\n",
    "# F[1] : shape(depth,) random `b` parameters for each row of the sketch. One row <-> One hash func <-> One `b`\n",
    "tf_F = tf.random.uniform(shape=(6, depth), minval=0, maxval=(1 << 31) - 1, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63e6f6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def sketch_for_vector(v):\n",
    "    \"\"\" Returns AGMS sketch for `v` (vector shape=(n,)). \n",
    "    Note: We serialize `F`, `width`, `depth` for efficiency \"\"\"\n",
    "    \n",
    "    F = tf.constant(tf_F)\n",
    "    width = tf.constant(tf_width)\n",
    "    depth = tf.constant(tf_depth)\n",
    "\n",
    "    @tf.function\n",
    "    def _hash31(x, a, b):\n",
    "        \"\"\" _hash31 : N -> {0, 1, ..., width} uniformly \"\"\"\n",
    "        r = a * x + b\n",
    "        fold = tf.bitwise.bitwise_xor(tf.bitwise.right_shift(r, 31), r)\n",
    "        return tf.bitwise.bitwise_and(fold, 2147483647)\n",
    "    \n",
    "    @tf.function\n",
    "    def _fourwise(x):\n",
    "        \"\"\" Fourwise independent hash of `x` (int) to {+1, -1}. \"\"\"\n",
    "        result = 2 * (tf.bitwise.right_shift(tf.bitwise.bitwise_and(_hash31(_hash31(_hash31(x, F[2], F[3]), x, F[4]), x, F[5]), 32768), 15)) - 1\n",
    "        return result\n",
    "\n",
    "    sketch = tf.zeros(shape=(depth, width), dtype=tf.float32)\n",
    "    indices = tf.range(tf.shape(v)[0], dtype=tf.int32)\n",
    "\n",
    "    for i in indices:\n",
    "        pos = _hash31(i, F[0], F[1]) % width\n",
    "        delta = tf.cast(_fourwise(i), dtype=tf.float32) * v[i]\n",
    "        indices_to_update = tf.stack([tf.range(depth, dtype=tf.int32), pos], axis=1)\n",
    "        sketch = tf.tensor_scatter_nd_add(sketch, indices_to_update, delta)\n",
    "\n",
    "    return sketch\n",
    "\n",
    "@tff.tf_computation\n",
    "def sketch_for_vector_fn(v):\n",
    "    return sketch_for_vector(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6aa65f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tff.tf_computation\n",
    "def estimate_euc_norm_squared(sketch):\n",
    "    \n",
    "    @tf.function\n",
    "    def _median(v):\n",
    "        \"\"\" Median of tensor `v` with shape=(n,). Note: Suboptimal O(nlogn) but it's ok bcz n = `depth`\"\"\"\n",
    "        length = tf.shape(v)[0]\n",
    "        sorted_v = tf.sort(v)\n",
    "        middle = length // 2\n",
    "\n",
    "        return tf.cond(\n",
    "            tf.equal(length % 2, 0),\n",
    "            lambda: (sorted_v[middle - 1] + sorted_v[middle]) / 2.0,\n",
    "            lambda: sorted_v[middle]\n",
    "        )\n",
    "    \n",
    "    return _median(tf.reduce_sum(tf.square(sketch), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e12a12",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a184b8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bca61e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def cosine_similarity(t1, t2):\n",
    "    flat_t1 = tf.reshape(t1, shape=[-1])\n",
    "    \n",
    "    flat_t2 = tf.reshape(t2, shape=[-1])\n",
    "    \n",
    "    dot = tf.tensordot(flat_t1, flat_t2, axes=1)\n",
    "    \n",
    "    norm1 = tf.norm(flat_t1)\n",
    "    \n",
    "    norm2 = tf.norm(flat_t2)\n",
    "    \n",
    "    return dot / (norm1 * norm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9e2e7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sketch_linearity(n):\n",
    "    a = tf.random.uniform(shape=(), minval=0, maxval=1, dtype=tf.float32)\n",
    "    b = tf.random.uniform(shape=(), minval=0, maxval=1, dtype=tf.float32)\n",
    "    \n",
    "    v1 = tf.random.uniform(shape=(n,), minval=0, maxval=1, dtype=tf.float32)\n",
    "    \n",
    "    v2 = tf.random.uniform(shape=(n,), minval=0, maxval=1, dtype=tf.float32)\n",
    "    \n",
    "    sk1 = sketch_for_vector(v1)\n",
    "    \n",
    "    sk2 = sketch_for_vector(v2)\n",
    "    \n",
    "    v1_plus_v2 = a*v1 + b*v2\n",
    "    \n",
    "    sk_1_plus_2 = sketch_for_vector(v1_plus_v2)\n",
    "    \n",
    "    cos_similarity = cosine_similarity(a*sk1+b*sk2, sk_1_plus_2)\n",
    "    \n",
    "    print(f\"Cosine Similarity between sk(a*v1+b*v2) and a*sk(v1)+b*sk(v2) : {cos_similarity}\")\n",
    "\n",
    "    v1_euc_norm = np.inner(v1, v1)\n",
    "    v1_euc_norm_est = estimate_euc_norm_squared(sk1)\n",
    "    \n",
    "    v2_euc_norm = np.inner(v2, v2)\n",
    "    v2_euc_norm_est = estimate_euc_norm_squared(sk2)\n",
    "    \n",
    "    print()\n",
    "    print(f\"||v1||^2 + ||v2||^2 : {v1_euc_norm+v2_euc_norm}\")\n",
    "    print(f\"M(sk(v1)) + M(sk(v2)) : {v1_euc_norm_est+v2_euc_norm_est}\")\n",
    "    \n",
    "    v1_plus_v2_euc_norm = np.inner(v1_plus_v2, v1_plus_v2)\n",
    "    \n",
    "    print()\n",
    "    print(f\"||v1 + v2||^2 : {v1_plus_v2_euc_norm}\")\n",
    "    print(f\"M(sk(v1) + sk(v2)) : {estimate_euc_norm_squared(sk1+sk2)}\") # sk_1_plus_2 is similar 100% to sk(v1)+sk(v2)\n",
    "\n",
    "    \n",
    "def test_sketch_accuracy_euc_norm_squared(n):\n",
    "\n",
    "    v = tf.random.uniform(shape=(n,), minval=0, maxval=1, dtype=tf.float32)\n",
    "\n",
    "    sk = sketch_for_vector(v)\n",
    "\n",
    "    inner_product_true = np.inner(v, v)\n",
    "    inner_product_estimated = estimate_euc_norm_squared(sk)\n",
    "\n",
    "    error = abs((inner_product_true - inner_product_estimated) / inner_product_true)\n",
    "    accuracy = 4. / np.sqrt(width)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print()\n",
    "    print(f\"True Euc Norm Squared: {inner_product_true}, Estimated Euc Norm Squared: {inner_product_estimated}\")\n",
    "    print()\n",
    "    print(f\"Error: {error}\")\n",
    "    assert error < accuracy, \"Accuracy not sufficient\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b88a324a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between sk(a*v1+b*v2) and a*sk(v1)+b*sk(v2) : 0.9999995827674866\n",
      "\n",
      "||v1||^2 + ||v2||^2 : 68.69020080566406\n",
      "M(sk(v1)) + M(sk(v2)) : 68.58819580078125\n",
      "\n",
      "||v1 + v2||^2 : 41.888065338134766\n",
      "M(sk(v1) + sk(v2)) : 120.91709899902344\n"
     ]
    }
   ],
   "source": [
    "test_sketch_linearity(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d65d3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.565685424949238\n",
      "\n",
      "True Euc Norm Squared: 29.884586334228516, Estimated Euc Norm Squared: 29.543384552001953\n",
      "\n",
      "Error: 0.011417316272854805\n"
     ]
    }
   ],
   "source": [
    "test_sketch_accuracy_euc_norm_squared(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ee0083d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0301ddea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbebd60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1ec3b46",
   "metadata": {},
   "source": [
    "# Tensor Approach for AMS-Sketch !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cb5537",
   "metadata": {},
   "source": [
    "Tensor based implementation of sketch. Very efficient (to be used in graphs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0275f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 17:32:35.914806: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-04 17:32:36.095770: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-04-04 17:32:36.095790: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-04-04 17:32:36.958819: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-04 17:32:36.958893: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-04 17:32:36.958901: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExtensionType\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mAmsSketch\u001b[39;00m(ExtensionType):\n\u001b[1;32m      4\u001b[0m     depth: \u001b[38;5;28mint\u001b[39m\n\u001b[1;32m      5\u001b[0m     width: \u001b[38;5;28mint\u001b[39m\n",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m, in \u001b[0;36mAmsSketch\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m depth: \u001b[38;5;28mint\u001b[39m\n\u001b[1;32m      5\u001b[0m width: \u001b[38;5;28mint\u001b[39m\n\u001b[0;32m----> 6\u001b[0m F: \u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mTensor\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m, width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1500\u001b[39m):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepth \u001b[38;5;241m=\u001b[39m depth\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.experimental import ExtensionType\n",
    "\n",
    "class AmsSketch(ExtensionType):\n",
    "    depth: int\n",
    "    width: int\n",
    "    F: tf.Tensor\n",
    "        \n",
    "        \n",
    "    def __init__(self, depth=7, width=1500):\n",
    "        self.depth = depth\n",
    "        self.width = width\n",
    "        self.F = tf.random.uniform(shape=(6, depth), minval=0, maxval=(1 << 31) - 1, dtype=tf.int32)\n",
    "\n",
    "        \n",
    "    @tf.function\n",
    "    def hash31(self, x, a, b):\n",
    "\n",
    "        r = a * x + b\n",
    "        fold = tf.bitwise.bitwise_xor(tf.bitwise.right_shift(r, 31), r)\n",
    "        return tf.bitwise.bitwise_and(fold, 2147483647)\n",
    "    \n",
    "    \n",
    "    @tf.function\n",
    "    def tensor_hash31(self, x, a, b): # GOOD\n",
    "        \"\"\" Assumed that x is tensor shaped (d,) , i.e., a vector (for example, indices, i.e., tf.range(d)) \"\"\"\n",
    "\n",
    "        # Reshape x to have an extra dimension, resulting in a shape of (k, 1)\n",
    "        x_reshaped = tf.expand_dims(x, axis=-1)\n",
    "\n",
    "        # shape=(`v_dim`, 7)\n",
    "        r = tf.multiply(a, x_reshaped) + b\n",
    "\n",
    "        fold = tf.bitwise.bitwise_xor(tf.bitwise.right_shift(r, 31), r)\n",
    "        \n",
    "        return tf.bitwise.bitwise_and(fold, 2147483647)\n",
    "    \n",
    "    \n",
    "    @tf.function\n",
    "    def tensor_fourwise(self, x):\n",
    "        \"\"\" Assumed that x is tensor shaped (d,) , i.e., a vector (for example, indices, i.e., tf.range(d)) \"\"\"\n",
    "        # 1st use the tensor hash31\n",
    "        in1 = self.tensor_hash31(x, self.F[2], self.F[3])  # (`x_dim`, 7)\n",
    "        \n",
    "        # 2nd (notice we swap the first two params, no change really)\n",
    "        in2 = self.tensor_hash31(x, in1, self.F[4])  # (`x_dim`, 7)\n",
    "        \n",
    "        in3 = self.tensor_hash31(x, in2, self.F[5])  # (`x_dim`, 7)\n",
    "        \n",
    "        in4 = tf.bitwise.bitwise_and(in3, 32768)  # (`x_dim`, 7)\n",
    "        \n",
    "        return 2 * (tf.bitwise.right_shift(in4, 15)) - 1  # (`x_dim`, 7)\n",
    "        \n",
    "        \n",
    "    @tf.function\n",
    "    def fourwise(self, x):\n",
    "\n",
    "        result = 2 * (tf.bitwise.right_shift(tf.bitwise.bitwise_and(self.hash31(self.hash31(self.hash31(x, self.F[2], self.F[3]), x, self.F[4]), x, self.F[5]), 32768), 15)) - 1\n",
    "        return result\n",
    "    \n",
    "    \n",
    "    @tf.function\n",
    "    def sketch_for_vector(self, v):\n",
    "        \"\"\" Extremely efficient computation of sketch with only using tensors. \"\"\"\n",
    "        \n",
    "        sketch = tf.zeros(shape=(self.depth, self.width), dtype=tf.float32)\n",
    "        \n",
    "        len_v = v.shape[0]\n",
    "        \n",
    "        pos_tensor = self.tensor_hash31(tf.range(len_v), self.F[0], self.F[1]) % self.width\n",
    "        \n",
    "        v_expand = tf.expand_dims(v, axis=-1)\n",
    "        \n",
    "        deltas_tensor = tf.multiply(tf.cast(self.tensor_fourwise(tf.range(len_v)), dtype=tf.float32), v_expand)\n",
    "        \n",
    "        range_tensor = tf.range(self.depth)\n",
    "        \n",
    "        # Expand dimensions to create a 2D tensor with shape (1, depth)\n",
    "        range_tensor_expanded = tf.expand_dims(range_tensor, 0)\n",
    "\n",
    "        # Use tf.tile to repeat the tensor `len_v` times\n",
    "        repeated_range_tensor = tf.tile(range_tensor_expanded, [len_v, 1])\n",
    "        \n",
    "        # shape=(`len_v`, 7, 2)\n",
    "        indices = tf.stack([repeated_range_tensor, pos_tensor], axis=-1)\n",
    "        \n",
    "        sketch = tf.tensor_scatter_nd_add(sketch, indices, deltas_tensor)\n",
    "        \n",
    "        return sketch\n",
    "    \n",
    "    \n",
    "    @tf.function\n",
    "    def sketch_for_vector2(self, v):\n",
    "        \"\"\" Bad implementation for tensorflow. \"\"\"\n",
    "\n",
    "        sketch = tf.zeros(shape=(self.depth, self.width), dtype=tf.float32)\n",
    "\n",
    "        for i in tf.range(tf.shape(v)[0], dtype=tf.int32):\n",
    "            pos = self.hash31(i, self.F[0], self.F[1]) % self.width\n",
    "            delta = tf.cast(self.fourwise(i), dtype=tf.float32) * v[i]\n",
    "            indices_to_update = tf.stack([tf.range(self.depth, dtype=tf.int32), pos], axis=1)\n",
    "            sketch = tf.tensor_scatter_nd_add(sketch, indices_to_update, delta)\n",
    "\n",
    "        return sketch\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    @tf.function\n",
    "    def estimate_euc_norm_squared(sketch):\n",
    "\n",
    "        @tf.function\n",
    "        def _median(v):\n",
    "            \"\"\" Median of tensor `v` with shape=(n,). Note: Suboptimal O(nlogn) but it's ok bcz n = `depth`\"\"\"\n",
    "            length = tf.shape(v)[0]\n",
    "            sorted_v = tf.sort(v)\n",
    "            middle = length // 2\n",
    "\n",
    "            return tf.cond(\n",
    "                tf.equal(length % 2, 0),\n",
    "                lambda: (sorted_v[middle - 1] + sorted_v[middle]) / 2.0,\n",
    "                lambda: sorted_v[middle]\n",
    "            )\n",
    "\n",
    "        return _median(tf.reduce_sum(tf.square(sketch), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58ca4c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tff-py39] *",
   "language": "python",
   "name": "conda-env-tff-py39-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
