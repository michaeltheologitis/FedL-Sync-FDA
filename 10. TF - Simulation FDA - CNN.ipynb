{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2759993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74531322",
   "metadata": {},
   "source": [
    "## Import EMNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a550108",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cc37c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77c8e4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_BATCH_INPUT = (None, 28, 28) # EMNIST dataset (None is used for batch size, as it varies)\n",
    "CNN_INPUT_RESHAPE = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a83a61",
   "metadata": {},
   "source": [
    "## Convert to Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3eb02a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = tf.constant(X_train, dtype=tf.float32)\n",
    "del X_train\n",
    "\n",
    "y_train_tensor = tf.constant(y_train, dtype=tf.int32)\n",
    "del y_train\n",
    "\n",
    "X_test_tensor = tf.constant(X_test, dtype=tf.float32)\n",
    "del X_test\n",
    "\n",
    "y_test_tensor = tf.constant(y_test, dtype=tf.int32)\n",
    "del y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567ab8a7",
   "metadata": {},
   "source": [
    "## Prepare data for Federated Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3e112b",
   "metadata": {},
   "source": [
    "### Create centralized testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fad165b",
   "metadata": {},
   "outputs": [],
   "source": [
    "slices_test = (X_test_tensor, y_test_tensor)\n",
    "\n",
    "def create_tf_dataset_for_testing(batch_size):\n",
    "    return tf.data.Dataset.from_tensor_slices(slices_test).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84aa24c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = create_tf_dataset_for_testing(256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a24a95c",
   "metadata": {},
   "source": [
    "### Slice the Tensors for each Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43734f7",
   "metadata": {},
   "source": [
    "We will cut the training data, i.e., (`X_train_tensor`, `y_train_tensor`) to equal parts, each part corresponding to one Client. We want to give the result back as a dictionary with key `client_id` and value the training tensor data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97b27a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_for_clients(num_clients):\n",
    "    \n",
    "    client_slices_train = {}\n",
    "\n",
    "    for i in range(num_clients):\n",
    "        # Compute the indices for this client's slice\n",
    "        start_idx = int(i * n_train / num_clients)\n",
    "        end_idx = int((i + 1) * n_train / num_clients)\n",
    "\n",
    "        # Get the slice for this client\n",
    "        X_client_train = X_train_tensor[start_idx:end_idx]\n",
    "        y_client_train = y_train_tensor[start_idx:end_idx]\n",
    "        \n",
    "        # Combine the slices into a single dataset\n",
    "        client_slices_train[f'client_{i}'] = (X_client_train, y_client_train)\n",
    "    \n",
    "    return client_slices_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88734523",
   "metadata": {},
   "source": [
    "### Create TF friendly data for each Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c58dbae",
   "metadata": {},
   "source": [
    "Given a Tensor slice (i.e. value of `client_slices_train[\"client_id\"]` we convert it to highly optimized `tf.data.Dataset` to prepare for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "794535c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_dataset_for_client(client_tensor_slices, batch_size, shuffle_buffer_size, num_steps_until_rtc_check, seed):\n",
    "    \n",
    "        return tf.data.Dataset.from_tensor_slices(client_tensor_slices) \\\n",
    "            .shuffle(buffer_size=shuffle_buffer_size, seed=seed).batch(batch_size) \\\n",
    "            .prefetch(tf.data.AUTOTUNE).take(num_steps_until_rtc_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0794b1a0",
   "metadata": {},
   "source": [
    "### Create Federated Learning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d770c13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_federated_data(client_slices_train, batch_size, shuffle_buffer_size, num_steps_until_rtc_check, seed=None):\n",
    "    \n",
    "    federated_dataset = [ \n",
    "        create_tf_dataset_for_client(client_tensor_slices, batch_size, shuffle_buffer_size, num_steps_until_rtc_check, seed)\n",
    "        for client, client_tensor_slices in client_slices_train.items()\n",
    "    ]\n",
    "    \n",
    "    return federated_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918a0455",
   "metadata": {},
   "source": [
    "# Miscallenious"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58d696f",
   "metadata": {},
   "source": [
    "## Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d6aa1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def variance(cnn_list, cnn_sync):\n",
    "    \n",
    "    squared_distances = [\n",
    "        tf.reduce_sum(tf.square(cnn.trainable_vars_as_vector() - cnn_sync.trainable_vars_as_vector())) \n",
    "        for cnn in cnn_list\n",
    "    ]\n",
    "    \n",
    "    var = tf.reduce_mean(squared_distances)\n",
    "    \n",
    "    return var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88347123",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "524397ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metrics_dict(fda_name, n_train, dataset_name, input_pixels, seed, epochs, num_clients, \n",
    "                        batch_size, steps_in_one_fda_step, theta, total_fda_steps, num_weights,\n",
    "                        total_rounds, final_accuracy, sketch_width=None, sketch_depth=None):\n",
    "    metrics = {\n",
    "            \"fda_name\" : fda_name,\n",
    "            \"theta\" : theta,\n",
    "            \"dataset_name\" : dataset_name, # new\n",
    "            \"input_pixels\" : input_pixels, # new\n",
    "            \"n_train\" : n_train, # new\n",
    "            \"num_weights\" : num_weights, # new\n",
    "            \"seed\" : seed,\n",
    "            \"epochs\" : epochs,\n",
    "            \"num_clients\" : num_clients,\n",
    "            \"batch_size\" : batch_size,\n",
    "            \"steps_in_one_fda_step\" : steps_in_one_fda_step,\n",
    "            \"sketch_width\" : sketch_width,\n",
    "            \"sketch_depth\" : sketch_depth\n",
    "        }\n",
    "    \n",
    "    # one batch bytes\n",
    "    metrics[\"one_sample_bytes\"] = 4 * (metrics[\"input_pixels\"] + 1)  # 4 bytes float32\n",
    "    \n",
    "    # training dataset size\n",
    "    metrics[\"training_dataset_bytes\"] = metrics[\"one_sample_bytes\"] * metrics[\"n_train\"]\n",
    "    \n",
    "    # model bytes\n",
    "    metrics[\"model_bytes\"] = metrics[\"num_weights\"] * 4\n",
    "    \n",
    "    \n",
    "    # local state bytes (i.e. S_i), for one client\n",
    "    if fda_name == \"naive\":\n",
    "        metrics[\"local_state_bytes\"] = 4\n",
    "    elif fda_name == \"linear\":\n",
    "        metrics[\"local_state_bytes\"] = 8\n",
    "    else:\n",
    "        metrics[\"local_state_bytes\"] = sketch_width * sketch_depth * 4 + 4\n",
    "        \n",
    "    # accuracy (already computed in parameter)\n",
    "    metrics[\"final_accuracy\"] = final_accuracy\n",
    "    \n",
    "    # total fda steps from algo\n",
    "    metrics[\"total_fda_steps\"] = total_fda_steps\n",
    "    \n",
    "    # total steps (a single fda step might have many normal SGD steps, batch steps)\n",
    "    metrics[\"total_steps\"] = metrics[\"total_fda_steps\"] * metrics[\"steps_in_one_fda_step\"]\n",
    "    \n",
    "    # total rounds in algo. Reason why we differentiate from the hardcoded NUM_ROUNDS\n",
    "    # is because we might run less rounds in the future (i.e. stop on 10^7 samples idk)\n",
    "    metrics[\"total_rounds\"] = total_rounds\n",
    "    \n",
    "    # bytes exchanged for synchronizing weights (x2 because server sends back)\n",
    "    metrics[\"model_bytes_exchanged\"] = metrics[\"total_rounds\"] * metrics[\"model_bytes\"] \\\n",
    "        * metrics[\"num_clients\"] * 2\n",
    "    \n",
    "    # bytes exchanged for monitoring the variance (communication)\n",
    "    metrics[\"monitoring_bytes_exchanged\"] = metrics[\"local_state_bytes\"] * metrics[\"total_fda_steps\"] \\\n",
    "        * metrics[\"num_clients\"]\n",
    "    \n",
    "    # total communication bytes (for both monitoring and model synchronization)\n",
    "    metrics[\"total_communication_bytes\"] = metrics[\"model_bytes_exchanged\"] + metrics[\"monitoring_bytes_exchanged\"]\n",
    "    \n",
    "    # total seen dataset bytes (across all learning, i.e., all clients)\n",
    "    metrics[\"trained_in_bytes\"] = metrics[\"batch_size\"] * metrics[\"one_sample_bytes\"] \\\n",
    "        * metrics[\"total_steps\"] * metrics[\"num_clients\"]\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e079822",
   "metadata": {},
   "source": [
    "## Neural Net weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc9b44d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_weights(model):\n",
    "    total_params = 0\n",
    "    for layer in model.layers:\n",
    "        total_params += np.sum([np.prod(weight.shape) for weight in layer.trainable_weights])\n",
    "    return int(total_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcee0c14",
   "metadata": {},
   "source": [
    "## Reseting NN weights for Server-Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8abe642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_trainable_variables(server_cnn, client_cnns, starting_trainable_variables):\n",
    "    \n",
    "    server_cnn.set_trainable_variables(starting_trainable_variables)\n",
    "    \n",
    "    for client_cnn in client_cnns:\n",
    "        client_cnn.set_trainable_variables(starting_trainable_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cbfbd3",
   "metadata": {},
   "source": [
    "# Simple Convolutional Neural Net (CNN) - Medium Size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c3a252",
   "metadata": {},
   "source": [
    "A simple Convolutional Neural Network with a single convolutional layer, followed by a max-pooling layer, and two dense layers for classification. Designed for 28x28 grayscale images. It has 692,352 weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dac88dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(tf.keras.Model):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        self.reshape = layers.Reshape(CNN_INPUT_RESHAPE)\n",
    "        self.conv1 = layers.Conv2D(32, 3, activation='relu')\n",
    "        self.max_pool = layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.dense1 = layers.Dense(128, activation='relu')\n",
    "        self.dense2 = layers.Dense(num_classes, activation='softmax')\n",
    "\n",
    "        \n",
    "    # Defines the computation from inputs to outputs\n",
    "    def call(self, inputs, training=None):\n",
    "        x = self.reshape(inputs)  # Add a channel dimension\n",
    "        x = self.conv1(x)\n",
    "        x = self.max_pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    @tf.function\n",
    "    def step(self, batch):\n",
    "        \n",
    "        x_batch, y_batch = batch\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass: Compute predictions\n",
    "            y_batch_pred = self(x_batch, training=True)\n",
    "\n",
    "            # Compute the loss value\n",
    "            # (the loss function is configured in `compile()`)\n",
    "            loss = self.compiled_loss(\n",
    "                y_true=y_batch,\n",
    "                y_pred=y_batch_pred,\n",
    "                regularization_losses=self.losses\n",
    "            )\n",
    "\n",
    "        # Compute gradients\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        \n",
    "        # Apply gradients to the model's trainable variables (update weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        \n",
    "        # Update metrics (includes the metric that tracks the loss)\n",
    "        #self.compiled_metrics.update_state(y_batch, y_batch_pred)\n",
    "    \n",
    "    \n",
    "    @tf.function\n",
    "    def train(self, dataset):\n",
    "\n",
    "        for batch in dataset:\n",
    "            self.step(batch)\n",
    "            \n",
    "    \n",
    "    def set_trainable_variables(self, trainable_vars):\n",
    "        \"\"\" Given `trainable_vars` set our `self.trainable_vars` \"\"\"\n",
    "        for model_var, var in zip(self.trainable_variables, trainable_vars):\n",
    "            model_var.assign(var)\n",
    "\n",
    "            \n",
    "    def trainable_vars_as_vector(self):\n",
    "        return tf.concat([tf.reshape(var, [-1]) for var in self.trainable_variables], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ead5a6c",
   "metadata": {},
   "source": [
    "### Helper function to compile and return the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82ddd2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_and_built_cnn():\n",
    "    cnn = CNN()\n",
    "    \n",
    "    cnn.compile(\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False), # we have softmax\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')]\n",
    "    )\n",
    "    \n",
    "    cnn.build(CNN_BATCH_INPUT)  # EMNIST dataset (None is used for batch size, as it varies)\n",
    "    \n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386f99e0",
   "metadata": {},
   "source": [
    "# Advanced Convolutional Neural Net (CNN) - Large Size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3259d325",
   "metadata": {},
   "source": [
    "A more complex Convolutional Neural Network with three sets of two convolutional layers, each followed by a max-pooling layer, and two dense layers with dropout for classification. Designed for 28x28 grayscale images. It has 2,592,202 weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee5705b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedCNN(tf.keras.Model):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(AdvancedCNN, self).__init__()\n",
    "        \n",
    "        self.reshape = layers.Reshape(CNN_INPUT_RESHAPE)\n",
    "        \n",
    "        self.conv1 = layers.Conv2D(64, kernel_size=3, activation='relu', padding='same')\n",
    "        self.conv2 = layers.Conv2D(64, kernel_size=3, activation='relu', padding='same')\n",
    "        self.max_pool1 = layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        \n",
    "        self.conv3 = layers.Conv2D(128, kernel_size=3, activation='relu', padding='same')\n",
    "        self.conv4 = layers.Conv2D(128, kernel_size=3, activation='relu', padding='same')\n",
    "        self.max_pool2 = layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        \n",
    "        self.conv5 = layers.Conv2D(256, kernel_size=3, activation='relu', padding='same')\n",
    "        self.conv6 = layers.Conv2D(256, kernel_size=3, activation='relu', padding='same')\n",
    "        self.max_pool3 = layers.MaxPooling2D(pool_size=(2, 2))\n",
    "\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.dense1 = layers.Dense(512, activation='relu')\n",
    "        self.dropout1 = layers.Dropout(0.5)\n",
    "        self.dense2 = layers.Dense(512, activation='relu')\n",
    "        self.dropout2 = layers.Dropout(0.5)\n",
    "        self.dense3 = layers.Dense(num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        x = self.reshape(inputs)  # Add a channel dimension\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.max_pool1(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.max_pool2(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.max_pool3(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dropout1(x, training=training)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dropout2(x, training=training)\n",
    "        x = self.dense3(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    @tf.function\n",
    "    def step(self, batch):\n",
    "        \n",
    "        x_batch, y_batch = batch\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass: Compute predictions\n",
    "            y_batch_pred = self(x_batch, training=True)\n",
    "\n",
    "            # Compute the loss value\n",
    "            # (the loss function is configured in `compile()`)\n",
    "            loss = self.compiled_loss(\n",
    "                y_true=y_batch,\n",
    "                y_pred=y_batch_pred,\n",
    "                regularization_losses=self.losses\n",
    "            )\n",
    "\n",
    "        # Compute gradients\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        \n",
    "        # Apply gradients to the model's trainable variables (update weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        \n",
    "        # Update metrics (includes the metric that tracks the loss)\n",
    "        #self.compiled_metrics.update_state(y_batch, y_batch_pred)\n",
    "    \n",
    "    \n",
    "    @tf.function\n",
    "    def train(self, dataset):\n",
    "\n",
    "        for batch in dataset:\n",
    "            self.step(batch)\n",
    "            \n",
    "    \n",
    "    def set_trainable_variables(self, trainable_vars):\n",
    "        \"\"\" Given `trainable_vars` set our `self.trainable_vars` \"\"\"\n",
    "        for model_var, var in zip(self.trainable_variables, trainable_vars):\n",
    "            model_var.assign(var)\n",
    "\n",
    "            \n",
    "    def trainable_vars_as_vector(self):\n",
    "        return tf.concat([tf.reshape(var, [-1]) for var in self.trainable_variables], axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1289f0",
   "metadata": {},
   "source": [
    "### Helper function to compile and return the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a705fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_and_built_advanced_cnn():\n",
    "    advanced_cnn = AdvancedCNN()\n",
    "    \n",
    "    advanced_cnn.compile(\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False), # we have softmax\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')]\n",
    "    )\n",
    "    \n",
    "    advanced_cnn.build(CNN_BATCH_INPUT)  # EMNIST dataset (None is used for batch size, as it varies)\n",
    "    \n",
    "    return advanced_cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c454f52",
   "metadata": {},
   "source": [
    "### Average NN weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7cb196c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_client_weights(client_models):\n",
    "    # client_weights[0] the trainable variables of Client 0 (a list of tf.Variable)\n",
    "    client_weights = [model.trainable_variables for model in client_models]\n",
    "\n",
    "    # concise solution. per layer. `layer_weight_tensors` corresponds to a list of tensors of a layer\n",
    "    avg_weights = [\n",
    "        tf.reduce_mean(layer_weight_tensors, axis=0)\n",
    "        for layer_weight_tensors in zip(*client_weights)\n",
    "    ]\n",
    "\n",
    "    return avg_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0e3dab",
   "metadata": {},
   "source": [
    "### Server - Clients synchronization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "666ac14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def synchronize(server_cnn, client_cnns):\n",
    "    # server average\n",
    "    server_cnn.set_trainable_variables(average_client_weights(client_cnns))\n",
    "    \n",
    "    # synchronize clients\n",
    "    for client_cnn in client_cnns:\n",
    "        client_cnn.set_trainable_variables(server_cnn.trainable_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9a13e6",
   "metadata": {},
   "source": [
    "# Functional Dynamic Averaging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f2a1b5",
   "metadata": {},
   "source": [
    "We follow the Functional Dynamic Averaging (FDA) scheme. Let the mean model be\n",
    "\n",
    "$$ \\overline{w_t} = \\frac{1}{k} \\sum_{i=1}^{k} w_t^{(i)} $$\n",
    "\n",
    "where $ w_t^{(i)} $ is the model at time $ t $ in some round in the $i$-th learner.\n",
    "\n",
    "Local models are trained independently and cooperatively and we want to monitor the Round Terminating Conditon (**RTC**):\n",
    "\n",
    "$$ \\frac{1}{k} \\sum_{i=1}^{k} \\lVert w_t^{(i)} - \\overline{w_t} \\rVert_2^2  \\leq \\Theta $$\n",
    "\n",
    "where the left-hand side is the **model variance**, and threshold $\\Theta$ is a hyperparameter of the FDA, defined at the beginning of the round; it may change at each round. When the monitoring logic cannot guarantee the validity of RTC, the round terminates. All local models are pulled into `tff.SERVER`, and $\\bar{w_t}$ is set to their average. Then, another round begins."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb0ccbb",
   "metadata": {},
   "source": [
    "### Monitoring the RTC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba6e34b",
   "metadata": {},
   "source": [
    "FDA monitors the RTC by applying techniques from Functionary [Functional Geometric Averaging](http://users.softnet.tuc.gr/~minos/Papers/edbt19.pdf). We first restate the problem of monitoring RTC into the standard distributed stream monitoring formulation. Let\n",
    "\n",
    "$$ S(t) =  \\frac{1}{k} \\sum_{i=1}^{k} S_i(t) $$\n",
    "\n",
    "where $ S(t) \\in \\mathbb{R}^n $ be the \"global state\" of the system and $ S_i(t) \\in \\mathbb{R}^n $ the \"local states\". The goal is to monitor the threshold condition on the global state in the form $ F(S(t)) \\leq \\Theta $ where $ F : \\mathbb{R}^n \\to \\mathbb{R} $ a non-linear function. Let\n",
    "\n",
    "$$ \\Delta_t^{(i)} = w_t^{(i)} - w_{t_0}^{(i)} $$\n",
    "\n",
    "be the update at the $ i $-th learner, that is, the change to the local model at time $t$ since the beginning of the current round at time $t_0$. Let the average update be\n",
    "\n",
    "$$ \\overline{\\Delta_t} = \\frac{1}{k} \\sum_{i=1}^{k} \\Delta_t^{(i)} $$\n",
    "\n",
    "it follows that the variance can be written as\n",
    "\n",
    "$$ \\frac{1}{k} \\sum_{i=1}^{k} \\lVert w_t^{(i)} - \\overline{w_t} \\rVert_2^2 = \\Big( \\frac{1}{k} \\sum_{i=1}^{k} \\lVert \\Delta_t^{(i)} \\rVert_2^2 \\Big) - \\lVert \\overline{\\Delta_t} \\rVert_2^2 $$\n",
    "\n",
    "So, conceptually, if we define\n",
    "$$ S_i(t) = \\begin{bmatrix}\n",
    "           \\lVert \\Delta_t^{(i)} \\rVert_2^2 \\\\\n",
    "           \\Delta_t^{(i)}\n",
    "         \\end{bmatrix} \\quad \\text{and} \\quad\n",
    "         F(\\begin{bmatrix}\n",
    "           v \\\\\n",
    "           \\bf{x}\n",
    "         \\end{bmatrix}) = v - \\lVert \\bf{x} \\rVert_2^2 $$\n",
    "\n",
    "The RTC is equivalent to condition $$ F(S(t)) \\leq \\Theta $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26a0df4",
   "metadata": {},
   "source": [
    "## 1️⃣ Naive FDA\n",
    "\n",
    "In the naive approach, we eliminate the update vector from the local state (i.e. recuce the dimension to 0). Define local state as\n",
    "\n",
    "$$ S_i(t) = \\lVert \\Delta_t^{(i)} \\rVert_2^2 \\in \\mathbb{R}$$ \n",
    "\n",
    "and the identity function\n",
    "\n",
    "$$ F(v) = v $$\n",
    "\n",
    "It is trivial that $ F(S(t)) \\leq \\Theta $ implies the RTC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6875d47",
   "metadata": {},
   "source": [
    "### Client Steps\n",
    "\n",
    "The number of steps depends on the dataset, i.e., `.take(num)` call on `tf.data.Dataset` creation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0cf704c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def steps_naive(last_sync_cnn, client_cnn, client_dataset):\n",
    "    # number of steps depend on `.take()` from `dataset`\n",
    "    client_cnn.train(client_dataset)\n",
    "    \n",
    "    Delta_i = client_cnn.trainable_vars_as_vector() - last_sync_cnn.trainable_vars_as_vector()\n",
    "    \n",
    "    Delta_i_euc_norm_squared = tf.reduce_sum(tf.square(Delta_i)) # ||D(t)_i||^2\n",
    "    \n",
    "    return Delta_i_euc_norm_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2013ea",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4780782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_naive(S):\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2c6b4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def run_federated_simulation_naive(server_cnn, client_cnns, federated_dataset,\n",
    "                                   num_epochs, theta, epoch_fda_steps):\n",
    "    \n",
    "    print(\"retracing naive\")\n",
    "    \n",
    "    total_rounds = 0\n",
    "    total_fda_steps = 0\n",
    "    \n",
    "    round_fda_steps = tf.constant(0, shape=(), dtype=tf.int32)\n",
    "    epoch_count = tf.constant(0, shape=(), dtype=tf.int32)\n",
    "    \n",
    "    S = tf.constant(0., shape=(), dtype=tf.float32)\n",
    "    \n",
    "    while epoch_count < num_epochs:\n",
    "        \n",
    "        while F_naive(S) <= theta:\n",
    "            S_i_clients = []\n",
    "\n",
    "            # client steps (number depends on `federated_dataset`, i.e., `.take(num)`)\n",
    "            for client_cnn, client_dataset in zip(client_cnns, federated_dataset):\n",
    "                Delta_i_euc_norm_squared = steps_naive(server_cnn, client_cnn, client_dataset)\n",
    "                S_i_clients.append(Delta_i_euc_norm_squared)\n",
    "                \n",
    "            S = tf.reduce_mean(S_i_clients)\n",
    "            \n",
    "            round_fda_steps += 1\n",
    "            total_fda_steps += 1\n",
    "            \n",
    "            if round_fda_steps == epoch_fda_steps:\n",
    "                epoch_count += 1\n",
    "                round_fda_steps = tf.constant(0, shape=(), dtype=tf.int32)\n",
    "                \n",
    "                if epoch_count == num_epochs:\n",
    "                    break\n",
    "        \n",
    "        \n",
    "        \"\"\"------------------------------test--------------------------------------------\"\"\"\n",
    "        Delta_i_clients = [\n",
    "            tf.subtract(client_cnn.trainable_vars_as_vector(), server_cnn.trainable_vars_as_vector()) \n",
    "            for client_cnn in client_cnns\n",
    "        ] #test\n",
    "        actual_S_2 = tf.reduce_sum(tf.square(tf.reduce_mean(Delta_i_clients, axis=0))) #test\n",
    "        \"\"\"------------------------------test--------------------------------------------\"\"\"\n",
    "        \n",
    "        # server average\n",
    "        server_cnn.set_trainable_variables(average_client_weights(client_cnns))\n",
    "        \n",
    "        \"\"\"------------------------------test--------------------------------------------\"\"\"\n",
    "        tf.print(\"Naive Epoch count: \", epoch_count, \" Total fda steps: \", total_fda_steps, output_stream=sys.stdout)\n",
    "        tf.print(\"Est var: \", S, \" Actual S_2 (Assumed 0): \", actual_S_2, \" Actual var: \", variance(client_cnns, server_cnn), output_stream=sys.stdout)\n",
    "        tf.print(\"\\n\", output_stream=sys.stdout)\n",
    "        \"\"\"------------------------------test--------------------------------------------\"\"\"\n",
    "        \n",
    "        # reset variance approx\n",
    "        S = tf.constant(0., shape=(), dtype=tf.float32)\n",
    "\n",
    "        # synchronize clients\n",
    "        for client_cnn in client_cnns:\n",
    "            client_cnn.set_trainable_variables(server_cnn.trainable_variables)\n",
    "            \n",
    "        total_rounds += 1\n",
    "    \n",
    "    return total_rounds, total_fda_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc6d3f1",
   "metadata": {},
   "source": [
    "## 2️⃣ Linear FDA\n",
    "\n",
    "In the linear case, we reduce the update vector to a scalar, $ \\xi \\Delta_t^{(i)} \\in \\mathbb{R}$, where $ \\xi $ is any unit vector.\n",
    "\n",
    "Define the local state to be \n",
    "\n",
    "$$ S_i(t) = \\begin{bmatrix}\n",
    "           \\lVert \\Delta_t^{(i)} \\rVert_2^2 \\\\\n",
    "           \\xi \\Delta_t^{(i)}\n",
    "         \\end{bmatrix} \\in \\mathbb{R}^2 $$\n",
    "\n",
    "Also, define \n",
    "\n",
    "$$ F(v, x) = v - x^2 $$\n",
    "\n",
    "The RTC is equivalent to condition \n",
    "\n",
    "$$ F(S(t)) \\leq \\Theta $$\n",
    "\n",
    "A random choice of $ \\xi $ is likely to perform poorly (terminate round prematurely), as it wil likely be close to orthogonal to $ \\overline{\\Delta_t} $. A good choice would be a vector $ \\xi $ correlated to $ \\overline{\\Delta_t} $. A heuristic choice is to take $ \\overline{\\Delta_{t_0}} $ (after scaling it to norm 1), i.e., the update vector right before the current round started. All nodes can estimate this without communication, as $ \\overline{w_{t_0}} - \\overline{w_{t_{-1}}} $, the difference of the last two models pushed by the Server. Hence, \n",
    "\n",
    "$$ \\xi = \\frac{\\overline{w_{t_0}} - \\overline{w_{t_{-1}}}}{\\lVert \\overline{w_{t_0}} - \\overline{w_{t_{-1}}} \\rVert_2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbfb12c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def ksi_unit_fn(w_t0, w_tminus1):\n",
    "    \n",
    "    if tf.reduce_all(tf.equal(w_t0, w_tminus1)):\n",
    "        # if equal then ksi becomes a random vector (will only happen in round 1)\n",
    "        ksi = tf.random.normal(shape=w_t0.shape)\n",
    "    else:\n",
    "        ksi = w_t0 - w_tminus1\n",
    "\n",
    "    # Normalize and return\n",
    "    return tf.divide(ksi, tf.norm(ksi))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b66f11",
   "metadata": {},
   "source": [
    "### Client Steps\n",
    "\n",
    "The number of steps depends on the dataset, i.e., `.take(num)` call on `tf.data.Dataset` creation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0ad6c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def steps_linear(cnn_tminus, cnn_t0, client_cnn, client_dataset):\n",
    "    # number of steps depend on `.take()` from `dataset`\n",
    "    client_cnn.train(client_dataset)\n",
    "    \n",
    "    Delta_i = client_cnn.trainable_vars_as_vector() - cnn_t0.trainable_vars_as_vector()\n",
    "    \n",
    "    #||D(t)_i||^2 , shape = (1,) \n",
    "    Delta_i_euc_norm_squared = tf.reduce_sum(tf.square(Delta_i)) # ||D(t)_i||^2\n",
    "    \n",
    "    # heuristic unit vector ksi\n",
    "    ksi = ksi_unit_fn(cnn_t0.trainable_vars_as_vector(), cnn_tminus.trainable_vars_as_vector())\n",
    "    \n",
    "    # ksi * Delta_i (* is dot) , shape = ()\n",
    "    ksi_Delta_i = tf.reduce_sum(tf.multiply(ksi, Delta_i))\n",
    "    \n",
    "    return Delta_i_euc_norm_squared, ksi_Delta_i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284c734b",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d8dd008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_linear(S_1, S_2):\n",
    "    return S_1 - S_2**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7e87dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def run_federated_simulation_linear(previous_server_cnn, server_cnn, client_cnns, federated_dataset,\n",
    "                                   num_epochs, theta, epoch_fda_steps):\n",
    "    \n",
    "    print(\"retracing linear\")\n",
    "    \n",
    "    total_rounds = 0\n",
    "    total_fda_steps = 0\n",
    "    \n",
    "    round_fda_steps = tf.constant(0, shape=(), dtype=tf.int32)\n",
    "    epoch_count = tf.constant(0, shape=(), dtype=tf.int32)\n",
    "    \n",
    "    S_1 = tf.constant(0., shape=(), dtype=tf.float32)\n",
    "    S_2 = tf.constant(0., shape=(), dtype=tf.float32)\n",
    "    \n",
    "    while epoch_count < num_epochs:\n",
    "        \n",
    "        while F_linear(S_1, S_2) <= theta:\n",
    "            euc_norm_squared_clients = []\n",
    "            ksi_delta_clients = []\n",
    "\n",
    "            # client steps (number depends on `federated_dataset`, i.e., `.take(num)`)\n",
    "            for client_cnn, client_dataset in zip(client_cnns, federated_dataset):\n",
    "                Delta_i_euc_norm_squared, ksi_Delta_i = steps_linear(\n",
    "                    previous_server_cnn, server_cnn, client_cnn, client_dataset\n",
    "                )\n",
    "                \n",
    "                euc_norm_squared_clients.append(Delta_i_euc_norm_squared)\n",
    "                ksi_delta_clients.append(ksi_Delta_i)\n",
    "            \n",
    "            S_1 = tf.reduce_mean(euc_norm_squared_clients)\n",
    "            S_2 = tf.reduce_mean(ksi_delta_clients)\n",
    "            \n",
    "            round_fda_steps += 1\n",
    "            total_fda_steps += 1\n",
    "            \n",
    "            if round_fda_steps == epoch_fda_steps:\n",
    "                epoch_count += 1\n",
    "                round_fda_steps = tf.constant(0, shape=(), dtype=tf.int32)\n",
    "                \n",
    "                if epoch_count == num_epochs:\n",
    "                    break\n",
    "        \n",
    "        \n",
    "        \"\"\"------------------------------test--------------------------------------------\"\"\"\n",
    "        Delta_i_clients = [\n",
    "            tf.subtract(client_cnn.trainable_vars_as_vector(), server_cnn.trainable_vars_as_vector()) \n",
    "            for client_cnn in client_cnns\n",
    "        ] #test\n",
    "        actual_S_2 = tf.reduce_sum(tf.square(tf.reduce_mean(Delta_i_clients, axis=0))) #test\n",
    "        \"\"\"------------------------------test--------------------------------------------\"\"\"\n",
    "        \n",
    "        # last server model (previous sync)\n",
    "        previous_server_cnn.set_trainable_variables(server_cnn.trainable_variables)\n",
    "        \n",
    "        # server average\n",
    "        server_cnn.set_trainable_variables(average_client_weights(client_cnns))\n",
    "        \n",
    "        \n",
    "        \"\"\"------------------------------test--------------------------------------------\"\"\"\n",
    "        tf.print(\"Linear Epoch count: \", epoch_count, \" Total fda steps: \", total_fda_steps, output_stream=sys.stdout)\n",
    "        tf.print(\"Est var: \", F_linear(S_1, S_2), \" Actual S_2: \", actual_S_2, \" Approx S_2: \", S_2**2, \" Actual var: \", variance(client_cnns, server_cnn), output_stream=sys.stdout)\n",
    "        tf.print(\"\\n\", output_stream=sys.stdout)\n",
    "        \"\"\"------------------------------test--------------------------------------------\"\"\"\n",
    "        \n",
    "        # reset variance approx\n",
    "        S_1 = tf.constant(0., shape=(), dtype=tf.float32)\n",
    "        S_2 = tf.constant(0., shape=(), dtype=tf.float32)\n",
    "\n",
    "        # synchronize clients\n",
    "        for client_cnn in client_cnns:\n",
    "            client_cnn.set_trainable_variables(server_cnn.trainable_variables)\n",
    "            \n",
    "        total_rounds += 1\n",
    "    \n",
    "    return total_rounds, total_fda_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b28f1a",
   "metadata": {},
   "source": [
    "## 3️⃣ Sketch FDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3a6434",
   "metadata": {},
   "source": [
    "An optimal estimator for $ \\lVert \\overline{\\Delta_t} \\rVert_2^2  $ can be obtained by employing AMS sketches. An AMS sketch of a vector $ v \\in \\mathbb{R}^M $ is a $ d \\times m $ real matrix\n",
    "\n",
    "$$ \\Xi = \\text{sk}(v) = \\begin{bmatrix}\n",
    "           \\Xi_1 \\\\\n",
    "           \\Xi_2 \\\\\n",
    "           \\vdots \\\\\n",
    "           \\Xi_d \n",
    "         \\end{bmatrix} $$\n",
    "         \n",
    "where $ d \\cdot m \\ll M$. Operator sk($ \\cdot $) is linear, i.e., let $a, b \\in \\mathbb{R}$ and $v_1, v_2 \\in \\mathbb{R}^N$ then \n",
    "\n",
    "$$ \\text{sk}(a v_1 + b v_2) = a \\; \\text{sk}(v_1) + b \\; \\text{sk}(v_2)  $$\n",
    "\n",
    "Also, sk($ v $) can be computed in $ \\mathcal{O}(dN) $ steps.\n",
    "\n",
    "The interesting property of AMS sketches is that the function \n",
    "\n",
    "$$ M(sk(\\textbf{v})) = \\underset{i=1,...,d}{\\text{median}} \\; \\lVert \\boldsymbol{\\Xi}_i \\rVert_2^2  $$ \n",
    "\n",
    "is an excellent estimator of the Euclidean norm of **v** (within relative $\\epsilon$-error):\n",
    "\n",
    "$$ M(sk(\\textbf{v})) \\; \\in (1 \\pm \\epsilon) \\lVert \\textbf{v} \\rVert_2^2 \\; \\; \\text{with probability at least} \\; (1-\\delta) $$\n",
    "\n",
    "where $m = \\mathcal{O}(\\frac{1}{\\epsilon^2})$ and $d = \\mathcal{O}(\\log \\frac{1}{\\delta})$\n",
    "            \n",
    "Moreover, let $\\boldsymbol{\\Xi} \\in \\mathbb{R}^{d \\times m}$ and $ k \\in \\mathbb{R}$. It can be proven that\n",
    "\n",
    "$$ M( \\frac{1}{k} \\boldsymbol{\\Xi}) = \\frac{1}{k^2} M(\\boldsymbol{\\Xi}) $$\n",
    "\n",
    "Let's investigate a little further on how this helps us. The $i$-th client computes $ sk(\\Delta_t^{(i)}) $ and sends it to the server. Notice\n",
    "\n",
    "$$ M\\big(sk(\\Delta_t^{(1)}) + sk(\\Delta_t^{(2)}) + ... + sk(\\Delta_t^{(k)}) \\big) = M\\Big( \\text{sk}\\big( \\sum_{i=1}^{k} \\Delta_t^{(i)} \\big) \\Big)$$\n",
    "\n",
    "Remember that\n",
    "\n",
    "$$ \\overline{\\boldsymbol{\\Delta}}_t = \\frac{1}{k} \\sum_{i=1}^{k} \\boldsymbol{\\Delta}_t^{(i)} $$\n",
    "\n",
    "Then\n",
    "            \n",
    "$$ M\\Big( \\text{sk}\\big( \\overline{\\boldsymbol{\\Delta}}_t \\big) \\Big) = M\\Big( \\text{sk}\\big( \\frac{1}{k} \\sum_{i=1}^{k} \\boldsymbol{\\Delta}_t^{(i)} \\big) \\Big) = \\frac{1}{k^2} M\\Big( \\text{sk}\\big( \\sum_{i=1}^{k} \\boldsymbol{\\Delta}_t^{(i)} \\big) \\Big) $$\n",
    "\n",
    "\n",
    "Which means that \n",
    "\n",
    "$$ \\frac{1}{k^2} M\\Big( \\text{sk}\\big( \\sum_{i=1}^{k} \\boldsymbol{\\Delta}_t^{(i)} \\big) \\Big) \\in (1 \\pm \\epsilon) \\lVert \\overline{\\boldsymbol{\\Delta}}_t \\rVert_2^2 \\; \\; \\text{w.p. at least} \\; (1-\\delta) $$\n",
    "\n",
    "In the monitoring process it is essential that we do not overestimate $ \\lVert \\overline{\\Delta_t} \\rVert_2^2 $ because we would then underestimate the variance which would potentially result in actual varience exceeding $ \\Theta$ without us noticing it. With this in mind,\n",
    "\n",
    "$$ \\frac{1}{k^2} M\\Big( \\text{sk}\\big( \\sum_{i=1}^{k} \\Delta_t^{(i)} \\big) \\Big) \\leq (1+\\epsilon) \\lVert \\overline{\\Delta_t} \\rVert_2^2 \\quad \\text{with probability at least} \\; (1-\\delta)$$\n",
    "\n",
    "Which means\n",
    "\n",
    "$$ \\frac{1}{(1+\\epsilon)} \\frac{1}{k^2} M\\Big( \\text{sk}\\big( \\sum_{i=1}^{k} \\Delta_t^{(i)} \\big) \\Big) \\leq \\lVert \\overline{\\Delta_t} \\rVert_2^2 \\quad \\text{with probability at least} \\; (1-\\delta)$$\n",
    "\n",
    "Hence, the Server's estimation of $ \\lVert \\overline{\\Delta_t} \\rVert_2^2 $ is\n",
    "\n",
    "$$ \\frac{1}{(1+\\epsilon)} \\frac{1}{k^2} M\\Big( sk(\\Delta_t^{(1)}) + sk(\\Delta_t^{(2)}) + ... + sk(\\Delta_t^{(k)}) \\big) \\Big) $$\n",
    "\n",
    "Define the local state to be \n",
    "\n",
    "$$ S_i(t) = \\begin{bmatrix}\n",
    "           \\lVert \\Delta_t^{(i)} \\rVert_2^2 \\\\\n",
    "           sk(\\Delta_t^{(i)})\n",
    "         \\end{bmatrix} \\in \\mathbb{R}^{1+d \\times m} \\quad \\text{and} \\quad\n",
    "         F(\\begin{bmatrix}\n",
    "           v \\\\\n",
    "           \\Xi\n",
    "         \\end{bmatrix}) = v - \\frac{1}{(1+\\epsilon)}  M(\\Xi) \\quad \\text{where} \\quad \\Xi = \\frac{1}{k} \\sum_{i=1}^{k} sk(\\Delta_t^{(i)}) $$\n",
    "\n",
    "It follows that $ F(S(t)) \\leq \\Theta $ implies that the variance is less or equal to $ \\Theta $ with probability at least $ 1-\\delta $.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db738526",
   "metadata": {},
   "source": [
    "## AMS sketch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94e3bfa",
   "metadata": {},
   "source": [
    "We use `ExtensionType` which is the way to go in order to avoid unecessary graph retracing when passing around `AmsSketch` type 'objects'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7f6b404",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.experimental import ExtensionType\n",
    "\n",
    "class AmsSketch(ExtensionType):\n",
    "    depth: int\n",
    "    width: int\n",
    "    F: tf.Tensor\n",
    "        \n",
    "        \n",
    "    def __init__(self, depth=7, width=1500):\n",
    "        self.depth = depth\n",
    "        self.width = width\n",
    "        self.F = tf.random.uniform(shape=(6, depth), minval=0, maxval=(1 << 31) - 1, dtype=tf.int32)\n",
    "\n",
    "        \n",
    "    @tf.function\n",
    "    def hash31(self, x, a, b):\n",
    "\n",
    "        r = a * x + b\n",
    "        fold = tf.bitwise.bitwise_xor(tf.bitwise.right_shift(r, 31), r)\n",
    "        return tf.bitwise.bitwise_and(fold, 2147483647)\n",
    "    \n",
    "    \n",
    "    @tf.function\n",
    "    def tensor_hash31(self, x, a, b): # GOOD\n",
    "        \"\"\" Assumed that x is tensor shaped (d,) , i.e., a vector (for example, indices, i.e., tf.range(d)) \"\"\"\n",
    "\n",
    "        # Reshape x to have an extra dimension, resulting in a shape of (k, 1)\n",
    "        x_reshaped = tf.expand_dims(x, axis=-1)\n",
    "\n",
    "        # shape=(`v_dim`, 7)\n",
    "        r = tf.multiply(a, x_reshaped) + b\n",
    "\n",
    "        fold = tf.bitwise.bitwise_xor(tf.bitwise.right_shift(r, 31), r)\n",
    "        \n",
    "        return tf.bitwise.bitwise_and(fold, 2147483647)\n",
    "    \n",
    "    \n",
    "    @tf.function\n",
    "    def tensor_fourwise(self, x):\n",
    "        \"\"\" Assumed that x is tensor shaped (d,) , i.e., a vector (for example, indices, i.e., tf.range(d)) \"\"\"\n",
    "        # 1st use the tensor hash31\n",
    "        in1 = self.tensor_hash31(x, self.F[2], self.F[3])  # (`x_dim`, 7)\n",
    "        \n",
    "        # 2nd (notice we swap the first two params, no change really)\n",
    "        in2 = self.tensor_hash31(x, in1, self.F[4])  # (`x_dim`, 7)\n",
    "        \n",
    "        in3 = self.tensor_hash31(x, in2, self.F[5])  # (`x_dim`, 7)\n",
    "        \n",
    "        in4 = tf.bitwise.bitwise_and(in3, 32768)  # (`x_dim`, 7)\n",
    "        \n",
    "        return 2 * (tf.bitwise.right_shift(in4, 15)) - 1  # (`x_dim`, 7)\n",
    "        \n",
    "        \n",
    "    @tf.function\n",
    "    def fourwise(self, x):\n",
    "\n",
    "        result = 2 * (tf.bitwise.right_shift(tf.bitwise.bitwise_and(self.hash31(self.hash31(self.hash31(x, self.F[2], self.F[3]), x, self.F[4]), x, self.F[5]), 32768), 15)) - 1\n",
    "        return result\n",
    "    \n",
    "    \n",
    "    @tf.function\n",
    "    def sketch_for_vector(self, v):\n",
    "        \"\"\" Extremely efficient computation of sketch with only using tensors. \"\"\"\n",
    "        \n",
    "        sketch = tf.zeros(shape=(self.depth, self.width), dtype=tf.float32)\n",
    "        \n",
    "        len_v = v.shape[0]\n",
    "        \n",
    "        pos_tensor = self.tensor_hash31(tf.range(len_v), self.F[0], self.F[1]) % self.width\n",
    "        \n",
    "        v_expand = tf.expand_dims(v, axis=-1)\n",
    "        \n",
    "        deltas_tensor = tf.multiply(tf.cast(self.tensor_fourwise(tf.range(len_v)), dtype=tf.float32), v_expand)\n",
    "        \n",
    "        range_tensor = tf.range(self.depth)\n",
    "        \n",
    "        # Expand dimensions to create a 2D tensor with shape (1, depth)\n",
    "        range_tensor_expanded = tf.expand_dims(range_tensor, 0)\n",
    "\n",
    "        # Use tf.tile to repeat the range `len_v` times\n",
    "        repeated_range_tensor = tf.tile(range_tensor_expanded, [len_v, 1])\n",
    "        \n",
    "        # shape=(`len_v`, 7, 2)\n",
    "        indices = tf.stack([repeated_range_tensor, pos_tensor], axis=-1)\n",
    "        \n",
    "        sketch = tf.tensor_scatter_nd_add(sketch, indices, deltas_tensor)\n",
    "        \n",
    "        return sketch\n",
    "    \n",
    "    \n",
    "    @tf.function\n",
    "    def sketch_for_vector2(self, v):\n",
    "        \"\"\" Bad implementation for tensorflow. \"\"\"\n",
    "\n",
    "        sketch = tf.zeros(shape=(self.depth, self.width), dtype=tf.float32)\n",
    "\n",
    "        for i in tf.range(tf.shape(v)[0], dtype=tf.int32):\n",
    "            pos = self.hash31(i, self.F[0], self.F[1]) % self.width\n",
    "            delta = tf.cast(self.fourwise(i), dtype=tf.float32) * v[i]\n",
    "            indices_to_update = tf.stack([tf.range(self.depth, dtype=tf.int32), pos], axis=1)\n",
    "            sketch = tf.tensor_scatter_nd_add(sketch, indices_to_update, delta)\n",
    "\n",
    "        return sketch\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    @tf.function\n",
    "    def estimate_euc_norm_squared(sketch):\n",
    "\n",
    "        @tf.function\n",
    "        def _median(v):\n",
    "            \"\"\" Median of tensor `v` with shape=(n,). Note: Suboptimal O(nlogn) but it's ok bcz n = `depth`\"\"\"\n",
    "            length = tf.shape(v)[0]\n",
    "            sorted_v = tf.sort(v)\n",
    "            middle = length // 2\n",
    "\n",
    "            return tf.cond(\n",
    "                tf.equal(length % 2, 0),\n",
    "                lambda: (sorted_v[middle - 1] + sorted_v[middle]) / 2.0,\n",
    "                lambda: sorted_v[middle]\n",
    "            )\n",
    "\n",
    "        return _median(tf.reduce_sum(tf.square(sketch), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe92e3b",
   "metadata": {},
   "source": [
    "### Client Steps\n",
    "\n",
    "The number of steps depends on the dataset, i.e., `.take(num)` call on `tf.data.Dataset` creation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "34a74388",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def steps_sketch(last_sync_cnn, client_cnn, client_dataset, ams_sketch):\n",
    "    # number of steps depend on `.take()` from `dataset`\n",
    "    client_cnn.train(client_dataset)\n",
    "    \n",
    "    Delta_i = client_cnn.trainable_vars_as_vector() - last_sync_cnn.trainable_vars_as_vector()\n",
    "    \n",
    "    #||D(t)_i||^2 , shape = (1,) \n",
    "    Delta_i_euc_norm_squared = tf.reduce_sum(tf.square(Delta_i)) # ||D(t)_i||^2\n",
    "    \n",
    "    # sketch approx\n",
    "    sketch = ams_sketch.sketch_for_vector(Delta_i)\n",
    "    \n",
    "    return Delta_i_euc_norm_squared, sketch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556ba6cf",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6b0043a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_sketch(S_1, S_2, epsilon):\n",
    "    \"\"\" `S_1` is mean || ||^2 as usual, S_2 is the `Ξ` as defined in the theoretical analysis above \"\"\"\n",
    "    \n",
    "    return S_1 - (1. / (1. + epsilon)) * AmsSketch.estimate_euc_norm_squared(S_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd3e3ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t(S_2, epsilon):\n",
    "    \n",
    "    return (1. / (1. + epsilon)) * AmsSketch.estimate_euc_norm_squared(S_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b9f520f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def run_federated_simulation_sketch(server_cnn, client_cnns, federated_dataset, num_epochs, \n",
    "                                    theta, epoch_fda_steps, ams_sketch, epsilon):\n",
    "    \n",
    "    print(\"retracing sketch\")\n",
    "    \n",
    "    total_rounds = 0\n",
    "    total_fda_steps = 0\n",
    "    \n",
    "    round_fda_steps = tf.constant(0, shape=(), dtype=tf.int32)\n",
    "    epoch_count = tf.constant(0, shape=(), dtype=tf.int32)\n",
    "    \n",
    "    S_1 = tf.constant(0., shape=(), dtype=tf.float32)\n",
    "    S_2 = tf.zeros(shape=(ams_sketch.depth, ams_sketch.width), dtype=tf.float32)\n",
    "    \n",
    "    while epoch_count < num_epochs:\n",
    "        \n",
    "        while F_sketch(S_1, S_2, epsilon) <= theta:\n",
    "            euc_norm_squared_clients = []\n",
    "            sketch_clients = []\n",
    "\n",
    "            # client steps (number depends on `federated_dataset`, i.e., `.take(num)`)\n",
    "            for client_cnn, client_dataset in zip(client_cnns, federated_dataset):\n",
    "                Delta_i_euc_norm_squared, sketch = steps_sketch(\n",
    "                    server_cnn, client_cnn, client_dataset, ams_sketch\n",
    "                )\n",
    "                \n",
    "                euc_norm_squared_clients.append(Delta_i_euc_norm_squared)\n",
    "                sketch_clients.append(sketch)\n",
    "            \n",
    "            S_1 = tf.reduce_mean(euc_norm_squared_clients)\n",
    "            S_2 = tf.reduce_mean(sketch_clients, axis=0)  # shape=(`depth`, width`). See `Ξ` in theoretical analysis\n",
    "            \n",
    "            round_fda_steps += 1\n",
    "            total_fda_steps += 1\n",
    "            \n",
    "            if round_fda_steps == epoch_fda_steps:\n",
    "                epoch_count += 1\n",
    "                round_fda_steps = tf.constant(0, shape=(), dtype=tf.int32)\n",
    "                \n",
    "                if epoch_count == num_epochs:\n",
    "                    break\n",
    "        \n",
    "        \n",
    "        \"\"\"------------------------------test--------------------------------------------\"\"\"\n",
    "        Delta_i_clients = [\n",
    "            tf.subtract(client_cnn.trainable_vars_as_vector(), server_cnn.trainable_vars_as_vector()) \n",
    "            for client_cnn in client_cnns\n",
    "        ] #test\n",
    "        actual_S_2 = tf.reduce_sum(tf.square(tf.reduce_mean(Delta_i_clients, axis=0))) #test\n",
    "        \"\"\"------------------------------test--------------------------------------------\"\"\"\n",
    "        \n",
    "        # server average\n",
    "        server_cnn.set_trainable_variables(average_client_weights(client_cnns))\n",
    "        \n",
    "        \"\"\"------------------------------test--------------------------------------------\"\"\"\n",
    "        tf.print(\"Sketch Epoch count: \", epoch_count, \" Total fda steps: \", total_fda_steps, output_stream=sys.stdout)\n",
    "        #tf.print(\"Naive Epoch count: \", epoch_count, output_stream=sys.stdout)\n",
    "        tf.print(\"Est var: \", F_sketch(S_1, S_2, epsilon), \" Actual S_2: \", actual_S_2, \" Apprxo S_2\", t(S_2, epsilon),  \" Actual var: \", variance(client_cnns, server_cnn), output_stream=sys.stdout)\n",
    "        tf.print(\"\\n\", output_stream=sys.stdout)\n",
    "        \"\"\"------------------------------test--------------------------------------------\"\"\"\n",
    "        \n",
    "        # reset variance approx\n",
    "        S_1 = tf.constant(0., shape=(), dtype=tf.float32)\n",
    "        S_2 = tf.zeros(shape=(ams_sketch.depth, ams_sketch.width), dtype=tf.float32)\n",
    "\n",
    "        # synchronize clients\n",
    "        for client_cnn in client_cnns:\n",
    "            client_cnn.set_trainable_variables(server_cnn.trainable_variables)\n",
    "            \n",
    "        total_rounds += 1\n",
    "    \n",
    "    return total_rounds, total_fda_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d998e29",
   "metadata": {},
   "source": [
    "# Simulation tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615142b0",
   "metadata": {},
   "source": [
    "###  Basic test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "94d94680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_test(server_cnn, client_cnns, previous_server_cnn, starting_trainable_variables, \n",
    "               NUM_EPOCHS, NUM_STEPS_UNTIL_RTC_CHECK, NUM_CLIENTS, BATCH_SIZE, \n",
    "               THETA, EPSILON, ams_sketch, client_slices_train, seed):\n",
    "    \n",
    "    \"\"\" One test for Naive,Linear,Sketch. Returns metrics \"\"\"\n",
    "    \n",
    "    num_epochs = tf.constant(NUM_EPOCHS, shape=(), dtype=tf.int32)\n",
    "    theta = tf.constant(THETA, shape=(), dtype=tf.float32)\n",
    "    \n",
    "    # for sketch\n",
    "    epsilon = tf.constant(EPSILON, shape=(), dtype=tf.float32) # new\n",
    "    \n",
    "    \n",
    "    epoch_client_batches = (n_train / BATCH_SIZE) / NUM_CLIENTS\n",
    "    epoch_max_fda_steps = epoch_client_batches / NUM_STEPS_UNTIL_RTC_CHECK\n",
    "    epoch_max_fda_steps = tf.constant(int(epoch_max_fda_steps), shape=(), dtype=tf.int32)\n",
    "    \n",
    "    basic_test_metrics = []\n",
    "    \n",
    "    \"\"\" --------------- Naive ----------------------------------\"\"\"\n",
    "    \n",
    "    print(server_cnn.trainable_variables)\n",
    "    print(client_cnns[0].trainable_variables)\n",
    "    \n",
    "    # 1. tf.data.Dataset (we create it again because we want determinism)\n",
    "\n",
    "    federated_dataset = create_federated_data(\n",
    "        client_slices_train=client_slices_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle_buffer_size=int(n_train/NUM_CLIENTS),\n",
    "        num_steps_until_rtc_check=NUM_STEPS_UNTIL_RTC_CHECK,\n",
    "        seed=seed\n",
    "    )\n",
    "\n",
    "    # 2. Run \n",
    "\n",
    "    total_rounds, total_fda_steps = run_federated_simulation_naive(\n",
    "        server_cnn, \n",
    "        client_cnns, \n",
    "        federated_dataset, \n",
    "        num_epochs, \n",
    "        theta,\n",
    "        epoch_max_fda_steps\n",
    "    )\n",
    "    \n",
    "    # 3. compute metrics\n",
    "    \n",
    "    _, acc = server_cnn.evaluate(test_dataset, verbose=0)\n",
    "\n",
    "    metrics = create_metrics_dict(\n",
    "        fda_name=\"naive\", \n",
    "        n_train=n_train, \n",
    "        dataset_name=\"EMNIST\", \n",
    "        input_pixels=784, \n",
    "        seed=seed, \n",
    "        epochs=NUM_EPOCHS, \n",
    "        num_clients=NUM_CLIENTS, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        steps_in_one_fda_step=NUM_STEPS_UNTIL_RTC_CHECK, \n",
    "        theta=THETA, \n",
    "        total_fda_steps=total_fda_steps.numpy(),\n",
    "        num_weights=count_weights(server_cnn),\n",
    "        total_rounds=total_rounds.numpy(), \n",
    "        final_accuracy=acc, \n",
    "        sketch_width=None, \n",
    "        sketch_depth=None\n",
    "    )\n",
    "    \n",
    "    basic_test_metrics.append(metrics)\n",
    "\n",
    "    del federated_dataset, total_rounds, total_fda_steps, acc\n",
    "    \n",
    "    # 4. IMPORTAND: Reset to the starting state all models\n",
    "    reset_trainable_variables(server_cnn, client_cnns, starting_trainable_variables)\n",
    "    \n",
    "    \n",
    "    \"\"\" --------------- Linear ----------------------------------\"\"\"\n",
    "    \n",
    "    print(server_cnn.trainable_variables)\n",
    "    print(client_cnns[0].trainable_variables)\n",
    "\n",
    "    # 1. tf.data.Dataset (we create it again because we want determinism)\n",
    "\n",
    "    federated_dataset = create_federated_data(\n",
    "        client_slices_train=client_slices_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle_buffer_size=int(n_train/NUM_CLIENTS),\n",
    "        num_steps_until_rtc_check=NUM_STEPS_UNTIL_RTC_CHECK,\n",
    "        seed=seed\n",
    "    )\n",
    "\n",
    "    # 3. Run \n",
    "\n",
    "    total_rounds, total_fda_steps = run_federated_simulation_linear(\n",
    "        previous_server_cnn,\n",
    "        server_cnn, \n",
    "        client_cnns, \n",
    "        federated_dataset, \n",
    "        num_epochs, \n",
    "        theta,\n",
    "        epoch_max_fda_steps\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # 4. compute metrics\n",
    "    \n",
    "    loss, acc = server_cnn.evaluate(test_dataset, verbose=0)\n",
    "\n",
    "    metrics = create_metrics_dict(\n",
    "        fda_name=\"linear\", \n",
    "        n_train=n_train, \n",
    "        dataset_name=\"EMNIST\", \n",
    "        input_pixels=784, \n",
    "        seed=seed, \n",
    "        epochs=NUM_EPOCHS, \n",
    "        num_clients=NUM_CLIENTS, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        steps_in_one_fda_step=NUM_STEPS_UNTIL_RTC_CHECK, \n",
    "        theta=THETA, \n",
    "        total_fda_steps=total_fda_steps.numpy(),\n",
    "        num_weights=count_weights(server_cnn),\n",
    "        total_rounds=total_rounds.numpy(), \n",
    "        final_accuracy=acc, \n",
    "        sketch_width=None, \n",
    "        sketch_depth=None\n",
    "    )\n",
    "    \n",
    "    basic_test_metrics.append(metrics)\n",
    "\n",
    "    del federated_dataset, total_rounds, total_fda_steps, acc\n",
    "    \n",
    "    # 4. IMPORTAND: Reset to the starting state all models\n",
    "    reset_trainable_variables(server_cnn, client_cnns, starting_trainable_variables)\n",
    "    \n",
    "    previous_server_cnn.set_trainable_variables(starting_trainable_variables)  # +\n",
    "\n",
    "    \n",
    "    \"\"\" ------------------------ Sketch ----------------------\"\"\"\n",
    "    \n",
    "    print(server_cnn.trainable_variables)\n",
    "    print(client_cnns[0].trainable_variables)\n",
    "    \n",
    "    # 1. tf.data.Dataset (we create it again because we want determinism)\n",
    "    \n",
    "    federated_dataset = create_federated_data(\n",
    "        client_slices_train=client_slices_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle_buffer_size=int(n_train/NUM_CLIENTS),\n",
    "        num_steps_until_rtc_check=NUM_STEPS_UNTIL_RTC_CHECK,\n",
    "        seed=seed\n",
    "    )\n",
    "\n",
    "    # 2. Run \n",
    "\n",
    "    total_rounds, total_fda_steps = run_federated_simulation_sketch(\n",
    "        server_cnn=server_cnn, \n",
    "        client_cnns=client_cnns, \n",
    "        federated_dataset=federated_dataset,\n",
    "        num_epochs=num_epochs, \n",
    "        theta=theta, \n",
    "        epoch_fda_steps=epoch_max_fda_steps, \n",
    "        ams_sketch=ams_sketch, \n",
    "        epsilon=epsilon\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # 3. compute metrics\n",
    "    \n",
    "    loss, acc = server_cnn.evaluate(test_dataset, verbose=0)\n",
    "\n",
    "    metrics = create_metrics_dict(\n",
    "        fda_name=\"sketch\", \n",
    "        n_train=n_train, \n",
    "        dataset_name=\"EMNIST\", \n",
    "        input_pixels=784, \n",
    "        seed=seed, \n",
    "        epochs=NUM_EPOCHS, \n",
    "        num_clients=NUM_CLIENTS, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        steps_in_one_fda_step=NUM_STEPS_UNTIL_RTC_CHECK, \n",
    "        theta=THETA, \n",
    "        total_fda_steps=total_fda_steps.numpy(),\n",
    "        num_weights=count_weights(server_cnn),\n",
    "        total_rounds=total_rounds.numpy(), \n",
    "        final_accuracy=acc, \n",
    "        sketch_width=ams_sketch.width, \n",
    "        sketch_depth=ams_sketch.depth\n",
    "    )\n",
    "    \n",
    "    basic_test_metrics.append(metrics)\n",
    "\n",
    "    del federated_dataset, total_rounds, total_fda_steps, acc\n",
    "    \n",
    "    # 4. IMPORTAND: Reset to the starting state all models\n",
    "    reset_trainable_variables(server_cnn, client_cnns, starting_trainable_variables)\n",
    "    \n",
    "    return basic_test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f9f94d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2f8f8877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_info_current_test(NUM_EPOCHS, NUM_STEPS_UNTIL_RTC_CHECK, NUM_CLIENTS, THETA, BATCH_SIZE):\n",
    "    print()\n",
    "    print(f\"----------- Current Test --------------\")\n",
    "    print(f\"Num Clients : {NUM_CLIENTS}\")\n",
    "    print(f\"Num Epochs : {NUM_EPOCHS}\")\n",
    "    print(f\"Number of steps until we check RTC : {NUM_STEPS_UNTIL_RTC_CHECK}\")\n",
    "    print(f\"Batch size : {BATCH_SIZE}\")\n",
    "    print(f\"Theta : {THETA}\")\n",
    "    print(\"----------------------------------------\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b2078c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt # new\n",
    "from copy import deepcopy\n",
    "\n",
    "def run_tests(NUM_CLIENTS_LIST, NUM_EPOCHS_LIST, NUM_STEPS_UNTIL_RTC_CHECK_LIST,\n",
    "              BATCH_SIZE_LIST, THETA_LIST, SKETCH_DEPTH, SKETCH_WIDTH, SEED=None):\n",
    "    \n",
    "    \"\"\" --------------- Fixed configurations -------------------\"\"\"\n",
    "\n",
    "    ams_sketch = AmsSketch(\n",
    "        depth=SKETCH_DEPTH,\n",
    "        width=SKETCH_WIDTH\n",
    "    )\n",
    "\n",
    "    EPSILON = 1. / sqrt(SKETCH_WIDTH)\n",
    "    \n",
    "    \n",
    "    \"\"\" --------------- Metrics list ----------------------\"\"\"\n",
    "    \n",
    "    all_metrics = []\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        \"\"\" --------------- Run tests -------------------\"\"\"\n",
    "        for NUM_CLIENTS in NUM_CLIENTS_LIST:\n",
    "            \n",
    "            client_slices_train = create_data_for_clients(NUM_CLIENTS)  # new sliced dataset (diff NUM_CLIENTS)\n",
    "            \n",
    "            # we will create the CNNs here to avoid graph retracing (we will keep the same starting variables)\n",
    "            server_cnn = get_compiled_and_built_advanced_cnn()\n",
    "            client_cnns = [get_compiled_and_built_advanced_cnn() for _ in range(NUM_CLIENTS)]\n",
    "            \n",
    "            previous_server_cnn = get_compiled_and_built_advanced_cnn()  # For linear\n",
    "            \n",
    "            # synchronize\n",
    "            synchronize(server_cnn, client_cnns)\n",
    "            \n",
    "            # keep the same starting variables in each test corresponding to the same `NUM_CLIENTS`\n",
    "            starting_trainable_variables = deepcopy(server_cnn.trainable_variables)\n",
    "            \n",
    "            previous_server_cnn.set_trainable_variables(starting_trainable_variables)  # For linear\n",
    "            \n",
    "            for NUM_EPOCHS in NUM_EPOCHS_LIST:\n",
    "                \n",
    "                for NUM_STEPS_UNTIL_RTC_CHECK in NUM_STEPS_UNTIL_RTC_CHECK_LIST:\n",
    "                    \n",
    "                    for BATCH_SIZE in BATCH_SIZE_LIST:\n",
    "                        \n",
    "                        for THETA in THETA_LIST:\n",
    "                            \n",
    "                            print_info_current_test(NUM_EPOCHS, NUM_STEPS_UNTIL_RTC_CHECK, NUM_CLIENTS, THETA, BATCH_SIZE)\n",
    "                            \n",
    "                            basic_test_metrics = basic_test(\n",
    "                                server_cnn=server_cnn,\n",
    "                                client_cnns=client_cnns,\n",
    "                                previous_server_cnn=previous_server_cnn,\n",
    "                                starting_trainable_variables=starting_trainable_variables,\n",
    "                                NUM_EPOCHS=NUM_EPOCHS, \n",
    "                                NUM_STEPS_UNTIL_RTC_CHECK=NUM_STEPS_UNTIL_RTC_CHECK,\n",
    "                                NUM_CLIENTS=NUM_CLIENTS,\n",
    "                                BATCH_SIZE=BATCH_SIZE, \n",
    "                                THETA=THETA, \n",
    "                                EPSILON=EPSILON,\n",
    "                                ams_sketch=ams_sketch,\n",
    "                                client_slices_train=client_slices_train,\n",
    "                                seed=SEED\n",
    "                            )\n",
    "                            \n",
    "                            all_metrics.extend(basic_test_metrics)\n",
    "            \n",
    "            # Delete previous stuff because we will encounter a different `NUM_CLIENTS`\n",
    "            del client_slices_train, server_cnn, client_cnns, previous_server_cnn, starting_trainable_variables\n",
    "            \n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"shit\")\n",
    "    \n",
    "    finally:\n",
    "        return all_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071e61e5",
   "metadata": {},
   "source": [
    "# Run Simulation Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a5b5b61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------- Current Test --------------\n",
      "Num Clients : 5\n",
      "Num Epochs : 1\n",
      "Number of steps until we check RTC : 1\n",
      "Batch size : 32\n",
      "Theta : 1.0\n",
      "----------------------------------------\n",
      "\n",
      "[<tf.Variable 'conv2d/kernel:0' shape=(3, 3, 1, 64) dtype=float32, numpy=\n",
      "array([[[[ 4.69302991e-03,  3.37426364e-03,  2.19125161e-03,\n",
      "           2.91349553e-02,  3.59704308e-02,  3.35291401e-02,\n",
      "          -1.86589058e-03, -5.22583239e-02,  2.21362524e-02,\n",
      "           2.20864527e-02, -3.31024416e-02,  3.65829915e-02,\n",
      "           1.88010447e-02, -1.93082895e-02,  2.26311311e-02,\n",
      "           3.17968288e-03,  2.87177274e-03, -1.66930053e-02,\n",
      "           5.14456145e-02, -1.63094569e-02,  9.23929922e-03,\n",
      "          -2.42445478e-03,  4.44680527e-02,  2.59505864e-02,\n",
      "           2.49891020e-02,  3.72667760e-02, -5.42905042e-03,\n",
      "           4.50321920e-02,  1.36958656e-03, -3.05980854e-02,\n",
      "           4.77468185e-02,  1.69727188e-02,  1.77619758e-03,\n",
      "          -1.99188739e-02,  3.07091810e-02,  2.04874650e-02,\n",
      "           2.19390169e-02,  5.08796796e-02, -1.71146747e-02,\n",
      "           2.98349420e-03, -1.52189638e-02,  5.16679175e-02,\n",
      "          -2.89168693e-02, -5.86817134e-03,  3.63412360e-03,\n",
      "          -1.31298285e-02, -2.78629456e-02,  3.75463925e-02,\n",
      "           4.95979413e-02, -4.23019528e-02,  3.70583534e-02,\n",
      "           9.22789890e-03, -2.82301269e-02,  1.92337781e-02,\n",
      "          -1.76793039e-02, -2.76176482e-02,  1.84574502e-03,\n",
      "          -4.30515483e-02, -4.45955507e-02, -8.96165241e-03,\n",
      "           8.15211236e-03,  1.32030500e-02,  2.49091107e-02,\n",
      "           3.94766442e-02]],\n",
      "\n",
      "        [[ 1.45616205e-02, -1.23089794e-02, -8.82542040e-03,\n",
      "          -1.40280845e-02, -2.47778352e-02,  1.63639169e-02,\n",
      "          -2.38024648e-02,  1.89477149e-02,  5.07089775e-03,\n",
      "          -2.16918942e-02, -1.83030870e-02,  1.13888830e-02,\n",
      "           1.71000436e-02, -1.99393295e-02, -7.53432512e-03,\n",
      "          -9.71188582e-03, -1.83555041e-03,  1.23756202e-02,\n",
      "           4.12984332e-03, -6.21094555e-03, -6.10662391e-03,\n",
      "           2.54831873e-02,  2.39051692e-02, -2.89049391e-02,\n",
      "           1.07440669e-02,  9.63003654e-03, -7.32476171e-03,\n",
      "           3.05531477e-03,  1.25412326e-02, -3.75757068e-02,\n",
      "           1.49495376e-03, -4.60694544e-02,  2.37678234e-02,\n",
      "          -3.81896831e-02,  4.96916473e-03, -1.11606428e-02,\n",
      "          -1.04744658e-02,  2.22350769e-02,  1.73008814e-02,\n",
      "          -2.25396012e-03,  9.13536269e-03, -8.82607233e-03,\n",
      "           3.41448411e-02, -5.37615409e-03, -1.96887963e-02,\n",
      "           2.02177502e-02,  4.84917536e-02, -6.16173167e-03,\n",
      "          -1.57577880e-02,  6.16703788e-03,  3.21167931e-02,\n",
      "           2.17581652e-02, -2.36726813e-02, -6.57048896e-02,\n",
      "          -5.10691032e-02,  2.03832276e-02, -2.97287758e-02,\n",
      "          -1.08682932e-02,  1.75594166e-02, -8.81559309e-03,\n",
      "          -3.09157670e-02, -1.53923836e-02, -3.16032693e-02,\n",
      "          -1.13144722e-02]],\n",
      "\n",
      "        [[ 8.50387197e-03,  2.40425505e-02,  7.63835292e-03,\n",
      "           2.20400542e-02, -1.29387332e-02,  2.88874172e-02,\n",
      "           5.76881040e-03, -2.07976885e-02,  3.82199064e-02,\n",
      "           1.06545556e-02,  3.22088413e-02,  2.17839070e-02,\n",
      "          -4.72020218e-03, -2.96973474e-02,  2.18057577e-02,\n",
      "           2.74818577e-02, -2.50776466e-02,  4.38850038e-02,\n",
      "          -2.04303414e-02, -2.70457268e-02,  2.19349358e-02,\n",
      "           1.87800489e-02, -1.02115003e-02, -1.41815217e-02,\n",
      "          -1.77215487e-02, -5.39975986e-02,  3.19239609e-02,\n",
      "           2.27688029e-02,  1.94193348e-02, -4.50390717e-03,\n",
      "           3.50805297e-02,  2.70072967e-02,  1.42641366e-02,\n",
      "           4.58479188e-02, -2.00699273e-04,  8.24478175e-03,\n",
      "          -5.16989008e-02, -1.90762840e-02,  2.90981177e-02,\n",
      "          -4.22064960e-03,  5.55003174e-02,  1.18892489e-03,\n",
      "           2.48052794e-02, -2.27682367e-02, -1.64160933e-02,\n",
      "          -3.61401327e-02,  4.01732922e-02, -2.89199315e-02,\n",
      "           4.51341979e-02,  8.31911527e-03,  2.28385106e-02,\n",
      "           9.17485263e-03,  1.42809032e-02,  2.77326349e-02,\n",
      "          -4.04833965e-02, -2.42071738e-03, -1.60024054e-02,\n",
      "          -2.62197864e-04,  8.57737847e-03, -4.58840989e-02,\n",
      "           1.39872879e-02, -4.37512714e-03,  5.36342375e-02,\n",
      "          -3.76154343e-03]]],\n",
      "\n",
      "\n",
      "       [[[-2.20133364e-03,  2.14545317e-02,  8.12655408e-03,\n",
      "          -2.19603516e-02,  2.73521487e-02, -7.20425248e-02,\n",
      "          -1.03813168e-02, -1.05949845e-02,  1.50047019e-02,\n",
      "           1.82605870e-02,  3.06408890e-02, -7.18349079e-03,\n",
      "          -1.24238823e-02,  6.28684741e-03, -1.63150541e-02,\n",
      "          -2.97569036e-02, -1.48355961e-04,  2.86485367e-02,\n",
      "           1.82602536e-02, -2.05290671e-02, -3.79407629e-02,\n",
      "          -2.54582651e-02,  4.20209840e-02,  5.83024183e-03,\n",
      "          -1.27243344e-02, -2.81695016e-02,  1.58032551e-02,\n",
      "           1.71110407e-02, -5.83288958e-03, -1.52904633e-02,\n",
      "          -6.55713666e-04, -2.96408199e-02,  3.44042070e-02,\n",
      "           3.47739495e-02, -2.30946131e-02, -3.50896269e-02,\n",
      "           1.84950624e-02, -1.04874074e-02, -6.25170162e-03,\n",
      "          -3.51443812e-02,  3.55142504e-02,  3.54961529e-02,\n",
      "           1.56817585e-02, -1.16126332e-02,  1.97999012e-02,\n",
      "           8.75438564e-03,  9.87303443e-03, -1.18035153e-02,\n",
      "           4.80689108e-02, -2.92890426e-02, -4.86439243e-02,\n",
      "          -4.41905968e-02, -2.29487307e-02,  3.99327502e-02,\n",
      "          -1.22015197e-02, -1.66862719e-02,  2.02293415e-02,\n",
      "          -1.77608393e-02, -1.32857878e-02, -1.89205371e-02,\n",
      "           3.82489641e-03, -3.15900184e-02, -3.32585573e-02,\n",
      "          -6.19566161e-03]],\n",
      "\n",
      "        [[-1.69845130e-02, -3.81657071e-02, -7.58720655e-03,\n",
      "           6.01498261e-02, -1.28172161e-02,  2.57162750e-03,\n",
      "           1.02623925e-02,  5.37205152e-02, -2.21458655e-02,\n",
      "          -2.72223055e-02,  2.21963059e-02, -2.08401345e-02,\n",
      "          -2.07621837e-03, -1.70091148e-02,  4.81749065e-02,\n",
      "          -4.15209830e-02, -3.27673778e-02,  2.87764277e-02,\n",
      "          -3.67776528e-02, -2.37760413e-02, -5.74703980e-03,\n",
      "          -1.43245105e-02,  2.78493725e-02, -6.21105656e-02,\n",
      "           1.19250072e-02,  1.56397987e-02,  2.34346688e-02,\n",
      "           3.88577580e-03, -7.71688810e-03,  3.28904465e-02,\n",
      "           2.67630033e-02, -4.04948462e-03,  5.44559881e-02,\n",
      "          -3.79709564e-02,  2.84216795e-02, -8.35509133e-03,\n",
      "          -2.32551619e-02,  2.60891262e-02, -1.33115454e-02,\n",
      "           1.31897088e-02,  1.47014111e-03,  7.55098183e-03,\n",
      "          -2.34918389e-02, -5.67182759e-03,  3.16367075e-02,\n",
      "           3.41646895e-02, -4.85566258e-02,  1.37538034e-02,\n",
      "          -5.62999733e-02,  6.08482817e-03,  2.25926824e-02,\n",
      "          -4.02651448e-03,  4.23353352e-02, -1.52538922e-02,\n",
      "           5.23217432e-02,  1.29320640e-02, -2.14086333e-03,\n",
      "          -6.61191810e-03,  2.27920897e-02,  1.15568982e-02,\n",
      "           1.29006873e-03,  6.21112287e-02, -1.32004367e-02,\n",
      "           2.60376371e-02]],\n",
      "\n",
      "        [[-1.29096885e-03, -4.86694649e-02, -4.03821394e-02,\n",
      "           1.39086274e-02, -1.93936117e-02, -4.26079631e-02,\n",
      "          -2.10104994e-02,  1.20487334e-02,  2.27260832e-02,\n",
      "          -3.60210985e-02, -1.19510945e-02,  5.55340061e-03,\n",
      "           3.62254418e-02,  2.54225433e-02, -2.00416110e-02,\n",
      "          -1.66004151e-02, -2.59591197e-03, -5.32943476e-03,\n",
      "          -1.13600190e-03, -6.79054717e-03, -3.10645215e-02,\n",
      "           9.28256381e-03, -1.57538208e-03,  1.88953187e-02,\n",
      "          -2.02346332e-02,  1.90278329e-02,  2.72330288e-02,\n",
      "          -2.43678205e-02,  8.87750066e-04, -2.47933697e-02,\n",
      "          -2.62972452e-02,  8.86332802e-03, -4.36784737e-02,\n",
      "          -2.65162997e-02,  8.90434254e-03,  1.19144041e-02,\n",
      "          -1.20046018e-02,  4.80996445e-02,  5.67427874e-02,\n",
      "           1.17805982e-02, -3.69768147e-03,  2.09587608e-02,\n",
      "           1.56568699e-02, -6.39659390e-02, -1.66788977e-02,\n",
      "          -1.92622729e-02,  6.77723158e-03,  2.01185653e-03,\n",
      "          -2.50990093e-02, -6.34651165e-03, -3.64954397e-02,\n",
      "           2.38137282e-02,  2.11377479e-02, -1.92195699e-02,\n",
      "           1.24313701e-02,  2.20784539e-04,  1.11806514e-02,\n",
      "           2.62219906e-02, -3.27389762e-02, -9.46105737e-03,\n",
      "          -2.04797834e-04,  1.69688947e-02, -4.08769511e-02,\n",
      "          -2.36489810e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 1.50658786e-02, -1.67859793e-02, -9.73447599e-03,\n",
      "          -1.92581583e-02,  8.78116582e-03,  2.47393246e-03,\n",
      "           1.31323691e-02,  4.43239510e-02, -3.51694077e-02,\n",
      "          -3.96518596e-02,  3.04188039e-02, -1.91871617e-02,\n",
      "          -6.48895511e-03, -3.08867749e-02, -5.51305711e-03,\n",
      "           8.70955735e-03, -1.02732182e-02,  1.78851634e-02,\n",
      "          -7.25005288e-03,  1.17081227e-02,  1.39763895e-02,\n",
      "           2.14620568e-02, -4.25374229e-03, -4.89892550e-02,\n",
      "          -5.60026010e-03,  2.20259614e-02,  1.90650262e-02,\n",
      "          -3.53529379e-02,  5.59007004e-02,  4.06744592e-02,\n",
      "           2.09713615e-02, -1.01905540e-02, -3.08042653e-02,\n",
      "           5.87631650e-02, -8.55806458e-04, -3.61257009e-02,\n",
      "           2.79527064e-02, -5.02914414e-02,  1.12394216e-02,\n",
      "           3.08075659e-02, -1.55430455e-02, -8.63420218e-03,\n",
      "           4.64576259e-02,  1.64304860e-02,  2.38798317e-02,\n",
      "          -3.89487632e-02,  2.42998935e-02, -4.66911644e-02,\n",
      "          -2.92278677e-02,  1.01588508e-02,  1.51568800e-02,\n",
      "          -3.36516574e-02, -2.21385043e-02, -2.18664315e-02,\n",
      "           3.38985436e-02,  2.09571142e-02,  6.46830350e-02,\n",
      "          -2.77479435e-03, -3.00884852e-03, -2.74872966e-02,\n",
      "          -8.93198140e-03, -1.66806802e-02,  2.34966371e-02,\n",
      "          -6.57104328e-03]],\n",
      "\n",
      "        [[-5.29452451e-02,  3.27528231e-02,  1.37223082e-03,\n",
      "          -3.19681764e-02, -5.14595583e-02, -6.32667262e-03,\n",
      "           5.41162631e-03, -1.85893308e-02,  1.13373622e-02,\n",
      "          -1.40797789e-03, -2.52241977e-02, -1.52368369e-02,\n",
      "           3.59482393e-02,  3.20400968e-02,  2.80946936e-03,\n",
      "          -2.27898024e-02,  1.91187430e-02,  3.03474423e-02,\n",
      "          -2.33284980e-02,  2.89409943e-02,  4.18077921e-03,\n",
      "           9.89397801e-03,  2.70920899e-02, -2.57372446e-02,\n",
      "          -4.74079736e-02,  1.22420648e-02,  3.19793820e-03,\n",
      "           1.85223855e-02, -1.69679783e-02,  5.86442370e-03,\n",
      "          -2.80498024e-02,  2.66606696e-02, -1.65463984e-03,\n",
      "          -8.94371141e-03, -3.68729085e-02,  2.74632368e-02,\n",
      "          -6.06720336e-02,  2.94769816e-02,  2.38269567e-05,\n",
      "           2.20094305e-02, -1.10853631e-02,  1.08918538e-02,\n",
      "           2.76126321e-02,  2.92046368e-03,  3.99905071e-02,\n",
      "           3.07704862e-02, -2.00590100e-02, -3.37166227e-02,\n",
      "           9.77098197e-03, -2.13173442e-02,  2.55870167e-02,\n",
      "           6.71831239e-03,  4.37166877e-02,  2.56980956e-02,\n",
      "           6.26422986e-02,  2.21089236e-02,  7.50459591e-03,\n",
      "           1.00820493e-02,  5.35349473e-02,  1.67291071e-02,\n",
      "          -2.94776633e-03, -4.23559546e-03,  3.26085463e-02,\n",
      "           2.49902271e-02]],\n",
      "\n",
      "        [[-1.71672869e-02,  2.68797521e-02, -2.72791591e-02,\n",
      "           4.64619249e-02,  2.69329734e-02,  2.23206002e-02,\n",
      "          -3.13342586e-02, -8.62600189e-03, -8.89792386e-03,\n",
      "           1.16631882e-02, -2.86546350e-03, -1.44477729e-02,\n",
      "           1.86275097e-03, -3.73945083e-03, -9.91139561e-03,\n",
      "           3.76042239e-02, -3.68952230e-02, -1.10306563e-02,\n",
      "           1.11948512e-02, -2.43955571e-02,  1.19361933e-02,\n",
      "          -2.00244784e-02,  2.61176135e-02, -3.20081562e-02,\n",
      "           3.49515378e-02,  3.13971052e-03,  3.48241851e-02,\n",
      "           3.73520143e-02,  4.84465584e-02,  1.79359913e-02,\n",
      "          -2.52514891e-02, -2.04734467e-02, -5.80106191e-02,\n",
      "          -1.11750066e-02, -3.45726162e-02, -1.70980319e-02,\n",
      "           2.43619690e-03,  9.55495052e-03, -2.44033779e-03,\n",
      "           3.63815054e-02,  2.67209802e-02,  2.15208810e-02,\n",
      "          -3.80503982e-02, -2.57798731e-02, -7.38425693e-03,\n",
      "          -2.04436146e-02,  5.72240958e-03,  3.36777456e-02,\n",
      "          -8.46002903e-03,  2.96797454e-02, -3.41828279e-02,\n",
      "          -4.68987674e-02,  1.96480900e-02,  5.09140734e-03,\n",
      "          -4.87036519e-02, -4.57877070e-02,  2.15520207e-02,\n",
      "           2.51700822e-02, -1.21161221e-02, -2.17158571e-02,\n",
      "          -3.01249623e-02, -1.44311786e-02, -5.24827130e-02,\n",
      "           2.09250711e-02]]]], dtype=float32)>, <tf.Variable 'conv2d/bias:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_1/kernel:0' shape=(3, 3, 64, 64) dtype=float32, numpy=\n",
      "array([[[[-1.69850569e-02,  2.16152016e-02,  3.28819044e-02, ...,\n",
      "          -1.57125052e-02, -3.36524704e-03, -4.09010425e-03],\n",
      "         [ 1.94126628e-02,  2.23356392e-02,  1.11600626e-02, ...,\n",
      "           6.66557346e-03, -5.62341372e-03,  9.31390096e-03],\n",
      "         [ 1.22247105e-02, -4.57744021e-03, -8.40049994e-04, ...,\n",
      "          -7.05706095e-03, -1.23524349e-02,  1.59517732e-02],\n",
      "         ...,\n",
      "         [ 2.64575686e-02,  1.70402229e-02,  1.28663925e-03, ...,\n",
      "           1.52844237e-02, -2.73575485e-02, -5.31145954e-04],\n",
      "         [ 4.05106619e-02,  8.81491578e-04, -1.08619984e-02, ...,\n",
      "          -2.32946016e-02, -1.94030441e-02, -8.15188326e-03],\n",
      "         [ 3.88534777e-02,  1.48940738e-02, -6.43774122e-03, ...,\n",
      "          -4.46374435e-03,  1.29817603e-02, -4.59266361e-03]],\n",
      "\n",
      "        [[-1.09307487e-02,  2.97727529e-02, -1.60785522e-02, ...,\n",
      "           9.89721157e-03, -4.77863476e-02, -1.16056744e-02],\n",
      "         [ 1.18100932e-02, -1.44465063e-02,  3.78657989e-02, ...,\n",
      "           4.39077541e-02, -6.91653928e-03,  4.27437568e-04],\n",
      "         [-5.75515907e-03,  1.76963471e-02,  2.81221326e-02, ...,\n",
      "           1.92463808e-02, -3.63918766e-03, -1.55910654e-02],\n",
      "         ...,\n",
      "         [-6.03428204e-03,  3.69359292e-02,  8.33700690e-03, ...,\n",
      "           5.78445848e-03,  4.04897965e-02,  2.57515870e-02],\n",
      "         [-2.09015850e-02,  9.45067033e-03,  1.67844985e-02, ...,\n",
      "          -4.13524220e-03,  2.65175197e-02,  2.71505123e-04],\n",
      "         [ 1.50609780e-02, -1.10825803e-02,  1.64174121e-02, ...,\n",
      "          -3.48542109e-02,  8.50073062e-03,  3.39857861e-02]],\n",
      "\n",
      "        [[-2.38746703e-02,  5.07535180e-03,  1.53692607e-02, ...,\n",
      "          -2.86570545e-02, -4.79030004e-03, -1.66585036e-02],\n",
      "         [-2.58522835e-02,  4.02647480e-02,  1.19532403e-02, ...,\n",
      "           1.70220602e-02,  2.78580189e-02,  4.29326290e-04],\n",
      "         [-4.46624542e-03, -1.67056359e-02,  1.20201092e-02, ...,\n",
      "          -4.17647883e-02,  2.39368603e-02,  3.56783345e-03],\n",
      "         ...,\n",
      "         [ 1.50896851e-02, -1.46195050e-02, -9.68745537e-03, ...,\n",
      "          -3.62509079e-02, -1.54748037e-02,  1.28558706e-02],\n",
      "         [ 2.08518635e-02, -1.41218929e-02, -1.60360634e-02, ...,\n",
      "          -2.72144489e-02, -2.92835087e-02,  2.91578472e-03],\n",
      "         [ 5.08023193e-03,  2.59717647e-02,  9.98698175e-03, ...,\n",
      "           2.49626450e-02,  3.93901253e-03,  1.98825784e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 9.37853940e-03, -2.50575319e-03, -1.78423394e-02, ...,\n",
      "          -3.75556163e-02,  1.50928367e-02, -1.02587265e-03],\n",
      "         [ 1.94024555e-02, -2.13303454e-02,  1.46425888e-02, ...,\n",
      "           2.34427974e-02,  2.17647990e-03, -3.31790820e-02],\n",
      "         [-7.54719507e-03, -4.78929188e-03, -7.57849496e-03, ...,\n",
      "           1.93845835e-02,  1.79364756e-02, -2.91001052e-02],\n",
      "         ...,\n",
      "         [-6.51289010e-03, -3.90158668e-02,  6.71462948e-03, ...,\n",
      "           1.94849353e-02, -6.60773832e-03, -8.78054928e-03],\n",
      "         [-1.27951801e-03, -4.61115222e-03, -5.32317907e-03, ...,\n",
      "           2.05590744e-02, -4.60475404e-03,  8.12095217e-03],\n",
      "         [-1.39441760e-02, -8.73556919e-03,  3.28896269e-02, ...,\n",
      "          -9.76466853e-03,  6.98370486e-03,  9.91995679e-04]],\n",
      "\n",
      "        [[ 1.13808392e-02, -2.09359191e-02,  3.83511148e-02, ...,\n",
      "           2.22321060e-02, -6.60886103e-03, -9.38955136e-03],\n",
      "         [ 4.71547656e-02, -6.62237435e-05, -6.49598613e-03, ...,\n",
      "           8.83513875e-03, -3.32988724e-02, -4.92197201e-02],\n",
      "         [-1.53132882e-02,  1.97858997e-02,  4.32632789e-02, ...,\n",
      "           8.35526921e-03, -1.06816245e-02, -8.23764596e-03],\n",
      "         ...,\n",
      "         [-6.68884069e-03,  5.03375661e-03,  2.55866945e-02, ...,\n",
      "          -1.48515776e-02, -6.79572811e-03, -1.64656900e-02],\n",
      "         [-1.22060033e-03, -2.45148912e-02,  1.02544092e-02, ...,\n",
      "           2.20892057e-02,  9.66365624e-04,  1.31071229e-02],\n",
      "         [-1.76311471e-02, -7.03729410e-03, -5.00715524e-03, ...,\n",
      "           2.81815771e-02,  1.68325659e-02, -3.81556302e-02]],\n",
      "\n",
      "        [[ 5.45228133e-03, -2.33304803e-03,  8.01392645e-03, ...,\n",
      "           5.22822281e-03,  9.17952694e-03,  1.27571579e-02],\n",
      "         [-6.46798592e-03, -1.42398300e-02,  1.21846925e-02, ...,\n",
      "          -3.39199826e-02,  9.28250886e-03, -1.53786692e-04],\n",
      "         [-1.64849160e-03,  2.19238047e-02,  1.67245232e-02, ...,\n",
      "          -3.27327917e-03,  1.98165933e-03,  1.94125620e-04],\n",
      "         ...,\n",
      "         [ 1.35729928e-02,  1.43849757e-02,  1.49786444e-02, ...,\n",
      "           8.84048361e-03, -3.36682908e-02,  4.78931256e-02],\n",
      "         [ 1.58846583e-02,  1.27267446e-02, -6.06256723e-03, ...,\n",
      "          -7.04374164e-03, -1.69550683e-02, -9.15747695e-03],\n",
      "         [ 1.52276205e-02,  2.70652883e-02,  1.54992891e-02, ...,\n",
      "           2.63607558e-02, -3.12110782e-02,  6.64010132e-03]]],\n",
      "\n",
      "\n",
      "       [[[ 5.10488823e-03,  1.79123096e-02, -1.95949227e-02, ...,\n",
      "          -8.75240285e-03, -2.25773314e-03, -2.35780180e-02],\n",
      "         [ 9.82910395e-04,  4.91259694e-02,  1.36077954e-02, ...,\n",
      "           3.57949510e-02, -3.90230827e-02,  1.35598928e-02],\n",
      "         [-1.62457824e-02,  2.78448015e-02,  7.24801444e-04, ...,\n",
      "          -1.47506250e-02,  1.93487853e-02, -3.21812145e-02],\n",
      "         ...,\n",
      "         [-1.29894940e-02, -2.89646778e-02,  7.15948036e-03, ...,\n",
      "           1.01401219e-02, -1.52206477e-02,  4.56305873e-03],\n",
      "         [-2.22396366e-02,  5.38704405e-03, -1.21123847e-02, ...,\n",
      "          -4.75738803e-03, -2.86845112e-04,  2.80545210e-03],\n",
      "         [-1.94492098e-02,  1.03651267e-02, -3.34172547e-02, ...,\n",
      "           5.92973316e-03,  1.87476054e-02, -1.75679363e-02]],\n",
      "\n",
      "        [[-7.86799937e-03, -2.90167816e-02,  3.32715139e-02, ...,\n",
      "           2.85675190e-02, -9.77609027e-03,  3.10400184e-02],\n",
      "         [-5.04170218e-03,  1.81888603e-02,  2.60965042e-02, ...,\n",
      "           2.60967463e-02, -9.08930041e-03,  9.08349641e-03],\n",
      "         [ 2.03069095e-02, -8.32101679e-04,  9.96956136e-03, ...,\n",
      "          -6.66226912e-03, -6.45001093e-03, -7.98114575e-03],\n",
      "         ...,\n",
      "         [ 1.61897726e-02,  9.97016113e-03,  7.67929200e-03, ...,\n",
      "           9.66314692e-03, -1.18881371e-02, -1.68536045e-02],\n",
      "         [ 2.46886462e-02, -4.84808441e-03,  3.32496986e-02, ...,\n",
      "          -3.00695300e-02,  1.86591689e-02, -2.99551301e-02],\n",
      "         [ 7.76787009e-03,  8.24970193e-03, -2.56463746e-03, ...,\n",
      "           6.22381875e-03, -1.78587530e-02,  1.80397239e-02]],\n",
      "\n",
      "        [[ 1.33872908e-02,  2.52852030e-02,  1.48601411e-02, ...,\n",
      "           1.91329177e-02,  2.05226578e-02,  1.48636270e-02],\n",
      "         [-1.76627878e-02,  2.20409478e-03,  1.14264889e-02, ...,\n",
      "           8.34738929e-03,  5.79036307e-03, -3.83756831e-02],\n",
      "         [ 2.34152786e-02, -2.60076532e-03,  3.76201351e-03, ...,\n",
      "          -2.42514722e-02, -6.18040576e-05, -8.37149471e-03],\n",
      "         ...,\n",
      "         [-1.05627328e-02,  1.69750787e-02,  7.54204532e-03, ...,\n",
      "           8.28418043e-03, -3.30608562e-02, -1.06123835e-02],\n",
      "         [-1.43872877e-03,  2.06616186e-02, -7.09084934e-03, ...,\n",
      "          -9.78706754e-04,  1.47251384e-02, -3.29769701e-02],\n",
      "         [ 1.72545086e-03,  2.33011991e-02, -1.32815186e-02, ...,\n",
      "          -1.40164467e-02,  2.17350069e-02,  5.80837065e-03]]]],\n",
      "      dtype=float32)>, <tf.Variable 'conv2d_1/bias:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_2/kernel:0' shape=(3, 3, 64, 128) dtype=float32, numpy=\n",
      "array([[[[ 1.55330421e-02,  7.89451133e-03,  2.22818796e-02, ...,\n",
      "          -3.99999693e-02,  1.00090671e-02,  2.43939157e-03],\n",
      "         [-3.10924258e-02, -1.33896247e-03,  1.00174118e-02, ...,\n",
      "          -8.84863641e-03, -3.97674646e-03,  1.10548073e-02],\n",
      "         [ 3.22904587e-02,  2.64930539e-02,  2.55429232e-03, ...,\n",
      "           2.38227542e-03,  2.60648187e-02,  9.08928085e-03],\n",
      "         ...,\n",
      "         [ 6.78988779e-03,  1.05358800e-02,  1.00721652e-02, ...,\n",
      "           8.99709761e-03,  1.63136981e-02, -7.33500812e-03],\n",
      "         [ 6.52481895e-03,  8.18916596e-03, -1.06267231e-02, ...,\n",
      "           1.15938787e-03,  6.69015199e-03,  8.00969731e-03],\n",
      "         [-7.73361465e-03, -1.53583828e-02, -1.26190661e-02, ...,\n",
      "           4.98951320e-03, -6.21584803e-03, -7.31204078e-03]],\n",
      "\n",
      "        [[-6.52625319e-03,  2.44503878e-02,  3.25109065e-03, ...,\n",
      "          -2.06250735e-02, -2.14925669e-02, -1.70768388e-02],\n",
      "         [ 7.82414060e-03,  1.40224490e-02, -1.20769106e-02, ...,\n",
      "           1.85488425e-02, -1.61821954e-02,  1.11016873e-02],\n",
      "         [-7.49591272e-03,  2.30836831e-02,  1.91182345e-02, ...,\n",
      "          -1.18307043e-02, -1.65702160e-02, -2.64782831e-03],\n",
      "         ...,\n",
      "         [-8.53101723e-03, -8.27609934e-03, -2.24090228e-03, ...,\n",
      "          -2.65822629e-03, -6.37788605e-03,  1.64830463e-03],\n",
      "         [-2.22959742e-03, -2.22323127e-02, -1.34892911e-02, ...,\n",
      "          -2.61538918e-03, -1.08894678e-02,  1.53158847e-02],\n",
      "         [-1.05845416e-02,  3.14284628e-03,  3.50863184e-03, ...,\n",
      "           1.94895489e-03, -1.68387108e-02,  2.44591385e-03]],\n",
      "\n",
      "        [[ 1.12561164e-02, -1.28767546e-02,  4.32431418e-03, ...,\n",
      "           2.57600658e-02, -2.98897419e-02,  1.87297799e-02],\n",
      "         [ 3.01338043e-02, -1.06937746e-02, -1.16586573e-02, ...,\n",
      "          -1.76433567e-02, -1.67626832e-02,  5.62294852e-03],\n",
      "         [ 4.05890215e-03,  1.01597663e-02,  3.74460667e-02, ...,\n",
      "          -9.22768551e-04, -3.37960944e-03, -1.67161524e-02],\n",
      "         ...,\n",
      "         [-3.15651158e-03,  8.77177902e-03,  9.71664302e-03, ...,\n",
      "          -1.51728769e-03, -5.67375263e-03, -3.56440470e-02],\n",
      "         [ 1.42511504e-03,  1.19914557e-03, -2.38386095e-02, ...,\n",
      "          -1.08856037e-02,  2.65703863e-03,  2.94418074e-02],\n",
      "         [ 1.07071381e-02, -1.81518085e-02, -4.50878823e-03, ...,\n",
      "          -1.20623317e-02, -9.52990167e-03,  2.86848005e-02]]],\n",
      "\n",
      "\n",
      "       [[[-1.87078547e-02, -6.71662251e-03, -8.74501094e-03, ...,\n",
      "           1.34501401e-02, -7.66675407e-03, -2.75039859e-02],\n",
      "         [ 1.04156639e-02, -2.70463079e-02,  3.38356085e-02, ...,\n",
      "          -6.84137736e-03, -8.89361277e-03, -9.75291710e-03],\n",
      "         [ 2.61676172e-03, -2.02119555e-02,  3.13913682e-03, ...,\n",
      "           1.99225303e-02,  2.59274244e-03,  1.61882062e-02],\n",
      "         ...,\n",
      "         [ 8.45706463e-03,  4.46811598e-03,  1.66599303e-02, ...,\n",
      "          -8.32779612e-03, -8.86786077e-03,  4.81734201e-02],\n",
      "         [ 3.29195475e-03,  6.31361175e-03,  6.04124274e-03, ...,\n",
      "          -1.10916030e-02, -1.05503965e-02,  1.98821048e-03],\n",
      "         [-1.68613009e-02,  2.46153399e-03,  8.96189641e-03, ...,\n",
      "           7.69274402e-03,  1.88778900e-02,  1.51297543e-02]],\n",
      "\n",
      "        [[ 1.33698282e-03, -2.43066810e-02, -2.94080307e-03, ...,\n",
      "          -7.50820618e-03,  2.67277956e-02, -5.11210132e-03],\n",
      "         [ 8.22935067e-03, -9.85523313e-03,  1.06211854e-02, ...,\n",
      "          -1.02260597e-02, -5.31843584e-03,  1.39407841e-02],\n",
      "         [-1.03483181e-02,  3.51361744e-02,  1.98557228e-02, ...,\n",
      "           4.87762678e-04, -5.36764180e-03,  5.07651502e-03],\n",
      "         ...,\n",
      "         [-4.09573726e-02,  1.43650714e-02, -2.24402850e-03, ...,\n",
      "           9.59959812e-03, -1.38064791e-02, -2.54108217e-02],\n",
      "         [-1.04426285e-02, -2.53118128e-02,  1.25362230e-02, ...,\n",
      "          -1.29782204e-02, -3.39892507e-03,  2.71982737e-02],\n",
      "         [ 1.70690082e-02, -1.84821002e-02,  1.70294885e-02, ...,\n",
      "          -7.28274113e-04, -9.58769000e-04, -2.05956027e-02]],\n",
      "\n",
      "        [[-1.15437973e-02,  5.33303153e-03,  2.69346833e-02, ...,\n",
      "           9.16972384e-03, -2.72847852e-03, -1.49986078e-03],\n",
      "         [-4.05243691e-03,  1.35285258e-02,  4.32128087e-02, ...,\n",
      "          -6.66610867e-05,  9.69690853e-04, -1.93567201e-03],\n",
      "         [ 2.54871398e-02, -8.39985348e-03, -7.34409178e-03, ...,\n",
      "          -1.09228340e-03, -1.23642702e-02,  1.26066562e-02],\n",
      "         ...,\n",
      "         [-2.23232917e-02, -1.02953222e-02,  2.59150621e-02, ...,\n",
      "          -2.29381733e-02, -7.36157584e-04, -2.50203605e-03],\n",
      "         [ 6.85013074e-04,  1.79236531e-02, -1.75429769e-02, ...,\n",
      "           6.00036990e-04, -1.08053011e-03, -1.93282068e-02],\n",
      "         [ 1.56154428e-02, -1.23550592e-03, -2.10529119e-02, ...,\n",
      "          -1.99366584e-02, -2.15538889e-02,  6.27811253e-03]]],\n",
      "\n",
      "\n",
      "       [[[ 1.75101943e-02, -1.64017864e-02, -2.86753173e-03, ...,\n",
      "          -8.60185828e-03,  4.47496101e-02, -2.16487981e-02],\n",
      "         [-1.10108219e-02, -9.19451378e-03, -2.42652372e-03, ...,\n",
      "           2.11245473e-02,  1.60501450e-02, -1.09475963e-02],\n",
      "         [ 9.94091202e-03,  1.81345083e-02,  1.64808333e-03, ...,\n",
      "           5.93491178e-03, -3.41981277e-02, -8.62089824e-03],\n",
      "         ...,\n",
      "         [ 2.44263709e-02,  1.67198486e-05, -1.40694259e-02, ...,\n",
      "          -8.01776722e-03,  4.82632592e-03,  1.42799215e-02],\n",
      "         [-1.28195230e-02, -1.37614859e-02, -3.62128764e-03, ...,\n",
      "          -3.01843937e-02,  9.66920145e-03,  9.96930874e-04],\n",
      "         [ 1.03708068e-02,  9.54047777e-03,  2.85105174e-03, ...,\n",
      "          -3.30542140e-02,  2.28296150e-03, -8.55067559e-03]],\n",
      "\n",
      "        [[ 8.54840409e-03,  2.37155873e-02, -1.41760558e-02, ...,\n",
      "          -7.07011390e-03, -1.74430180e-02,  2.39164121e-02],\n",
      "         [-1.76514052e-02, -1.31998956e-03,  2.44448446e-02, ...,\n",
      "          -2.84587704e-02, -1.11538405e-02,  8.28811433e-03],\n",
      "         [-3.09070796e-02,  4.02639061e-03, -6.66497508e-03, ...,\n",
      "           3.99810728e-03, -3.95998359e-04, -3.03989649e-03],\n",
      "         ...,\n",
      "         [-6.30411273e-03, -3.00408900e-03,  2.19981442e-03, ...,\n",
      "          -1.07875597e-02, -1.15119051e-02, -1.19949272e-02],\n",
      "         [-5.83135104e-03,  1.65529735e-02, -9.03939479e-04, ...,\n",
      "           2.94972751e-02, -7.02255964e-03,  5.36368182e-03],\n",
      "         [-1.56298466e-02, -1.01858182e-02, -2.78143771e-02, ...,\n",
      "           1.91304348e-02,  1.78056431e-03, -1.80921815e-02]],\n",
      "\n",
      "        [[-3.68387322e-03, -4.92543587e-03,  5.37132192e-03, ...,\n",
      "          -8.82843789e-03, -1.11225247e-02,  2.64379522e-03],\n",
      "         [ 2.30790731e-02,  1.36093618e-02, -9.55715030e-03, ...,\n",
      "           1.37783978e-02, -8.31942447e-03,  9.43226274e-03],\n",
      "         [-4.08443250e-03, -1.07486767e-03, -1.14936773e-02, ...,\n",
      "           1.42926034e-02, -3.03679649e-02, -8.16721376e-03],\n",
      "         ...,\n",
      "         [ 3.79139856e-02,  3.84526630e-03,  2.96537783e-02, ...,\n",
      "          -1.82215869e-02, -3.48568568e-03,  2.43196334e-03],\n",
      "         [ 1.76732484e-02, -2.60170642e-02,  6.03523990e-03, ...,\n",
      "          -1.61153432e-02,  4.74537583e-03, -1.39055122e-02],\n",
      "         [-4.49509686e-03,  1.87516324e-02, -8.22879001e-03, ...,\n",
      "           1.14619290e-03,  1.65395010e-02, -8.63442756e-03]]]],\n",
      "      dtype=float32)>, <tf.Variable 'conv2d_2/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_3/kernel:0' shape=(3, 3, 128, 128) dtype=float32, numpy=\n",
      "array([[[[-1.68600716e-02, -1.79312825e-02,  1.56610422e-02, ...,\n",
      "           2.33031134e-03,  2.44804751e-02,  2.02444028e-02],\n",
      "         [ 1.77019127e-02,  2.91587468e-02,  4.45633428e-03, ...,\n",
      "           1.42396810e-02, -2.89265849e-02,  4.72779619e-03],\n",
      "         [-9.21144325e-04, -9.66222584e-03, -1.04102995e-02, ...,\n",
      "          -1.47317154e-02,  1.18395685e-04, -1.08037284e-02],\n",
      "         ...,\n",
      "         [ 3.45268520e-03,  9.29052569e-03,  2.21795309e-02, ...,\n",
      "          -5.73424762e-03,  1.65490282e-03, -3.66365095e-03],\n",
      "         [-6.69058273e-03,  1.20818159e-02, -1.52439149e-02, ...,\n",
      "          -1.73150264e-02,  2.40473729e-02, -1.29415561e-02],\n",
      "         [ 4.51561064e-04,  4.78552654e-03, -9.24593210e-03, ...,\n",
      "           8.77422863e-04,  6.81729522e-03,  2.92378152e-03]],\n",
      "\n",
      "        [[-1.82376746e-02, -7.29917642e-03, -1.91094242e-02, ...,\n",
      "           4.46839537e-03, -5.85866813e-03,  1.00972280e-02],\n",
      "         [-5.54028433e-03,  1.73025206e-03,  8.59043933e-03, ...,\n",
      "           1.78645179e-02, -6.77104760e-03,  5.78062003e-03],\n",
      "         [ 1.14615110e-03, -1.93275753e-02,  4.39174986e-03, ...,\n",
      "          -1.19022722e-03, -3.63576040e-03,  1.94072220e-02],\n",
      "         ...,\n",
      "         [-2.69912332e-02, -1.98374745e-02, -3.24954093e-03, ...,\n",
      "           4.18132655e-02, -3.27313952e-02,  2.23652087e-02],\n",
      "         [-7.51773245e-04,  3.35277850e-03, -2.63632828e-04, ...,\n",
      "           3.87683138e-03,  6.72382582e-03, -2.65672244e-02],\n",
      "         [ 9.23694950e-03, -1.20849535e-02, -3.99352144e-03, ...,\n",
      "           3.12072644e-03, -1.21377083e-02,  4.39008558e-03]],\n",
      "\n",
      "        [[ 1.18882190e-02, -1.05912779e-02, -8.55815317e-03, ...,\n",
      "           1.51981013e-02, -2.72535421e-02,  3.11360415e-02],\n",
      "         [-7.90557172e-03,  5.06107276e-03,  1.29528192e-03, ...,\n",
      "           4.32946393e-03, -5.09707723e-03, -2.15586238e-02],\n",
      "         [-7.46782729e-03, -2.61854343e-02, -1.43078584e-02, ...,\n",
      "           6.80623949e-03,  1.86342876e-02,  1.66742299e-02],\n",
      "         ...,\n",
      "         [ 2.59614345e-02,  6.37450209e-03, -1.25909001e-02, ...,\n",
      "           2.95578176e-03, -1.43891303e-02,  2.10052729e-02],\n",
      "         [-3.68665904e-04,  2.17544548e-02, -2.04895623e-02, ...,\n",
      "          -4.32615727e-03,  3.06768040e-03, -1.71130407e-03],\n",
      "         [ 1.12429345e-02, -1.69592090e-02,  9.57026705e-03, ...,\n",
      "           1.12022611e-03,  1.61850359e-02,  1.44066667e-04]]],\n",
      "\n",
      "\n",
      "       [[[ 8.28434154e-03,  5.95645513e-03,  1.21646319e-02, ...,\n",
      "          -3.19344248e-03,  3.46364081e-02, -4.63093352e-03],\n",
      "         [-2.75902753e-03,  1.70640331e-02,  8.04351177e-03, ...,\n",
      "          -1.21885221e-02, -1.34093361e-02,  5.47396368e-04],\n",
      "         [-2.39504944e-03, -2.97223171e-03, -1.54845845e-02, ...,\n",
      "           1.56629458e-03,  2.39671953e-03,  9.32943821e-03],\n",
      "         ...,\n",
      "         [ 7.52308685e-03, -2.45563239e-02,  1.15194349e-02, ...,\n",
      "           5.93533274e-03,  3.96983046e-03, -4.12434340e-04],\n",
      "         [ 1.49836782e-02,  1.61951897e-03,  2.38039419e-02, ...,\n",
      "          -1.01086637e-02, -1.01220282e-02, -2.57146396e-02],\n",
      "         [ 2.86382623e-02, -1.38390334e-02,  3.32710594e-02, ...,\n",
      "          -1.89913996e-02, -2.04573832e-02, -1.52477650e-02]],\n",
      "\n",
      "        [[-2.23263865e-03, -4.92641353e-04,  4.48024040e-03, ...,\n",
      "           8.49423185e-03, -1.71311870e-02, -1.33621292e-02],\n",
      "         [ 4.64720000e-03,  1.81475189e-02,  8.09995085e-03, ...,\n",
      "           1.83497481e-02, -9.22507327e-03, -1.20283784e-02],\n",
      "         [ 6.16327673e-03, -1.38403922e-02,  3.31444293e-03, ...,\n",
      "          -2.12481758e-03, -2.00286886e-04,  2.26665474e-02],\n",
      "         ...,\n",
      "         [-9.41476785e-03,  5.95694408e-03, -1.07929884e-02, ...,\n",
      "          -2.02198476e-02,  1.01543311e-02, -1.19918864e-02],\n",
      "         [-1.84496008e-02,  9.63620562e-03,  1.03705954e-02, ...,\n",
      "           2.35224515e-02,  3.15950811e-03, -2.56738849e-02],\n",
      "         [ 1.04985973e-02, -2.71488866e-03,  4.28893697e-03, ...,\n",
      "           1.93005316e-02, -2.53575225e-03, -9.28728282e-03]],\n",
      "\n",
      "        [[-2.14060349e-03, -1.11367982e-02, -1.91013403e-02, ...,\n",
      "          -5.14764199e-03,  2.13546003e-03,  3.93546978e-03],\n",
      "         [-3.26629058e-02,  1.69438329e-02, -5.83066791e-03, ...,\n",
      "          -1.20727085e-02,  3.92806763e-03, -2.65100598e-03],\n",
      "         [ 1.17076049e-02,  5.25426120e-04,  1.32288784e-02, ...,\n",
      "          -1.40965581e-02,  7.61730364e-03,  2.34908126e-02],\n",
      "         ...,\n",
      "         [ 9.61063523e-03,  1.46244112e-02, -1.46315275e-02, ...,\n",
      "          -7.72865140e-04,  1.64468624e-02,  9.12775286e-03],\n",
      "         [ 2.63083223e-02,  1.56332832e-02,  9.52444971e-05, ...,\n",
      "          -2.14055181e-04, -4.63692751e-03,  5.39174024e-03],\n",
      "         [ 1.96255185e-02,  1.00587551e-02,  5.53621259e-03, ...,\n",
      "          -2.01724712e-02,  3.03693172e-02, -8.40166956e-03]]],\n",
      "\n",
      "\n",
      "       [[[ 1.91492345e-02,  4.91146091e-03,  8.86066258e-03, ...,\n",
      "          -1.27897505e-02,  1.04346760e-02, -4.18366864e-04],\n",
      "         [-1.50846760e-03,  5.84047195e-03, -4.95833158e-03, ...,\n",
      "          -9.15053487e-03, -2.24396633e-03,  8.02232977e-03],\n",
      "         [ 8.58783815e-03,  1.14439987e-02, -2.32668081e-03, ...,\n",
      "          -2.05389336e-02,  3.60727170e-03, -2.10732082e-03],\n",
      "         ...,\n",
      "         [ 1.79432336e-05,  1.22186001e-02, -2.40476127e-03, ...,\n",
      "           2.17446387e-02, -9.24086547e-04,  2.45803781e-03],\n",
      "         [-2.25741346e-03,  1.95177253e-02, -7.28319352e-03, ...,\n",
      "           6.89894799e-03,  6.95950538e-03,  1.75596923e-02],\n",
      "         [-1.65119171e-02,  6.17762888e-03, -7.69994687e-03, ...,\n",
      "           4.36105113e-03, -6.67222124e-03, -1.52524712e-03]],\n",
      "\n",
      "        [[-2.68091774e-03,  1.14288572e-02, -1.01229547e-04, ...,\n",
      "          -2.29866989e-02, -1.39320018e-02,  1.10912481e-02],\n",
      "         [ 1.49797124e-03, -2.21974440e-02,  2.92917038e-03, ...,\n",
      "           1.95784271e-02,  8.18899181e-03,  6.90270215e-03],\n",
      "         [ 8.88831168e-03, -1.16145322e-02,  9.71318502e-03, ...,\n",
      "           2.04516854e-02,  4.83893929e-03, -1.43167973e-02],\n",
      "         ...,\n",
      "         [-4.23407927e-03,  1.46921007e-02,  6.73678378e-03, ...,\n",
      "           7.15662912e-03, -8.15077103e-04, -2.68315291e-03],\n",
      "         [-1.52547751e-02,  3.87287745e-03,  7.87371583e-03, ...,\n",
      "           1.70902424e-02,  1.18185801e-03,  7.57160014e-04],\n",
      "         [-3.62662040e-03, -3.57209891e-03,  6.09114161e-03, ...,\n",
      "           1.00606112e-02,  2.07147608e-03, -1.20693650e-02]],\n",
      "\n",
      "        [[ 5.64282294e-03, -7.02428806e-04, -2.59701423e-02, ...,\n",
      "           2.60888096e-02, -1.49183823e-02, -6.04292890e-03],\n",
      "         [ 1.95780257e-03, -2.28765290e-02, -3.21015040e-03, ...,\n",
      "           6.73468271e-03,  3.96141503e-03, -5.97986567e-04],\n",
      "         [-8.77301861e-03, -5.87994466e-03, -3.81213566e-03, ...,\n",
      "           1.68248061e-02,  2.20860355e-02, -4.78024408e-03],\n",
      "         ...,\n",
      "         [ 1.50999771e-02, -2.48276647e-02,  2.16559004e-02, ...,\n",
      "          -1.15447231e-02,  1.29404636e-02,  7.38131395e-03],\n",
      "         [ 6.81906054e-03, -1.06928358e-02,  3.39160929e-03, ...,\n",
      "          -1.27613721e-02, -1.02338810e-02, -1.33014694e-02],\n",
      "         [-2.04848349e-02,  1.13968737e-02,  6.38285885e-03, ...,\n",
      "          -5.55682788e-03, -4.83729225e-03, -2.11270386e-03]]]],\n",
      "      dtype=float32)>, <tf.Variable 'conv2d_3/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_4/kernel:0' shape=(3, 3, 128, 256) dtype=float32, numpy=\n",
      "array([[[[ 9.38101090e-04,  9.41079669e-03,  1.91091071e-03, ...,\n",
      "          -9.24799126e-03, -1.54646961e-02,  8.69168621e-03],\n",
      "         [-5.11594117e-04,  8.11659638e-03,  1.60382930e-02, ...,\n",
      "          -7.49598723e-03, -6.12122426e-03,  1.40403081e-02],\n",
      "         [ 3.06343962e-03, -1.56165604e-02,  1.78318995e-03, ...,\n",
      "           1.10988934e-02,  1.04692954e-04,  7.37054041e-03],\n",
      "         ...,\n",
      "         [ 1.29268272e-02,  1.50449695e-02,  7.36299902e-03, ...,\n",
      "           7.16500077e-03,  1.24830855e-02,  1.60094984e-02],\n",
      "         [ 6.09391183e-03, -2.83854385e-03, -1.92624088e-02, ...,\n",
      "           1.68619975e-02,  1.54019892e-02, -2.42746482e-03],\n",
      "         [ 1.04143266e-02,  6.08501816e-03,  7.35059893e-03, ...,\n",
      "          -4.50389925e-03,  4.94999904e-03, -2.39166990e-03]],\n",
      "\n",
      "        [[-5.19708556e-04,  6.92136600e-05,  1.29895331e-02, ...,\n",
      "           1.00578871e-02, -5.43782720e-03, -5.87740820e-03],\n",
      "         [-7.74383685e-03, -7.00865034e-03, -2.32416596e-02, ...,\n",
      "           4.13378095e-03,  3.34228436e-03,  1.40723586e-02],\n",
      "         [ 4.68040118e-03,  3.33214318e-03,  8.57507903e-03, ...,\n",
      "          -1.14191172e-03, -4.92405705e-03,  3.13814217e-03],\n",
      "         ...,\n",
      "         [-5.75297466e-03,  2.03895122e-02,  2.29473179e-03, ...,\n",
      "          -5.63082937e-03,  2.16440298e-02, -1.87410193e-03],\n",
      "         [-8.12007021e-03, -2.95716664e-03, -1.52364895e-02, ...,\n",
      "           6.99859113e-03,  2.99948007e-02,  1.54666533e-03],\n",
      "         [ 3.00459634e-03,  4.56618378e-03,  1.22779887e-02, ...,\n",
      "           2.00580861e-02,  1.08545516e-02, -7.09137181e-03]],\n",
      "\n",
      "        [[-8.48515145e-03, -8.07471108e-03,  1.09916497e-02, ...,\n",
      "           2.34776433e-03, -3.37706064e-03,  1.76683273e-02],\n",
      "         [-6.53252983e-03, -3.65203479e-03,  4.51303925e-03, ...,\n",
      "          -2.78949738e-05, -1.05218096e-02, -5.25709521e-03],\n",
      "         [ 2.48900112e-02,  1.10369991e-03,  9.47912131e-03, ...,\n",
      "           2.35215388e-02,  1.17893144e-02,  9.32310987e-03],\n",
      "         ...,\n",
      "         [-1.25768874e-02, -1.47429826e-02, -5.93531970e-03, ...,\n",
      "           2.50586756e-02, -3.82331753e-04,  3.19343817e-04],\n",
      "         [-5.08236978e-03, -1.37152779e-03,  1.60741284e-02, ...,\n",
      "          -2.07834356e-02,  9.79110785e-03, -1.00161200e-02],\n",
      "         [-2.13199351e-02,  2.70394608e-03,  1.47483591e-02, ...,\n",
      "          -2.06157938e-02, -1.57850869e-02, -2.91180937e-03]]],\n",
      "\n",
      "\n",
      "       [[[-9.79332603e-04,  1.09335575e-02, -4.83454112e-03, ...,\n",
      "          -1.10377120e-02, -1.71845555e-02, -1.07443165e-02],\n",
      "         [ 4.77302447e-03,  7.00547034e-03, -1.13027748e-02, ...,\n",
      "           6.63061719e-03, -2.98636779e-03,  9.53530334e-03],\n",
      "         [ 9.75708850e-03,  1.28126265e-02, -4.96906135e-03, ...,\n",
      "          -1.51046962e-02, -2.05768552e-02, -1.27679529e-02],\n",
      "         ...,\n",
      "         [ 4.54072666e-04,  1.18600931e-02, -1.18814479e-03, ...,\n",
      "          -5.28277224e-03, -1.49164768e-02,  5.91010461e-03],\n",
      "         [-1.35589959e-02,  2.69634603e-03,  6.67500484e-04, ...,\n",
      "          -3.35310842e-03, -1.03604514e-02,  1.83794107e-02],\n",
      "         [ 6.19912241e-03, -1.12663349e-02, -2.29164455e-02, ...,\n",
      "          -6.60053734e-03,  2.07998604e-03,  4.05754516e-04]],\n",
      "\n",
      "        [[-2.10388992e-02, -1.02671608e-03,  7.16996798e-03, ...,\n",
      "           1.12436274e-02, -1.14799347e-02,  1.17038656e-02],\n",
      "         [ 6.57428196e-03, -1.08385663e-02,  5.41459396e-03, ...,\n",
      "           2.89312750e-03,  5.68809966e-03,  1.56560503e-02],\n",
      "         [-9.42557864e-03, -1.52329798e-03,  1.43470075e-02, ...,\n",
      "          -7.46843591e-03,  1.39602991e-02, -9.81563982e-03],\n",
      "         ...,\n",
      "         [-5.03597502e-03, -1.69049706e-02, -5.72245917e-04, ...,\n",
      "          -1.30208135e-02,  9.54891182e-03, -1.62975187e-03],\n",
      "         [ 6.39600214e-03,  3.06906854e-03, -7.74460146e-03, ...,\n",
      "           1.07413474e-02,  2.63535287e-02,  2.15845220e-02],\n",
      "         [-1.25767263e-02,  8.34091939e-03, -5.79803949e-03, ...,\n",
      "          -6.09115325e-03,  5.83740231e-03, -9.56486538e-03]],\n",
      "\n",
      "        [[-6.89579174e-03, -1.26772700e-02,  8.24454799e-03, ...,\n",
      "           1.59133156e-03, -6.42991811e-03, -1.10219968e-02],\n",
      "         [-1.26093086e-02,  9.55381338e-03, -9.37520154e-03, ...,\n",
      "           8.46547540e-03, -4.82591335e-03, -2.80387700e-04],\n",
      "         [ 1.23221837e-02, -6.61702221e-03,  2.13298891e-02, ...,\n",
      "           2.78009480e-04, -8.69119167e-03, -2.00885739e-02],\n",
      "         ...,\n",
      "         [ 9.53424163e-03, -4.12647286e-03, -1.13452235e-02, ...,\n",
      "           1.35899484e-02, -9.82897170e-03,  1.01023000e-02],\n",
      "         [ 7.22507155e-03,  1.13505051e-02, -5.63574117e-03, ...,\n",
      "           9.24158748e-03, -7.46141002e-03,  5.45170298e-03],\n",
      "         [-1.08119939e-02, -1.25809237e-02, -4.62670636e-04, ...,\n",
      "           9.29966755e-03, -8.92106723e-03, -1.78110506e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 1.63003914e-02, -4.70378529e-03, -1.47964861e-02, ...,\n",
      "           1.89816987e-03,  2.61922192e-04, -1.22205494e-02],\n",
      "         [-1.29662780e-02,  9.19378735e-03,  1.05769001e-02, ...,\n",
      "          -5.87354368e-03, -1.21543249e-02,  2.72257114e-03],\n",
      "         [-2.20671599e-03, -8.79194122e-03,  1.18137896e-03, ...,\n",
      "           9.75729548e-04,  1.71659179e-02, -7.31177628e-04],\n",
      "         ...,\n",
      "         [-4.97732218e-03,  1.32462587e-02,  1.17739933e-02, ...,\n",
      "           1.54227521e-02, -1.26842037e-02, -1.72186680e-02],\n",
      "         [-2.04054639e-04, -9.03271697e-03, -2.02495744e-03, ...,\n",
      "          -9.15702432e-04,  1.33330477e-02,  1.11438408e-02],\n",
      "         [ 8.31623736e-04, -1.21005420e-02,  1.05486559e-02, ...,\n",
      "          -3.58647341e-03,  5.52983861e-03, -6.90472592e-03]],\n",
      "\n",
      "        [[-1.64963938e-02, -1.20757343e-02, -1.71085950e-02, ...,\n",
      "          -4.83736023e-03,  5.65790664e-03,  5.67073142e-03],\n",
      "         [-1.31628988e-02, -3.95905366e-03,  1.52005460e-02, ...,\n",
      "           1.67341735e-02, -6.16826396e-03, -3.91509384e-03],\n",
      "         [ 8.08256504e-04,  6.88067451e-03,  3.38931871e-03, ...,\n",
      "          -2.59117037e-03, -1.59210265e-02, -4.56688320e-03],\n",
      "         ...,\n",
      "         [ 1.04546193e-02,  1.87348872e-02, -1.62250327e-03, ...,\n",
      "          -1.71747734e-03,  1.39768119e-03,  2.23533739e-03],\n",
      "         [ 2.06528534e-03,  2.58926302e-04,  5.69310319e-03, ...,\n",
      "           2.32607499e-03, -7.99944904e-03, -2.28265449e-02],\n",
      "         [-6.12018537e-03, -2.44722981e-02, -3.36103654e-03, ...,\n",
      "          -1.31035866e-02,  2.17804201e-02,  2.02171244e-02]],\n",
      "\n",
      "        [[ 1.00940708e-02,  5.98998042e-03, -1.11633446e-02, ...,\n",
      "          -2.47165076e-02,  9.01285093e-03, -1.18551878e-02],\n",
      "         [-7.66188884e-03, -7.75487628e-03,  9.89340805e-03, ...,\n",
      "          -4.40504542e-03, -1.26334075e-02,  5.88859525e-03],\n",
      "         [-1.33023430e-02,  5.83989080e-03, -5.00751799e-03, ...,\n",
      "           2.29313783e-02, -6.68126345e-03, -3.03386524e-03],\n",
      "         ...,\n",
      "         [-3.43279308e-03,  3.51786101e-03,  8.70536547e-03, ...,\n",
      "           7.18047330e-03, -5.29755559e-03, -5.43724373e-03],\n",
      "         [ 7.50573492e-03,  5.74872829e-03, -5.02925599e-03, ...,\n",
      "          -1.48512777e-02, -5.57736959e-03,  6.02410594e-03],\n",
      "         [-4.98506706e-03,  1.41982231e-02, -9.13532451e-03, ...,\n",
      "           2.28011602e-04, -4.99738520e-03,  4.12441697e-03]]]],\n",
      "      dtype=float32)>, <tf.Variable 'conv2d_4/bias:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'conv2d_5/kernel:0' shape=(3, 3, 256, 256) dtype=float32, numpy=\n",
      "array([[[[ 1.54978605e-02, -3.35570099e-03,  3.21339490e-03, ...,\n",
      "           3.48461722e-03, -3.49673268e-04,  8.46261997e-03],\n",
      "         [-4.65426221e-03, -5.58018917e-03,  1.45805459e-02, ...,\n",
      "           9.60927922e-03, -4.59554780e-04, -1.13227163e-02],\n",
      "         [ 8.30768980e-03,  8.66838079e-03, -1.26637202e-02, ...,\n",
      "           7.50721386e-03, -8.72638635e-03, -4.12948430e-03],\n",
      "         ...,\n",
      "         [-1.70411100e-03,  6.89844647e-03,  1.81325118e-03, ...,\n",
      "          -4.47081495e-03,  3.20765423e-03,  2.12090090e-04],\n",
      "         [-2.05811132e-02, -1.38239879e-02, -6.24410808e-04, ...,\n",
      "          -2.08784826e-02,  1.82481222e-02, -4.51691169e-03],\n",
      "         [ 1.51515845e-02,  1.68998055e-02,  4.66944650e-03, ...,\n",
      "           5.81107521e-03,  3.98985576e-03,  1.38471951e-03]],\n",
      "\n",
      "        [[ 1.29733430e-02,  8.31148960e-03,  5.15338685e-03, ...,\n",
      "          -8.95667836e-05, -4.26856149e-03, -3.78017360e-03],\n",
      "         [-1.63108390e-02, -1.12540554e-02, -1.82563555e-03, ...,\n",
      "           4.68140980e-03,  1.03716971e-02,  1.10954417e-04],\n",
      "         [ 1.65666677e-02,  1.18814595e-02, -5.11186430e-03, ...,\n",
      "          -2.81578675e-03,  3.74475121e-03,  9.39060189e-03],\n",
      "         ...,\n",
      "         [-8.49339762e-04, -4.09149099e-03,  1.78908859e-03, ...,\n",
      "          -5.15646115e-03, -1.13775637e-02,  6.54881913e-03],\n",
      "         [ 4.27274173e-03, -9.53136105e-03,  6.64295629e-04, ...,\n",
      "           5.66878181e-04,  2.31140712e-03,  3.96688143e-03],\n",
      "         [ 5.58750238e-03,  1.16821649e-02,  9.18151462e-04, ...,\n",
      "           6.06626133e-03, -1.55816227e-02,  9.45182983e-03]],\n",
      "\n",
      "        [[ 7.05195731e-03,  9.77751240e-03,  9.16928038e-05, ...,\n",
      "           9.13357735e-03, -8.25522467e-03,  7.43757794e-03],\n",
      "         [ 7.94301927e-03, -5.94195630e-03, -1.37788430e-02, ...,\n",
      "           9.48520564e-03, -1.02477777e-03, -2.14720611e-02],\n",
      "         [ 1.12013961e-03,  5.13362873e-04,  2.79054791e-03, ...,\n",
      "          -1.19533660e-02, -2.16427147e-02, -1.29747798e-03],\n",
      "         ...,\n",
      "         [-2.02872371e-03,  1.61321852e-02, -7.36910105e-03, ...,\n",
      "           7.80271017e-04,  1.15327798e-02, -9.32691805e-03],\n",
      "         [ 1.15449203e-03,  4.64562234e-03,  1.97210517e-02, ...,\n",
      "          -4.48797643e-03, -1.00365374e-02, -4.37354017e-03],\n",
      "         [ 1.83447748e-02,  1.99716981e-03, -6.10341178e-03, ...,\n",
      "          -7.54236663e-03, -2.17134394e-02, -1.11401780e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 4.64890152e-04,  1.01167653e-02,  7.97419157e-03, ...,\n",
      "           5.94450720e-03, -5.14396559e-03,  5.79674961e-03],\n",
      "         [ 1.25558181e-02, -4.49996721e-03, -1.35061573e-02, ...,\n",
      "           8.67357757e-03,  1.00780148e-02, -2.53288588e-03],\n",
      "         [ 9.42348503e-03,  6.57224935e-03, -1.80330500e-03, ...,\n",
      "          -5.86067233e-03,  1.20491087e-02,  7.45730242e-03],\n",
      "         ...,\n",
      "         [-8.92363023e-03, -5.04188240e-04, -1.36151689e-03, ...,\n",
      "          -1.36536341e-02,  6.33844000e-04,  1.31715285e-02],\n",
      "         [-6.13968354e-03, -4.49633831e-03,  3.31261021e-04, ...,\n",
      "           6.49623107e-03,  1.48259550e-02,  7.07149785e-03],\n",
      "         [ 2.72981892e-03,  2.40530749e-03, -1.33943949e-02, ...,\n",
      "           1.07632969e-02, -6.21172367e-03, -5.87121025e-03]],\n",
      "\n",
      "        [[ 5.96655253e-03, -3.49337980e-03,  1.44751845e-02, ...,\n",
      "           6.00010948e-03, -1.54554276e-02,  8.83793365e-03],\n",
      "         [ 7.12692644e-03, -1.17023627e-03, -1.02669178e-02, ...,\n",
      "           4.60448256e-03, -4.92867921e-03, -6.00638520e-03],\n",
      "         [ 5.00132889e-03, -7.99021509e-04,  5.70593961e-03, ...,\n",
      "          -8.22449382e-03, -1.97285786e-03,  9.47370939e-03],\n",
      "         ...,\n",
      "         [ 1.12835346e-02,  8.90923385e-03, -2.83290807e-04, ...,\n",
      "          -4.24231635e-03, -7.48188421e-03, -9.80542041e-03],\n",
      "         [-9.94871138e-04,  2.71313265e-03, -1.77998433e-03, ...,\n",
      "           3.99212539e-03,  1.07628666e-02, -2.86504556e-03],\n",
      "         [-8.17846041e-03,  1.33171873e-02,  6.56141620e-03, ...,\n",
      "           8.17253906e-03,  1.03925915e-04,  1.07165016e-02]],\n",
      "\n",
      "        [[-2.84769270e-03,  5.56358509e-03,  5.82188461e-03, ...,\n",
      "           5.87398652e-03,  1.32865403e-02,  1.84360181e-03],\n",
      "         [ 3.68441129e-03, -9.93298274e-03,  1.49904517e-02, ...,\n",
      "          -1.86374467e-02, -3.71849095e-03,  2.11982522e-02],\n",
      "         [ 6.54558931e-03,  7.40765175e-03, -1.33966850e-02, ...,\n",
      "          -4.99514956e-03,  5.92611963e-03,  1.07838679e-02],\n",
      "         ...,\n",
      "         [-5.44869248e-03,  3.67517758e-04, -7.64207169e-03, ...,\n",
      "          -1.85705721e-05, -4.31761146e-03, -6.37428078e-04],\n",
      "         [-1.43301636e-02, -8.26253183e-03, -7.88924284e-03, ...,\n",
      "           2.53433292e-03,  9.18006338e-03, -9.79615725e-04],\n",
      "         [-3.19266459e-03,  6.16872823e-03,  1.94984563e-02, ...,\n",
      "          -6.77163759e-03,  1.23773841e-02, -1.83580822e-04]]],\n",
      "\n",
      "\n",
      "       [[[-6.89069182e-03,  1.03352610e-02,  1.90807544e-02, ...,\n",
      "          -1.45971030e-02, -1.00947637e-02, -7.06390664e-03],\n",
      "         [ 2.43955781e-03, -2.62899254e-03, -5.60121145e-03, ...,\n",
      "           3.80227040e-03, -1.17650917e-02,  1.07683372e-02],\n",
      "         [-1.08845076e-02,  4.42476338e-03,  7.51633104e-03, ...,\n",
      "           3.68347275e-03, -5.03756152e-03,  6.69992715e-03],\n",
      "         ...,\n",
      "         [-6.79868448e-04,  1.34946406e-02, -1.47094484e-02, ...,\n",
      "           1.84112340e-02,  3.20203602e-04, -7.31320167e-03],\n",
      "         [ 1.18899299e-02, -1.01106968e-02, -1.49023179e-02, ...,\n",
      "           1.21974200e-03, -1.41101331e-02,  1.48208928e-03],\n",
      "         [ 4.15055733e-03, -3.57180834e-04,  5.43589424e-03, ...,\n",
      "          -2.81735370e-03, -1.75350811e-02,  2.77062086e-03]],\n",
      "\n",
      "        [[-1.24111101e-02,  9.98174399e-03, -1.48280826e-03, ...,\n",
      "           1.54189020e-02, -1.13799591e-02,  1.67319481e-03],\n",
      "         [-2.42374884e-03, -6.47830497e-03,  5.53533668e-03, ...,\n",
      "           2.02362309e-03, -6.75436715e-03,  8.05855636e-03],\n",
      "         [ 4.40331409e-03, -1.92145985e-02,  4.88715898e-03, ...,\n",
      "           3.32788378e-03,  9.22324229e-03,  2.09037773e-03],\n",
      "         ...,\n",
      "         [-4.74603567e-03, -4.30747587e-03, -1.87458005e-02, ...,\n",
      "          -1.94001081e-03,  1.34209041e-02, -1.89500544e-02],\n",
      "         [ 4.25531436e-03,  4.43855673e-03,  2.04473771e-02, ...,\n",
      "          -2.05176999e-03,  6.12895796e-03, -1.48992660e-02],\n",
      "         [ 7.50545412e-03, -6.91828877e-03,  1.06430948e-02, ...,\n",
      "          -1.27789201e-02, -7.97746330e-03, -1.49650383e-03]],\n",
      "\n",
      "        [[-5.77496085e-03,  1.76816303e-02,  4.11041074e-05, ...,\n",
      "          -5.46987355e-03, -3.05958092e-05,  2.30636005e-03],\n",
      "         [ 8.12403101e-04,  4.73794620e-03, -6.74866140e-03, ...,\n",
      "          -9.56585817e-03, -8.37872736e-03,  1.54705448e-02],\n",
      "         [-3.59913940e-03, -9.20750760e-03, -1.48238731e-03, ...,\n",
      "          -4.44027130e-03,  1.04130236e-02,  7.57871056e-03],\n",
      "         ...,\n",
      "         [-1.46735432e-02,  1.80649571e-02,  1.72576234e-02, ...,\n",
      "          -2.01385515e-03, -6.82948809e-03, -1.34972651e-02],\n",
      "         [-8.40432593e-04, -2.83474801e-03,  5.18418988e-03, ...,\n",
      "           2.65499093e-02, -1.92435610e-03, -1.85556710e-05],\n",
      "         [-9.42859333e-03,  1.93015076e-02,  1.34590771e-02, ...,\n",
      "           1.13062337e-02,  3.28685204e-03, -1.25803147e-02]]]],\n",
      "      dtype=float32)>, <tf.Variable 'conv2d_5/bias:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'dense/kernel:0' shape=(2304, 512) dtype=float32, numpy=\n",
      "array([[ 0.02385678, -0.01708137, -0.01980681, ..., -0.01377731,\n",
      "        -0.01039699, -0.0184339 ],\n",
      "       [ 0.01103689,  0.01146318, -0.01172199, ...,  0.00382193,\n",
      "        -0.01237808,  0.01963927],\n",
      "       [ 0.0145363 ,  0.00121166,  0.01249356, ...,  0.01183785,\n",
      "        -0.00050989, -0.01849926],\n",
      "       ...,\n",
      "       [ 0.00687497,  0.01915836,  0.01331924, ..., -0.0280219 ,\n",
      "         0.0068067 , -0.01355464],\n",
      "       [ 0.00161706,  0.00991912,  0.01146639, ..., -0.00049773,\n",
      "         0.01187798,  0.00091365],\n",
      "       [ 0.02775753,  0.00742965,  0.0019823 , ...,  0.01172384,\n",
      "         0.00355823, -0.00359935]], dtype=float32)>, <tf.Variable 'dense/bias:0' shape=(512,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32)>, <tf.Variable 'dense_1/kernel:0' shape=(512, 512) dtype=float32, numpy=\n",
      "array([[-0.02023735, -0.00763321, -0.0138274 , ...,  0.00112092,\n",
      "        -0.02045008, -0.01703559],\n",
      "       [ 0.00960613,  0.00314439,  0.01477535, ...,  0.01999935,\n",
      "        -0.0063148 , -0.00529457],\n",
      "       [-0.01191304, -0.02159967,  0.00859792, ...,  0.02719501,\n",
      "         0.01979006,  0.02705568],\n",
      "       ...,\n",
      "       [ 0.02434819, -0.00532917, -0.03129631, ..., -0.00571337,\n",
      "        -0.00992187, -0.05179047],\n",
      "       [ 0.00296902,  0.00918856,  0.01105028, ..., -0.00010223,\n",
      "         0.02605464, -0.02978878],\n",
      "       [ 0.00143632,  0.00043027, -0.05044768, ..., -0.01034095,\n",
      "         0.01487789, -0.01073238]], dtype=float32)>, <tf.Variable 'dense_1/bias:0' shape=(512,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32)>, <tf.Variable 'dense_2/kernel:0' shape=(512, 10) dtype=float32, numpy=\n",
      "array([[ 0.01040562,  0.0189325 ,  0.00473445, ...,  0.01427844,\n",
      "         0.02012391,  0.00017488],\n",
      "       [-0.01612941, -0.01367897, -0.05753319, ...,  0.00490254,\n",
      "         0.00562195,  0.02872174],\n",
      "       [-0.01637073,  0.03274264, -0.01681058, ..., -0.04870444,\n",
      "         0.02867155,  0.01389187],\n",
      "       ...,\n",
      "       [-0.00517967, -0.02594587,  0.01534636, ..., -0.00495481,\n",
      "        -0.03358068, -0.01063015],\n",
      "       [ 0.03603722,  0.04263733, -0.00949048, ..., -0.00582884,\n",
      "        -0.03767002,  0.02827438],\n",
      "       [ 0.03534377,  0.01434573,  0.02727861, ...,  0.02735108,\n",
      "         0.00896482,  0.01441311]], dtype=float32)>, <tf.Variable 'dense_2/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]\n",
      "[<tf.Variable 'conv2d_6/kernel:0' shape=(3, 3, 1, 64) dtype=float32, numpy=\n",
      "array([[[[ 4.69302991e-03,  3.37426364e-03,  2.19125161e-03,\n",
      "           2.91349553e-02,  3.59704308e-02,  3.35291401e-02,\n",
      "          -1.86589058e-03, -5.22583239e-02,  2.21362524e-02,\n",
      "           2.20864527e-02, -3.31024416e-02,  3.65829915e-02,\n",
      "           1.88010447e-02, -1.93082895e-02,  2.26311311e-02,\n",
      "           3.17968288e-03,  2.87177274e-03, -1.66930053e-02,\n",
      "           5.14456145e-02, -1.63094569e-02,  9.23929922e-03,\n",
      "          -2.42445478e-03,  4.44680527e-02,  2.59505864e-02,\n",
      "           2.49891020e-02,  3.72667760e-02, -5.42905042e-03,\n",
      "           4.50321920e-02,  1.36958656e-03, -3.05980854e-02,\n",
      "           4.77468185e-02,  1.69727188e-02,  1.77619758e-03,\n",
      "          -1.99188739e-02,  3.07091810e-02,  2.04874650e-02,\n",
      "           2.19390169e-02,  5.08796796e-02, -1.71146747e-02,\n",
      "           2.98349420e-03, -1.52189638e-02,  5.16679175e-02,\n",
      "          -2.89168693e-02, -5.86817134e-03,  3.63412360e-03,\n",
      "          -1.31298285e-02, -2.78629456e-02,  3.75463925e-02,\n",
      "           4.95979413e-02, -4.23019528e-02,  3.70583534e-02,\n",
      "           9.22789890e-03, -2.82301269e-02,  1.92337781e-02,\n",
      "          -1.76793039e-02, -2.76176482e-02,  1.84574502e-03,\n",
      "          -4.30515483e-02, -4.45955507e-02, -8.96165241e-03,\n",
      "           8.15211236e-03,  1.32030500e-02,  2.49091107e-02,\n",
      "           3.94766442e-02]],\n",
      "\n",
      "        [[ 1.45616205e-02, -1.23089794e-02, -8.82542040e-03,\n",
      "          -1.40280845e-02, -2.47778352e-02,  1.63639169e-02,\n",
      "          -2.38024648e-02,  1.89477149e-02,  5.07089775e-03,\n",
      "          -2.16918942e-02, -1.83030870e-02,  1.13888830e-02,\n",
      "           1.71000436e-02, -1.99393295e-02, -7.53432512e-03,\n",
      "          -9.71188582e-03, -1.83555041e-03,  1.23756202e-02,\n",
      "           4.12984332e-03, -6.21094555e-03, -6.10662391e-03,\n",
      "           2.54831873e-02,  2.39051692e-02, -2.89049391e-02,\n",
      "           1.07440669e-02,  9.63003654e-03, -7.32476171e-03,\n",
      "           3.05531477e-03,  1.25412326e-02, -3.75757068e-02,\n",
      "           1.49495376e-03, -4.60694544e-02,  2.37678234e-02,\n",
      "          -3.81896831e-02,  4.96916473e-03, -1.11606428e-02,\n",
      "          -1.04744658e-02,  2.22350769e-02,  1.73008814e-02,\n",
      "          -2.25396012e-03,  9.13536269e-03, -8.82607233e-03,\n",
      "           3.41448411e-02, -5.37615409e-03, -1.96887963e-02,\n",
      "           2.02177502e-02,  4.84917536e-02, -6.16173167e-03,\n",
      "          -1.57577880e-02,  6.16703788e-03,  3.21167931e-02,\n",
      "           2.17581652e-02, -2.36726813e-02, -6.57048896e-02,\n",
      "          -5.10691032e-02,  2.03832276e-02, -2.97287758e-02,\n",
      "          -1.08682932e-02,  1.75594166e-02, -8.81559309e-03,\n",
      "          -3.09157670e-02, -1.53923836e-02, -3.16032693e-02,\n",
      "          -1.13144722e-02]],\n",
      "\n",
      "        [[ 8.50387197e-03,  2.40425505e-02,  7.63835292e-03,\n",
      "           2.20400542e-02, -1.29387332e-02,  2.88874172e-02,\n",
      "           5.76881040e-03, -2.07976885e-02,  3.82199064e-02,\n",
      "           1.06545556e-02,  3.22088413e-02,  2.17839070e-02,\n",
      "          -4.72020218e-03, -2.96973474e-02,  2.18057577e-02,\n",
      "           2.74818577e-02, -2.50776466e-02,  4.38850038e-02,\n",
      "          -2.04303414e-02, -2.70457268e-02,  2.19349358e-02,\n",
      "           1.87800489e-02, -1.02115003e-02, -1.41815217e-02,\n",
      "          -1.77215487e-02, -5.39975986e-02,  3.19239609e-02,\n",
      "           2.27688029e-02,  1.94193348e-02, -4.50390717e-03,\n",
      "           3.50805297e-02,  2.70072967e-02,  1.42641366e-02,\n",
      "           4.58479188e-02, -2.00699273e-04,  8.24478175e-03,\n",
      "          -5.16989008e-02, -1.90762840e-02,  2.90981177e-02,\n",
      "          -4.22064960e-03,  5.55003174e-02,  1.18892489e-03,\n",
      "           2.48052794e-02, -2.27682367e-02, -1.64160933e-02,\n",
      "          -3.61401327e-02,  4.01732922e-02, -2.89199315e-02,\n",
      "           4.51341979e-02,  8.31911527e-03,  2.28385106e-02,\n",
      "           9.17485263e-03,  1.42809032e-02,  2.77326349e-02,\n",
      "          -4.04833965e-02, -2.42071738e-03, -1.60024054e-02,\n",
      "          -2.62197864e-04,  8.57737847e-03, -4.58840989e-02,\n",
      "           1.39872879e-02, -4.37512714e-03,  5.36342375e-02,\n",
      "          -3.76154343e-03]]],\n",
      "\n",
      "\n",
      "       [[[-2.20133364e-03,  2.14545317e-02,  8.12655408e-03,\n",
      "          -2.19603516e-02,  2.73521487e-02, -7.20425248e-02,\n",
      "          -1.03813168e-02, -1.05949845e-02,  1.50047019e-02,\n",
      "           1.82605870e-02,  3.06408890e-02, -7.18349079e-03,\n",
      "          -1.24238823e-02,  6.28684741e-03, -1.63150541e-02,\n",
      "          -2.97569036e-02, -1.48355961e-04,  2.86485367e-02,\n",
      "           1.82602536e-02, -2.05290671e-02, -3.79407629e-02,\n",
      "          -2.54582651e-02,  4.20209840e-02,  5.83024183e-03,\n",
      "          -1.27243344e-02, -2.81695016e-02,  1.58032551e-02,\n",
      "           1.71110407e-02, -5.83288958e-03, -1.52904633e-02,\n",
      "          -6.55713666e-04, -2.96408199e-02,  3.44042070e-02,\n",
      "           3.47739495e-02, -2.30946131e-02, -3.50896269e-02,\n",
      "           1.84950624e-02, -1.04874074e-02, -6.25170162e-03,\n",
      "          -3.51443812e-02,  3.55142504e-02,  3.54961529e-02,\n",
      "           1.56817585e-02, -1.16126332e-02,  1.97999012e-02,\n",
      "           8.75438564e-03,  9.87303443e-03, -1.18035153e-02,\n",
      "           4.80689108e-02, -2.92890426e-02, -4.86439243e-02,\n",
      "          -4.41905968e-02, -2.29487307e-02,  3.99327502e-02,\n",
      "          -1.22015197e-02, -1.66862719e-02,  2.02293415e-02,\n",
      "          -1.77608393e-02, -1.32857878e-02, -1.89205371e-02,\n",
      "           3.82489641e-03, -3.15900184e-02, -3.32585573e-02,\n",
      "          -6.19566161e-03]],\n",
      "\n",
      "        [[-1.69845130e-02, -3.81657071e-02, -7.58720655e-03,\n",
      "           6.01498261e-02, -1.28172161e-02,  2.57162750e-03,\n",
      "           1.02623925e-02,  5.37205152e-02, -2.21458655e-02,\n",
      "          -2.72223055e-02,  2.21963059e-02, -2.08401345e-02,\n",
      "          -2.07621837e-03, -1.70091148e-02,  4.81749065e-02,\n",
      "          -4.15209830e-02, -3.27673778e-02,  2.87764277e-02,\n",
      "          -3.67776528e-02, -2.37760413e-02, -5.74703980e-03,\n",
      "          -1.43245105e-02,  2.78493725e-02, -6.21105656e-02,\n",
      "           1.19250072e-02,  1.56397987e-02,  2.34346688e-02,\n",
      "           3.88577580e-03, -7.71688810e-03,  3.28904465e-02,\n",
      "           2.67630033e-02, -4.04948462e-03,  5.44559881e-02,\n",
      "          -3.79709564e-02,  2.84216795e-02, -8.35509133e-03,\n",
      "          -2.32551619e-02,  2.60891262e-02, -1.33115454e-02,\n",
      "           1.31897088e-02,  1.47014111e-03,  7.55098183e-03,\n",
      "          -2.34918389e-02, -5.67182759e-03,  3.16367075e-02,\n",
      "           3.41646895e-02, -4.85566258e-02,  1.37538034e-02,\n",
      "          -5.62999733e-02,  6.08482817e-03,  2.25926824e-02,\n",
      "          -4.02651448e-03,  4.23353352e-02, -1.52538922e-02,\n",
      "           5.23217432e-02,  1.29320640e-02, -2.14086333e-03,\n",
      "          -6.61191810e-03,  2.27920897e-02,  1.15568982e-02,\n",
      "           1.29006873e-03,  6.21112287e-02, -1.32004367e-02,\n",
      "           2.60376371e-02]],\n",
      "\n",
      "        [[-1.29096885e-03, -4.86694649e-02, -4.03821394e-02,\n",
      "           1.39086274e-02, -1.93936117e-02, -4.26079631e-02,\n",
      "          -2.10104994e-02,  1.20487334e-02,  2.27260832e-02,\n",
      "          -3.60210985e-02, -1.19510945e-02,  5.55340061e-03,\n",
      "           3.62254418e-02,  2.54225433e-02, -2.00416110e-02,\n",
      "          -1.66004151e-02, -2.59591197e-03, -5.32943476e-03,\n",
      "          -1.13600190e-03, -6.79054717e-03, -3.10645215e-02,\n",
      "           9.28256381e-03, -1.57538208e-03,  1.88953187e-02,\n",
      "          -2.02346332e-02,  1.90278329e-02,  2.72330288e-02,\n",
      "          -2.43678205e-02,  8.87750066e-04, -2.47933697e-02,\n",
      "          -2.62972452e-02,  8.86332802e-03, -4.36784737e-02,\n",
      "          -2.65162997e-02,  8.90434254e-03,  1.19144041e-02,\n",
      "          -1.20046018e-02,  4.80996445e-02,  5.67427874e-02,\n",
      "           1.17805982e-02, -3.69768147e-03,  2.09587608e-02,\n",
      "           1.56568699e-02, -6.39659390e-02, -1.66788977e-02,\n",
      "          -1.92622729e-02,  6.77723158e-03,  2.01185653e-03,\n",
      "          -2.50990093e-02, -6.34651165e-03, -3.64954397e-02,\n",
      "           2.38137282e-02,  2.11377479e-02, -1.92195699e-02,\n",
      "           1.24313701e-02,  2.20784539e-04,  1.11806514e-02,\n",
      "           2.62219906e-02, -3.27389762e-02, -9.46105737e-03,\n",
      "          -2.04797834e-04,  1.69688947e-02, -4.08769511e-02,\n",
      "          -2.36489810e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 1.50658786e-02, -1.67859793e-02, -9.73447599e-03,\n",
      "          -1.92581583e-02,  8.78116582e-03,  2.47393246e-03,\n",
      "           1.31323691e-02,  4.43239510e-02, -3.51694077e-02,\n",
      "          -3.96518596e-02,  3.04188039e-02, -1.91871617e-02,\n",
      "          -6.48895511e-03, -3.08867749e-02, -5.51305711e-03,\n",
      "           8.70955735e-03, -1.02732182e-02,  1.78851634e-02,\n",
      "          -7.25005288e-03,  1.17081227e-02,  1.39763895e-02,\n",
      "           2.14620568e-02, -4.25374229e-03, -4.89892550e-02,\n",
      "          -5.60026010e-03,  2.20259614e-02,  1.90650262e-02,\n",
      "          -3.53529379e-02,  5.59007004e-02,  4.06744592e-02,\n",
      "           2.09713615e-02, -1.01905540e-02, -3.08042653e-02,\n",
      "           5.87631650e-02, -8.55806458e-04, -3.61257009e-02,\n",
      "           2.79527064e-02, -5.02914414e-02,  1.12394216e-02,\n",
      "           3.08075659e-02, -1.55430455e-02, -8.63420218e-03,\n",
      "           4.64576259e-02,  1.64304860e-02,  2.38798317e-02,\n",
      "          -3.89487632e-02,  2.42998935e-02, -4.66911644e-02,\n",
      "          -2.92278677e-02,  1.01588508e-02,  1.51568800e-02,\n",
      "          -3.36516574e-02, -2.21385043e-02, -2.18664315e-02,\n",
      "           3.38985436e-02,  2.09571142e-02,  6.46830350e-02,\n",
      "          -2.77479435e-03, -3.00884852e-03, -2.74872966e-02,\n",
      "          -8.93198140e-03, -1.66806802e-02,  2.34966371e-02,\n",
      "          -6.57104328e-03]],\n",
      "\n",
      "        [[-5.29452451e-02,  3.27528231e-02,  1.37223082e-03,\n",
      "          -3.19681764e-02, -5.14595583e-02, -6.32667262e-03,\n",
      "           5.41162631e-03, -1.85893308e-02,  1.13373622e-02,\n",
      "          -1.40797789e-03, -2.52241977e-02, -1.52368369e-02,\n",
      "           3.59482393e-02,  3.20400968e-02,  2.80946936e-03,\n",
      "          -2.27898024e-02,  1.91187430e-02,  3.03474423e-02,\n",
      "          -2.33284980e-02,  2.89409943e-02,  4.18077921e-03,\n",
      "           9.89397801e-03,  2.70920899e-02, -2.57372446e-02,\n",
      "          -4.74079736e-02,  1.22420648e-02,  3.19793820e-03,\n",
      "           1.85223855e-02, -1.69679783e-02,  5.86442370e-03,\n",
      "          -2.80498024e-02,  2.66606696e-02, -1.65463984e-03,\n",
      "          -8.94371141e-03, -3.68729085e-02,  2.74632368e-02,\n",
      "          -6.06720336e-02,  2.94769816e-02,  2.38269567e-05,\n",
      "           2.20094305e-02, -1.10853631e-02,  1.08918538e-02,\n",
      "           2.76126321e-02,  2.92046368e-03,  3.99905071e-02,\n",
      "           3.07704862e-02, -2.00590100e-02, -3.37166227e-02,\n",
      "           9.77098197e-03, -2.13173442e-02,  2.55870167e-02,\n",
      "           6.71831239e-03,  4.37166877e-02,  2.56980956e-02,\n",
      "           6.26422986e-02,  2.21089236e-02,  7.50459591e-03,\n",
      "           1.00820493e-02,  5.35349473e-02,  1.67291071e-02,\n",
      "          -2.94776633e-03, -4.23559546e-03,  3.26085463e-02,\n",
      "           2.49902271e-02]],\n",
      "\n",
      "        [[-1.71672869e-02,  2.68797521e-02, -2.72791591e-02,\n",
      "           4.64619249e-02,  2.69329734e-02,  2.23206002e-02,\n",
      "          -3.13342586e-02, -8.62600189e-03, -8.89792386e-03,\n",
      "           1.16631882e-02, -2.86546350e-03, -1.44477729e-02,\n",
      "           1.86275097e-03, -3.73945083e-03, -9.91139561e-03,\n",
      "           3.76042239e-02, -3.68952230e-02, -1.10306563e-02,\n",
      "           1.11948512e-02, -2.43955571e-02,  1.19361933e-02,\n",
      "          -2.00244784e-02,  2.61176135e-02, -3.20081562e-02,\n",
      "           3.49515378e-02,  3.13971052e-03,  3.48241851e-02,\n",
      "           3.73520143e-02,  4.84465584e-02,  1.79359913e-02,\n",
      "          -2.52514891e-02, -2.04734467e-02, -5.80106191e-02,\n",
      "          -1.11750066e-02, -3.45726162e-02, -1.70980319e-02,\n",
      "           2.43619690e-03,  9.55495052e-03, -2.44033779e-03,\n",
      "           3.63815054e-02,  2.67209802e-02,  2.15208810e-02,\n",
      "          -3.80503982e-02, -2.57798731e-02, -7.38425693e-03,\n",
      "          -2.04436146e-02,  5.72240958e-03,  3.36777456e-02,\n",
      "          -8.46002903e-03,  2.96797454e-02, -3.41828279e-02,\n",
      "          -4.68987674e-02,  1.96480900e-02,  5.09140734e-03,\n",
      "          -4.87036519e-02, -4.57877070e-02,  2.15520207e-02,\n",
      "           2.51700822e-02, -1.21161221e-02, -2.17158571e-02,\n",
      "          -3.01249623e-02, -1.44311786e-02, -5.24827130e-02,\n",
      "           2.09250711e-02]]]], dtype=float32)>, <tf.Variable 'conv2d_6/bias:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_7/kernel:0' shape=(3, 3, 64, 64) dtype=float32, numpy=\n",
      "array([[[[-1.69850569e-02,  2.16152016e-02,  3.28819044e-02, ...,\n",
      "          -1.57125052e-02, -3.36524704e-03, -4.09010425e-03],\n",
      "         [ 1.94126628e-02,  2.23356392e-02,  1.11600626e-02, ...,\n",
      "           6.66557346e-03, -5.62341372e-03,  9.31390096e-03],\n",
      "         [ 1.22247105e-02, -4.57744021e-03, -8.40049994e-04, ...,\n",
      "          -7.05706095e-03, -1.23524349e-02,  1.59517732e-02],\n",
      "         ...,\n",
      "         [ 2.64575686e-02,  1.70402229e-02,  1.28663925e-03, ...,\n",
      "           1.52844237e-02, -2.73575485e-02, -5.31145954e-04],\n",
      "         [ 4.05106619e-02,  8.81491578e-04, -1.08619984e-02, ...,\n",
      "          -2.32946016e-02, -1.94030441e-02, -8.15188326e-03],\n",
      "         [ 3.88534777e-02,  1.48940738e-02, -6.43774122e-03, ...,\n",
      "          -4.46374435e-03,  1.29817603e-02, -4.59266361e-03]],\n",
      "\n",
      "        [[-1.09307487e-02,  2.97727529e-02, -1.60785522e-02, ...,\n",
      "           9.89721157e-03, -4.77863476e-02, -1.16056744e-02],\n",
      "         [ 1.18100932e-02, -1.44465063e-02,  3.78657989e-02, ...,\n",
      "           4.39077541e-02, -6.91653928e-03,  4.27437568e-04],\n",
      "         [-5.75515907e-03,  1.76963471e-02,  2.81221326e-02, ...,\n",
      "           1.92463808e-02, -3.63918766e-03, -1.55910654e-02],\n",
      "         ...,\n",
      "         [-6.03428204e-03,  3.69359292e-02,  8.33700690e-03, ...,\n",
      "           5.78445848e-03,  4.04897965e-02,  2.57515870e-02],\n",
      "         [-2.09015850e-02,  9.45067033e-03,  1.67844985e-02, ...,\n",
      "          -4.13524220e-03,  2.65175197e-02,  2.71505123e-04],\n",
      "         [ 1.50609780e-02, -1.10825803e-02,  1.64174121e-02, ...,\n",
      "          -3.48542109e-02,  8.50073062e-03,  3.39857861e-02]],\n",
      "\n",
      "        [[-2.38746703e-02,  5.07535180e-03,  1.53692607e-02, ...,\n",
      "          -2.86570545e-02, -4.79030004e-03, -1.66585036e-02],\n",
      "         [-2.58522835e-02,  4.02647480e-02,  1.19532403e-02, ...,\n",
      "           1.70220602e-02,  2.78580189e-02,  4.29326290e-04],\n",
      "         [-4.46624542e-03, -1.67056359e-02,  1.20201092e-02, ...,\n",
      "          -4.17647883e-02,  2.39368603e-02,  3.56783345e-03],\n",
      "         ...,\n",
      "         [ 1.50896851e-02, -1.46195050e-02, -9.68745537e-03, ...,\n",
      "          -3.62509079e-02, -1.54748037e-02,  1.28558706e-02],\n",
      "         [ 2.08518635e-02, -1.41218929e-02, -1.60360634e-02, ...,\n",
      "          -2.72144489e-02, -2.92835087e-02,  2.91578472e-03],\n",
      "         [ 5.08023193e-03,  2.59717647e-02,  9.98698175e-03, ...,\n",
      "           2.49626450e-02,  3.93901253e-03,  1.98825784e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 9.37853940e-03, -2.50575319e-03, -1.78423394e-02, ...,\n",
      "          -3.75556163e-02,  1.50928367e-02, -1.02587265e-03],\n",
      "         [ 1.94024555e-02, -2.13303454e-02,  1.46425888e-02, ...,\n",
      "           2.34427974e-02,  2.17647990e-03, -3.31790820e-02],\n",
      "         [-7.54719507e-03, -4.78929188e-03, -7.57849496e-03, ...,\n",
      "           1.93845835e-02,  1.79364756e-02, -2.91001052e-02],\n",
      "         ...,\n",
      "         [-6.51289010e-03, -3.90158668e-02,  6.71462948e-03, ...,\n",
      "           1.94849353e-02, -6.60773832e-03, -8.78054928e-03],\n",
      "         [-1.27951801e-03, -4.61115222e-03, -5.32317907e-03, ...,\n",
      "           2.05590744e-02, -4.60475404e-03,  8.12095217e-03],\n",
      "         [-1.39441760e-02, -8.73556919e-03,  3.28896269e-02, ...,\n",
      "          -9.76466853e-03,  6.98370486e-03,  9.91995679e-04]],\n",
      "\n",
      "        [[ 1.13808392e-02, -2.09359191e-02,  3.83511148e-02, ...,\n",
      "           2.22321060e-02, -6.60886103e-03, -9.38955136e-03],\n",
      "         [ 4.71547656e-02, -6.62237435e-05, -6.49598613e-03, ...,\n",
      "           8.83513875e-03, -3.32988724e-02, -4.92197201e-02],\n",
      "         [-1.53132882e-02,  1.97858997e-02,  4.32632789e-02, ...,\n",
      "           8.35526921e-03, -1.06816245e-02, -8.23764596e-03],\n",
      "         ...,\n",
      "         [-6.68884069e-03,  5.03375661e-03,  2.55866945e-02, ...,\n",
      "          -1.48515776e-02, -6.79572811e-03, -1.64656900e-02],\n",
      "         [-1.22060033e-03, -2.45148912e-02,  1.02544092e-02, ...,\n",
      "           2.20892057e-02,  9.66365624e-04,  1.31071229e-02],\n",
      "         [-1.76311471e-02, -7.03729410e-03, -5.00715524e-03, ...,\n",
      "           2.81815771e-02,  1.68325659e-02, -3.81556302e-02]],\n",
      "\n",
      "        [[ 5.45228133e-03, -2.33304803e-03,  8.01392645e-03, ...,\n",
      "           5.22822281e-03,  9.17952694e-03,  1.27571579e-02],\n",
      "         [-6.46798592e-03, -1.42398300e-02,  1.21846925e-02, ...,\n",
      "          -3.39199826e-02,  9.28250886e-03, -1.53786692e-04],\n",
      "         [-1.64849160e-03,  2.19238047e-02,  1.67245232e-02, ...,\n",
      "          -3.27327917e-03,  1.98165933e-03,  1.94125620e-04],\n",
      "         ...,\n",
      "         [ 1.35729928e-02,  1.43849757e-02,  1.49786444e-02, ...,\n",
      "           8.84048361e-03, -3.36682908e-02,  4.78931256e-02],\n",
      "         [ 1.58846583e-02,  1.27267446e-02, -6.06256723e-03, ...,\n",
      "          -7.04374164e-03, -1.69550683e-02, -9.15747695e-03],\n",
      "         [ 1.52276205e-02,  2.70652883e-02,  1.54992891e-02, ...,\n",
      "           2.63607558e-02, -3.12110782e-02,  6.64010132e-03]]],\n",
      "\n",
      "\n",
      "       [[[ 5.10488823e-03,  1.79123096e-02, -1.95949227e-02, ...,\n",
      "          -8.75240285e-03, -2.25773314e-03, -2.35780180e-02],\n",
      "         [ 9.82910395e-04,  4.91259694e-02,  1.36077954e-02, ...,\n",
      "           3.57949510e-02, -3.90230827e-02,  1.35598928e-02],\n",
      "         [-1.62457824e-02,  2.78448015e-02,  7.24801444e-04, ...,\n",
      "          -1.47506250e-02,  1.93487853e-02, -3.21812145e-02],\n",
      "         ...,\n",
      "         [-1.29894940e-02, -2.89646778e-02,  7.15948036e-03, ...,\n",
      "           1.01401219e-02, -1.52206477e-02,  4.56305873e-03],\n",
      "         [-2.22396366e-02,  5.38704405e-03, -1.21123847e-02, ...,\n",
      "          -4.75738803e-03, -2.86845112e-04,  2.80545210e-03],\n",
      "         [-1.94492098e-02,  1.03651267e-02, -3.34172547e-02, ...,\n",
      "           5.92973316e-03,  1.87476054e-02, -1.75679363e-02]],\n",
      "\n",
      "        [[-7.86799937e-03, -2.90167816e-02,  3.32715139e-02, ...,\n",
      "           2.85675190e-02, -9.77609027e-03,  3.10400184e-02],\n",
      "         [-5.04170218e-03,  1.81888603e-02,  2.60965042e-02, ...,\n",
      "           2.60967463e-02, -9.08930041e-03,  9.08349641e-03],\n",
      "         [ 2.03069095e-02, -8.32101679e-04,  9.96956136e-03, ...,\n",
      "          -6.66226912e-03, -6.45001093e-03, -7.98114575e-03],\n",
      "         ...,\n",
      "         [ 1.61897726e-02,  9.97016113e-03,  7.67929200e-03, ...,\n",
      "           9.66314692e-03, -1.18881371e-02, -1.68536045e-02],\n",
      "         [ 2.46886462e-02, -4.84808441e-03,  3.32496986e-02, ...,\n",
      "          -3.00695300e-02,  1.86591689e-02, -2.99551301e-02],\n",
      "         [ 7.76787009e-03,  8.24970193e-03, -2.56463746e-03, ...,\n",
      "           6.22381875e-03, -1.78587530e-02,  1.80397239e-02]],\n",
      "\n",
      "        [[ 1.33872908e-02,  2.52852030e-02,  1.48601411e-02, ...,\n",
      "           1.91329177e-02,  2.05226578e-02,  1.48636270e-02],\n",
      "         [-1.76627878e-02,  2.20409478e-03,  1.14264889e-02, ...,\n",
      "           8.34738929e-03,  5.79036307e-03, -3.83756831e-02],\n",
      "         [ 2.34152786e-02, -2.60076532e-03,  3.76201351e-03, ...,\n",
      "          -2.42514722e-02, -6.18040576e-05, -8.37149471e-03],\n",
      "         ...,\n",
      "         [-1.05627328e-02,  1.69750787e-02,  7.54204532e-03, ...,\n",
      "           8.28418043e-03, -3.30608562e-02, -1.06123835e-02],\n",
      "         [-1.43872877e-03,  2.06616186e-02, -7.09084934e-03, ...,\n",
      "          -9.78706754e-04,  1.47251384e-02, -3.29769701e-02],\n",
      "         [ 1.72545086e-03,  2.33011991e-02, -1.32815186e-02, ...,\n",
      "          -1.40164467e-02,  2.17350069e-02,  5.80837065e-03]]]],\n",
      "      dtype=float32)>, <tf.Variable 'conv2d_7/bias:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_8/kernel:0' shape=(3, 3, 64, 128) dtype=float32, numpy=\n",
      "array([[[[ 1.55330421e-02,  7.89451133e-03,  2.22818796e-02, ...,\n",
      "          -3.99999693e-02,  1.00090671e-02,  2.43939157e-03],\n",
      "         [-3.10924258e-02, -1.33896247e-03,  1.00174118e-02, ...,\n",
      "          -8.84863641e-03, -3.97674646e-03,  1.10548073e-02],\n",
      "         [ 3.22904587e-02,  2.64930539e-02,  2.55429232e-03, ...,\n",
      "           2.38227542e-03,  2.60648187e-02,  9.08928085e-03],\n",
      "         ...,\n",
      "         [ 6.78988779e-03,  1.05358800e-02,  1.00721652e-02, ...,\n",
      "           8.99709761e-03,  1.63136981e-02, -7.33500812e-03],\n",
      "         [ 6.52481895e-03,  8.18916596e-03, -1.06267231e-02, ...,\n",
      "           1.15938787e-03,  6.69015199e-03,  8.00969731e-03],\n",
      "         [-7.73361465e-03, -1.53583828e-02, -1.26190661e-02, ...,\n",
      "           4.98951320e-03, -6.21584803e-03, -7.31204078e-03]],\n",
      "\n",
      "        [[-6.52625319e-03,  2.44503878e-02,  3.25109065e-03, ...,\n",
      "          -2.06250735e-02, -2.14925669e-02, -1.70768388e-02],\n",
      "         [ 7.82414060e-03,  1.40224490e-02, -1.20769106e-02, ...,\n",
      "           1.85488425e-02, -1.61821954e-02,  1.11016873e-02],\n",
      "         [-7.49591272e-03,  2.30836831e-02,  1.91182345e-02, ...,\n",
      "          -1.18307043e-02, -1.65702160e-02, -2.64782831e-03],\n",
      "         ...,\n",
      "         [-8.53101723e-03, -8.27609934e-03, -2.24090228e-03, ...,\n",
      "          -2.65822629e-03, -6.37788605e-03,  1.64830463e-03],\n",
      "         [-2.22959742e-03, -2.22323127e-02, -1.34892911e-02, ...,\n",
      "          -2.61538918e-03, -1.08894678e-02,  1.53158847e-02],\n",
      "         [-1.05845416e-02,  3.14284628e-03,  3.50863184e-03, ...,\n",
      "           1.94895489e-03, -1.68387108e-02,  2.44591385e-03]],\n",
      "\n",
      "        [[ 1.12561164e-02, -1.28767546e-02,  4.32431418e-03, ...,\n",
      "           2.57600658e-02, -2.98897419e-02,  1.87297799e-02],\n",
      "         [ 3.01338043e-02, -1.06937746e-02, -1.16586573e-02, ...,\n",
      "          -1.76433567e-02, -1.67626832e-02,  5.62294852e-03],\n",
      "         [ 4.05890215e-03,  1.01597663e-02,  3.74460667e-02, ...,\n",
      "          -9.22768551e-04, -3.37960944e-03, -1.67161524e-02],\n",
      "         ...,\n",
      "         [-3.15651158e-03,  8.77177902e-03,  9.71664302e-03, ...,\n",
      "          -1.51728769e-03, -5.67375263e-03, -3.56440470e-02],\n",
      "         [ 1.42511504e-03,  1.19914557e-03, -2.38386095e-02, ...,\n",
      "          -1.08856037e-02,  2.65703863e-03,  2.94418074e-02],\n",
      "         [ 1.07071381e-02, -1.81518085e-02, -4.50878823e-03, ...,\n",
      "          -1.20623317e-02, -9.52990167e-03,  2.86848005e-02]]],\n",
      "\n",
      "\n",
      "       [[[-1.87078547e-02, -6.71662251e-03, -8.74501094e-03, ...,\n",
      "           1.34501401e-02, -7.66675407e-03, -2.75039859e-02],\n",
      "         [ 1.04156639e-02, -2.70463079e-02,  3.38356085e-02, ...,\n",
      "          -6.84137736e-03, -8.89361277e-03, -9.75291710e-03],\n",
      "         [ 2.61676172e-03, -2.02119555e-02,  3.13913682e-03, ...,\n",
      "           1.99225303e-02,  2.59274244e-03,  1.61882062e-02],\n",
      "         ...,\n",
      "         [ 8.45706463e-03,  4.46811598e-03,  1.66599303e-02, ...,\n",
      "          -8.32779612e-03, -8.86786077e-03,  4.81734201e-02],\n",
      "         [ 3.29195475e-03,  6.31361175e-03,  6.04124274e-03, ...,\n",
      "          -1.10916030e-02, -1.05503965e-02,  1.98821048e-03],\n",
      "         [-1.68613009e-02,  2.46153399e-03,  8.96189641e-03, ...,\n",
      "           7.69274402e-03,  1.88778900e-02,  1.51297543e-02]],\n",
      "\n",
      "        [[ 1.33698282e-03, -2.43066810e-02, -2.94080307e-03, ...,\n",
      "          -7.50820618e-03,  2.67277956e-02, -5.11210132e-03],\n",
      "         [ 8.22935067e-03, -9.85523313e-03,  1.06211854e-02, ...,\n",
      "          -1.02260597e-02, -5.31843584e-03,  1.39407841e-02],\n",
      "         [-1.03483181e-02,  3.51361744e-02,  1.98557228e-02, ...,\n",
      "           4.87762678e-04, -5.36764180e-03,  5.07651502e-03],\n",
      "         ...,\n",
      "         [-4.09573726e-02,  1.43650714e-02, -2.24402850e-03, ...,\n",
      "           9.59959812e-03, -1.38064791e-02, -2.54108217e-02],\n",
      "         [-1.04426285e-02, -2.53118128e-02,  1.25362230e-02, ...,\n",
      "          -1.29782204e-02, -3.39892507e-03,  2.71982737e-02],\n",
      "         [ 1.70690082e-02, -1.84821002e-02,  1.70294885e-02, ...,\n",
      "          -7.28274113e-04, -9.58769000e-04, -2.05956027e-02]],\n",
      "\n",
      "        [[-1.15437973e-02,  5.33303153e-03,  2.69346833e-02, ...,\n",
      "           9.16972384e-03, -2.72847852e-03, -1.49986078e-03],\n",
      "         [-4.05243691e-03,  1.35285258e-02,  4.32128087e-02, ...,\n",
      "          -6.66610867e-05,  9.69690853e-04, -1.93567201e-03],\n",
      "         [ 2.54871398e-02, -8.39985348e-03, -7.34409178e-03, ...,\n",
      "          -1.09228340e-03, -1.23642702e-02,  1.26066562e-02],\n",
      "         ...,\n",
      "         [-2.23232917e-02, -1.02953222e-02,  2.59150621e-02, ...,\n",
      "          -2.29381733e-02, -7.36157584e-04, -2.50203605e-03],\n",
      "         [ 6.85013074e-04,  1.79236531e-02, -1.75429769e-02, ...,\n",
      "           6.00036990e-04, -1.08053011e-03, -1.93282068e-02],\n",
      "         [ 1.56154428e-02, -1.23550592e-03, -2.10529119e-02, ...,\n",
      "          -1.99366584e-02, -2.15538889e-02,  6.27811253e-03]]],\n",
      "\n",
      "\n",
      "       [[[ 1.75101943e-02, -1.64017864e-02, -2.86753173e-03, ...,\n",
      "          -8.60185828e-03,  4.47496101e-02, -2.16487981e-02],\n",
      "         [-1.10108219e-02, -9.19451378e-03, -2.42652372e-03, ...,\n",
      "           2.11245473e-02,  1.60501450e-02, -1.09475963e-02],\n",
      "         [ 9.94091202e-03,  1.81345083e-02,  1.64808333e-03, ...,\n",
      "           5.93491178e-03, -3.41981277e-02, -8.62089824e-03],\n",
      "         ...,\n",
      "         [ 2.44263709e-02,  1.67198486e-05, -1.40694259e-02, ...,\n",
      "          -8.01776722e-03,  4.82632592e-03,  1.42799215e-02],\n",
      "         [-1.28195230e-02, -1.37614859e-02, -3.62128764e-03, ...,\n",
      "          -3.01843937e-02,  9.66920145e-03,  9.96930874e-04],\n",
      "         [ 1.03708068e-02,  9.54047777e-03,  2.85105174e-03, ...,\n",
      "          -3.30542140e-02,  2.28296150e-03, -8.55067559e-03]],\n",
      "\n",
      "        [[ 8.54840409e-03,  2.37155873e-02, -1.41760558e-02, ...,\n",
      "          -7.07011390e-03, -1.74430180e-02,  2.39164121e-02],\n",
      "         [-1.76514052e-02, -1.31998956e-03,  2.44448446e-02, ...,\n",
      "          -2.84587704e-02, -1.11538405e-02,  8.28811433e-03],\n",
      "         [-3.09070796e-02,  4.02639061e-03, -6.66497508e-03, ...,\n",
      "           3.99810728e-03, -3.95998359e-04, -3.03989649e-03],\n",
      "         ...,\n",
      "         [-6.30411273e-03, -3.00408900e-03,  2.19981442e-03, ...,\n",
      "          -1.07875597e-02, -1.15119051e-02, -1.19949272e-02],\n",
      "         [-5.83135104e-03,  1.65529735e-02, -9.03939479e-04, ...,\n",
      "           2.94972751e-02, -7.02255964e-03,  5.36368182e-03],\n",
      "         [-1.56298466e-02, -1.01858182e-02, -2.78143771e-02, ...,\n",
      "           1.91304348e-02,  1.78056431e-03, -1.80921815e-02]],\n",
      "\n",
      "        [[-3.68387322e-03, -4.92543587e-03,  5.37132192e-03, ...,\n",
      "          -8.82843789e-03, -1.11225247e-02,  2.64379522e-03],\n",
      "         [ 2.30790731e-02,  1.36093618e-02, -9.55715030e-03, ...,\n",
      "           1.37783978e-02, -8.31942447e-03,  9.43226274e-03],\n",
      "         [-4.08443250e-03, -1.07486767e-03, -1.14936773e-02, ...,\n",
      "           1.42926034e-02, -3.03679649e-02, -8.16721376e-03],\n",
      "         ...,\n",
      "         [ 3.79139856e-02,  3.84526630e-03,  2.96537783e-02, ...,\n",
      "          -1.82215869e-02, -3.48568568e-03,  2.43196334e-03],\n",
      "         [ 1.76732484e-02, -2.60170642e-02,  6.03523990e-03, ...,\n",
      "          -1.61153432e-02,  4.74537583e-03, -1.39055122e-02],\n",
      "         [-4.49509686e-03,  1.87516324e-02, -8.22879001e-03, ...,\n",
      "           1.14619290e-03,  1.65395010e-02, -8.63442756e-03]]]],\n",
      "      dtype=float32)>, <tf.Variable 'conv2d_8/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_9/kernel:0' shape=(3, 3, 128, 128) dtype=float32, numpy=\n",
      "array([[[[-1.68600716e-02, -1.79312825e-02,  1.56610422e-02, ...,\n",
      "           2.33031134e-03,  2.44804751e-02,  2.02444028e-02],\n",
      "         [ 1.77019127e-02,  2.91587468e-02,  4.45633428e-03, ...,\n",
      "           1.42396810e-02, -2.89265849e-02,  4.72779619e-03],\n",
      "         [-9.21144325e-04, -9.66222584e-03, -1.04102995e-02, ...,\n",
      "          -1.47317154e-02,  1.18395685e-04, -1.08037284e-02],\n",
      "         ...,\n",
      "         [ 3.45268520e-03,  9.29052569e-03,  2.21795309e-02, ...,\n",
      "          -5.73424762e-03,  1.65490282e-03, -3.66365095e-03],\n",
      "         [-6.69058273e-03,  1.20818159e-02, -1.52439149e-02, ...,\n",
      "          -1.73150264e-02,  2.40473729e-02, -1.29415561e-02],\n",
      "         [ 4.51561064e-04,  4.78552654e-03, -9.24593210e-03, ...,\n",
      "           8.77422863e-04,  6.81729522e-03,  2.92378152e-03]],\n",
      "\n",
      "        [[-1.82376746e-02, -7.29917642e-03, -1.91094242e-02, ...,\n",
      "           4.46839537e-03, -5.85866813e-03,  1.00972280e-02],\n",
      "         [-5.54028433e-03,  1.73025206e-03,  8.59043933e-03, ...,\n",
      "           1.78645179e-02, -6.77104760e-03,  5.78062003e-03],\n",
      "         [ 1.14615110e-03, -1.93275753e-02,  4.39174986e-03, ...,\n",
      "          -1.19022722e-03, -3.63576040e-03,  1.94072220e-02],\n",
      "         ...,\n",
      "         [-2.69912332e-02, -1.98374745e-02, -3.24954093e-03, ...,\n",
      "           4.18132655e-02, -3.27313952e-02,  2.23652087e-02],\n",
      "         [-7.51773245e-04,  3.35277850e-03, -2.63632828e-04, ...,\n",
      "           3.87683138e-03,  6.72382582e-03, -2.65672244e-02],\n",
      "         [ 9.23694950e-03, -1.20849535e-02, -3.99352144e-03, ...,\n",
      "           3.12072644e-03, -1.21377083e-02,  4.39008558e-03]],\n",
      "\n",
      "        [[ 1.18882190e-02, -1.05912779e-02, -8.55815317e-03, ...,\n",
      "           1.51981013e-02, -2.72535421e-02,  3.11360415e-02],\n",
      "         [-7.90557172e-03,  5.06107276e-03,  1.29528192e-03, ...,\n",
      "           4.32946393e-03, -5.09707723e-03, -2.15586238e-02],\n",
      "         [-7.46782729e-03, -2.61854343e-02, -1.43078584e-02, ...,\n",
      "           6.80623949e-03,  1.86342876e-02,  1.66742299e-02],\n",
      "         ...,\n",
      "         [ 2.59614345e-02,  6.37450209e-03, -1.25909001e-02, ...,\n",
      "           2.95578176e-03, -1.43891303e-02,  2.10052729e-02],\n",
      "         [-3.68665904e-04,  2.17544548e-02, -2.04895623e-02, ...,\n",
      "          -4.32615727e-03,  3.06768040e-03, -1.71130407e-03],\n",
      "         [ 1.12429345e-02, -1.69592090e-02,  9.57026705e-03, ...,\n",
      "           1.12022611e-03,  1.61850359e-02,  1.44066667e-04]]],\n",
      "\n",
      "\n",
      "       [[[ 8.28434154e-03,  5.95645513e-03,  1.21646319e-02, ...,\n",
      "          -3.19344248e-03,  3.46364081e-02, -4.63093352e-03],\n",
      "         [-2.75902753e-03,  1.70640331e-02,  8.04351177e-03, ...,\n",
      "          -1.21885221e-02, -1.34093361e-02,  5.47396368e-04],\n",
      "         [-2.39504944e-03, -2.97223171e-03, -1.54845845e-02, ...,\n",
      "           1.56629458e-03,  2.39671953e-03,  9.32943821e-03],\n",
      "         ...,\n",
      "         [ 7.52308685e-03, -2.45563239e-02,  1.15194349e-02, ...,\n",
      "           5.93533274e-03,  3.96983046e-03, -4.12434340e-04],\n",
      "         [ 1.49836782e-02,  1.61951897e-03,  2.38039419e-02, ...,\n",
      "          -1.01086637e-02, -1.01220282e-02, -2.57146396e-02],\n",
      "         [ 2.86382623e-02, -1.38390334e-02,  3.32710594e-02, ...,\n",
      "          -1.89913996e-02, -2.04573832e-02, -1.52477650e-02]],\n",
      "\n",
      "        [[-2.23263865e-03, -4.92641353e-04,  4.48024040e-03, ...,\n",
      "           8.49423185e-03, -1.71311870e-02, -1.33621292e-02],\n",
      "         [ 4.64720000e-03,  1.81475189e-02,  8.09995085e-03, ...,\n",
      "           1.83497481e-02, -9.22507327e-03, -1.20283784e-02],\n",
      "         [ 6.16327673e-03, -1.38403922e-02,  3.31444293e-03, ...,\n",
      "          -2.12481758e-03, -2.00286886e-04,  2.26665474e-02],\n",
      "         ...,\n",
      "         [-9.41476785e-03,  5.95694408e-03, -1.07929884e-02, ...,\n",
      "          -2.02198476e-02,  1.01543311e-02, -1.19918864e-02],\n",
      "         [-1.84496008e-02,  9.63620562e-03,  1.03705954e-02, ...,\n",
      "           2.35224515e-02,  3.15950811e-03, -2.56738849e-02],\n",
      "         [ 1.04985973e-02, -2.71488866e-03,  4.28893697e-03, ...,\n",
      "           1.93005316e-02, -2.53575225e-03, -9.28728282e-03]],\n",
      "\n",
      "        [[-2.14060349e-03, -1.11367982e-02, -1.91013403e-02, ...,\n",
      "          -5.14764199e-03,  2.13546003e-03,  3.93546978e-03],\n",
      "         [-3.26629058e-02,  1.69438329e-02, -5.83066791e-03, ...,\n",
      "          -1.20727085e-02,  3.92806763e-03, -2.65100598e-03],\n",
      "         [ 1.17076049e-02,  5.25426120e-04,  1.32288784e-02, ...,\n",
      "          -1.40965581e-02,  7.61730364e-03,  2.34908126e-02],\n",
      "         ...,\n",
      "         [ 9.61063523e-03,  1.46244112e-02, -1.46315275e-02, ...,\n",
      "          -7.72865140e-04,  1.64468624e-02,  9.12775286e-03],\n",
      "         [ 2.63083223e-02,  1.56332832e-02,  9.52444971e-05, ...,\n",
      "          -2.14055181e-04, -4.63692751e-03,  5.39174024e-03],\n",
      "         [ 1.96255185e-02,  1.00587551e-02,  5.53621259e-03, ...,\n",
      "          -2.01724712e-02,  3.03693172e-02, -8.40166956e-03]]],\n",
      "\n",
      "\n",
      "       [[[ 1.91492345e-02,  4.91146091e-03,  8.86066258e-03, ...,\n",
      "          -1.27897505e-02,  1.04346760e-02, -4.18366864e-04],\n",
      "         [-1.50846760e-03,  5.84047195e-03, -4.95833158e-03, ...,\n",
      "          -9.15053487e-03, -2.24396633e-03,  8.02232977e-03],\n",
      "         [ 8.58783815e-03,  1.14439987e-02, -2.32668081e-03, ...,\n",
      "          -2.05389336e-02,  3.60727170e-03, -2.10732082e-03],\n",
      "         ...,\n",
      "         [ 1.79432336e-05,  1.22186001e-02, -2.40476127e-03, ...,\n",
      "           2.17446387e-02, -9.24086547e-04,  2.45803781e-03],\n",
      "         [-2.25741346e-03,  1.95177253e-02, -7.28319352e-03, ...,\n",
      "           6.89894799e-03,  6.95950538e-03,  1.75596923e-02],\n",
      "         [-1.65119171e-02,  6.17762888e-03, -7.69994687e-03, ...,\n",
      "           4.36105113e-03, -6.67222124e-03, -1.52524712e-03]],\n",
      "\n",
      "        [[-2.68091774e-03,  1.14288572e-02, -1.01229547e-04, ...,\n",
      "          -2.29866989e-02, -1.39320018e-02,  1.10912481e-02],\n",
      "         [ 1.49797124e-03, -2.21974440e-02,  2.92917038e-03, ...,\n",
      "           1.95784271e-02,  8.18899181e-03,  6.90270215e-03],\n",
      "         [ 8.88831168e-03, -1.16145322e-02,  9.71318502e-03, ...,\n",
      "           2.04516854e-02,  4.83893929e-03, -1.43167973e-02],\n",
      "         ...,\n",
      "         [-4.23407927e-03,  1.46921007e-02,  6.73678378e-03, ...,\n",
      "           7.15662912e-03, -8.15077103e-04, -2.68315291e-03],\n",
      "         [-1.52547751e-02,  3.87287745e-03,  7.87371583e-03, ...,\n",
      "           1.70902424e-02,  1.18185801e-03,  7.57160014e-04],\n",
      "         [-3.62662040e-03, -3.57209891e-03,  6.09114161e-03, ...,\n",
      "           1.00606112e-02,  2.07147608e-03, -1.20693650e-02]],\n",
      "\n",
      "        [[ 5.64282294e-03, -7.02428806e-04, -2.59701423e-02, ...,\n",
      "           2.60888096e-02, -1.49183823e-02, -6.04292890e-03],\n",
      "         [ 1.95780257e-03, -2.28765290e-02, -3.21015040e-03, ...,\n",
      "           6.73468271e-03,  3.96141503e-03, -5.97986567e-04],\n",
      "         [-8.77301861e-03, -5.87994466e-03, -3.81213566e-03, ...,\n",
      "           1.68248061e-02,  2.20860355e-02, -4.78024408e-03],\n",
      "         ...,\n",
      "         [ 1.50999771e-02, -2.48276647e-02,  2.16559004e-02, ...,\n",
      "          -1.15447231e-02,  1.29404636e-02,  7.38131395e-03],\n",
      "         [ 6.81906054e-03, -1.06928358e-02,  3.39160929e-03, ...,\n",
      "          -1.27613721e-02, -1.02338810e-02, -1.33014694e-02],\n",
      "         [-2.04848349e-02,  1.13968737e-02,  6.38285885e-03, ...,\n",
      "          -5.55682788e-03, -4.83729225e-03, -2.11270386e-03]]]],\n",
      "      dtype=float32)>, <tf.Variable 'conv2d_9/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_10/kernel:0' shape=(3, 3, 128, 256) dtype=float32, numpy=\n",
      "array([[[[ 9.38101090e-04,  9.41079669e-03,  1.91091071e-03, ...,\n",
      "          -9.24799126e-03, -1.54646961e-02,  8.69168621e-03],\n",
      "         [-5.11594117e-04,  8.11659638e-03,  1.60382930e-02, ...,\n",
      "          -7.49598723e-03, -6.12122426e-03,  1.40403081e-02],\n",
      "         [ 3.06343962e-03, -1.56165604e-02,  1.78318995e-03, ...,\n",
      "           1.10988934e-02,  1.04692954e-04,  7.37054041e-03],\n",
      "         ...,\n",
      "         [ 1.29268272e-02,  1.50449695e-02,  7.36299902e-03, ...,\n",
      "           7.16500077e-03,  1.24830855e-02,  1.60094984e-02],\n",
      "         [ 6.09391183e-03, -2.83854385e-03, -1.92624088e-02, ...,\n",
      "           1.68619975e-02,  1.54019892e-02, -2.42746482e-03],\n",
      "         [ 1.04143266e-02,  6.08501816e-03,  7.35059893e-03, ...,\n",
      "          -4.50389925e-03,  4.94999904e-03, -2.39166990e-03]],\n",
      "\n",
      "        [[-5.19708556e-04,  6.92136600e-05,  1.29895331e-02, ...,\n",
      "           1.00578871e-02, -5.43782720e-03, -5.87740820e-03],\n",
      "         [-7.74383685e-03, -7.00865034e-03, -2.32416596e-02, ...,\n",
      "           4.13378095e-03,  3.34228436e-03,  1.40723586e-02],\n",
      "         [ 4.68040118e-03,  3.33214318e-03,  8.57507903e-03, ...,\n",
      "          -1.14191172e-03, -4.92405705e-03,  3.13814217e-03],\n",
      "         ...,\n",
      "         [-5.75297466e-03,  2.03895122e-02,  2.29473179e-03, ...,\n",
      "          -5.63082937e-03,  2.16440298e-02, -1.87410193e-03],\n",
      "         [-8.12007021e-03, -2.95716664e-03, -1.52364895e-02, ...,\n",
      "           6.99859113e-03,  2.99948007e-02,  1.54666533e-03],\n",
      "         [ 3.00459634e-03,  4.56618378e-03,  1.22779887e-02, ...,\n",
      "           2.00580861e-02,  1.08545516e-02, -7.09137181e-03]],\n",
      "\n",
      "        [[-8.48515145e-03, -8.07471108e-03,  1.09916497e-02, ...,\n",
      "           2.34776433e-03, -3.37706064e-03,  1.76683273e-02],\n",
      "         [-6.53252983e-03, -3.65203479e-03,  4.51303925e-03, ...,\n",
      "          -2.78949738e-05, -1.05218096e-02, -5.25709521e-03],\n",
      "         [ 2.48900112e-02,  1.10369991e-03,  9.47912131e-03, ...,\n",
      "           2.35215388e-02,  1.17893144e-02,  9.32310987e-03],\n",
      "         ...,\n",
      "         [-1.25768874e-02, -1.47429826e-02, -5.93531970e-03, ...,\n",
      "           2.50586756e-02, -3.82331753e-04,  3.19343817e-04],\n",
      "         [-5.08236978e-03, -1.37152779e-03,  1.60741284e-02, ...,\n",
      "          -2.07834356e-02,  9.79110785e-03, -1.00161200e-02],\n",
      "         [-2.13199351e-02,  2.70394608e-03,  1.47483591e-02, ...,\n",
      "          -2.06157938e-02, -1.57850869e-02, -2.91180937e-03]]],\n",
      "\n",
      "\n",
      "       [[[-9.79332603e-04,  1.09335575e-02, -4.83454112e-03, ...,\n",
      "          -1.10377120e-02, -1.71845555e-02, -1.07443165e-02],\n",
      "         [ 4.77302447e-03,  7.00547034e-03, -1.13027748e-02, ...,\n",
      "           6.63061719e-03, -2.98636779e-03,  9.53530334e-03],\n",
      "         [ 9.75708850e-03,  1.28126265e-02, -4.96906135e-03, ...,\n",
      "          -1.51046962e-02, -2.05768552e-02, -1.27679529e-02],\n",
      "         ...,\n",
      "         [ 4.54072666e-04,  1.18600931e-02, -1.18814479e-03, ...,\n",
      "          -5.28277224e-03, -1.49164768e-02,  5.91010461e-03],\n",
      "         [-1.35589959e-02,  2.69634603e-03,  6.67500484e-04, ...,\n",
      "          -3.35310842e-03, -1.03604514e-02,  1.83794107e-02],\n",
      "         [ 6.19912241e-03, -1.12663349e-02, -2.29164455e-02, ...,\n",
      "          -6.60053734e-03,  2.07998604e-03,  4.05754516e-04]],\n",
      "\n",
      "        [[-2.10388992e-02, -1.02671608e-03,  7.16996798e-03, ...,\n",
      "           1.12436274e-02, -1.14799347e-02,  1.17038656e-02],\n",
      "         [ 6.57428196e-03, -1.08385663e-02,  5.41459396e-03, ...,\n",
      "           2.89312750e-03,  5.68809966e-03,  1.56560503e-02],\n",
      "         [-9.42557864e-03, -1.52329798e-03,  1.43470075e-02, ...,\n",
      "          -7.46843591e-03,  1.39602991e-02, -9.81563982e-03],\n",
      "         ...,\n",
      "         [-5.03597502e-03, -1.69049706e-02, -5.72245917e-04, ...,\n",
      "          -1.30208135e-02,  9.54891182e-03, -1.62975187e-03],\n",
      "         [ 6.39600214e-03,  3.06906854e-03, -7.74460146e-03, ...,\n",
      "           1.07413474e-02,  2.63535287e-02,  2.15845220e-02],\n",
      "         [-1.25767263e-02,  8.34091939e-03, -5.79803949e-03, ...,\n",
      "          -6.09115325e-03,  5.83740231e-03, -9.56486538e-03]],\n",
      "\n",
      "        [[-6.89579174e-03, -1.26772700e-02,  8.24454799e-03, ...,\n",
      "           1.59133156e-03, -6.42991811e-03, -1.10219968e-02],\n",
      "         [-1.26093086e-02,  9.55381338e-03, -9.37520154e-03, ...,\n",
      "           8.46547540e-03, -4.82591335e-03, -2.80387700e-04],\n",
      "         [ 1.23221837e-02, -6.61702221e-03,  2.13298891e-02, ...,\n",
      "           2.78009480e-04, -8.69119167e-03, -2.00885739e-02],\n",
      "         ...,\n",
      "         [ 9.53424163e-03, -4.12647286e-03, -1.13452235e-02, ...,\n",
      "           1.35899484e-02, -9.82897170e-03,  1.01023000e-02],\n",
      "         [ 7.22507155e-03,  1.13505051e-02, -5.63574117e-03, ...,\n",
      "           9.24158748e-03, -7.46141002e-03,  5.45170298e-03],\n",
      "         [-1.08119939e-02, -1.25809237e-02, -4.62670636e-04, ...,\n",
      "           9.29966755e-03, -8.92106723e-03, -1.78110506e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 1.63003914e-02, -4.70378529e-03, -1.47964861e-02, ...,\n",
      "           1.89816987e-03,  2.61922192e-04, -1.22205494e-02],\n",
      "         [-1.29662780e-02,  9.19378735e-03,  1.05769001e-02, ...,\n",
      "          -5.87354368e-03, -1.21543249e-02,  2.72257114e-03],\n",
      "         [-2.20671599e-03, -8.79194122e-03,  1.18137896e-03, ...,\n",
      "           9.75729548e-04,  1.71659179e-02, -7.31177628e-04],\n",
      "         ...,\n",
      "         [-4.97732218e-03,  1.32462587e-02,  1.17739933e-02, ...,\n",
      "           1.54227521e-02, -1.26842037e-02, -1.72186680e-02],\n",
      "         [-2.04054639e-04, -9.03271697e-03, -2.02495744e-03, ...,\n",
      "          -9.15702432e-04,  1.33330477e-02,  1.11438408e-02],\n",
      "         [ 8.31623736e-04, -1.21005420e-02,  1.05486559e-02, ...,\n",
      "          -3.58647341e-03,  5.52983861e-03, -6.90472592e-03]],\n",
      "\n",
      "        [[-1.64963938e-02, -1.20757343e-02, -1.71085950e-02, ...,\n",
      "          -4.83736023e-03,  5.65790664e-03,  5.67073142e-03],\n",
      "         [-1.31628988e-02, -3.95905366e-03,  1.52005460e-02, ...,\n",
      "           1.67341735e-02, -6.16826396e-03, -3.91509384e-03],\n",
      "         [ 8.08256504e-04,  6.88067451e-03,  3.38931871e-03, ...,\n",
      "          -2.59117037e-03, -1.59210265e-02, -4.56688320e-03],\n",
      "         ...,\n",
      "         [ 1.04546193e-02,  1.87348872e-02, -1.62250327e-03, ...,\n",
      "          -1.71747734e-03,  1.39768119e-03,  2.23533739e-03],\n",
      "         [ 2.06528534e-03,  2.58926302e-04,  5.69310319e-03, ...,\n",
      "           2.32607499e-03, -7.99944904e-03, -2.28265449e-02],\n",
      "         [-6.12018537e-03, -2.44722981e-02, -3.36103654e-03, ...,\n",
      "          -1.31035866e-02,  2.17804201e-02,  2.02171244e-02]],\n",
      "\n",
      "        [[ 1.00940708e-02,  5.98998042e-03, -1.11633446e-02, ...,\n",
      "          -2.47165076e-02,  9.01285093e-03, -1.18551878e-02],\n",
      "         [-7.66188884e-03, -7.75487628e-03,  9.89340805e-03, ...,\n",
      "          -4.40504542e-03, -1.26334075e-02,  5.88859525e-03],\n",
      "         [-1.33023430e-02,  5.83989080e-03, -5.00751799e-03, ...,\n",
      "           2.29313783e-02, -6.68126345e-03, -3.03386524e-03],\n",
      "         ...,\n",
      "         [-3.43279308e-03,  3.51786101e-03,  8.70536547e-03, ...,\n",
      "           7.18047330e-03, -5.29755559e-03, -5.43724373e-03],\n",
      "         [ 7.50573492e-03,  5.74872829e-03, -5.02925599e-03, ...,\n",
      "          -1.48512777e-02, -5.57736959e-03,  6.02410594e-03],\n",
      "         [-4.98506706e-03,  1.41982231e-02, -9.13532451e-03, ...,\n",
      "           2.28011602e-04, -4.99738520e-03,  4.12441697e-03]]]],\n",
      "      dtype=float32)>, <tf.Variable 'conv2d_10/bias:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'conv2d_11/kernel:0' shape=(3, 3, 256, 256) dtype=float32, numpy=\n",
      "array([[[[ 1.54978605e-02, -3.35570099e-03,  3.21339490e-03, ...,\n",
      "           3.48461722e-03, -3.49673268e-04,  8.46261997e-03],\n",
      "         [-4.65426221e-03, -5.58018917e-03,  1.45805459e-02, ...,\n",
      "           9.60927922e-03, -4.59554780e-04, -1.13227163e-02],\n",
      "         [ 8.30768980e-03,  8.66838079e-03, -1.26637202e-02, ...,\n",
      "           7.50721386e-03, -8.72638635e-03, -4.12948430e-03],\n",
      "         ...,\n",
      "         [-1.70411100e-03,  6.89844647e-03,  1.81325118e-03, ...,\n",
      "          -4.47081495e-03,  3.20765423e-03,  2.12090090e-04],\n",
      "         [-2.05811132e-02, -1.38239879e-02, -6.24410808e-04, ...,\n",
      "          -2.08784826e-02,  1.82481222e-02, -4.51691169e-03],\n",
      "         [ 1.51515845e-02,  1.68998055e-02,  4.66944650e-03, ...,\n",
      "           5.81107521e-03,  3.98985576e-03,  1.38471951e-03]],\n",
      "\n",
      "        [[ 1.29733430e-02,  8.31148960e-03,  5.15338685e-03, ...,\n",
      "          -8.95667836e-05, -4.26856149e-03, -3.78017360e-03],\n",
      "         [-1.63108390e-02, -1.12540554e-02, -1.82563555e-03, ...,\n",
      "           4.68140980e-03,  1.03716971e-02,  1.10954417e-04],\n",
      "         [ 1.65666677e-02,  1.18814595e-02, -5.11186430e-03, ...,\n",
      "          -2.81578675e-03,  3.74475121e-03,  9.39060189e-03],\n",
      "         ...,\n",
      "         [-8.49339762e-04, -4.09149099e-03,  1.78908859e-03, ...,\n",
      "          -5.15646115e-03, -1.13775637e-02,  6.54881913e-03],\n",
      "         [ 4.27274173e-03, -9.53136105e-03,  6.64295629e-04, ...,\n",
      "           5.66878181e-04,  2.31140712e-03,  3.96688143e-03],\n",
      "         [ 5.58750238e-03,  1.16821649e-02,  9.18151462e-04, ...,\n",
      "           6.06626133e-03, -1.55816227e-02,  9.45182983e-03]],\n",
      "\n",
      "        [[ 7.05195731e-03,  9.77751240e-03,  9.16928038e-05, ...,\n",
      "           9.13357735e-03, -8.25522467e-03,  7.43757794e-03],\n",
      "         [ 7.94301927e-03, -5.94195630e-03, -1.37788430e-02, ...,\n",
      "           9.48520564e-03, -1.02477777e-03, -2.14720611e-02],\n",
      "         [ 1.12013961e-03,  5.13362873e-04,  2.79054791e-03, ...,\n",
      "          -1.19533660e-02, -2.16427147e-02, -1.29747798e-03],\n",
      "         ...,\n",
      "         [-2.02872371e-03,  1.61321852e-02, -7.36910105e-03, ...,\n",
      "           7.80271017e-04,  1.15327798e-02, -9.32691805e-03],\n",
      "         [ 1.15449203e-03,  4.64562234e-03,  1.97210517e-02, ...,\n",
      "          -4.48797643e-03, -1.00365374e-02, -4.37354017e-03],\n",
      "         [ 1.83447748e-02,  1.99716981e-03, -6.10341178e-03, ...,\n",
      "          -7.54236663e-03, -2.17134394e-02, -1.11401780e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 4.64890152e-04,  1.01167653e-02,  7.97419157e-03, ...,\n",
      "           5.94450720e-03, -5.14396559e-03,  5.79674961e-03],\n",
      "         [ 1.25558181e-02, -4.49996721e-03, -1.35061573e-02, ...,\n",
      "           8.67357757e-03,  1.00780148e-02, -2.53288588e-03],\n",
      "         [ 9.42348503e-03,  6.57224935e-03, -1.80330500e-03, ...,\n",
      "          -5.86067233e-03,  1.20491087e-02,  7.45730242e-03],\n",
      "         ...,\n",
      "         [-8.92363023e-03, -5.04188240e-04, -1.36151689e-03, ...,\n",
      "          -1.36536341e-02,  6.33844000e-04,  1.31715285e-02],\n",
      "         [-6.13968354e-03, -4.49633831e-03,  3.31261021e-04, ...,\n",
      "           6.49623107e-03,  1.48259550e-02,  7.07149785e-03],\n",
      "         [ 2.72981892e-03,  2.40530749e-03, -1.33943949e-02, ...,\n",
      "           1.07632969e-02, -6.21172367e-03, -5.87121025e-03]],\n",
      "\n",
      "        [[ 5.96655253e-03, -3.49337980e-03,  1.44751845e-02, ...,\n",
      "           6.00010948e-03, -1.54554276e-02,  8.83793365e-03],\n",
      "         [ 7.12692644e-03, -1.17023627e-03, -1.02669178e-02, ...,\n",
      "           4.60448256e-03, -4.92867921e-03, -6.00638520e-03],\n",
      "         [ 5.00132889e-03, -7.99021509e-04,  5.70593961e-03, ...,\n",
      "          -8.22449382e-03, -1.97285786e-03,  9.47370939e-03],\n",
      "         ...,\n",
      "         [ 1.12835346e-02,  8.90923385e-03, -2.83290807e-04, ...,\n",
      "          -4.24231635e-03, -7.48188421e-03, -9.80542041e-03],\n",
      "         [-9.94871138e-04,  2.71313265e-03, -1.77998433e-03, ...,\n",
      "           3.99212539e-03,  1.07628666e-02, -2.86504556e-03],\n",
      "         [-8.17846041e-03,  1.33171873e-02,  6.56141620e-03, ...,\n",
      "           8.17253906e-03,  1.03925915e-04,  1.07165016e-02]],\n",
      "\n",
      "        [[-2.84769270e-03,  5.56358509e-03,  5.82188461e-03, ...,\n",
      "           5.87398652e-03,  1.32865403e-02,  1.84360181e-03],\n",
      "         [ 3.68441129e-03, -9.93298274e-03,  1.49904517e-02, ...,\n",
      "          -1.86374467e-02, -3.71849095e-03,  2.11982522e-02],\n",
      "         [ 6.54558931e-03,  7.40765175e-03, -1.33966850e-02, ...,\n",
      "          -4.99514956e-03,  5.92611963e-03,  1.07838679e-02],\n",
      "         ...,\n",
      "         [-5.44869248e-03,  3.67517758e-04, -7.64207169e-03, ...,\n",
      "          -1.85705721e-05, -4.31761146e-03, -6.37428078e-04],\n",
      "         [-1.43301636e-02, -8.26253183e-03, -7.88924284e-03, ...,\n",
      "           2.53433292e-03,  9.18006338e-03, -9.79615725e-04],\n",
      "         [-3.19266459e-03,  6.16872823e-03,  1.94984563e-02, ...,\n",
      "          -6.77163759e-03,  1.23773841e-02, -1.83580822e-04]]],\n",
      "\n",
      "\n",
      "       [[[-6.89069182e-03,  1.03352610e-02,  1.90807544e-02, ...,\n",
      "          -1.45971030e-02, -1.00947637e-02, -7.06390664e-03],\n",
      "         [ 2.43955781e-03, -2.62899254e-03, -5.60121145e-03, ...,\n",
      "           3.80227040e-03, -1.17650917e-02,  1.07683372e-02],\n",
      "         [-1.08845076e-02,  4.42476338e-03,  7.51633104e-03, ...,\n",
      "           3.68347275e-03, -5.03756152e-03,  6.69992715e-03],\n",
      "         ...,\n",
      "         [-6.79868448e-04,  1.34946406e-02, -1.47094484e-02, ...,\n",
      "           1.84112340e-02,  3.20203602e-04, -7.31320167e-03],\n",
      "         [ 1.18899299e-02, -1.01106968e-02, -1.49023179e-02, ...,\n",
      "           1.21974200e-03, -1.41101331e-02,  1.48208928e-03],\n",
      "         [ 4.15055733e-03, -3.57180834e-04,  5.43589424e-03, ...,\n",
      "          -2.81735370e-03, -1.75350811e-02,  2.77062086e-03]],\n",
      "\n",
      "        [[-1.24111101e-02,  9.98174399e-03, -1.48280826e-03, ...,\n",
      "           1.54189020e-02, -1.13799591e-02,  1.67319481e-03],\n",
      "         [-2.42374884e-03, -6.47830497e-03,  5.53533668e-03, ...,\n",
      "           2.02362309e-03, -6.75436715e-03,  8.05855636e-03],\n",
      "         [ 4.40331409e-03, -1.92145985e-02,  4.88715898e-03, ...,\n",
      "           3.32788378e-03,  9.22324229e-03,  2.09037773e-03],\n",
      "         ...,\n",
      "         [-4.74603567e-03, -4.30747587e-03, -1.87458005e-02, ...,\n",
      "          -1.94001081e-03,  1.34209041e-02, -1.89500544e-02],\n",
      "         [ 4.25531436e-03,  4.43855673e-03,  2.04473771e-02, ...,\n",
      "          -2.05176999e-03,  6.12895796e-03, -1.48992660e-02],\n",
      "         [ 7.50545412e-03, -6.91828877e-03,  1.06430948e-02, ...,\n",
      "          -1.27789201e-02, -7.97746330e-03, -1.49650383e-03]],\n",
      "\n",
      "        [[-5.77496085e-03,  1.76816303e-02,  4.11041074e-05, ...,\n",
      "          -5.46987355e-03, -3.05958092e-05,  2.30636005e-03],\n",
      "         [ 8.12403101e-04,  4.73794620e-03, -6.74866140e-03, ...,\n",
      "          -9.56585817e-03, -8.37872736e-03,  1.54705448e-02],\n",
      "         [-3.59913940e-03, -9.20750760e-03, -1.48238731e-03, ...,\n",
      "          -4.44027130e-03,  1.04130236e-02,  7.57871056e-03],\n",
      "         ...,\n",
      "         [-1.46735432e-02,  1.80649571e-02,  1.72576234e-02, ...,\n",
      "          -2.01385515e-03, -6.82948809e-03, -1.34972651e-02],\n",
      "         [-8.40432593e-04, -2.83474801e-03,  5.18418988e-03, ...,\n",
      "           2.65499093e-02, -1.92435610e-03, -1.85556710e-05],\n",
      "         [-9.42859333e-03,  1.93015076e-02,  1.34590771e-02, ...,\n",
      "           1.13062337e-02,  3.28685204e-03, -1.25803147e-02]]]],\n",
      "      dtype=float32)>, <tf.Variable 'conv2d_11/bias:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'dense_3/kernel:0' shape=(2304, 512) dtype=float32, numpy=\n",
      "array([[ 0.02385678, -0.01708137, -0.01980681, ..., -0.01377731,\n",
      "        -0.01039699, -0.0184339 ],\n",
      "       [ 0.01103689,  0.01146318, -0.01172199, ...,  0.00382193,\n",
      "        -0.01237808,  0.01963927],\n",
      "       [ 0.0145363 ,  0.00121166,  0.01249356, ...,  0.01183785,\n",
      "        -0.00050989, -0.01849926],\n",
      "       ...,\n",
      "       [ 0.00687497,  0.01915836,  0.01331924, ..., -0.0280219 ,\n",
      "         0.0068067 , -0.01355464],\n",
      "       [ 0.00161706,  0.00991912,  0.01146639, ..., -0.00049773,\n",
      "         0.01187798,  0.00091365],\n",
      "       [ 0.02775753,  0.00742965,  0.0019823 , ...,  0.01172384,\n",
      "         0.00355823, -0.00359935]], dtype=float32)>, <tf.Variable 'dense_3/bias:0' shape=(512,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32)>, <tf.Variable 'dense_4/kernel:0' shape=(512, 512) dtype=float32, numpy=\n",
      "array([[-0.02023735, -0.00763321, -0.0138274 , ...,  0.00112092,\n",
      "        -0.02045008, -0.01703559],\n",
      "       [ 0.00960613,  0.00314439,  0.01477535, ...,  0.01999935,\n",
      "        -0.0063148 , -0.00529457],\n",
      "       [-0.01191304, -0.02159967,  0.00859792, ...,  0.02719501,\n",
      "         0.01979006,  0.02705568],\n",
      "       ...,\n",
      "       [ 0.02434819, -0.00532917, -0.03129631, ..., -0.00571337,\n",
      "        -0.00992187, -0.05179047],\n",
      "       [ 0.00296902,  0.00918856,  0.01105028, ..., -0.00010223,\n",
      "         0.02605464, -0.02978878],\n",
      "       [ 0.00143632,  0.00043027, -0.05044768, ..., -0.01034095,\n",
      "         0.01487789, -0.01073238]], dtype=float32)>, <tf.Variable 'dense_4/bias:0' shape=(512,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32)>, <tf.Variable 'dense_5/kernel:0' shape=(512, 10) dtype=float32, numpy=\n",
      "array([[ 0.01040562,  0.0189325 ,  0.00473445, ...,  0.01427844,\n",
      "         0.02012391,  0.00017488],\n",
      "       [-0.01612941, -0.01367897, -0.05753319, ...,  0.00490254,\n",
      "         0.00562195,  0.02872174],\n",
      "       [-0.01637073,  0.03274264, -0.01681058, ..., -0.04870444,\n",
      "         0.02867155,  0.01389187],\n",
      "       ...,\n",
      "       [-0.00517967, -0.02594587,  0.01534636, ..., -0.00495481,\n",
      "        -0.03358068, -0.01063015],\n",
      "       [ 0.03603722,  0.04263733, -0.00949048, ..., -0.00582884,\n",
      "        -0.03767002,  0.02827438],\n",
      "       [ 0.03534377,  0.01434573,  0.02727861, ...,  0.02735108,\n",
      "         0.00896482,  0.01441311]], dtype=float32)>, <tf.Variable 'dense_5/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retracing naive\n",
      "Naive Epoch count:  0  Total fda steps:  7\n",
      "Est var:  1.24206424  Actual S_2 (Assumed 0):  0.256296575  Actual var:  0.985767663\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  14\n",
      "Est var:  1.10003257  Actual S_2 (Assumed 0):  0.232205868  Actual var:  0.867826819\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  24\n",
      "Est var:  1.22782195  Actual S_2 (Assumed 0):  0.272410214  Actual var:  0.955411732\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  32\n",
      "Est var:  1.16612613  Actual S_2 (Assumed 0):  0.241038129  Actual var:  0.925088108\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  39\n",
      "Est var:  1.1574688  Actual S_2 (Assumed 0):  0.253170609  Actual var:  0.904298306\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  47\n",
      "Est var:  1.23339677  Actual S_2 (Assumed 0):  0.443443  Actual var:  0.789953828\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  53\n",
      "Est var:  1.08645952  Actual S_2 (Assumed 0):  0.312647104  Actual var:  0.773812413\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  58\n",
      "Est var:  1.13917637  Actual S_2 (Assumed 0):  0.461306155  Actual var:  0.677870393\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  63\n",
      "Est var:  1.29290175  Actual S_2 (Assumed 0):  0.536659837  Actual var:  0.756241918\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  67\n",
      "Est var:  1.40362406  Actual S_2 (Assumed 0):  0.741070092  Actual var:  0.662553966\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  70\n",
      "Est var:  1.289294  Actual S_2 (Assumed 0):  0.575173557  Actual var:  0.714120507\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  73\n",
      "Est var:  1.40291929  Actual S_2 (Assumed 0):  0.587633729  Actual var:  0.815285563\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  76\n",
      "Est var:  1.50468087  Actual S_2 (Assumed 0):  0.618195891  Actual var:  0.886485\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  79\n",
      "Est var:  1.56218278  Actual S_2 (Assumed 0):  0.755218387  Actual var:  0.806964517\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  82\n",
      "Est var:  1.37191796  Actual S_2 (Assumed 0):  0.616633534  Actual var:  0.755284429\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  85\n",
      "Est var:  1.26377845  Actual S_2 (Assumed 0):  0.535331845  Actual var:  0.728446603\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  88\n",
      "Est var:  1.060269  Actual S_2 (Assumed 0):  0.459228754  Actual var:  0.601040184\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  91\n",
      "Est var:  1.02924025  Actual S_2 (Assumed 0):  0.470267713  Actual var:  0.558972538\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  94\n",
      "Est var:  1.09164846  Actual S_2 (Assumed 0):  0.552288473  Actual var:  0.53936\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  97\n",
      "Est var:  1.17680681  Actual S_2 (Assumed 0):  0.616464436  Actual var:  0.560342371\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  100\n",
      "Est var:  1.18718553  Actual S_2 (Assumed 0):  0.606425524  Actual var:  0.580759883\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  103\n",
      "Est var:  1.18500865  Actual S_2 (Assumed 0):  0.538131177  Actual var:  0.646877468\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  106\n",
      "Est var:  1.16601491  Actual S_2 (Assumed 0):  0.502595961  Actual var:  0.663418889\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  109\n",
      "Est var:  1.16449893  Actual S_2 (Assumed 0):  0.503822207  Actual var:  0.660676599\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  112\n",
      "Est var:  1.22382522  Actual S_2 (Assumed 0):  0.501484275  Actual var:  0.722340763\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  115\n",
      "Est var:  1.2500695  Actual S_2 (Assumed 0):  0.475613  Actual var:  0.774456501\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  118\n",
      "Est var:  1.2598052  Actual S_2 (Assumed 0):  0.466825843  Actual var:  0.792979538\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  121\n",
      "Est var:  1.27047729  Actual S_2 (Assumed 0):  0.477721632  Actual var:  0.792755663\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  124\n",
      "Est var:  1.19351292  Actual S_2 (Assumed 0):  0.454566568  Actual var:  0.738946319\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  127\n",
      "Est var:  1.18789864  Actual S_2 (Assumed 0):  0.451242745  Actual var:  0.736655951\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  130\n",
      "Est var:  1.13164783  Actual S_2 (Assumed 0):  0.434847325  Actual var:  0.69680053\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  133\n",
      "Est var:  1.06398129  Actual S_2 (Assumed 0):  0.388857871  Actual var:  0.675123394\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  136\n",
      "Est var:  1.03974986  Actual S_2 (Assumed 0):  0.424843311  Actual var:  0.614906549\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  140\n",
      "Est var:  1.60228848  Actual S_2 (Assumed 0):  0.668252468  Actual var:  0.934036076\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  144\n",
      "Est var:  1.49203622  Actual S_2 (Assumed 0):  0.5512622  Actual var:  0.940774143\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  148\n",
      "Est var:  1.5189445  Actual S_2 (Assumed 0):  0.581957221  Actual var:  0.936987281\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  152\n",
      "Est var:  1.39167833  Actual S_2 (Assumed 0):  0.498843491  Actual var:  0.892834842\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  156\n",
      "Est var:  1.26441121  Actual S_2 (Assumed 0):  0.417941213  Actual var:  0.84647\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  160\n",
      "Est var:  1.38985407  Actual S_2 (Assumed 0):  0.457186043  Actual var:  0.93266809\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  164\n",
      "Est var:  1.25859284  Actual S_2 (Assumed 0):  0.394032687  Actual var:  0.86456\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  168\n",
      "Est var:  1.1892935  Actual S_2 (Assumed 0):  0.357465267  Actual var:  0.831828117\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  172\n",
      "Est var:  1.26400065  Actual S_2 (Assumed 0):  0.344770312  Actual var:  0.919230461\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  176\n",
      "Est var:  1.19641697  Actual S_2 (Assumed 0):  0.346625894  Actual var:  0.849791169\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  180\n",
      "Est var:  1.13432586  Actual S_2 (Assumed 0):  0.317544699  Actual var:  0.816781044\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  184\n",
      "Est var:  1.21073651  Actual S_2 (Assumed 0):  0.356453687  Actual var:  0.854282737\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  188\n",
      "Est var:  1.262344  Actual S_2 (Assumed 0):  0.364416212  Actual var:  0.897927582\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  192\n",
      "Est var:  1.29614  Actual S_2 (Assumed 0):  0.402396679  Actual var:  0.893743336\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  196\n",
      "Est var:  1.22070909  Actual S_2 (Assumed 0):  0.396940887  Actual var:  0.823768258\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  200\n",
      "Est var:  1.17541385  Actual S_2 (Assumed 0):  0.380432487  Actual var:  0.794981301\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  204\n",
      "Est var:  1.14952147  Actual S_2 (Assumed 0):  0.34796229  Actual var:  0.801559091\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  208\n",
      "Est var:  1.23469961  Actual S_2 (Assumed 0):  0.405261844  Actual var:  0.829437852\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  212\n",
      "Est var:  1.25898623  Actual S_2 (Assumed 0):  0.411090344  Actual var:  0.847895801\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  216\n",
      "Est var:  1.18029308  Actual S_2 (Assumed 0):  0.355885476  Actual var:  0.824407697\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  220\n",
      "Est var:  1.27541709  Actual S_2 (Assumed 0):  0.341860503  Actual var:  0.933556437\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  224\n",
      "Est var:  1.11741698  Actual S_2 (Assumed 0):  0.32649681  Actual var:  0.79092\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  229\n",
      "Est var:  1.25960696  Actual S_2 (Assumed 0):  0.360844105  Actual var:  0.898762822\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  234\n",
      "Est var:  1.11011553  Actual S_2 (Assumed 0):  0.302988052  Actual var:  0.807127357\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  239\n",
      "Est var:  1.16620958  Actual S_2 (Assumed 0):  0.327083737  Actual var:  0.839125931\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  244\n",
      "Est var:  1.2332902  Actual S_2 (Assumed 0):  0.33026275  Actual var:  0.903027415\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  249\n",
      "Est var:  1.38005459  Actual S_2 (Assumed 0):  0.385870308  Actual var:  0.994184315\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  254\n",
      "Est var:  1.38499475  Actual S_2 (Assumed 0):  0.405915856  Actual var:  0.979078889\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  259\n",
      "Est var:  1.46851516  Actual S_2 (Assumed 0):  0.365611285  Actual var:  1.10290384\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  264\n",
      "Est var:  1.31576133  Actual S_2 (Assumed 0):  0.370130837  Actual var:  0.945630431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  269\n",
      "Est var:  1.3879621  Actual S_2 (Assumed 0):  0.379698634  Actual var:  1.00826335\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  274\n",
      "Est var:  1.45566976  Actual S_2 (Assumed 0):  0.375587702  Actual var:  1.08008218\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  279\n",
      "Est var:  1.28448784  Actual S_2 (Assumed 0):  0.347105503  Actual var:  0.93738234\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  284\n",
      "Est var:  1.22039533  Actual S_2 (Assumed 0):  0.299758673  Actual var:  0.920636654\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  289\n",
      "Est var:  1.121665  Actual S_2 (Assumed 0):  0.295349896  Actual var:  0.826315045\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  294\n",
      "Est var:  1.11389184  Actual S_2 (Assumed 0):  0.258741796  Actual var:  0.855150044\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  299\n",
      "Est var:  1.30047441  Actual S_2 (Assumed 0):  0.312526256  Actual var:  0.98794812\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  304\n",
      "Est var:  1.27300406  Actual S_2 (Assumed 0):  0.299250603  Actual var:  0.973753333\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  309\n",
      "Est var:  1.16374362  Actual S_2 (Assumed 0):  0.287199736  Actual var:  0.87654388\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  314\n",
      "Est var:  1.06110537  Actual S_2 (Assumed 0):  0.279112369  Actual var:  0.781992912\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  319\n",
      "Est var:  1.23563349  Actual S_2 (Assumed 0):  0.307083875  Actual var:  0.928549588\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  325\n",
      "Est var:  1.33872986  Actual S_2 (Assumed 0):  0.332550228  Actual var:  1.00617957\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  331\n",
      "Est var:  1.1641748  Actual S_2 (Assumed 0):  0.300276041  Actual var:  0.863898754\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  337\n",
      "Est var:  1.21548438  Actual S_2 (Assumed 0):  0.273520797  Actual var:  0.941963553\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  343\n",
      "Est var:  1.37296867  Actual S_2 (Assumed 0):  0.336386  Actual var:  1.03658259\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  348\n",
      "Est var:  1.20354879  Actual S_2 (Assumed 0):  0.272351176  Actual var:  0.931197762\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  353\n",
      "Est var:  1.01581049  Actual S_2 (Assumed 0):  0.271290928  Actual var:  0.744519472\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  358\n",
      "Est var:  1.07045078  Actual S_2 (Assumed 0):  0.280470431  Actual var:  0.789980412\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  363\n",
      "Est var:  1.07367754  Actual S_2 (Assumed 0):  0.261601478  Actual var:  0.812076092\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  369\n",
      "Est var:  1.31587851  Actual S_2 (Assumed 0):  0.336824685  Actual var:  0.979053855\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  374\n",
      "Est var:  1.19907987  Actual S_2 (Assumed 0):  0.286089331  Actual var:  0.912990689\n",
      "\n",
      "\n",
      "Naive Epoch count:  1  Total fda steps:  375\n",
      "Est var:  0.0498480871  Actual S_2 (Assumed 0):  0.0116995908  Actual var:  0.0381485\n",
      "\n",
      "\n",
      "name 'server_model' is not defined\n",
      "shit\n"
     ]
    }
   ],
   "source": [
    "all_metrics = run_tests(\n",
    "    NUM_CLIENTS_LIST=[5],\n",
    "    NUM_EPOCHS_LIST=[1],\n",
    "    NUM_STEPS_UNTIL_RTC_CHECK_LIST=[1],\n",
    "    BATCH_SIZE_LIST=[32],\n",
    "    THETA_LIST=[1.],\n",
    "    SKETCH_DEPTH=7,\n",
    "    SKETCH_WIDTH=1700,\n",
    "    SEED=7\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93aa398",
   "metadata": {},
   "source": [
    "TODO:\n",
    "    \n",
    "1. Check why no change in accuracy between steps. Do the updates happen at all? What the fuck is going on here?\n",
    "2. Check accuracy final\n",
    "3. `synchronize` retracing\n",
    "4. DONE: `get_compiled_and_built_...()` retraces for `server_cnn` every time (ofc for `client_cnns` aswell).\n",
    "   BUT: make sure once more that when we `reset` then afterwards `.evaluate` works correctly. Maybe weird shit with metrics. Check plz\n",
    "\n",
    "\n",
    "5. Approach on sketch should be `reduce_mean`, change it in PA-I.\n",
    "6. Approach on global tests `for` loop PA-I\n",
    "7. remove `one` as a `tf.constant(1)` PA-I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a4b2b222",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "da382e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test_results/advanced_cnn_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3e3cd8a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8952a821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d977ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tff-py39] *",
   "language": "python",
   "name": "conda-env-tff-py39-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
