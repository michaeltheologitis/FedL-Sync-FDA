{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2759993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74531322",
   "metadata": {},
   "source": [
    "## Import EMNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a550108",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cc37c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77c8e4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_BATCH_INPUT = (None, 28, 28) # EMNIST dataset (None is used for batch size, as it varies)\n",
    "CNN_INPUT_RESHAPE = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a83a61",
   "metadata": {},
   "source": [
    "## Convert to Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3eb02a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = tf.constant(X_train, dtype=tf.float32)\n",
    "del X_train\n",
    "\n",
    "y_train_tensor = tf.constant(y_train, dtype=tf.int32)\n",
    "del y_train\n",
    "\n",
    "X_test_tensor = tf.constant(X_test, dtype=tf.float32)\n",
    "del X_test\n",
    "\n",
    "y_test_tensor = tf.constant(y_test, dtype=tf.int32)\n",
    "del y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567ab8a7",
   "metadata": {},
   "source": [
    "## Prepare data for Federated Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3e112b",
   "metadata": {},
   "source": [
    "### Create centralized testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fad165b",
   "metadata": {},
   "outputs": [],
   "source": [
    "slices_test = (X_test_tensor, y_test_tensor)\n",
    "\n",
    "def create_tf_dataset_for_testing(batch_size):\n",
    "    return tf.data.Dataset.from_tensor_slices(slices_test).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84aa24c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = create_tf_dataset_for_testing(256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a24a95c",
   "metadata": {},
   "source": [
    "### Slice the Tensors for each Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43734f7",
   "metadata": {},
   "source": [
    "We will cut the training data, i.e., (`X_train_tensor`, `y_train_tensor`) to equal parts, each part corresponding to one Client. We want to give the result back as a dictionary with key `client_id` and value the training tensor data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97b27a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_for_clients(num_clients):\n",
    "    \n",
    "    client_slices_train = {}\n",
    "\n",
    "    for i in range(num_clients):\n",
    "        # Compute the indices for this client's slice\n",
    "        start_idx = int(i * n_train / num_clients)\n",
    "        end_idx = int((i + 1) * n_train / num_clients)\n",
    "\n",
    "        # Get the slice for this client\n",
    "        X_client_train = X_train_tensor[start_idx:end_idx]\n",
    "        y_client_train = y_train_tensor[start_idx:end_idx]\n",
    "        \n",
    "        # Combine the slices into a single dataset\n",
    "        client_slices_train[f'client_{i}'] = (X_client_train, y_client_train)\n",
    "    \n",
    "    return client_slices_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88734523",
   "metadata": {},
   "source": [
    "### Create TF friendly data for each Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c58dbae",
   "metadata": {},
   "source": [
    "Given a Tensor slice (i.e. value of `client_slices_train[\"client_id\"]` we convert it to highly optimized `tf.data.Dataset` to prepare for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "794535c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_dataset_for_client(client_tensor_slices, batch_size, shuffle_buffer_size, num_steps_until_rtc_check, seed):\n",
    "    \n",
    "        return tf.data.Dataset.from_tensor_slices(client_tensor_slices) \\\n",
    "            .shuffle(buffer_size=shuffle_buffer_size, seed=seed).batch(batch_size) \\\n",
    "            .prefetch(tf.data.AUTOTUNE).take(num_steps_until_rtc_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0794b1a0",
   "metadata": {},
   "source": [
    "### Create Federated Learning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d770c13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_federated_data(client_slices_train, batch_size, shuffle_buffer_size, num_steps_until_rtc_check, seed=None):\n",
    "    \n",
    "    federated_dataset = [ \n",
    "        create_tf_dataset_for_client(client_tensor_slices, batch_size, shuffle_buffer_size, num_steps_until_rtc_check, seed)\n",
    "        for client, client_tensor_slices in client_slices_train.items()\n",
    "    ]\n",
    "    \n",
    "    return federated_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918a0455",
   "metadata": {},
   "source": [
    "# Miscallenious"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58d696f",
   "metadata": {},
   "source": [
    "## Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d6aa1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def variance(cnn_list, cnn_sync):\n",
    "    \n",
    "    squared_distances = [\n",
    "        tf.reduce_sum(tf.square(cnn.trainable_vars_as_vector() - cnn_sync.trainable_vars_as_vector())) \n",
    "        for cnn in cnn_list\n",
    "    ]\n",
    "    \n",
    "    var = tf.reduce_mean(squared_distances)\n",
    "    \n",
    "    return var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88347123",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "524397ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metrics_dict(fda_name, n_train, dataset_name, input_pixels, seed, epochs, num_clients, \n",
    "                        batch_size, steps_in_one_fda_step, theta, total_fda_steps, num_weights,\n",
    "                        total_rounds, final_accuracy, sketch_width=None, sketch_depth=None):\n",
    "    metrics = {\n",
    "            \"fda_name\" : fda_name,\n",
    "            \"theta\" : theta,\n",
    "            \"dataset_name\" : dataset_name, # new\n",
    "            \"input_pixels\" : input_pixels, # new\n",
    "            \"n_train\" : n_train, # new\n",
    "            \"num_weights\" : num_weights, # new\n",
    "            \"seed\" : seed,\n",
    "            \"epochs\" : epochs,\n",
    "            \"num_clients\" : num_clients,\n",
    "            \"batch_size\" : batch_size,\n",
    "            \"steps_in_one_fda_step\" : steps_in_one_fda_step,\n",
    "            \"sketch_width\" : sketch_width,\n",
    "            \"sketch_depth\" : sketch_depth\n",
    "        }\n",
    "    \n",
    "    # one batch bytes\n",
    "    metrics[\"one_sample_bytes\"] = 4 * (metrics[\"input_pixels\"] + 1)  # 4 bytes float32\n",
    "    \n",
    "    # training dataset size\n",
    "    metrics[\"training_dataset_bytes\"] = metrics[\"one_sample_bytes\"] * metrics[\"n_train\"]\n",
    "    \n",
    "    # model bytes\n",
    "    metrics[\"model_bytes\"] = metrics[\"num_weights\"] * 4\n",
    "    \n",
    "    \n",
    "    # local state bytes (i.e. S_i), for one client\n",
    "    if fda_name == \"naive\":\n",
    "        metrics[\"local_state_bytes\"] = 4\n",
    "    elif fda_name == \"linear\":\n",
    "        metrics[\"local_state_bytes\"] = 8\n",
    "    else:\n",
    "        metrics[\"local_state_bytes\"] = sketch_width * sketch_depth * 4 + 4\n",
    "        \n",
    "    # accuracy (already computed in parameter)\n",
    "    metrics[\"final_accuracy\"] = final_accuracy\n",
    "    \n",
    "    # total fda steps from algo\n",
    "    metrics[\"total_fda_steps\"] = total_fda_steps\n",
    "    \n",
    "    # total steps (a single fda step might have many normal SGD steps, batch steps)\n",
    "    metrics[\"total_steps\"] = metrics[\"total_fda_steps\"] * metrics[\"steps_in_one_fda_step\"]\n",
    "    \n",
    "    # total rounds in algo. Reason why we differentiate from the hardcoded NUM_ROUNDS\n",
    "    # is because we might run less rounds in the future (i.e. stop on 10^7 samples idk)\n",
    "    metrics[\"total_rounds\"] = total_rounds\n",
    "    \n",
    "    # bytes exchanged for synchronizing weights (x2 because server sends back)\n",
    "    metrics[\"model_bytes_exchanged\"] = metrics[\"total_rounds\"] * metrics[\"model_bytes\"] \\\n",
    "        * metrics[\"num_clients\"] * 2\n",
    "    \n",
    "    # bytes exchanged for monitoring the variance (communication)\n",
    "    metrics[\"monitoring_bytes_exchanged\"] = metrics[\"local_state_bytes\"] * metrics[\"total_fda_steps\"] \\\n",
    "        * metrics[\"num_clients\"]\n",
    "    \n",
    "    # total communication bytes (for both monitoring and model synchronization)\n",
    "    metrics[\"total_communication_bytes\"] = metrics[\"model_bytes_exchanged\"] + metrics[\"monitoring_bytes_exchanged\"]\n",
    "    \n",
    "    # total seen dataset bytes (across all learning, i.e., all clients)\n",
    "    metrics[\"trained_in_bytes\"] = metrics[\"batch_size\"] * metrics[\"one_sample_bytes\"] \\\n",
    "        * metrics[\"total_steps\"] * metrics[\"num_clients\"]\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e079822",
   "metadata": {},
   "source": [
    "## Neural Net weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc9b44d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_weights(model):\n",
    "    total_params = 0\n",
    "    for layer in model.layers:\n",
    "        total_params += np.sum([np.prod(weight.shape) for weight in layer.trainable_weights])\n",
    "    return int(total_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cbfbd3",
   "metadata": {},
   "source": [
    "# Simple Convolutional Neural Net (CNN) - Medium Size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c3a252",
   "metadata": {},
   "source": [
    "A simple Convolutional Neural Network with a single convolutional layer, followed by a max-pooling layer, and two dense layers for classification. Designed for 28x28 grayscale images. It has 692,352 weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dac88dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(tf.keras.Model):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        self.reshape = layers.Reshape(CNN_INPUT_RESHAPE)\n",
    "        self.conv1 = layers.Conv2D(32, 3, activation='relu')\n",
    "        self.max_pool = layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.dense1 = layers.Dense(128, activation='relu')\n",
    "        self.dense2 = layers.Dense(num_classes, activation='softmax')\n",
    "\n",
    "        \n",
    "    # Defines the computation from inputs to outputs\n",
    "    def call(self, inputs, training=None):\n",
    "        x = self.reshape(inputs)  # Add a channel dimension\n",
    "        x = self.conv1(x)\n",
    "        x = self.max_pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    @tf.function\n",
    "    def step(self, batch):\n",
    "        \n",
    "        x_batch, y_batch = batch\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass: Compute predictions\n",
    "            y_batch_pred = self(x_batch, training=True)\n",
    "\n",
    "            # Compute the loss value\n",
    "            # (the loss function is configured in `compile()`)\n",
    "            loss = self.compiled_loss(\n",
    "                y_true=y_batch,\n",
    "                y_pred=y_batch_pred,\n",
    "                regularization_losses=self.losses\n",
    "            )\n",
    "\n",
    "        # Compute gradients\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        \n",
    "        # Apply gradients to the model's trainable variables (update weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        \n",
    "        # Update metrics (includes the metric that tracks the loss)\n",
    "        #self.compiled_metrics.update_state(y_batch, y_batch_pred)\n",
    "    \n",
    "    \n",
    "    @tf.function\n",
    "    def train(self, dataset):\n",
    "\n",
    "        for batch in dataset:\n",
    "            self.step(batch)\n",
    "            \n",
    "    \n",
    "    def set_trainable_variables(self, trainable_vars):\n",
    "        \"\"\" Given `trainable_vars` set our `self.trainable_vars` \"\"\"\n",
    "        for model_var, var in zip(self.trainable_variables, trainable_vars):\n",
    "            model_var.assign(var)\n",
    "\n",
    "            \n",
    "    def trainable_vars_as_vector(self):\n",
    "        return tf.concat([tf.reshape(var, [-1]) for var in self.trainable_variables], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ead5a6c",
   "metadata": {},
   "source": [
    "### Helper function to compile and return the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82ddd2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_and_built_cnn():\n",
    "    cnn = CNN()\n",
    "    \n",
    "    cnn.compile(\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False), # we have softmax\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')]\n",
    "    )\n",
    "    \n",
    "    cnn.build(CNN_BATCH_INPUT)  # EMNIST dataset (None is used for batch size, as it varies)\n",
    "    \n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386f99e0",
   "metadata": {},
   "source": [
    "# Advanced Convolutional Neural Net (CNN) - Large Size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3259d325",
   "metadata": {},
   "source": [
    "A more complex Convolutional Neural Network with three sets of two convolutional layers, each followed by a max-pooling layer, and two dense layers with dropout for classification. Designed for 28x28 grayscale images. It has 2,592,202 weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee5705b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedCNN(tf.keras.Model):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(AdvancedCNN, self).__init__()\n",
    "        \n",
    "        self.reshape = layers.Reshape(CNN_INPUT_RESHAPE)\n",
    "        \n",
    "        self.conv1 = layers.Conv2D(64, kernel_size=3, activation='relu', padding='same')\n",
    "        self.conv2 = layers.Conv2D(64, kernel_size=3, activation='relu', padding='same')\n",
    "        self.max_pool1 = layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        \n",
    "        self.conv3 = layers.Conv2D(128, kernel_size=3, activation='relu', padding='same')\n",
    "        self.conv4 = layers.Conv2D(128, kernel_size=3, activation='relu', padding='same')\n",
    "        self.max_pool2 = layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        \n",
    "        self.conv5 = layers.Conv2D(256, kernel_size=3, activation='relu', padding='same')\n",
    "        self.conv6 = layers.Conv2D(256, kernel_size=3, activation='relu', padding='same')\n",
    "        self.max_pool3 = layers.MaxPooling2D(pool_size=(2, 2))\n",
    "\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.dense1 = layers.Dense(512, activation='relu')\n",
    "        self.dropout1 = layers.Dropout(0.5)\n",
    "        self.dense2 = layers.Dense(512, activation='relu')\n",
    "        self.dropout2 = layers.Dropout(0.5)\n",
    "        self.dense3 = layers.Dense(num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        x = self.reshape(inputs)  # Add a channel dimension\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.max_pool1(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.max_pool2(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.max_pool3(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dropout1(x, training=training)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dropout2(x, training=training)\n",
    "        x = self.dense3(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    @tf.function\n",
    "    def step(self, batch):\n",
    "        \n",
    "        x_batch, y_batch = batch\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass: Compute predictions\n",
    "            y_batch_pred = self(x_batch, training=True)\n",
    "\n",
    "            # Compute the loss value\n",
    "            # (the loss function is configured in `compile()`)\n",
    "            loss = self.compiled_loss(\n",
    "                y_true=y_batch,\n",
    "                y_pred=y_batch_pred,\n",
    "                regularization_losses=self.losses\n",
    "            )\n",
    "\n",
    "        # Compute gradients\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        \n",
    "        # Apply gradients to the model's trainable variables (update weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        \n",
    "        # Update metrics (includes the metric that tracks the loss)\n",
    "        #self.compiled_metrics.update_state(y_batch, y_batch_pred)\n",
    "    \n",
    "    \n",
    "    @tf.function\n",
    "    def train(self, dataset):\n",
    "\n",
    "        for batch in dataset:\n",
    "            self.step(batch)\n",
    "            \n",
    "    \n",
    "    def set_trainable_variables(self, trainable_vars):\n",
    "        \"\"\" Given `trainable_vars` set our `self.trainable_vars` \"\"\"\n",
    "        for model_var, var in zip(self.trainable_variables, trainable_vars):\n",
    "            model_var.assign(var)\n",
    "\n",
    "            \n",
    "    def trainable_vars_as_vector(self):\n",
    "        return tf.concat([tf.reshape(var, [-1]) for var in self.trainable_variables], axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1289f0",
   "metadata": {},
   "source": [
    "### Helper function to compile and return the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a705fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_and_built_advanced_cnn():\n",
    "    advanced_cnn = AdvancedCNN()\n",
    "    \n",
    "    advanced_cnn.compile(\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False), # we have softmax\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')]\n",
    "    )\n",
    "    \n",
    "    advanced_cnn.build(CNN_BATCH_INPUT)  # EMNIST dataset (None is used for batch size, as it varies)\n",
    "    \n",
    "    return advanced_cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c454f52",
   "metadata": {},
   "source": [
    "### Average NN weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7cb196c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_client_weights(client_models):\n",
    "    # client_weights[0] the trainable variables of Client 0 (a list of tf.Variable)\n",
    "    client_weights = [model.trainable_variables for model in client_models]\n",
    "\n",
    "    # concise solution. per layer. `layer_weight_tensors` corresponds to a list of tensors of a layer\n",
    "    avg_weights = [\n",
    "        tf.reduce_mean(layer_weight_tensors, axis=0)\n",
    "        for layer_weight_tensors in zip(*client_weights)\n",
    "    ]\n",
    "\n",
    "    return avg_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9a13e6",
   "metadata": {},
   "source": [
    "# Functional Dynamic Averaging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f2a1b5",
   "metadata": {},
   "source": [
    "We follow the Functional Dynamic Averaging (FDA) scheme. Let the mean model be\n",
    "\n",
    "$$ \\overline{w_t} = \\frac{1}{k} \\sum_{i=1}^{k} w_t^{(i)} $$\n",
    "\n",
    "where $ w_t^{(i)} $ is the model at time $ t $ in some round in the $i$-th learner.\n",
    "\n",
    "Local models are trained independently and cooperatively and we want to monitor the Round Terminating Conditon (**RTC**):\n",
    "\n",
    "$$ \\frac{1}{k} \\sum_{i=1}^{k} \\lVert w_t^{(i)} - \\overline{w_t} \\rVert_2^2  \\leq \\Theta $$\n",
    "\n",
    "where the left-hand side is the **model variance**, and threshold $\\Theta$ is a hyperparameter of the FDA, defined at the beginning of the round; it may change at each round. When the monitoring logic cannot guarantee the validity of RTC, the round terminates. All local models are pulled into `tff.SERVER`, and $\\bar{w_t}$ is set to their average. Then, another round begins."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb0ccbb",
   "metadata": {},
   "source": [
    "### Monitoring the RTC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba6e34b",
   "metadata": {},
   "source": [
    "FDA monitors the RTC by applying techniques from Functionary [Functional Geometric Averaging](http://users.softnet.tuc.gr/~minos/Papers/edbt19.pdf). We first restate the problem of monitoring RTC into the standard distributed stream monitoring formulation. Let\n",
    "\n",
    "$$ S(t) =  \\frac{1}{k} \\sum_{i=1}^{k} S_i(t) $$\n",
    "\n",
    "where $ S(t) \\in \\mathbb{R}^n $ be the \"global state\" of the system and $ S_i(t) \\in \\mathbb{R}^n $ the \"local states\". The goal is to monitor the threshold condition on the global state in the form $ F(S(t)) \\leq \\Theta $ where $ F : \\mathbb{R}^n \\to \\mathbb{R} $ a non-linear function. Let\n",
    "\n",
    "$$ \\Delta_t^{(i)} = w_t^{(i)} - w_{t_0}^{(i)} $$\n",
    "\n",
    "be the update at the $ i $-th learner, that is, the change to the local model at time $t$ since the beginning of the current round at time $t_0$. Let the average update be\n",
    "\n",
    "$$ \\overline{\\Delta_t} = \\frac{1}{k} \\sum_{i=1}^{k} \\Delta_t^{(i)} $$\n",
    "\n",
    "it follows that the variance can be written as\n",
    "\n",
    "$$ \\frac{1}{k} \\sum_{i=1}^{k} \\lVert w_t^{(i)} - \\overline{w_t} \\rVert_2^2 = \\Big( \\frac{1}{k} \\sum_{i=1}^{k} \\lVert \\Delta_t^{(i)} \\rVert_2^2 \\Big) - \\lVert \\overline{\\Delta_t} \\rVert_2^2 $$\n",
    "\n",
    "So, conceptually, if we define\n",
    "$$ S_i(t) = \\begin{bmatrix}\n",
    "           \\lVert \\Delta_t^{(i)} \\rVert_2^2 \\\\\n",
    "           \\Delta_t^{(i)}\n",
    "         \\end{bmatrix} \\quad \\text{and} \\quad\n",
    "         F(\\begin{bmatrix}\n",
    "           v \\\\\n",
    "           \\bf{x}\n",
    "         \\end{bmatrix}) = v - \\lVert \\bf{x} \\rVert_2^2 $$\n",
    "\n",
    "The RTC is equivalent to condition $$ F(S(t)) \\leq \\Theta $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2989181",
   "metadata": {},
   "source": [
    "### Server - Clients synchronization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5f00c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def synchronize(server_cnn, client_cnns):\n",
    "    # server average\n",
    "    server_cnn.set_trainable_variables(average_client_weights(client_cnns))\n",
    "    \n",
    "    # synchronize clients\n",
    "    for client_cnn in client_cnns:\n",
    "        client_cnn.set_trainable_variables(server_cnn.trainable_variables)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26a0df4",
   "metadata": {},
   "source": [
    "## 1️⃣ Naive FDA\n",
    "\n",
    "In the naive approach, we eliminate the update vector from the local state (i.e. recuce the dimension to 0). Define local state as\n",
    "\n",
    "$$ S_i(t) = \\lVert \\Delta_t^{(i)} \\rVert_2^2 \\in \\mathbb{R}$$ \n",
    "\n",
    "and the identity function\n",
    "\n",
    "$$ F(v) = v $$\n",
    "\n",
    "It is trivial that $ F(S(t)) \\leq \\Theta $ implies the RTC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6875d47",
   "metadata": {},
   "source": [
    "### Client Steps\n",
    "\n",
    "The number of steps depends on the dataset, i.e., `.take(num)` call on `tf.data.Dataset` creation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0cf704c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def steps_naive(last_sync_cnn, client_cnn, client_dataset):\n",
    "    # number of steps depend on `.take()` from `dataset`\n",
    "    client_cnn.train(client_dataset)\n",
    "    \n",
    "    Delta_i = client_cnn.trainable_vars_as_vector() - last_sync_cnn.trainable_vars_as_vector()\n",
    "    \n",
    "    Delta_i_euc_norm_squared = tf.reduce_sum(tf.square(Delta_i)) # ||D(t)_i||^2\n",
    "    \n",
    "    return Delta_i_euc_norm_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2013ea",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4780782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_naive(S):\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2c6b4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def run_federated_simulation_naive(server_cnn, client_cnns, federated_dataset,\n",
    "                                   num_epochs, theta, epoch_fda_steps):\n",
    "    \n",
    "    print(\"retracing naive\")\n",
    "    \n",
    "    total_rounds = 0\n",
    "    total_fda_steps = 0\n",
    "    \n",
    "    round_fda_steps = tf.constant(0, shape=(), dtype=tf.int32)\n",
    "    epoch_count = tf.constant(0, shape=(), dtype=tf.int32)\n",
    "    \n",
    "    S = tf.constant(0., shape=(), dtype=tf.float32)\n",
    "    \n",
    "    while epoch_count < num_epochs:\n",
    "        \n",
    "        while F_naive(S) <= theta:\n",
    "            S_i_clients = []\n",
    "\n",
    "            # client steps (number depends on `federated_dataset`, i.e., `.take(num)`)\n",
    "            for client_cnn, client_dataset in zip(client_cnns, federated_dataset):\n",
    "                Delta_i_euc_norm_squared = steps_naive(server_cnn, client_cnn, client_dataset)\n",
    "                S_i_clients.append(Delta_i_euc_norm_squared)\n",
    "                \n",
    "            S = tf.reduce_mean(S_i_clients)\n",
    "            \n",
    "            round_fda_steps += 1\n",
    "            total_fda_steps += 1\n",
    "            \n",
    "            if round_fda_steps == epoch_fda_steps:\n",
    "                epoch_count += 1\n",
    "                round_fda_steps = tf.constant(0, shape=(), dtype=tf.int32)\n",
    "                \n",
    "                if epoch_count == num_epochs:\n",
    "                    break\n",
    "        \n",
    "        \n",
    "        \"\"\"------------------------------test--------------------------------------------\"\"\"\n",
    "        Delta_i_clients = [\n",
    "            tf.subtract(client_cnn.trainable_vars_as_vector(), server_cnn.trainable_vars_as_vector()) \n",
    "            for client_cnn in client_cnns\n",
    "        ] #test\n",
    "        actual_S_2 = tf.reduce_sum(tf.square(tf.reduce_mean(Delta_i_clients, axis=0))) #test\n",
    "        \"\"\"------------------------------test--------------------------------------------\"\"\"\n",
    "        \n",
    "        # server average\n",
    "        server_cnn.set_trainable_variables(average_client_weights(client_cnns))\n",
    "        \n",
    "        \"\"\"------------------------------test--------------------------------------------\"\"\"\n",
    "        tf.print(\"Naive Epoch count: \", epoch_count, \" Total fda steps: \", total_fda_steps, output_stream=sys.stdout)\n",
    "        tf.print(\"Est var: \", S, \" Actual S_2 (Assumed 0): \", actual_S_2, \" Actual var: \", variance(client_cnns, server_cnn), output_stream=sys.stdout)\n",
    "        tf.print(\"\\n\", output_stream=sys.stdout)\n",
    "        \"\"\"------------------------------test--------------------------------------------\"\"\"\n",
    "        \n",
    "        # reset variance approx\n",
    "        S = tf.constant(0., shape=(), dtype=tf.float32)\n",
    "\n",
    "        # synchronize clients\n",
    "        for client_cnn in client_cnns:\n",
    "            client_cnn.set_trainable_variables(server_cnn.trainable_variables)\n",
    "            \n",
    "        total_rounds += 1\n",
    "    \n",
    "    return total_rounds, total_fda_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc6d3f1",
   "metadata": {},
   "source": [
    "## 2️⃣ Linear FDA\n",
    "\n",
    "In the linear case, we reduce the update vector to a scalar, $ \\xi \\Delta_t^{(i)} \\in \\mathbb{R}$, where $ \\xi $ is any unit vector.\n",
    "\n",
    "Define the local state to be \n",
    "\n",
    "$$ S_i(t) = \\begin{bmatrix}\n",
    "           \\lVert \\Delta_t^{(i)} \\rVert_2^2 \\\\\n",
    "           \\xi \\Delta_t^{(i)}\n",
    "         \\end{bmatrix} \\in \\mathbb{R}^2 $$\n",
    "\n",
    "Also, define \n",
    "\n",
    "$$ F(v, x) = v - x^2 $$\n",
    "\n",
    "The RTC is equivalent to condition \n",
    "\n",
    "$$ F(S(t)) \\leq \\Theta $$\n",
    "\n",
    "A random choice of $ \\xi $ is likely to perform poorly (terminate round prematurely), as it wil likely be close to orthogonal to $ \\overline{\\Delta_t} $. A good choice would be a vector $ \\xi $ correlated to $ \\overline{\\Delta_t} $. A heuristic choice is to take $ \\overline{\\Delta_{t_0}} $ (after scaling it to norm 1), i.e., the update vector right before the current round started. All nodes can estimate this without communication, as $ \\overline{w_{t_0}} - \\overline{w_{t_{-1}}} $, the difference of the last two models pushed by the Server. Hence, \n",
    "\n",
    "$$ \\xi = \\frac{\\overline{w_{t_0}} - \\overline{w_{t_{-1}}}}{\\lVert \\overline{w_{t_0}} - \\overline{w_{t_{-1}}} \\rVert_2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbfb12c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def ksi_unit_fn(w_t0, w_tminus1):\n",
    "    \n",
    "    if tf.reduce_all(tf.equal(w_t0, w_tminus1)):\n",
    "        # if equal then ksi becomes a random vector (will only happen in round 1)\n",
    "        ksi = tf.random.normal(shape=w_t0.shape)\n",
    "    else:\n",
    "        ksi = w_t0 - w_tminus1\n",
    "\n",
    "    # Normalize and return\n",
    "    return tf.divide(ksi, tf.norm(ksi))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b66f11",
   "metadata": {},
   "source": [
    "### Client Steps\n",
    "\n",
    "The number of steps depends on the dataset, i.e., `.take(num)` call on `tf.data.Dataset` creation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0ad6c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def steps_linear(cnn_tminus, cnn_t0, client_cnn, client_dataset):\n",
    "    # number of steps depend on `.take()` from `dataset`\n",
    "    client_cnn.train(client_dataset)\n",
    "    \n",
    "    Delta_i = client_cnn.trainable_vars_as_vector() - cnn_t0.trainable_vars_as_vector()\n",
    "    \n",
    "    #||D(t)_i||^2 , shape = (1,) \n",
    "    Delta_i_euc_norm_squared = tf.reduce_sum(tf.square(Delta_i)) # ||D(t)_i||^2\n",
    "    \n",
    "    # heuristic unit vector ksi\n",
    "    ksi = ksi_unit_fn(cnn_t0.trainable_vars_as_vector(), cnn_tminus.trainable_vars_as_vector())\n",
    "    \n",
    "    # ksi * Delta_i (* is dot) , shape = ()\n",
    "    ksi_Delta_i = tf.reduce_sum(tf.multiply(ksi, Delta_i))\n",
    "    \n",
    "    return Delta_i_euc_norm_squared, ksi_Delta_i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284c734b",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d8dd008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_linear(S_1, S_2):\n",
    "    return S_1 - S_2**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7e87dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def run_federated_simulation_linear(previous_server_cnn, server_cnn, client_cnns, federated_dataset,\n",
    "                                   num_epochs, theta, epoch_fda_steps):\n",
    "    \n",
    "    print(\"retracing linear\")\n",
    "    \n",
    "    total_rounds = 0\n",
    "    total_fda_steps = 0\n",
    "    \n",
    "    round_fda_steps = tf.constant(0, shape=(), dtype=tf.int32)\n",
    "    epoch_count = tf.constant(0, shape=(), dtype=tf.int32)\n",
    "    \n",
    "    S_1 = tf.constant(0., shape=(), dtype=tf.float32)\n",
    "    S_2 = tf.constant(0., shape=(), dtype=tf.float32)\n",
    "    \n",
    "    while epoch_count < num_epochs:\n",
    "        \n",
    "        while F_linear(S_1, S_2) <= theta:\n",
    "            euc_norm_squared_clients = []\n",
    "            ksi_delta_clients = []\n",
    "\n",
    "            # client steps (number depends on `federated_dataset`, i.e., `.take(num)`)\n",
    "            for client_cnn, client_dataset in zip(client_cnns, federated_dataset):\n",
    "                Delta_i_euc_norm_squared, ksi_Delta_i = steps_linear(\n",
    "                    previous_server_cnn, server_cnn, client_cnn, client_dataset\n",
    "                )\n",
    "                \n",
    "                euc_norm_squared_clients.append(Delta_i_euc_norm_squared)\n",
    "                ksi_delta_clients.append(ksi_Delta_i)\n",
    "            \n",
    "            S_1 = tf.reduce_mean(euc_norm_squared_clients)\n",
    "            S_2 = tf.reduce_mean(ksi_delta_clients)\n",
    "            \n",
    "            round_fda_steps += 1\n",
    "            total_fda_steps += 1\n",
    "            \n",
    "            if round_fda_steps == epoch_fda_steps:\n",
    "                epoch_count += 1\n",
    "                round_fda_steps = tf.constant(0, shape=(), dtype=tf.int32)\n",
    "                \n",
    "                if epoch_count == num_epochs:\n",
    "                    break\n",
    "        \n",
    "        \n",
    "        \"\"\"------------------------------test--------------------------------------------\"\"\"\n",
    "        Delta_i_clients = [\n",
    "            tf.subtract(client_cnn.trainable_vars_as_vector(), server_cnn.trainable_vars_as_vector()) \n",
    "            for client_cnn in client_cnns\n",
    "        ] #test\n",
    "        actual_S_2 = tf.reduce_sum(tf.square(tf.reduce_mean(Delta_i_clients, axis=0))) #test\n",
    "        \"\"\"------------------------------test--------------------------------------------\"\"\"\n",
    "        \n",
    "        # last server model (previous sync)\n",
    "        previous_server_cnn.set_trainable_variables(server_cnn.trainable_variables)\n",
    "        \n",
    "        # server average\n",
    "        server_cnn.set_trainable_variables(average_client_weights(client_cnns))\n",
    "        \n",
    "        \n",
    "        \"\"\"------------------------------test--------------------------------------------\"\"\"\n",
    "        tf.print(\"Linear Epoch count: \", epoch_count, \" Total fda steps: \", total_fda_steps, output_stream=sys.stdout)\n",
    "        tf.print(\"Est var: \", F_linear(S_1, S_2), \" Actual S_2: \", actual_S_2, \" Approx S_2: \", S_2**2, \" Actual var: \", variance(client_cnns, server_cnn), output_stream=sys.stdout)\n",
    "        tf.print(\"\\n\", output_stream=sys.stdout)\n",
    "        \"\"\"------------------------------test--------------------------------------------\"\"\"\n",
    "        \n",
    "        # reset variance approx\n",
    "        S_1 = tf.constant(0., shape=(), dtype=tf.float32)\n",
    "        S_2 = tf.constant(0., shape=(), dtype=tf.float32)\n",
    "\n",
    "        # synchronize clients\n",
    "        for client_cnn in client_cnns:\n",
    "            client_cnn.set_trainable_variables(server_cnn.trainable_variables)\n",
    "            \n",
    "        total_rounds += 1\n",
    "    \n",
    "    return total_rounds, total_fda_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b28f1a",
   "metadata": {},
   "source": [
    "## 3️⃣ Sketch FDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3a6434",
   "metadata": {},
   "source": [
    "An optimal estimator for $ \\lVert \\overline{\\Delta_t} \\rVert_2^2  $ can be obtained by employing AMS sketches. An AMS sketch of a vector $ v \\in \\mathbb{R}^M $ is a $ d \\times m $ real matrix\n",
    "\n",
    "$$ \\Xi = \\text{sk}(v) = \\begin{bmatrix}\n",
    "           \\Xi_1 \\\\\n",
    "           \\Xi_2 \\\\\n",
    "           \\vdots \\\\\n",
    "           \\Xi_d \n",
    "         \\end{bmatrix} $$\n",
    "         \n",
    "where $ d \\cdot m \\ll M$. Operator sk($ \\cdot $) is linear, i.e., let $a, b \\in \\mathbb{R}$ and $v_1, v_2 \\in \\mathbb{R}^N$ then \n",
    "\n",
    "$$ \\text{sk}(a v_1 + b v_2) = a \\; \\text{sk}(v_1) + b \\; \\text{sk}(v_2)  $$\n",
    "\n",
    "Also, sk($ v $) can be computed in $ \\mathcal{O}(dN) $ steps.\n",
    "\n",
    "The interesting property of AMS sketches is that the function \n",
    "\n",
    "$$ M(sk(\\textbf{v})) = \\underset{i=1,...,d}{\\text{median}} \\; \\lVert \\boldsymbol{\\Xi}_i \\rVert_2^2  $$ \n",
    "\n",
    "is an excellent estimator of the Euclidean norm of **v** (within relative $\\epsilon$-error):\n",
    "\n",
    "$$ M(sk(\\textbf{v})) \\; \\in (1 \\pm \\epsilon) \\lVert \\textbf{v} \\rVert_2^2 \\; \\; \\text{with probability at least} \\; (1-\\delta) $$\n",
    "\n",
    "where $m = \\mathcal{O}(\\frac{1}{\\epsilon^2})$ and $d = \\mathcal{O}(\\log \\frac{1}{\\delta})$\n",
    "            \n",
    "Moreover, let $\\boldsymbol{\\Xi} \\in \\mathbb{R}^{d \\times m}$ and $ k \\in \\mathbb{R}$. It can be proven that\n",
    "\n",
    "$$ M( \\frac{1}{k} \\boldsymbol{\\Xi}) = \\frac{1}{k^2} M(\\boldsymbol{\\Xi}) $$\n",
    "\n",
    "Let's investigate a little further on how this helps us. The $i$-th client computes $ sk(\\Delta_t^{(i)}) $ and sends it to the server. Notice\n",
    "\n",
    "$$ M\\big(sk(\\Delta_t^{(1)}) + sk(\\Delta_t^{(2)}) + ... + sk(\\Delta_t^{(k)}) \\big) = M\\Big( \\text{sk}\\big( \\sum_{i=1}^{k} \\Delta_t^{(i)} \\big) \\Big)$$\n",
    "\n",
    "Remember that\n",
    "\n",
    "$$ \\overline{\\boldsymbol{\\Delta}}_t = \\frac{1}{k} \\sum_{i=1}^{k} \\boldsymbol{\\Delta}_t^{(i)} $$\n",
    "\n",
    "Then\n",
    "            \n",
    "$$ M\\Big( \\text{sk}\\big( \\overline{\\boldsymbol{\\Delta}}_t \\big) \\Big) = M\\Big( \\text{sk}\\big( \\frac{1}{k} \\sum_{i=1}^{k} \\boldsymbol{\\Delta}_t^{(i)} \\big) \\Big) = \\frac{1}{k^2} M\\Big( \\text{sk}\\big( \\sum_{i=1}^{k} \\boldsymbol{\\Delta}_t^{(i)} \\big) \\Big) $$\n",
    "\n",
    "\n",
    "Which means that \n",
    "\n",
    "$$ \\frac{1}{k^2} M\\Big( \\text{sk}\\big( \\sum_{i=1}^{k} \\boldsymbol{\\Delta}_t^{(i)} \\big) \\Big) \\in (1 \\pm \\epsilon) \\lVert \\overline{\\boldsymbol{\\Delta}}_t \\rVert_2^2 \\; \\; \\text{w.p. at least} \\; (1-\\delta) $$\n",
    "\n",
    "In the monitoring process it is essential that we do not overestimate $ \\lVert \\overline{\\Delta_t} \\rVert_2^2 $ because we would then underestimate the variance which would potentially result in actual varience exceeding $ \\Theta$ without us noticing it. With this in mind,\n",
    "\n",
    "$$ \\frac{1}{k^2} M\\Big( \\text{sk}\\big( \\sum_{i=1}^{k} \\Delta_t^{(i)} \\big) \\Big) \\leq (1+\\epsilon) \\lVert \\overline{\\Delta_t} \\rVert_2^2 \\quad \\text{with probability at least} \\; (1-\\delta)$$\n",
    "\n",
    "Which means\n",
    "\n",
    "$$ \\frac{1}{(1+\\epsilon)} \\frac{1}{k^2} M\\Big( \\text{sk}\\big( \\sum_{i=1}^{k} \\Delta_t^{(i)} \\big) \\Big) \\leq \\lVert \\overline{\\Delta_t} \\rVert_2^2 \\quad \\text{with probability at least} \\; (1-\\delta)$$\n",
    "\n",
    "Hence, the Server's estimation of $ \\lVert \\overline{\\Delta_t} \\rVert_2^2 $ is\n",
    "\n",
    "$$ \\frac{1}{(1+\\epsilon)} \\frac{1}{k^2} M\\Big( sk(\\Delta_t^{(1)}) + sk(\\Delta_t^{(2)}) + ... + sk(\\Delta_t^{(k)}) \\big) \\Big) $$\n",
    "\n",
    "Define the local state to be \n",
    "\n",
    "$$ S_i(t) = \\begin{bmatrix}\n",
    "           \\lVert \\Delta_t^{(i)} \\rVert_2^2 \\\\\n",
    "           sk(\\Delta_t^{(i)})\n",
    "         \\end{bmatrix} \\in \\mathbb{R}^{1+d \\times m} \\quad \\text{and} \\quad\n",
    "         F(\\begin{bmatrix}\n",
    "           v \\\\\n",
    "           \\Xi\n",
    "         \\end{bmatrix}) = v - \\frac{1}{(1+\\epsilon)}  M(\\Xi) \\quad \\text{where} \\quad \\Xi = \\frac{1}{k} \\sum_{i=1}^{k} sk(\\Delta_t^{(i)}) $$\n",
    "\n",
    "It follows that $ F(S(t)) \\leq \\Theta $ implies that the variance is less or equal to $ \\Theta $ with probability at least $ 1-\\delta $.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db738526",
   "metadata": {},
   "source": [
    "## AMS sketch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94e3bfa",
   "metadata": {},
   "source": [
    "We use `ExtensionType` which is the way to go in order to avoid unecessary graph retracing when passing around `AmsSketch` type 'objects'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7f6b404",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.experimental import ExtensionType\n",
    "\n",
    "class AmsSketch(ExtensionType):\n",
    "    depth: int\n",
    "    width: int\n",
    "    F: tf.Tensor\n",
    "        \n",
    "        \n",
    "    def __init__(self, depth=7, width=1500):\n",
    "        self.depth = depth\n",
    "        self.width = width\n",
    "        self.F = tf.random.uniform(shape=(6, depth), minval=0, maxval=(1 << 31) - 1, dtype=tf.int32)\n",
    "\n",
    "        \n",
    "    @tf.function\n",
    "    def hash31(self, x, a, b):\n",
    "\n",
    "        r = a * x + b\n",
    "        fold = tf.bitwise.bitwise_xor(tf.bitwise.right_shift(r, 31), r)\n",
    "        return tf.bitwise.bitwise_and(fold, 2147483647)\n",
    "    \n",
    "    \n",
    "    @tf.function\n",
    "    def tensor_hash31(self, x, a, b): # GOOD\n",
    "        \"\"\" Assumed that x is tensor shaped (d,) , i.e., a vector (for example, indices, i.e., tf.range(d)) \"\"\"\n",
    "\n",
    "        # Reshape x to have an extra dimension, resulting in a shape of (k, 1)\n",
    "        x_reshaped = tf.expand_dims(x, axis=-1)\n",
    "\n",
    "        # shape=(`v_dim`, 7)\n",
    "        r = tf.multiply(a, x_reshaped) + b\n",
    "\n",
    "        fold = tf.bitwise.bitwise_xor(tf.bitwise.right_shift(r, 31), r)\n",
    "        \n",
    "        return tf.bitwise.bitwise_and(fold, 2147483647)\n",
    "    \n",
    "    \n",
    "    @tf.function\n",
    "    def tensor_fourwise(self, x):\n",
    "        \"\"\" Assumed that x is tensor shaped (d,) , i.e., a vector (for example, indices, i.e., tf.range(d)) \"\"\"\n",
    "        # 1st use the tensor hash31\n",
    "        in1 = self.tensor_hash31(x, self.F[2], self.F[3])  # (`x_dim`, 7)\n",
    "        \n",
    "        # 2nd (notice we swap the first two params, no change really)\n",
    "        in2 = self.tensor_hash31(x, in1, self.F[4])  # (`x_dim`, 7)\n",
    "        \n",
    "        in3 = self.tensor_hash31(x, in2, self.F[5])  # (`x_dim`, 7)\n",
    "        \n",
    "        in4 = tf.bitwise.bitwise_and(in3, 32768)  # (`x_dim`, 7)\n",
    "        \n",
    "        return 2 * (tf.bitwise.right_shift(in4, 15)) - 1  # (`x_dim`, 7)\n",
    "        \n",
    "        \n",
    "    @tf.function\n",
    "    def fourwise(self, x):\n",
    "\n",
    "        result = 2 * (tf.bitwise.right_shift(tf.bitwise.bitwise_and(self.hash31(self.hash31(self.hash31(x, self.F[2], self.F[3]), x, self.F[4]), x, self.F[5]), 32768), 15)) - 1\n",
    "        return result\n",
    "    \n",
    "    \n",
    "    @tf.function\n",
    "    def sketch_for_vector(self, v):\n",
    "        \"\"\" Extremely efficient computation of sketch with only using tensors. \"\"\"\n",
    "        \n",
    "        sketch = tf.zeros(shape=(self.depth, self.width), dtype=tf.float32)\n",
    "        \n",
    "        len_v = v.shape[0]\n",
    "        \n",
    "        pos_tensor = self.tensor_hash31(tf.range(len_v), self.F[0], self.F[1]) % self.width\n",
    "        \n",
    "        v_expand = tf.expand_dims(v, axis=-1)\n",
    "        \n",
    "        deltas_tensor = tf.multiply(tf.cast(self.tensor_fourwise(tf.range(len_v)), dtype=tf.float32), v_expand)\n",
    "        \n",
    "        range_tensor = tf.range(self.depth)\n",
    "        \n",
    "        # Expand dimensions to create a 2D tensor with shape (1, depth)\n",
    "        range_tensor_expanded = tf.expand_dims(range_tensor, 0)\n",
    "\n",
    "        # Use tf.tile to repeat the range `len_v` times\n",
    "        repeated_range_tensor = tf.tile(range_tensor_expanded, [len_v, 1])\n",
    "        \n",
    "        # shape=(`len_v`, 7, 2)\n",
    "        indices = tf.stack([repeated_range_tensor, pos_tensor], axis=-1)\n",
    "        \n",
    "        sketch = tf.tensor_scatter_nd_add(sketch, indices, deltas_tensor)\n",
    "        \n",
    "        return sketch\n",
    "    \n",
    "    \n",
    "    @tf.function\n",
    "    def sketch_for_vector2(self, v):\n",
    "        \"\"\" Bad implementation for tensorflow. \"\"\"\n",
    "\n",
    "        sketch = tf.zeros(shape=(self.depth, self.width), dtype=tf.float32)\n",
    "\n",
    "        for i in tf.range(tf.shape(v)[0], dtype=tf.int32):\n",
    "            pos = self.hash31(i, self.F[0], self.F[1]) % self.width\n",
    "            delta = tf.cast(self.fourwise(i), dtype=tf.float32) * v[i]\n",
    "            indices_to_update = tf.stack([tf.range(self.depth, dtype=tf.int32), pos], axis=1)\n",
    "            sketch = tf.tensor_scatter_nd_add(sketch, indices_to_update, delta)\n",
    "\n",
    "        return sketch\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    @tf.function\n",
    "    def estimate_euc_norm_squared(sketch):\n",
    "\n",
    "        @tf.function\n",
    "        def _median(v):\n",
    "            \"\"\" Median of tensor `v` with shape=(n,). Note: Suboptimal O(nlogn) but it's ok bcz n = `depth`\"\"\"\n",
    "            length = tf.shape(v)[0]\n",
    "            sorted_v = tf.sort(v)\n",
    "            middle = length // 2\n",
    "\n",
    "            return tf.cond(\n",
    "                tf.equal(length % 2, 0),\n",
    "                lambda: (sorted_v[middle - 1] + sorted_v[middle]) / 2.0,\n",
    "                lambda: sorted_v[middle]\n",
    "            )\n",
    "\n",
    "        return _median(tf.reduce_sum(tf.square(sketch), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe92e3b",
   "metadata": {},
   "source": [
    "### Client Steps\n",
    "\n",
    "The number of steps depends on the dataset, i.e., `.take(num)` call on `tf.data.Dataset` creation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34a74388",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def steps_sketch(last_sync_cnn, client_cnn, client_dataset, ams_sketch):\n",
    "    # number of steps depend on `.take()` from `dataset`\n",
    "    client_cnn.train(client_dataset)\n",
    "    \n",
    "    Delta_i = client_cnn.trainable_vars_as_vector() - last_sync_cnn.trainable_vars_as_vector()\n",
    "    \n",
    "    #||D(t)_i||^2 , shape = (1,) \n",
    "    Delta_i_euc_norm_squared = tf.reduce_sum(tf.square(Delta_i)) # ||D(t)_i||^2\n",
    "    \n",
    "    # sketch approx\n",
    "    sketch = ams_sketch.sketch_for_vector(Delta_i)\n",
    "    \n",
    "    return Delta_i_euc_norm_squared, sketch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556ba6cf",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e6b0043a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_sketch(S_1, S_2, epsilon):\n",
    "    \"\"\" `S_1` is mean || ||^2 as usual, S_2 is the `Ξ` as defined in the theoretical analysis above \"\"\"\n",
    "    \n",
    "    return S_1 - (1. / (1. + epsilon)) * AmsSketch.estimate_euc_norm_squared(S_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd3e3ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t(S_2, epsilon):\n",
    "    \n",
    "    return (1. / (1. + epsilon)) * AmsSketch.estimate_euc_norm_squared(S_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b9f520f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def run_federated_simulation_sketch(server_cnn, client_cnns, federated_dataset, num_epochs, \n",
    "                                    theta, epoch_fda_steps, ams_sketch, epsilon):\n",
    "    \n",
    "    print(\"retracing sketch\")\n",
    "    \n",
    "    total_rounds = 0\n",
    "    total_fda_steps = 0\n",
    "    \n",
    "    round_fda_steps = tf.constant(0, shape=(), dtype=tf.int32)\n",
    "    epoch_count = tf.constant(0, shape=(), dtype=tf.int32)\n",
    "    \n",
    "    S_1 = tf.constant(0., shape=(), dtype=tf.float32)\n",
    "    S_2 = tf.zeros(shape=(ams_sketch.depth, ams_sketch.width), dtype=tf.float32)\n",
    "    \n",
    "    while epoch_count < num_epochs:\n",
    "        \n",
    "        while F_sketch(S_1, S_2, epsilon) <= theta:\n",
    "            euc_norm_squared_clients = []\n",
    "            sketch_clients = []\n",
    "\n",
    "            # client steps (number depends on `federated_dataset`, i.e., `.take(num)`)\n",
    "            for client_cnn, client_dataset in zip(client_cnns, federated_dataset):\n",
    "                Delta_i_euc_norm_squared, sketch = steps_sketch(\n",
    "                    server_cnn, client_cnn, client_dataset, ams_sketch\n",
    "                )\n",
    "                \n",
    "                euc_norm_squared_clients.append(Delta_i_euc_norm_squared)\n",
    "                sketch_clients.append(sketch)\n",
    "            \n",
    "            S_1 = tf.reduce_mean(euc_norm_squared_clients)\n",
    "            S_2 = tf.reduce_mean(sketch_clients, axis=0)  # shape=(`depth`, width`). See `Ξ` in theoretical analysis\n",
    "            \n",
    "            round_fda_steps += 1\n",
    "            total_fda_steps += 1\n",
    "            \n",
    "            if round_fda_steps == epoch_fda_steps:\n",
    "                epoch_count += 1\n",
    "                round_fda_steps = tf.constant(0, shape=(), dtype=tf.int32)\n",
    "                \n",
    "                if epoch_count == num_epochs:\n",
    "                    break\n",
    "        \n",
    "        \n",
    "        \"\"\"------------------------------test--------------------------------------------\"\"\"\n",
    "        Delta_i_clients = [\n",
    "            tf.subtract(client_cnn.trainable_vars_as_vector(), server_cnn.trainable_vars_as_vector()) \n",
    "            for client_cnn in client_cnns\n",
    "        ] #test\n",
    "        actual_S_2 = tf.reduce_sum(tf.square(tf.reduce_mean(Delta_i_clients, axis=0))) #test\n",
    "        \"\"\"------------------------------test--------------------------------------------\"\"\"\n",
    "        \n",
    "        # server average\n",
    "        server_cnn.set_trainable_variables(average_client_weights(client_cnns))\n",
    "        \n",
    "        \"\"\"------------------------------test--------------------------------------------\"\"\"\n",
    "        tf.print(\"Sketch Epoch count: \", epoch_count, \" Total fda steps: \", total_fda_steps, output_stream=sys.stdout)\n",
    "        #tf.print(\"Naive Epoch count: \", epoch_count, output_stream=sys.stdout)\n",
    "        tf.print(\"Est var: \", F_sketch(S_1, S_2, epsilon), \" Actual S_2: \", actual_S_2, \" Apprxo S_2\", t(S_2, epsilon),  \" Actual var: \", variance(client_cnns, server_cnn), output_stream=sys.stdout)\n",
    "        tf.print(\"\\n\", output_stream=sys.stdout)\n",
    "        \"\"\"------------------------------test--------------------------------------------\"\"\"\n",
    "        \n",
    "        # reset variance approx\n",
    "        S_1 = tf.constant(0., shape=(), dtype=tf.float32)\n",
    "        S_2 = tf.zeros(shape=(ams_sketch.depth, ams_sketch.width), dtype=tf.float32)\n",
    "\n",
    "        # synchronize clients\n",
    "        for client_cnn in client_cnns:\n",
    "            client_cnn.set_trainable_variables(server_cnn.trainable_variables)\n",
    "            \n",
    "        total_rounds += 1\n",
    "    \n",
    "    return total_rounds, total_fda_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d998e29",
   "metadata": {},
   "source": [
    "# Simulation tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615142b0",
   "metadata": {},
   "source": [
    "###  Basic test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "94d94680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_test(NUM_EPOCHS, NUM_STEPS_UNTIL_RTC_CHECK, NUM_CLIENTS, BATCH_SIZE, \n",
    "               THETA, EPSILON, ams_sketch, client_slices_train, seed):\n",
    "    \"\"\" One test for Naive,Linear,Sketch. Returns metrics \"\"\"\n",
    "    \n",
    "    num_epochs = tf.constant(NUM_EPOCHS, shape=(), dtype=tf.int32)\n",
    "    theta = tf.constant(THETA, shape=(), dtype=tf.float32)\n",
    "    \n",
    "    # for sketch\n",
    "    epsilon = tf.constant(EPSILON, shape=(), dtype=tf.float32) # new\n",
    "    \n",
    "    \n",
    "    epoch_client_batches = (n_train / BATCH_SIZE) / NUM_CLIENTS\n",
    "    epoch_max_fda_steps = epoch_client_batches / NUM_STEPS_UNTIL_RTC_CHECK\n",
    "    epoch_max_fda_steps = tf.constant(int(epoch_max_fda_steps), shape=(), dtype=tf.int32)\n",
    "    \n",
    "    basic_test_metrics = []\n",
    "    \n",
    "    \"\"\" --------------- Naive ----------------------------------\"\"\"\n",
    "    \n",
    "    # 1. tf.data.Dataset (we create it again because we want determinism)\n",
    "\n",
    "    federated_dataset = create_federated_data(\n",
    "        client_slices_train=client_slices_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle_buffer_size=int(n_train/NUM_CLIENTS),\n",
    "        num_steps_until_rtc_check=NUM_STEPS_UNTIL_RTC_CHECK,\n",
    "        seed=seed\n",
    "    )\n",
    "\n",
    "    # 2. Models init - Sync\n",
    "\n",
    "    client_cnns = [\n",
    "        get_compiled_and_built_advanced_cnn() for _ in range(NUM_CLIENTS)\n",
    "    ]\n",
    "\n",
    "    server_cnn = get_compiled_and_built_advanced_cnn()\n",
    "    \n",
    "    #synchronize before starting\n",
    "    synchronize(server_cnn, client_cnns)\n",
    "\n",
    "    # 3. Run \n",
    "\n",
    "    total_rounds, total_fda_steps = run_federated_simulation_naive(\n",
    "        server_cnn, \n",
    "        client_cnns, \n",
    "        federated_dataset, \n",
    "        num_epochs, \n",
    "        theta,\n",
    "        epoch_max_fda_steps\n",
    "    )\n",
    "    \n",
    "    # compute metrics\n",
    "    \n",
    "    _, acc = server_cnn.evaluate(test_dataset, verbose=0)\n",
    "\n",
    "    metrics = create_metrics_dict(\n",
    "        fda_name=\"naive\", \n",
    "        n_train=n_train, \n",
    "        dataset_name=\"EMNIST\", \n",
    "        input_pixels=784, \n",
    "        seed=seed, \n",
    "        epochs=NUM_EPOCHS, \n",
    "        num_clients=NUM_CLIENTS, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        steps_in_one_fda_step=NUM_STEPS_UNTIL_RTC_CHECK, \n",
    "        theta=THETA, \n",
    "        total_fda_steps=total_fda_steps.numpy(),\n",
    "        num_weights=count_weights(server_cnn),\n",
    "        total_rounds=total_rounds.numpy(), \n",
    "        final_accuracy=acc, \n",
    "        sketch_width=None, \n",
    "        sketch_depth=None\n",
    "    )\n",
    "    \n",
    "    basic_test_metrics.append(metrics)\n",
    "\n",
    "    del federated_dataset, server_cnn, client_cnns, total_rounds, total_fda_steps, acc\n",
    "    \n",
    "    \n",
    "    \"\"\" --------------- Linear ----------------------------------\"\"\"\n",
    "\n",
    "    # 1. tf.data.Dataset (we create it again because we want determinism)\n",
    "\n",
    "    federated_dataset = create_federated_data(\n",
    "        client_slices_train=client_slices_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle_buffer_size=int(n_train/NUM_CLIENTS),\n",
    "        num_steps_until_rtc_check=NUM_STEPS_UNTIL_RTC_CHECK,\n",
    "        seed=seed\n",
    "    )\n",
    "\n",
    "    # 2. Models init - Sync\n",
    "\n",
    "    client_cnns = [\n",
    "        get_compiled_and_built_advanced_cnn() for _ in range(NUM_CLIENTS)\n",
    "    ]\n",
    "\n",
    "    previous_server_cnn = get_compiled_and_built_advanced_cnn()\n",
    "\n",
    "    server_cnn = get_compiled_and_built_advanced_cnn()\n",
    "    \n",
    "    #synchronize before starting\n",
    "    synchronize(server_cnn, client_cnns)\n",
    "    previous_server_cnn.set_trainable_variables(server_cnn.trainable_variables)\n",
    "\n",
    "    # 3. Run \n",
    "\n",
    "    total_rounds, total_fda_steps = run_federated_simulation_linear(\n",
    "        previous_server_cnn,\n",
    "        server_cnn, \n",
    "        client_cnns, \n",
    "        federated_dataset, \n",
    "        num_epochs, \n",
    "        theta,\n",
    "        epoch_max_fda_steps\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # 4. compute metrics\n",
    "    \n",
    "    loss, acc = server_cnn.evaluate(test_dataset, verbose=0)\n",
    "\n",
    "    metrics = create_metrics_dict(\n",
    "        fda_name=\"linear\", \n",
    "        n_train=n_train, \n",
    "        dataset_name=\"EMNIST\", \n",
    "        input_pixels=784, \n",
    "        seed=seed, \n",
    "        epochs=NUM_EPOCHS, \n",
    "        num_clients=NUM_CLIENTS, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        steps_in_one_fda_step=NUM_STEPS_UNTIL_RTC_CHECK, \n",
    "        theta=THETA, \n",
    "        total_fda_steps=total_fda_steps.numpy(),\n",
    "        num_weights=count_weights(server_cnn),\n",
    "        total_rounds=total_rounds.numpy(), \n",
    "        final_accuracy=acc, \n",
    "        sketch_width=None, \n",
    "        sketch_depth=None\n",
    "    )\n",
    "    \n",
    "    basic_test_metrics.append(metrics)\n",
    "\n",
    "    del federated_dataset, server_cnn, previous_server_cnn, client_cnns, total_rounds, total_fda_steps, acc\n",
    "\n",
    "    \n",
    "    \"\"\" ------------------------ Sketch ----------------------\"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    federated_dataset = create_federated_data(\n",
    "        client_slices_train=client_slices_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle_buffer_size=int(n_train/NUM_CLIENTS),\n",
    "        num_steps_until_rtc_check=NUM_STEPS_UNTIL_RTC_CHECK,\n",
    "        seed=seed\n",
    "    )\n",
    "\n",
    "    # 2. Models init - Sync\n",
    "\n",
    "    client_cnns = [\n",
    "        get_compiled_and_built_advanced_cnn() for _ in range(NUM_CLIENTS)\n",
    "    ]\n",
    "\n",
    "    server_cnn = get_compiled_and_built_advanced_cnn()\n",
    "    \n",
    "    #synchronize before starting\n",
    "    synchronize(server_cnn, client_cnns)\n",
    "\n",
    "    # 3. Run \n",
    "\n",
    "    total_rounds, total_fda_steps = run_federated_simulation_sketch(\n",
    "        server_cnn=server_cnn, \n",
    "        client_cnns=client_cnns, \n",
    "        federated_dataset=federated_dataset,\n",
    "        num_epochs=num_epochs, \n",
    "        theta=theta, \n",
    "        epoch_fda_steps=epoch_max_fda_steps, \n",
    "        ams_sketch=ams_sketch, \n",
    "        epsilon=epsilon\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # 4. compute metrics\n",
    "    \n",
    "    loss, acc = server_cnn.evaluate(test_dataset, verbose=0)\n",
    "\n",
    "    metrics = create_metrics_dict(\n",
    "        fda_name=\"sketch\", \n",
    "        n_train=n_train, \n",
    "        dataset_name=\"EMNIST\", \n",
    "        input_pixels=784, \n",
    "        seed=seed, \n",
    "        epochs=NUM_EPOCHS, \n",
    "        num_clients=NUM_CLIENTS, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        steps_in_one_fda_step=NUM_STEPS_UNTIL_RTC_CHECK, \n",
    "        theta=THETA, \n",
    "        total_fda_steps=total_fda_steps.numpy(),\n",
    "        num_weights=count_weights(server_cnn),\n",
    "        total_rounds=total_rounds.numpy(), \n",
    "        final_accuracy=acc, \n",
    "        sketch_width=ams_sketch.width, \n",
    "        sketch_depth=ams_sketch.depth\n",
    "    )\n",
    "    \n",
    "    basic_test_metrics.append(metrics)\n",
    "\n",
    "    del federated_dataset, server_cnn, client_cnns, total_rounds, total_fda_steps, acc\n",
    "    \n",
    "    return basic_test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f9f94d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f8f8877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_info_current_test(NUM_EPOCHS, NUM_STEPS_UNTIL_RTC_CHECK, NUM_CLIENTS, THETA, BATCH_SIZE):\n",
    "    print()\n",
    "    print(f\"----------- Current Test --------------\")\n",
    "    print(f\"Num Clients : {NUM_CLIENTS}\")\n",
    "    print(f\"Num Epochs : {NUM_EPOCHS}\")\n",
    "    print(f\"Number of steps until we check RTC : {NUM_STEPS_UNTIL_RTC_CHECK}\")\n",
    "    print(f\"Batch size : {BATCH_SIZE}\")\n",
    "    print(f\"Theta : {THETA}\")\n",
    "    print(\"----------------------------------------\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b2078c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt # new\n",
    "\n",
    "def run_tests(NUM_CLIENTS_LIST, NUM_EPOCHS_LIST, NUM_STEPS_UNTIL_RTC_CHECK_LIST,\n",
    "              BATCH_SIZE_LIST, THETA_LIST, SKETCH_DEPTH, SKETCH_WIDTH, SEED=None):\n",
    "    \n",
    "    \"\"\" --------------- Fixed configurations -------------------\"\"\"\n",
    "\n",
    "    ams_sketch = AmsSketch(\n",
    "        depth=SKETCH_DEPTH,\n",
    "        width=SKETCH_WIDTH\n",
    "    )\n",
    "\n",
    "    EPSILON = 1. / sqrt(SKETCH_WIDTH)\n",
    "    \n",
    "    \n",
    "    \"\"\" --------------- Metrics list ----------------------\"\"\"\n",
    "    \n",
    "    all_metrics = []\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        \"\"\" --------------- Run tests -------------------\"\"\"\n",
    "        for NUM_CLIENTS in NUM_CLIENTS_LIST:\n",
    "            \n",
    "            client_slices_train = create_data_for_clients(NUM_CLIENTS)  # new sliced dataset (diff NUM_CLIENTS)\n",
    "            \n",
    "            for NUM_EPOCHS in NUM_EPOCHS_LIST:\n",
    "                \n",
    "                for NUM_STEPS_UNTIL_RTC_CHECK in NUM_STEPS_UNTIL_RTC_CHECK_LIST:\n",
    "                    \n",
    "                    for BATCH_SIZE in BATCH_SIZE_LIST:\n",
    "                        \n",
    "                        for THETA in THETA_LIST:\n",
    "                            \n",
    "                            print_info_current_test(NUM_EPOCHS, NUM_STEPS_UNTIL_RTC_CHECK, NUM_CLIENTS, THETA, BATCH_SIZE)\n",
    "                            \n",
    "                            basic_test_metrics = basic_test(\n",
    "                                NUM_EPOCHS=NUM_EPOCHS, \n",
    "                                NUM_STEPS_UNTIL_RTC_CHECK=NUM_STEPS_UNTIL_RTC_CHECK,\n",
    "                                NUM_CLIENTS=NUM_CLIENTS,\n",
    "                                BATCH_SIZE=BATCH_SIZE, \n",
    "                                THETA=THETA, \n",
    "                                EPSILON=EPSILON,\n",
    "                                ams_sketch=ams_sketch,\n",
    "                                client_slices_train=client_slices_train,\n",
    "                                seed=SEED\n",
    "                            )\n",
    "                            \n",
    "                            all_metrics.extend(basic_test_metrics)\n",
    "                            \n",
    "            del client_slices_train\n",
    "            \n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"shit\")\n",
    "    \n",
    "    finally:\n",
    "        return all_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071e61e5",
   "metadata": {},
   "source": [
    "# Run Simulation Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a5b5b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------- Current Test --------------\n",
      "Num Clients : 5\n",
      "Num Epochs : 1\n",
      "Number of steps until we check RTC : 1\n",
      "Batch size : 32\n",
      "Theta : 1.0\n",
      "----------------------------------------\n",
      "\n",
      "retracing naive\n",
      "Naive Epoch count:  0  Total fda steps:  7\n",
      "Est var:  1.31188869  Actual S_2 (Assumed 0):  0.273981065  Actual var:  1.0379076\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  14\n",
      "Est var:  1.21460855  Actual S_2 (Assumed 0):  0.246637434  Actual var:  0.967971206\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  22\n",
      "Est var:  1.00722766  Actual S_2 (Assumed 0):  0.222358078  Actual var:  0.784869552\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  32\n",
      "Est var:  1.07464337  Actual S_2 (Assumed 0):  0.28869465  Actual var:  0.785948753\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  45\n",
      "Est var:  1.00317311  Actual S_2 (Assumed 0):  0.200156674  Actual var:  0.803016365\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  55\n",
      "Est var:  1.02757311  Actual S_2 (Assumed 0):  0.248951733  Actual var:  0.778621554\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  63\n",
      "Est var:  1.11572731  Actual S_2 (Assumed 0):  0.311780095  Actual var:  0.80394727\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  69\n",
      "Est var:  1.00277364  Actual S_2 (Assumed 0):  0.460852861  Actual var:  0.5419209\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  74\n",
      "Est var:  1.51744008  Actual S_2 (Assumed 0):  0.926223338  Actual var:  0.591216683\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  77\n",
      "Est var:  1.07516456  Actual S_2 (Assumed 0):  0.500537157  Actual var:  0.574627519\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  80\n",
      "Est var:  1.50466347  Actual S_2 (Assumed 0):  0.717373133  Actual var:  0.787290335\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  83\n",
      "Est var:  1.56791902  Actual S_2 (Assumed 0):  0.53004992  Actual var:  1.03786922\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  86\n",
      "Est var:  1.50293875  Actual S_2 (Assumed 0):  0.492089629  Actual var:  1.010849\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  89\n",
      "Est var:  1.57247961  Actual S_2 (Assumed 0):  0.565060437  Actual var:  1.00741911\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  92\n",
      "Est var:  1.25154877  Actual S_2 (Assumed 0):  0.519279599  Actual var:  0.732269228\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  95\n",
      "Est var:  1.1397959  Actual S_2 (Assumed 0):  0.553689837  Actual var:  0.586106181\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  98\n",
      "Est var:  1.22840524  Actual S_2 (Assumed 0):  0.633149266  Actual var:  0.595255852\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  101\n",
      "Est var:  1.2114141  Actual S_2 (Assumed 0):  0.599301219  Actual var:  0.61211288\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  104\n",
      "Est var:  1.35148025  Actual S_2 (Assumed 0):  0.681343  Actual var:  0.670137167\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  107\n",
      "Est var:  1.28094554  Actual S_2 (Assumed 0):  0.637529552  Actual var:  0.643415928\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  110\n",
      "Est var:  1.24057078  Actual S_2 (Assumed 0):  0.655911565  Actual var:  0.584659457\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  113\n",
      "Est var:  1.3341682  Actual S_2 (Assumed 0):  0.698760033  Actual var:  0.635408282\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  116\n",
      "Est var:  1.2524718  Actual S_2 (Assumed 0):  0.6035344  Actual var:  0.648937345\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  119\n",
      "Est var:  1.29678702  Actual S_2 (Assumed 0):  0.5961712  Actual var:  0.700615942\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  122\n",
      "Est var:  1.2990768  Actual S_2 (Assumed 0):  0.607827902  Actual var:  0.691248894\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  125\n",
      "Est var:  1.25238156  Actual S_2 (Assumed 0):  0.580687165  Actual var:  0.671694458\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  128\n",
      "Est var:  1.28752708  Actual S_2 (Assumed 0):  0.543125033  Actual var:  0.744402051\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  131\n",
      "Est var:  1.29882  Actual S_2 (Assumed 0):  0.5398  Actual var:  0.75902003\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  134\n",
      "Est var:  1.2584368  Actual S_2 (Assumed 0):  0.510763943  Actual var:  0.747672737\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  137\n",
      "Est var:  1.1678822  Actual S_2 (Assumed 0):  0.449849784  Actual var:  0.718032241\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  140\n",
      "Est var:  1.12516153  Actual S_2 (Assumed 0):  0.447430968  Actual var:  0.67773062\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  143\n",
      "Est var:  1.11207581  Actual S_2 (Assumed 0):  0.407512844  Actual var:  0.704562962\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  146\n",
      "Est var:  1.10012698  Actual S_2 (Assumed 0):  0.388897091  Actual var:  0.71123\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  149\n",
      "Est var:  1.05825806  Actual S_2 (Assumed 0):  0.394130111  Actual var:  0.664127946\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  152\n",
      "Est var:  1.02857375  Actual S_2 (Assumed 0):  0.36838  Actual var:  0.660193801\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  156\n",
      "Est var:  1.66176  Actual S_2 (Assumed 0):  0.60702455  Actual var:  1.0547353\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  160\n",
      "Est var:  1.60347426  Actual S_2 (Assumed 0):  0.570325553  Actual var:  1.03314865\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  164\n",
      "Est var:  1.45027328  Actual S_2 (Assumed 0):  0.52073  Actual var:  0.929543316\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  168\n",
      "Est var:  1.41862965  Actual S_2 (Assumed 0):  0.499742031  Actual var:  0.918887615\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  172\n",
      "Est var:  1.54686737  Actual S_2 (Assumed 0):  0.469717234  Actual var:  1.07715011\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  176\n",
      "Est var:  1.54983401  Actual S_2 (Assumed 0):  0.466171116  Actual var:  1.08366299\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  180\n",
      "Est var:  1.46302009  Actual S_2 (Assumed 0):  0.412778616  Actual var:  1.05024147\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  184\n",
      "Est var:  1.51326394  Actual S_2 (Assumed 0):  0.484770775  Actual var:  1.02849293\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  188\n",
      "Est var:  1.51323926  Actual S_2 (Assumed 0):  0.449057  Actual var:  1.06418228\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  192\n",
      "Est var:  1.33011949  Actual S_2 (Assumed 0):  0.435270369  Actual var:  0.894849181\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  196\n",
      "Est var:  1.20903397  Actual S_2 (Assumed 0):  0.409400105  Actual var:  0.799633801\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  200\n",
      "Est var:  1.14704764  Actual S_2 (Assumed 0):  0.345453054  Actual var:  0.801594615\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  204\n",
      "Est var:  1.1622436  Actual S_2 (Assumed 0):  0.34548822  Actual var:  0.816755414\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  208\n",
      "Est var:  1.14008164  Actual S_2 (Assumed 0):  0.379180133  Actual var:  0.76090157\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  212\n",
      "Est var:  1.05674171  Actual S_2 (Assumed 0):  0.355192035  Actual var:  0.701549709\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  216\n",
      "Est var:  1.11709845  Actual S_2 (Assumed 0):  0.362249702  Actual var:  0.754848599\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  220\n",
      "Est var:  1.0935874  Actual S_2 (Assumed 0):  0.342799276  Actual var:  0.750788152\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  224\n",
      "Est var:  1.09643161  Actual S_2 (Assumed 0):  0.318453193  Actual var:  0.777978539\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  228\n",
      "Est var:  1.06609583  Actual S_2 (Assumed 0):  0.304008961  Actual var:  0.762087\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  233\n",
      "Est var:  1.40316081  Actual S_2 (Assumed 0):  0.418800414  Actual var:  0.984360337\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  237\n",
      "Est var:  1.05876088  Actual S_2 (Assumed 0):  0.32319361  Actual var:  0.735567331\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  241\n",
      "Est var:  1.19914317  Actual S_2 (Assumed 0):  0.320554823  Actual var:  0.878588498\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  245\n",
      "Est var:  1.08655286  Actual S_2 (Assumed 0):  0.294114828  Actual var:  0.79243809\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  249\n",
      "Est var:  1.22846603  Actual S_2 (Assumed 0):  0.365370661  Actual var:  0.863095284\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  253\n",
      "Est var:  1.1649338  Actual S_2 (Assumed 0):  0.338166445  Actual var:  0.826767445\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  257\n",
      "Est var:  1.09608924  Actual S_2 (Assumed 0):  0.321571559  Actual var:  0.774517715\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Est var:  1.015396  Actual S_2 (Assumed 0):  0.333368599  Actual var:  0.682027459\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  266\n",
      "Est var:  1.34075749  Actual S_2 (Assumed 0):  0.431881934  Actual var:  0.908875465\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  271\n",
      "Est var:  1.27304041  Actual S_2 (Assumed 0):  0.36389178  Actual var:  0.909148693\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  276\n",
      "Est var:  1.4168694  Actual S_2 (Assumed 0):  0.3717902  Actual var:  1.04507911\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  281\n",
      "Est var:  1.32717991  Actual S_2 (Assumed 0):  0.345947087  Actual var:  0.981232822\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  285\n",
      "Est var:  1.16755104  Actual S_2 (Assumed 0):  0.326565057  Actual var:  0.840986073\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  290\n",
      "Est var:  1.45194602  Actual S_2 (Assumed 0):  0.387878954  Actual var:  1.06406701\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  295\n",
      "Est var:  1.37221694  Actual S_2 (Assumed 0):  0.370472193  Actual var:  1.00174487\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  299\n",
      "Est var:  1.02576149  Actual S_2 (Assumed 0):  0.282805592  Actual var:  0.742955863\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  303\n",
      "Est var:  1.00371933  Actual S_2 (Assumed 0):  0.284604222  Actual var:  0.719115\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  308\n",
      "Est var:  1.27786636  Actual S_2 (Assumed 0):  0.333426416  Actual var:  0.944439888\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  313\n",
      "Est var:  1.25489104  Actual S_2 (Assumed 0):  0.333540142  Actual var:  0.921350777\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  318\n",
      "Est var:  1.24310827  Actual S_2 (Assumed 0):  0.330811888  Actual var:  0.912296414\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  323\n",
      "Est var:  1.35730422  Actual S_2 (Assumed 0):  0.324685514  Actual var:  1.03261852\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  328\n",
      "Est var:  1.13970017  Actual S_2 (Assumed 0):  0.286328793  Actual var:  0.853371501\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  334\n",
      "Est var:  1.29782069  Actual S_2 (Assumed 0):  0.312627465  Actual var:  0.985193253\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  340\n",
      "Est var:  1.20362115  Actual S_2 (Assumed 0):  0.318236917  Actual var:  0.885384262\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  346\n",
      "Est var:  1.2715776  Actual S_2 (Assumed 0):  0.316560507  Actual var:  0.955016911\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  351\n",
      "Est var:  1.12254202  Actual S_2 (Assumed 0):  0.296743661  Actual var:  0.825798213\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  356\n",
      "Est var:  1.1469034  Actual S_2 (Assumed 0):  0.28352356  Actual var:  0.863379955\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  361\n",
      "Est var:  1.27855217  Actual S_2 (Assumed 0):  0.344834596  Actual var:  0.933717608\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  366\n",
      "Est var:  1.07764697  Actual S_2 (Assumed 0):  0.292365879  Actual var:  0.785281181\n",
      "\n",
      "\n",
      "Naive Epoch count:  0  Total fda steps:  371\n",
      "Est var:  1.34870899  Actual S_2 (Assumed 0):  0.338432044  Actual var:  1.01027703\n",
      "\n",
      "\n",
      "Naive Epoch count:  1  Total fda steps:  375\n",
      "Est var:  0.761267304  Actual S_2 (Assumed 0):  0.170786604  Actual var:  0.590480685\n",
      "\n",
      "\n",
      "retracing linear\n",
      "Linear Epoch count:  0  Total fda steps:  6\n",
      "Est var:  1.01601768  Actual S_2:  0.222138256  Approx S_2:  1.42522767e-08  Actual var:  0.79387939\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  14\n",
      "Est var:  1.16042244  Actual S_2:  0.275829315  Approx S_2:  0.131284356  Actual var:  1.0158776\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  26\n",
      "Est var:  1.05464935  Actual S_2:  0.273391187  Approx S_2:  0.119356677  Actual var:  0.900614738\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  38\n",
      "Est var:  1.09292161  Actual S_2:  0.223276  Approx S_2:  0.0303099938  Actual var:  0.89995575\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  50\n",
      "Est var:  1.00964463  Actual S_2:  0.246538982  Approx S_2:  0.0593377911  Actual var:  0.822443366\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  61\n",
      "Est var:  1.02562034  Actual S_2:  0.199707121  Approx S_2:  0.0398171879  Actual var:  0.865730464\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  70\n",
      "Est var:  1.05651236  Actual S_2:  0.321534753  Approx S_2:  0.0944787189  Actual var:  0.82945621\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  76\n",
      "Est var:  1.01390433  Actual S_2:  1.01106882  Approx S_2:  0.579853594  Actual var:  0.582689166\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  80\n",
      "Est var:  1.37019563  Actual S_2:  1.37059879  Approx S_2:  0.764315128  Actual var:  0.763911724\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  83\n",
      "Est var:  1.49658096  Actual S_2:  1.02348876  Approx S_2:  0.618548274  Actual var:  1.09164023\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  86\n",
      "Est var:  1.71594286  Actual S_2:  0.848269  Approx S_2:  0.486511469  Actual var:  1.35418534\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  89\n",
      "Est var:  1.6136651  Actual S_2:  0.849432945  Approx S_2:  0.520157516  Actual var:  1.28438973\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  92\n",
      "Est var:  1.59125757  Actual S_2:  0.908501863  Approx S_2:  0.38563329  Actual var:  1.06838894\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  95\n",
      "Est var:  1.54593229  Actual S_2:  0.861155272  Approx S_2:  0.401793599  Actual var:  1.0865705\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  98\n",
      "Est var:  1.2340194  Actual S_2:  0.829281211  Approx S_2:  0.559628963  Actual var:  0.964367032\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  101\n",
      "Est var:  1.01679349  Actual S_2:  0.92449224  Approx S_2:  0.675553143  Actual var:  0.767854273\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  104\n",
      "Est var:  1.12659216  Actual S_2:  0.821458459  Approx S_2:  0.501518309  Actual var:  0.806652069\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  107\n",
      "Est var:  1.21955466  Actual S_2:  0.708726525  Approx S_2:  0.413159251  Actual var:  0.923987389\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  110\n",
      "Est var:  1.08594382  Actual S_2:  0.701151907  Approx S_2:  0.47890833  Actual var:  0.863700211\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  113\n",
      "Est var:  1.24824727  Actual S_2:  0.758876562  Approx S_2:  0.344484895  Actual var:  0.833855629\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  117\n",
      "Est var:  1.62820172  Actual S_2:  1.0876025  Approx S_2:  0.617279768  Actual var:  1.15787911\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  121\n",
      "Est var:  1.53159022  Actual S_2:  0.969793618  Approx S_2:  0.48446849  Actual var:  1.04626513\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  125\n",
      "Est var:  1.46059704  Actual S_2:  0.822970748  Approx S_2:  0.355949968  Actual var:  0.993576407\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  129\n",
      "Est var:  1.50013518  Actual S_2:  0.74466  Approx S_2:  0.244667664  Actual var:  1.00014269\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  133\n",
      "Est var:  1.20628047  Actual S_2:  0.606608033  Approx S_2:  0.240529731  Actual var:  0.840202034\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  137\n",
      "Est var:  1.07170987  Actual S_2:  0.600114882  Approx S_2:  0.314013898  Actual var:  0.785608768\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  141\n",
      "Est var:  1.11060357  Actual S_2:  0.486858189  Approx S_2:  0.143597811  Actual var:  0.767343044\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  145\n",
      "Est var:  1.06895328  Actual S_2:  0.505676925  Approx S_2:  0.210827768  Actual var:  0.774104238\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  149\n",
      "Est var:  1.10035098  Actual S_2:  0.450169295  Approx S_2:  0.14672038  Actual var:  0.796902061\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  154\n",
      "Est var:  1.46800542  Actual S_2:  0.636814833  Approx S_2:  0.350932628  Actual var:  1.18212318\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  158\n",
      "Est var:  1.13642144  Actual S_2:  0.433396786  Approx S_2:  0.191740438  Actual var:  0.8947649\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  162\n",
      "Est var:  1.02645624  Actual S_2:  0.403782964  Approx S_2:  0.173156247  Actual var:  0.795829654\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  167\n",
      "Est var:  1.3530364  Actual S_2:  0.506692171  Approx S_2:  0.287902057  Actual var:  1.13424647\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  172\n",
      "Est var:  1.38973451  Actual S_2:  0.524257243  Approx S_2:  0.22065486  Actual var:  1.08613217\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  177\n",
      "Est var:  1.40676832  Actual S_2:  0.475705057  Approx S_2:  0.195048064  Actual var:  1.12611127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  182\n",
      "Est var:  1.34339547  Actual S_2:  0.466649055  Approx S_2:  0.223472163  Actual var:  1.10021853\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  187\n",
      "Est var:  1.10328472  Actual S_2:  0.420609385  Approx S_2:  0.261965841  Actual var:  0.944641232\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  193\n",
      "Est var:  1.32734942  Actual S_2:  0.516306281  Approx S_2:  0.207547784  Actual var:  1.01859093\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  199\n",
      "Est var:  1.26105809  Actual S_2:  0.465349764  Approx S_2:  0.16419211  Actual var:  0.95990026\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  204\n",
      "Est var:  1.0870266  Actual S_2:  0.367054284  Approx S_2:  0.082846947  Actual var:  0.802819431\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  210\n",
      "Est var:  1.38486075  Actual S_2:  0.449177414  Approx S_2:  0.210866824  Actual var:  1.14655\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  215\n",
      "Est var:  1.10040963  Actual S_2:  0.364641041  Approx S_2:  0.1491023  Actual var:  0.884871125\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  220\n",
      "Est var:  1.18497467  Actual S_2:  0.371060848  Approx S_2:  0.14674896  Actual var:  0.960662663\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  225\n",
      "Est var:  1.16566  Actual S_2:  0.36689043  Approx S_2:  0.149567798  Actual var:  0.948337436\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  231\n",
      "Est var:  1.30559611  Actual S_2:  0.411310047  Approx S_2:  0.235764697  Actual var:  1.13005078\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  237\n",
      "Est var:  1.22306585  Actual S_2:  0.376885  Approx S_2:  0.155359924  Actual var:  1.0015409\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  243\n",
      "Est var:  1.17976832  Actual S_2:  0.37438345  Approx S_2:  0.180410534  Actual var:  0.985795319\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  249\n",
      "Est var:  1.34738278  Actual S_2:  0.385814965  Approx S_2:  0.0904421285  Actual var:  1.05201018\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  254\n",
      "Est var:  1.06437492  Actual S_2:  0.333618194  Approx S_2:  0.0887794048  Actual var:  0.81953609\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  259\n",
      "Est var:  1.00435686  Actual S_2:  0.301064342  Approx S_2:  0.103993215  Actual var:  0.807285666\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  265\n",
      "Est var:  1.12328982  Actual S_2:  0.343806297  Approx S_2:  0.167102456  Actual var:  0.946586\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  271\n",
      "Est var:  1.2490108  Actual S_2:  0.400796  Approx S_2:  0.151402906  Actual var:  0.999617755\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  277\n",
      "Est var:  1.20568192  Actual S_2:  0.325962722  Approx S_2:  0.0964440629  Actual var:  0.976163208\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  283\n",
      "Est var:  1.17263198  Actual S_2:  0.397760838  Approx S_2:  0.127080694  Actual var:  0.901951909\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  289\n",
      "Est var:  1.11043954  Actual S_2:  0.313655019  Approx S_2:  0.100337088  Actual var:  0.897121429\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  294\n",
      "Est var:  1.01182783  Actual S_2:  0.291169226  Approx S_2:  0.0750446394  Actual var:  0.795703232\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  299\n",
      "Est var:  1.06258917  Actual S_2:  0.268328  Approx S_2:  0.0989305526  Actual var:  0.893191814\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  305\n",
      "Est var:  1.3446027  Actual S_2:  0.383790821  Approx S_2:  0.138269708  Actual var:  1.09908152\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  311\n",
      "Est var:  1.12909675  Actual S_2:  0.33593145  Approx S_2:  0.138084  Actual var:  0.931249321\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  316\n",
      "Est var:  1.01192057  Actual S_2:  0.294540524  Approx S_2:  0.0866885111  Actual var:  0.804068565\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  321\n",
      "Est var:  1.07500315  Actual S_2:  0.262313038  Approx S_2:  0.0787380561  Actual var:  0.891428173\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  326\n",
      "Est var:  1.05806851  Actual S_2:  0.288594455  Approx S_2:  0.123416297  Actual var:  0.892890275\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  332\n",
      "Est var:  1.28533161  Actual S_2:  0.375168592  Approx S_2:  0.108856328  Actual var:  1.01901937\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  337\n",
      "Est var:  1.01117671  Actual S_2:  0.275865018  Approx S_2:  0.104437813  Actual var:  0.839749515\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  343\n",
      "Est var:  1.3618927  Actual S_2:  0.383682668  Approx S_2:  0.177818269  Actual var:  1.15602815\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  348\n",
      "Est var:  1.02512074  Actual S_2:  0.329744816  Approx S_2:  0.107720181  Actual var:  0.803096\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  354\n",
      "Est var:  1.18944979  Actual S_2:  0.325814724  Approx S_2:  0.114642657  Actual var:  0.978277683\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  359\n",
      "Est var:  1.07537174  Actual S_2:  0.319684178  Approx S_2:  0.0469007455  Actual var:  0.802588165\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  365\n",
      "Est var:  1.09293067  Actual S_2:  0.319969237  Approx S_2:  0.0670364  Actual var:  0.839997888\n",
      "\n",
      "\n",
      "Linear Epoch count:  0  Total fda steps:  371\n",
      "Est var:  1.15379012  Actual S_2:  0.31864059  Approx S_2:  0.0414673  Actual var:  0.876616776\n",
      "\n",
      "\n",
      "Linear Epoch count:  1  Total fda steps:  375\n",
      "Est var:  0.464472026  Actual S_2:  0.130028278  Approx S_2:  0.0669005215  Actual var:  0.401344299\n",
      "\n",
      "\n",
      "retracing sketch\n",
      "WARNING:tensorflow:From /home/miketheologitis/anaconda3/envs/tff-py39/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Sketch Epoch count:  0  Total fda steps:  7\n",
      "Est var:  1.12492168  Actual S_2:  0.282814801  Apprxo S_2 0.2659477  Actual var:  1.10805452\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  14\n",
      "Est var:  1.030388  Actual S_2:  0.279487342  Apprxo S_2 0.272512943  Actual var:  1.02341354\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  25\n",
      "Est var:  1.20878983  Actual S_2:  0.336804032  Apprxo S_2 0.340210974  Actual var:  1.21219659\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  36\n",
      "Est var:  1.16357219  Actual S_2:  0.32434088  Apprxo S_2 0.315703779  Actual var:  1.15493512\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  50\n",
      "Est var:  1.07951367  Actual S_2:  0.367562503  Apprxo S_2 0.363040715  Actual var:  1.07499194\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  65\n",
      "Est var:  1.12037194  Actual S_2:  0.272461295  Apprxo S_2 0.264122099  Actual var:  1.11203277\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  79\n",
      "Est var:  1.04872751  Actual S_2:  0.319903135  Apprxo S_2 0.305108488  Actual var:  1.03393292\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  88\n",
      "Est var:  1.00445437  Actual S_2:  0.411480397  Apprxo S_2 0.402287126  Actual var:  0.995261\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  94\n",
      "Est var:  1.41380978  Actual S_2:  0.435257941  Apprxo S_2 0.425659835  Actual var:  1.40421188\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  98\n",
      "Est var:  1.06522024  Actual S_2:  0.451497  Apprxo S_2 0.430458754  Actual var:  1.04418194\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  102\n",
      "Est var:  1.04970598  Actual S_2:  0.706061125  Apprxo S_2 0.691399395  Actual var:  1.03504431\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  106\n",
      "Est var:  1.22967923  Actual S_2:  1.22998679  Apprxo S_2 1.20636356  Actual var:  1.20605588\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  109\n",
      "Est var:  1.298913  Actual S_2:  0.863338172  Apprxo S_2 0.81873554  Actual var:  1.25431061\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  112\n",
      "Est var:  1.2186892  Actual S_2:  0.625640273  Apprxo S_2 0.614454329  Actual var:  1.20750332\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  115\n",
      "Est var:  1.10245216  Actual S_2:  0.556720674  Apprxo S_2 0.540020704  Actual var:  1.08575225\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  119\n",
      "Est var:  1.26939571  Actual S_2:  0.896816373  Apprxo S_2 0.873273253  Actual var:  1.24585235\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  123\n",
      "Est var:  1.06579542  Actual S_2:  1.07882071  Apprxo S_2 1.0621419  Actual var:  1.04911673\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Est var:  1.15944672  Actual S_2:  1.35896909  Apprxo S_2 1.34940696  Actual var:  1.1498847\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  131\n",
      "Est var:  1.32734692  Actual S_2:  1.53323019  Apprxo S_2 1.55963123  Actual var:  1.35374761\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  135\n",
      "Est var:  1.36793876  Actual S_2:  1.59164262  Apprxo S_2 1.5908525  Actual var:  1.36714864\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  139\n",
      "Est var:  1.52951074  Actual S_2:  1.41810608  Apprxo S_2 1.39678407  Actual var:  1.50818884\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  142\n",
      "Est var:  1.07803297  Actual S_2:  0.780180335  Apprxo S_2 0.780751765  Actual var:  1.0786041\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  145\n",
      "Est var:  1.01122284  Actual S_2:  0.677497745  Apprxo S_2 0.68013972  Actual var:  1.01386487\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  149\n",
      "Est var:  1.46389031  Actual S_2:  1.08175087  Apprxo S_2 1.08296299  Actual var:  1.46510255\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  153\n",
      "Est var:  1.26473117  Actual S_2:  0.911829  Apprxo S_2 0.890133381  Actual var:  1.24303555\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  157\n",
      "Est var:  1.13677  Actual S_2:  0.861219  Apprxo S_2 0.839963257  Actual var:  1.11551416\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  161\n",
      "Est var:  1.26727581  Actual S_2:  0.963477492  Apprxo S_2 0.938734472  Actual var:  1.24253273\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  165\n",
      "Est var:  1.39300823  Actual S_2:  0.780277252  Apprxo S_2 0.738454342  Actual var:  1.35118508\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  169\n",
      "Est var:  1.25518727  Actual S_2:  0.74692  Apprxo S_2 0.70746  Actual var:  1.21572721\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  173\n",
      "Est var:  1.16308498  Actual S_2:  0.668336868  Apprxo S_2 0.637242317  Actual var:  1.13199008\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  177\n",
      "Est var:  1.12216187  Actual S_2:  0.563011408  Apprxo S_2 0.538644552  Actual var:  1.09779513\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  181\n",
      "Est var:  1.13942409  Actual S_2:  0.565807939  Apprxo S_2 0.5507195  Actual var:  1.12433565\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  185\n",
      "Est var:  1.05008507  Actual S_2:  0.538858  Apprxo S_2 0.525293  Actual var:  1.03652024\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  189\n",
      "Est var:  1.08342135  Actual S_2:  0.472783506  Apprxo S_2 0.454945654  Actual var:  1.06558347\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  193\n",
      "Est var:  1.05028844  Actual S_2:  0.546329  Apprxo S_2 0.526003838  Actual var:  1.02996325\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  197\n",
      "Est var:  1.01097929  Actual S_2:  0.494660676  Apprxo S_2 0.476294547  Actual var:  0.992613\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  201\n",
      "Est var:  1.08728611  Actual S_2:  0.484694839  Apprxo S_2 0.47303772  Actual var:  1.075629\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  206\n",
      "Est var:  1.38010931  Actual S_2:  0.730802417  Apprxo S_2 0.716018617  Actual var:  1.36532605\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  211\n",
      "Est var:  1.20506787  Actual S_2:  0.655655921  Apprxo S_2 0.640818954  Actual var:  1.19023085\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  216\n",
      "Est var:  1.38390231  Actual S_2:  0.743322551  Apprxo S_2 0.73103565  Actual var:  1.37161541\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  221\n",
      "Est var:  1.33372331  Actual S_2:  0.636588752  Apprxo S_2 0.62102139  Actual var:  1.31815612\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  226\n",
      "Est var:  1.2071842  Actual S_2:  0.518249512  Apprxo S_2 0.497177392  Actual var:  1.18611217\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  231\n",
      "Est var:  1.16368175  Actual S_2:  0.408007  Apprxo S_2 0.381028116  Actual var:  1.13670278\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  236\n",
      "Est var:  1.17230952  Actual S_2:  0.439005941  Apprxo S_2 0.422043681  Actual var:  1.15534735\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  241\n",
      "Est var:  1.2492379  Actual S_2:  0.433946878  Apprxo S_2 0.402271122  Actual var:  1.21756232\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  246\n",
      "Est var:  1.20888257  Actual S_2:  0.497415096  Apprxo S_2 0.492998183  Actual var:  1.20446575\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  251\n",
      "Est var:  1.15815234  Actual S_2:  0.473786831  Apprxo S_2 0.452144325  Actual var:  1.13650966\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  256\n",
      "Est var:  1.16624379  Actual S_2:  0.510887921  Apprxo S_2 0.494051427  Actual var:  1.14940763\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  261\n",
      "Est var:  1.20522583  Actual S_2:  0.48061955  Apprxo S_2 0.46874094  Actual var:  1.19334722\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  266\n",
      "Est var:  1.01980567  Actual S_2:  0.445275247  Apprxo S_2 0.434326082  Actual var:  1.00885653\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  271\n",
      "Est var:  1.13660419  Actual S_2:  0.466038734  Apprxo S_2 0.443132788  Actual var:  1.11369824\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  276\n",
      "Est var:  1.04779565  Actual S_2:  0.435350031  Apprxo S_2 0.425982565  Actual var:  1.03842843\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  282\n",
      "Est var:  1.27465463  Actual S_2:  0.620562375  Apprxo S_2 0.603139877  Actual var:  1.25723195\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  287\n",
      "Est var:  1.03783596  Actual S_2:  0.437197953  Apprxo S_2 0.41569981  Actual var:  1.01633775\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  293\n",
      "Est var:  1.33156157  Actual S_2:  0.491424173  Apprxo S_2 0.488833278  Actual var:  1.32897079\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  298\n",
      "Est var:  1.06875896  Actual S_2:  0.422401875  Apprxo S_2 0.425640851  Actual var:  1.07199812\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  304\n",
      "Est var:  1.32038236  Actual S_2:  0.520977914  Apprxo S_2 0.521760941  Actual var:  1.32116532\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  310\n",
      "Est var:  1.25985789  Actual S_2:  0.492892534  Apprxo S_2 0.485272318  Actual var:  1.25223756\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  315\n",
      "Est var:  1.03771806  Actual S_2:  0.373913974  Apprxo S_2 0.367271274  Actual var:  1.03107536\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  320\n",
      "Est var:  1.30221379  Actual S_2:  0.47356084  Apprxo S_2 0.463197321  Actual var:  1.29185045\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  325\n",
      "Est var:  1.22025824  Actual S_2:  0.476973027  Apprxo S_2 0.462446034  Actual var:  1.20573139\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  331\n",
      "Est var:  1.156304  Actual S_2:  0.51850915  Apprxo S_2 0.488286108  Actual var:  1.12608099\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  337\n",
      "Est var:  1.23395634  Actual S_2:  0.468045384  Apprxo S_2 0.449694335  Actual var:  1.21560538\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  343\n",
      "Est var:  1.17307663  Actual S_2:  0.384197861  Apprxo S_2 0.380455196  Actual var:  1.16933382\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  349\n",
      "Est var:  1.17846406  Actual S_2:  0.458880424  Apprxo S_2 0.452192515  Actual var:  1.17177618\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  355\n",
      "Est var:  1.11145353  Actual S_2:  0.419622958  Apprxo S_2 0.398254722  Actual var:  1.09008539\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  361\n",
      "Est var:  1.20373118  Actual S_2:  0.396386802  Apprxo S_2 0.375305742  Actual var:  1.18265\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  367\n",
      "Est var:  1.2063309  Actual S_2:  0.444037199  Apprxo S_2 0.420913428  Actual var:  1.18320704\n",
      "\n",
      "\n",
      "Sketch Epoch count:  0  Total fda steps:  373\n",
      "Est var:  1.08989584  Actual S_2:  0.379191905  Apprxo S_2 0.362461776  Actual var:  1.07316589\n",
      "\n",
      "\n",
      "Sketch Epoch count:  1  Total fda steps:  375\n",
      "Est var:  0.169500828  Actual S_2:  0.0662478  Apprxo S_2 0.0646672472  Actual var:  0.167920277\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_metrics = run_tests(\n",
    "    NUM_CLIENTS_LIST=[5],\n",
    "    NUM_EPOCHS_LIST=[1],\n",
    "    NUM_STEPS_UNTIL_RTC_CHECK_LIST=[1],\n",
    "    BATCH_SIZE_LIST=[32],\n",
    "    THETA_LIST=[1.],\n",
    "    SKETCH_DEPTH=7,\n",
    "    SKETCH_WIDTH=1700,\n",
    "    SEED=7\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93aa398",
   "metadata": {},
   "source": [
    "TODO:\n",
    "    \n",
    "1. Check why no change in accuracy between steps. Do the updates happen at all? What the fuck is going on here?\n",
    "2. Check accuracy final\n",
    "3. `synchronize` retracing\n",
    "4. `get_compiled_and_built_...()` retraces for `server_cnn` every time (ofc for `client_cnns` aswell).\n",
    "\n",
    "5. Approach on sketch should be `reduce_mean`, change it in PA-I.\n",
    "6. Approach on global tests `for` loop PA-I\n",
    "7. remove `one` as a `tf.constant(1)` PA-I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a4b2b222",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "da382e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test_results/advanced_cnn_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3e3cd8a9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'fda_name': 'naive',\n",
       "  'theta': 1.0,\n",
       "  'dataset_name': 'EMNIST',\n",
       "  'input_pixels': 784,\n",
       "  'n_train': 60000,\n",
       "  'num_weights': 2592202,\n",
       "  'seed': 7,\n",
       "  'epochs': 1,\n",
       "  'num_clients': 5,\n",
       "  'batch_size': 32,\n",
       "  'steps_in_one_fda_step': 1,\n",
       "  'sketch_width': None,\n",
       "  'sketch_depth': None,\n",
       "  'one_sample_bytes': 3140,\n",
       "  'training_dataset_bytes': 188400000,\n",
       "  'model_bytes': 10368808,\n",
       "  'local_state_bytes': 4,\n",
       "  'final_accuracy': 0.9684000015258789,\n",
       "  'total_fda_steps': 375,\n",
       "  'total_steps': 375,\n",
       "  'total_rounds': 85,\n",
       "  'model_bytes_exchanged': 8813486800,\n",
       "  'monitoring_bytes_exchanged': 7500,\n",
       "  'total_communication_bytes': 8813494300,\n",
       "  'trained_in_bytes': 188400000},\n",
       " {'fda_name': 'linear',\n",
       "  'theta': 1.0,\n",
       "  'dataset_name': 'EMNIST',\n",
       "  'input_pixels': 784,\n",
       "  'n_train': 60000,\n",
       "  'num_weights': 2592202,\n",
       "  'seed': 7,\n",
       "  'epochs': 1,\n",
       "  'num_clients': 5,\n",
       "  'batch_size': 32,\n",
       "  'steps_in_one_fda_step': 1,\n",
       "  'sketch_width': None,\n",
       "  'sketch_depth': None,\n",
       "  'one_sample_bytes': 3140,\n",
       "  'training_dataset_bytes': 188400000,\n",
       "  'model_bytes': 10368808,\n",
       "  'local_state_bytes': 8,\n",
       "  'final_accuracy': 0.9552000164985657,\n",
       "  'total_fda_steps': 375,\n",
       "  'total_steps': 375,\n",
       "  'total_rounds': 71,\n",
       "  'model_bytes_exchanged': 7361853680,\n",
       "  'monitoring_bytes_exchanged': 15000,\n",
       "  'total_communication_bytes': 7361868680,\n",
       "  'trained_in_bytes': 188400000},\n",
       " {'fda_name': 'sketch',\n",
       "  'theta': 1.0,\n",
       "  'dataset_name': 'EMNIST',\n",
       "  'input_pixels': 784,\n",
       "  'n_train': 60000,\n",
       "  'num_weights': 2592202,\n",
       "  'seed': 7,\n",
       "  'epochs': 1,\n",
       "  'num_clients': 5,\n",
       "  'batch_size': 32,\n",
       "  'steps_in_one_fda_step': 1,\n",
       "  'sketch_width': 1700,\n",
       "  'sketch_depth': 7,\n",
       "  'one_sample_bytes': 3140,\n",
       "  'training_dataset_bytes': 188400000,\n",
       "  'model_bytes': 10368808,\n",
       "  'local_state_bytes': 47604,\n",
       "  'final_accuracy': 0.9646000266075134,\n",
       "  'total_fda_steps': 375,\n",
       "  'total_steps': 375,\n",
       "  'total_rounds': 70,\n",
       "  'model_bytes_exchanged': 7258165600,\n",
       "  'monitoring_bytes_exchanged': 89257500,\n",
       "  'total_communication_bytes': 7347423100,\n",
       "  'trained_in_bytes': 188400000}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2a540b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_advanced_cnn():\n",
    "    advanced_cnn = AdvancedCNN()\n",
    "    \n",
    "    advanced_cnn.compile(\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False), # we have softmax\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')]\n",
    "    )\n",
    "    \n",
    "    return advanced_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8880c855",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def synchronize2(server_cnn, client_cnns):\n",
    "    # server average\n",
    "    server_cnn.set_trainable_variables(average_client_weights(client_cnns))\n",
    "    \n",
    "    # synchronize clients\n",
    "    for client_cnn in client_cnns:\n",
    "        client_cnn.set_trainable_variables(server_cnn.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6f1435c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_retrace(client_cnns, server_cnn, federated_dataset, num_epochs, theta, epoch_max_fda_steps):\n",
    "    \n",
    "    print(\"retrace\")\n",
    "    # 1. Build models\n",
    "    server_cnn.build(CNN_BATCH_INPUT)\n",
    "    for client_cnn in client_cnns:\n",
    "        client_cnn.build(CNN_BATCH_INPUT)\n",
    "    # 2. Sycnrhonize\n",
    "    #synchronize2(server_cnn, client_cnns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "03c2f4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLIENTS = 10\n",
    "\n",
    "server_cnn = get_compiled_and_built_advanced_cnn()\n",
    "client_cnns = [get_compiled_and_built_advanced_cnn() for _ in range(NUM_CLIENTS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0a196071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "starting_trainable_variables_copy = copy.deepcopy(server_cnn.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "578723e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "synchronize2(server_cnn, client_cnns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "823d6d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_cnn.set_trainable_variables(starting_trainable_variables_copy)\n",
    "\n",
    "for client_cnn in client_cnns:\n",
    "    client_cnn.set_trainable_variables(starting_trainable_variables_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7aa4b229",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = tf.constant(10, shape=(), dtype=tf.int32)\n",
    "theta = tf.constant(3., shape=(), dtype=tf.float32)\n",
    "BATCH_SIZE = 35\n",
    "\n",
    "seed = 7\n",
    "\n",
    "NUM_STEPS_UNTIL_RTC_CHECK = 1\n",
    "\n",
    "# for sketch\n",
    "epsilon = tf.constant(3., shape=(), dtype=tf.float32) # new\n",
    "\n",
    "epoch_max_fda_steps = tf.constant(4, shape=(), dtype=tf.int32)\n",
    "\n",
    "basic_test_metrics = []\n",
    "\n",
    "client_slices_train = create_data_for_clients(NUM_CLIENTS)  # new sliced dataset (diff NUM_CLIENTS)\n",
    "\n",
    "\"\"\" --------------- Naive ----------------------------------\"\"\"\n",
    "\n",
    "# 1. tf.data.Dataset (we create it again because we want determinism)\n",
    "\n",
    "federated_dataset = create_federated_data(\n",
    "    client_slices_train=client_slices_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle_buffer_size=int(n_train/NUM_CLIENTS),\n",
    "    num_steps_until_rtc_check=NUM_STEPS_UNTIL_RTC_CHECK,\n",
    "    seed=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e8903b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_retrace(client_cnns, server_cnn, federated_dataset, num_epochs, theta, epoch_max_fda_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee5417f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024e556c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tff-py39] *",
   "language": "python",
   "name": "conda-env-tff-py39-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
