{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2759993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883135f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a550108",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a65570a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3eb02a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = tf.constant(X_train, dtype=tf.float32)\n",
    "del X_train\n",
    "\n",
    "y_train_tensor = tf.constant(y_train, dtype=tf.int32)\n",
    "del y_train\n",
    "\n",
    "X_test_tensor = tf.constant(X_test, dtype=tf.float32)\n",
    "del X_test\n",
    "\n",
    "y_test_tensor = tf.constant(y_test, dtype=tf.int32)\n",
    "del y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fad165b",
   "metadata": {},
   "outputs": [],
   "source": [
    "slices_test = (X_test_tensor, y_test_tensor)\n",
    "\n",
    "def create_tf_dataset_for_testing(batch_size):\n",
    "    return tf.data.Dataset.from_tensor_slices(slices_test).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97b27a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_for_clients(num_clients):\n",
    "    \n",
    "    client_slices_train = {}\n",
    "\n",
    "    for i in range(num_clients):\n",
    "        # Compute the indices for this client's slice\n",
    "        start_idx = int(i * n_train / num_clients)\n",
    "        end_idx = int((i + 1) * n_train / num_clients)\n",
    "\n",
    "        # Get the slice for this client\n",
    "        X_client_train = X_train_tensor[start_idx:end_idx]\n",
    "        y_client_train = y_train_tensor[start_idx:end_idx]\n",
    "        \n",
    "        # Combine the slices into a single dataset\n",
    "        client_slices_train[f'client_{i}'] = (X_client_train, y_client_train)\n",
    "    \n",
    "    return client_slices_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d50888b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "794535c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_dataset_for_client(client_tensor_slices, batch_size, shuffle_buffer_size, num_steps_until_rtc_check, seed):\n",
    "    \n",
    "        return tf.data.Dataset.from_tensor_slices(client_tensor_slices) \\\n",
    "            .shuffle(buffer_size=shuffle_buffer_size, seed=seed).batch(batch_size) \\\n",
    "            .prefetch(tf.data.AUTOTUNE).take(num_steps_until_rtc_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d770c13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_federated_data(client_slices_train, batch_size, shuffle_buffer_size, num_steps_until_rtc_check, seed=None):\n",
    "    \n",
    "    federated_dataset = [ \n",
    "        create_tf_dataset_for_client(client_tensor_slices, batch_size, shuffle_buffer_size, num_steps_until_rtc_check, seed)\n",
    "        for client, client_tensor_slices in client_slices_train.items()\n",
    "    ]\n",
    "    \n",
    "    return federated_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93e6cba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uncompiled_model():\n",
    "    inputs = keras.Input(shape=(28, 28, 1), name=\"digits\")\n",
    "    x = layers.Conv2D(32, 3, activation='relu')(inputs)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    outputs = layers.Dense(10, activation='softmax')(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9cda023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_model():\n",
    "    model = get_uncompiled_model()\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False), # we have softmax\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd8b240",
   "metadata": {},
   "source": [
    "Approach -> [Keras Doc](https://keras.io/guides/customizing_what_happens_in_fit/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7743fd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def client_train(model, dataset):\n",
    "    \n",
    "    print(\"Retrace `client_train`\")\n",
    "    \n",
    "    @tf.function\n",
    "    def _step(model, batch):\n",
    "        \n",
    "        x_batch, y_batch = batch\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass: Compute predictions\n",
    "            y_batch_pred = model(x_batch, training=True)  # Forward pass\n",
    "\n",
    "            # Compute the loss value\n",
    "            # (the loss function is configured in `compile()`)\n",
    "            loss = model.compiled_loss(\n",
    "                y_true=y_batch,\n",
    "                y_pred=y_batch_pred,\n",
    "                regularization_losses=model.losses\n",
    "            )\n",
    "\n",
    "        # Compute gradients\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "\n",
    "        # Apply gradients to the model's trainable variables (update weights)\n",
    "        model.optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "        # Update metrics (includes the metric that tracks the loss)\n",
    "        model.compiled_metrics.update_state(y_batch, y_batch_pred)\n",
    "    \n",
    "    for batch in dataset:\n",
    "        _step(model, batch)\n",
    "    \n",
    "    # Return a dict mapping metric names to current value\n",
    "    #return {m.name: m.result() for m in model.metrics}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e316fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train(model, r):\n",
    "    for _ in tf.range(r):\n",
    "        client_train(model, fed_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e385a69e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ddd2ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a2f34a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3898ba75",
   "metadata": {},
   "source": [
    "# Early tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b1d8487",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_slices_train = create_data_for_clients(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a58f62d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_data = create_federated_data(\n",
    "    client_slices_train=client_slices_train,\n",
    "    batch_size=32,\n",
    "    shuffle_buffer_size=n_train,\n",
    "    num_steps_until_rtc_check=1,\n",
    "    seed=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fed50518",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = get_compiled_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6209f7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = get_compiled_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3b0f090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/miketheologitis/anaconda3/envs/tff-py39/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Retrace `client_train`\n"
     ]
    }
   ],
   "source": [
    "train(model1, tf.constant(500, shape=(), dtype=tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "315f9f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.28858897>,\n",
       " 'test_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9164375>}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{m.name: m.result() for m in model1.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e22f7b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrace `client_train`\n"
     ]
    }
   ],
   "source": [
    "train(model2, tf.constant(1000, shape=(), dtype=tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3102178f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.19986692>,\n",
       " 'test_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.94>}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{m.name: m.result() for m in model2.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719d3a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check difference variance etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4043dbe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f307b87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9739970b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b3eb45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras.utils.plot_model(model, \"damn.png\", show_shapes=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tff-py39] *",
   "language": "python",
   "name": "conda-env-tff-py39-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
