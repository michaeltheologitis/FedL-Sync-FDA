{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b4bea7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "055b8db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.11.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313ca374",
   "metadata": {},
   "source": [
    "## Create Binary Classification data with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69940316",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "n = 100_000\n",
    "d = 100\n",
    "\n",
    "\n",
    "noise_factor = 0.01 # % of the labels are randomly flipped, DEFAULT=0.01\n",
    "test_size = 0.1 # % of n\n",
    "# The factor multiplying the hypercube size. Larger values spread out the \n",
    "# clusters/classes and make the classification task easier. DEFAULT=1\n",
    "class_sep = -1\n",
    "seed = 7\n",
    "\n",
    "# Create (noisy) testing data for binary classification.\n",
    "X, y = make_classification(\n",
    "    n_samples=n, \n",
    "    n_features=d,\n",
    "    n_informative=d,\n",
    "    n_redundant=0, \n",
    "    n_classes=2,\n",
    "    class_sep=class_sep,\n",
    "    flip_y=noise_factor,\n",
    "    random_state=seed\n",
    ")\n",
    "\n",
    "# We will work with label values -1, +1 and not 0, +1 (convert)\n",
    "y[y == 0] = -1\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba160f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7846"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# PA-I regressor from sklearn\n",
    "pa1 = PassiveAggressiveClassifier(C=0.01, loss=\"hinge\", n_jobs=-1)\n",
    "pa1.fit(X_train, y_train)\n",
    "\n",
    "accuracy_score(y_test, pa1.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7841b1",
   "metadata": {},
   "source": [
    "## Convert to Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c46d87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = tf.constant(X_train, dtype=tf.float32)\n",
    "y_train_tensor = tf.constant(y_train, dtype=tf.float32)\n",
    "X_test_tensor = tf.constant(X_test, dtype=tf.float32)\n",
    "y_test_tensor = tf.constant(y_test, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358adb8f",
   "metadata": {},
   "source": [
    "Delete sklearn type data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8626b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X, y, X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7779e542",
   "metadata": {},
   "source": [
    "## Prepare data for Federated Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a002f9cf",
   "metadata": {},
   "source": [
    "### Create centralized testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a351bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "slices_test = (X_test_tensor, y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dc0a0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_dataset_for_testing(batch_size):\n",
    "    return tf.data.Dataset.from_tensor_slices(slices_test).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5576ca5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = create_tf_dataset_for_testing(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4809df",
   "metadata": {},
   "source": [
    "### Slice the Tensors for each Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5792cb",
   "metadata": {},
   "source": [
    "We will cut the training data, i.e., (`X_train_tensor`, `y_train_tensor`) to equal parts, each part corresponding to one Client. We want to give the result back as a dictionary with key `client_id` and value the training tensor data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b21e4eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_for_clients(num_clients):\n",
    "    \n",
    "    client_slices_train = {}\n",
    "\n",
    "    n_test = int(n - n*test_size)\n",
    "\n",
    "    for i in range(num_clients):\n",
    "        # Compute the indices for this client's slice\n",
    "        start_idx = int(i * n_test / num_clients)\n",
    "        end_idx = int((i + 1) * n_test / num_clients)\n",
    "\n",
    "        # Get the slice for this client\n",
    "        X_client_train = X_train_tensor[start_idx:end_idx]\n",
    "        y_client_train = y_train_tensor[start_idx:end_idx]\n",
    "        \n",
    "        # Combine the slices into a single dataset\n",
    "        client_slices_train[f'client_{i}'] = (X_client_train, y_client_train)\n",
    "    \n",
    "    return client_slices_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28604a1c",
   "metadata": {},
   "source": [
    "### Create TF friendly data for each Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f351360",
   "metadata": {},
   "source": [
    "Given a Tensor slice (i.e. value of `client_slices_train[\"client_id\"]` we convert it to highly optimized `tf.data.Dataset` to prepare for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba400a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_dataset_for_client(client_tensor_slices, batch_size, shuffle_buffer_size, num_steps_until_rtc_check, seed):\n",
    "    \n",
    "        return tf.data.Dataset.from_tensor_slices(client_tensor_slices) \\\n",
    "            .shuffle(buffer_size=shuffle_buffer_size, seed=seed).batch(batch_size) \\\n",
    "            .prefetch(tf.data.AUTOTUNE).take(num_steps_until_rtc_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e16b23",
   "metadata": {},
   "source": [
    "### Create Federated Learning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16be409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_federated_data(client_slices_train, batch_size, shuffle_buffer_size, num_steps_until_rtc_check, seed=None):\n",
    "    \n",
    "    federated_dataset = [ \n",
    "        create_tf_dataset_for_client(client_tensor_slices, batch_size, shuffle_buffer_size, num_steps_until_rtc_check, seed)\n",
    "        for client, client_tensor_slices in client_slices_train.items()\n",
    "    ]\n",
    "    \n",
    "    return federated_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6e7be4",
   "metadata": {},
   "source": [
    "## PA-Classiers (binary classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c37ce06",
   "metadata": {},
   "source": [
    "![PA](images/PA_binary_classifiers.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38f96baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def client_train(model, dataset, C):\n",
    "\n",
    "    @tf.function\n",
    "    def _train_on_batch(model, batch, C):\n",
    "\n",
    "        x_batch, y_batch = batch\n",
    "        \n",
    "        # from shape (d,) make it (d,1)\n",
    "        y_batch = tf.expand_dims(y_batch, axis=1)\n",
    "\n",
    "        # dot(w, x) for the batch (each instance of x in x_batch) with with shape=(batchsize, 1)\n",
    "        weights_dot_x_batch = tf.matmul(x_batch, model)\n",
    "\n",
    "        # Prediction batch with shape=(batchsize, 1)\n",
    "        y_pred_batch = tf.sign(weights_dot_x_batch)\n",
    "\n",
    "        # Suffer loss for each prediction (of instance) in the batch with shape=(batchsize,1)\n",
    "        loss_batch = tf.maximum(0., 1. - tf.multiply(y_batch, weights_dot_x_batch))\n",
    "\n",
    "        # shape=(batchsize,1) where each instance is ||x||^2, x in x_batch\n",
    "        norm_batch = tf.expand_dims(tf.reduce_sum(tf.square(x_batch), axis=1), axis=1)\n",
    "        \n",
    "        # PA-1 : Learning rate t for each instance x, with shape=(batchsize,1)\n",
    "        t_batch = tf.maximum(C, tf.divide(loss_batch, norm_batch))\n",
    "\n",
    "        # each instance is y*t*x, where y,t scalars and x in x_batch. shape=(batchsize,d)\n",
    "        t_y_x_batch = tf.multiply(t_batch, tf.multiply(y_batch, x_batch))\n",
    "\n",
    "        # !!!! Update with mean t*y*x\n",
    "        t_y_x_update = tf.expand_dims(tf.reduce_mean(t_y_x_batch, axis=0) ,axis=1)\n",
    "\n",
    "        # Update\n",
    "        model.assign_add(t_y_x_update)\n",
    "    \n",
    "    for batch in dataset:\n",
    "        _train_on_batch(model, batch, C)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93115f92",
   "metadata": {},
   "source": [
    "# Functional Dynamic Averaging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a2a6d7",
   "metadata": {},
   "source": [
    "We follow the Functional Dynamic Averaging (FDA) scheme. Let the mean model be\n",
    "\n",
    "$$ \\overline{w_t} = \\frac{1}{k} \\sum_{i=1}^{k} w_t^{(i)} $$\n",
    "\n",
    "where $ w_t^{(i)} $ is the model at time $ t $ in some round in the $i$-th learner.\n",
    "\n",
    "Local models are trained independently and cooperatively and we want to monitor the Round Terminating Conditon (**RTC**):\n",
    "\n",
    "$$ \\frac{1}{k} \\sum_{i=1}^{k} \\lVert w_t^{(i)} - \\overline{w_t} \\rVert_2^2  \\leq \\Theta $$\n",
    "\n",
    "where the left-hand side is the **model variance**, and threshold $\\Theta$ is a hyperparameter of the FDA, defined at the beginning of the round; it may change at each round. When the monitoring logic cannot guarantee the validity of RTC, the round terminates. All local models are pulled into `tff.SERVER`, and $\\bar{w_t}$ is set to their average. Then, another round begins."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003fe9e9",
   "metadata": {},
   "source": [
    "### Monitoring the RTC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c20ea38",
   "metadata": {},
   "source": [
    "FDA monitors the RTC by applying techniques from Functionary [Functional Geometric Averaging](http://users.softnet.tuc.gr/~minos/Papers/edbt19.pdf). We first restate the problem of monitoring RTC into the standard distributed stream monitoring formulation. Let\n",
    "\n",
    "$$ S(t) =  \\frac{1}{k} \\sum_{i=1}^{k} S_i(t) $$\n",
    "\n",
    "where $ S(t) \\in \\mathbb{R}^n $ be the \"global state\" of the system and $ S_i(t) \\in \\mathbb{R}^n $ the \"local states\". The goal is to monitor the threshold condition on the global state in the form $ F(S(t)) \\leq \\Theta $ where $ F : \\mathbb{R}^n \\to \\mathbb{R} $ a non-linear function. Let\n",
    "\n",
    "$$ \\Delta_t^{(i)} = w_t^{(i)} - w_{t_0}^{(i)} $$\n",
    "\n",
    "be the update at the $ i $-th learner, that is, the change to the local model at time $t$ since the beginning of the current round at time $t_0$. Let the average update be\n",
    "\n",
    "$$ \\overline{\\Delta_t} = \\frac{1}{k} \\sum_{i=1}^{k} \\Delta_t^{(i)} $$\n",
    "\n",
    "it follows that the variance can be written as\n",
    "\n",
    "$$ \\frac{1}{k} \\sum_{i=1}^{k} \\lVert w_t^{(i)} - \\overline{w_t} \\rVert_2^2 = \\Big( \\frac{1}{k} \\sum_{i=1}^{k} \\lVert \\Delta_t^{(i)} \\rVert_2^2 \\Big) - \\lVert \\overline{\\Delta_t} \\rVert_2^2 $$\n",
    "\n",
    "So, conceptually, if we define\n",
    "$$ S_i(t) = \\begin{bmatrix}\n",
    "           \\lVert \\Delta_t^{(i)} \\rVert_2^2 \\\\\n",
    "           \\Delta_t^{(i)}\n",
    "         \\end{bmatrix} \\quad \\text{and} \\quad\n",
    "         F(\\begin{bmatrix}\n",
    "           v \\\\\n",
    "           \\bf{x}\n",
    "         \\end{bmatrix}) = v - \\lVert \\bf{x} \\rVert_2^2 $$\n",
    "\n",
    "The RTC is equivalent to condition $$ F(S(t)) \\leq \\Theta $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3f52bb",
   "metadata": {},
   "source": [
    "## 1️⃣ Naive FDA\n",
    "\n",
    "In the naive approach, we eliminate the update vector from the local state (i.e. recuce the dimension to 0). Define local state as\n",
    "\n",
    "$$ S_i(t) = \\lVert \\Delta_t^{(i)} \\rVert_2^2 \\in \\mathbb{R}$$ \n",
    "\n",
    "and the identity function\n",
    "\n",
    "$$ F(v) = v $$\n",
    "\n",
    "It is trivial that $ F(S(t)) \\leq \\Theta $ implies the RTC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ab590e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def steps(last_sync_model, model, dataset, C):\n",
    "    # number of steps depent on `.take()` from `dataset`\n",
    "    client_train(model, dataset, C)\n",
    "    \n",
    "    Delta_i = model - last_sync_model\n",
    "    Delta_i_euc_norm_squared = tf.reduce_sum(tf.square(Delta_i), axis=0) # ||D(t)_i||^2\n",
    "    \n",
    "    return Delta_i_euc_norm_squared, Delta_i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31896e11",
   "metadata": {},
   "source": [
    "## Accuracy Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2459aeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def accuracy(model, dataset):\n",
    "    \n",
    "    @tf.function\n",
    "    def _batch_accuracy(model, batch):\n",
    "        x_batch, y_batch = batch\n",
    "        # from shape (d,) make it (d,1)\n",
    "        y_batch = tf.expand_dims(y_batch, axis=1)\n",
    "\n",
    "        # dot(w, x) for the batch (each instance of x in x_batch) with with shape=(batchsize, 1)\n",
    "        weights_dot_x_batch = tf.matmul(x_batch, model)\n",
    "\n",
    "        # Prediction batch with shape=(batchsize, 1)\n",
    "        y_pred_batch = tf.sign(weights_dot_x_batch)\n",
    "\n",
    "        accuracy = tf.reduce_mean(tf.cast(tf.equal(y_pred_batch, y_batch), tf.float32))\n",
    "\n",
    "        return accuracy\n",
    "    \n",
    "    # We take advantage of AutoGraph (convert Python code to TensorFlow-compatible graph code automatically)\n",
    "    acc, num_batches = 0., 0.\n",
    "    for batch in dataset:\n",
    "        acc += _batch_accuracy(model, batch)\n",
    "        num_batches += 1\n",
    "        \n",
    "    acc = acc / num_batches\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050f36f4",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "518ced69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "783257fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics:\n",
    "    def __init__(self, fda_name, n_train, d_train, test_size, num_clients, \n",
    "                 batch_size, steps_at_a_time, theta, C, sketch_width=0, sketch_depth=0):\n",
    "        \n",
    "        if fda_name == \"Naive\":\n",
    "            local_state_bytes = 4\n",
    "        elif fda_name == \"Linear\":\n",
    "            local_state_bytes = 8\n",
    "        else:\n",
    "            local_state_bytes = sketch_width * sketch_depth * 4\n",
    "        \n",
    "        self.initial_conditions = {\n",
    "            \"theta\" : tf.constant(theta, shape=(), dtype=tf.float64),\n",
    "            \"n_train\" : tf.constant(n_train, shape=(), dtype=tf.int64),\n",
    "            \"d_train\" : tf.constant(d_train, shape=(), dtype=tf.int64),\n",
    "            \"test_size\" : tf.constant(test_size, shape=(), dtype=tf.float64),\n",
    "            \"num_clients\" : tf.constant(num_clients, shape=(), dtype=tf.int64),\n",
    "            \"batch_size\" : tf.constant(batch_size, shape=(), dtype=tf.int64),\n",
    "            \"steps_at_a_time\" : tf.constant(steps_at_a_time, shape=(), dtype=tf.int64),\n",
    "            \"local_state_bytes\" : tf.constant(local_state_bytes, shape=(), dtype=tf.int64),\n",
    "            \"sketch_width\" : tf.constant(sketch_width, shape=(), dtype=tf.int64),\n",
    "            \"sketch_depth\" : tf.constant(sketch_depth, shape=(), dtype=tf.int64),\n",
    "            \"C\" : tf.constant(C, shape=(), dtype=tf.float64),\n",
    "            \"model_bytes\" : tf.constant(d*4, shape=(), dtype=tf.int64)\n",
    "        }\n",
    "        \n",
    "        self.final_metrics = {\n",
    "            \"accuracy\" : tf.Variable(0., dtype=tf.float32),\n",
    "            \"steps\" : tf.Variable(0, dtype=tf.int64),\n",
    "            \"rounds\" : tf.Variable(0, dtype=tf.int64),\n",
    "            \"monitoring_bytes_exchanged\" : tf.Variable(0, dtype=tf.int64),\n",
    "            \"model_bytes_exchanged\" : tf.Variable(0, dtype=tf.int64),\n",
    "            \"total_communication_bytes\" : tf.Variable(0, dtype=tf.int64),\n",
    "            \"trained_in_bytes\" : tf.Variable(0, dtype=tf.int64)\n",
    "        }\n",
    "\n",
    "    @tf.function\n",
    "    def step_completed(self):\n",
    "        self.final_metrics[\"steps\"].assign_add(1)\n",
    "        \n",
    "        self.final_metrics[\"monitoring_bytes_exchanged\"].assign_add(\n",
    "            self.initial_conditions[\"local_state_bytes\"] * self.initial_conditions[\"num_clients\"]\n",
    "        )\n",
    "        \n",
    "    \n",
    "    @tf.function\n",
    "    def round_completed(self):\n",
    "        # x2 because server sends back\n",
    "        self.final_metrics[\"model_bytes_exchanged\"].assign_add(\n",
    "            self.initial_conditions[\"model_bytes\"] * self.initial_conditions[\"num_clients\"] * 2\n",
    "        )\n",
    "        \n",
    "        self.final_metrics[\"rounds\"].assign_add(1)\n",
    "        \n",
    "        \n",
    "    @tf.function\n",
    "    def compute_final_metrics(self, model):\n",
    "        \n",
    "        self.final_metrics[\"accuracy\"].assign(\n",
    "            tf.cast(accuracy(model, test_dataset), dtype=tf.float32)\n",
    "        )\n",
    "        \n",
    "        self.final_metrics[\"total_communication_bytes\"].assign(\n",
    "            self.final_metrics[\"monitoring_bytes_exchanged\"] + self.final_metrics[\"model_bytes_exchanged\"]\n",
    "        )\n",
    "        \n",
    "        # `steps_at_a_time` basically is the number of batches per step (number of SGD steps<->batches)\n",
    "        self.final_metrics[\"trained_in_bytes\"].assign(\n",
    "            self.initial_conditions[\"batch_size\"] * (self.initial_conditions[\"d_train\"] + 1) * 4 \\\n",
    "            * self.initial_conditions[\"steps_at_a_time\"] * self.final_metrics[\"steps\"] \\\n",
    "            * self.initial_conditions[\"num_clients\"]\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aeccaf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_spec = tf.TensorSpec(shape=(20, d, 1), dtype=tf.float32)\n",
    "\n",
    "@tf.function(input_signature=[w_spec, w_spec])\n",
    "def variance(w_t, w_sync):\n",
    "    # w_t , w_sync tensors with shape=(NUM_CLIENTS, d, 1)\n",
    "    \n",
    "    # tensor with shape=(NUM_CLIENTS, d, 1)\n",
    "    diff = w_t - w_sync\n",
    "    \n",
    "    # tensor with shape=(NUM_CLIENTS, 1) , For each client ||w_i_t - w_t||^2\n",
    "    dot = tf.reduce_sum(tf.square(diff), axis=1)\n",
    "    \n",
    "    # Variance shape=() , scalar\n",
    "    var = tf.reduce_mean(dot)\n",
    "    \n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e57ba2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7cdd3460",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLIENTS = 20\n",
    "\n",
    "server_model = tf.Variable(tf.zeros(shape=(d, 1)), trainable=True, name='weights', dtype=tf.float32)\n",
    "\n",
    "testing_approx_0 = tf.Variable(tf.zeros(shape=()), trainable=True, name='zeros', dtype=tf.float32)\n",
    "    \n",
    "client_models = [\n",
    "    tf.Variable(tf.zeros(shape=(d, 1)), trainable=True, name='weights', dtype=tf.float32)\n",
    "    for _ in range(NUM_CLIENTS)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f27a8007",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_slices_train = create_data_for_clients(NUM_CLIENTS)\n",
    "BATCH_SIZE = 32\n",
    "NUM_STEPS_UNTIL_RTC_CHECK = 1\n",
    "\n",
    "federated_dataset = create_federated_data(\n",
    "    client_slices_train=client_slices_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle_buffer_size=int(n/20),\n",
    "    num_steps_until_rtc_check=NUM_STEPS_UNTIL_RTC_CHECK,\n",
    "    seed=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cbb3d9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ROUNDS = 5\n",
    "C = 0.01\n",
    "theta = 2.\n",
    "    \n",
    "metrics = Metrics(\n",
    "    fda_name=\"Naive\",\n",
    "    n_train=n, \n",
    "    d_train=d,\n",
    "    test_size=test_size,\n",
    "    num_clients=NUM_CLIENTS,\n",
    "    batch_size= BATCH_SIZE,\n",
    "    steps_at_a_time=NUM_STEPS_UNTIL_RTC_CHECK,\n",
    "    theta=theta,\n",
    "    C=C\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ebb80a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RTC(S, theta):\n",
    "    return S <= theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3c94064",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_everything(server_model, client_models, federated_dataset):\n",
    "    \n",
    "    S = tf.constant(0., dtype=tf.float32, shape=())\n",
    "    theta = 2.\n",
    "    \n",
    "    for r in range(NUM_ROUNDS):\n",
    "        \n",
    "        while RTC(S, theta):\n",
    "            S_i_clients = []\n",
    "            \n",
    "            Delta_i_clients = [] # test\n",
    "\n",
    "            # client steps (number depends on `federated_dataset`, i.e., `.take(num)`)\n",
    "            for client_model, client_dataset in zip(client_models, federated_dataset):\n",
    "                # test Delta_i\n",
    "                Delta_i_euc_norm_squared, Delta_i = steps(server_model, client_model, client_dataset, 0.01)\n",
    "                S_i_clients.append(Delta_i_euc_norm_squared)\n",
    "                \n",
    "                # test \n",
    "                Delta_i_clients.append(Delta_i) # test\n",
    "                \n",
    "            S = tf.reduce_mean(S_i_clients)\n",
    "            \n",
    "            metrics.step_completed() # METRICS\n",
    "            \n",
    "        # server average\n",
    "        server_model.assign(tf.reduce_mean(client_models, axis=0))\n",
    "        \n",
    "        # test\n",
    "        testing_approx_0 = tf.reduce_sum(tf.square(tf.reduce_mean(Delta_i_clients, axis=0)), axis=0) #test\n",
    "        \n",
    "        \n",
    "        #test\n",
    "        print(f\"var_approx = {S}\")\n",
    "        print(f\"assumed_0 = {testing_approx_0}\")\n",
    "        print(f\"var_actual = {variance(client_models, [server_model]*NUM_CLIENTS)}\")\n",
    "        print()\n",
    "        \n",
    "        # reset variance approx\n",
    "        S = tf.constant(0., dtype=tf.float32, shape=())\n",
    "\n",
    "        # synchronize clients\n",
    "        for client_model in client_models:\n",
    "            client_model.assign(server_model)\n",
    "        \n",
    "        metrics.round_completed() # METRICS\n",
    "    \n",
    "    \n",
    "    metrics.compute_final_metrics(server_model) # METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d7e7d0d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/miketheologitis/anaconda3/envs/tff-py39/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "var_approx = 2.0028328895568848\n",
      "assumed_0 = [1.7377768]\n",
      "var_actual = 0.26505622267723083\n",
      "\n",
      "var_approx = 2.1058177947998047\n",
      "assumed_0 = [1.8244708]\n",
      "var_actual = 0.2813469469547272\n",
      "\n",
      "var_approx = 2.0628159046173096\n",
      "assumed_0 = [1.7777321]\n",
      "var_actual = 0.2850838899612427\n",
      "\n",
      "var_approx = 2.036029100418091\n",
      "assumed_0 = [1.7657549]\n",
      "var_actual = 0.2702741026878357\n",
      "\n",
      "var_approx = 2.1346335411071777\n",
      "assumed_0 = [1.8287218]\n",
      "var_actual = 0.3059118986129761\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_everything(server_model, client_models, federated_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3143035c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.8177915>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(server_model, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8add81f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.8177915>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.final_metrics[\"accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "172b6f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=int64, numpy=121>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.final_metrics[\"steps\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b31cceb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=int64, numpy=5>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.final_metrics[\"rounds\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1d42c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=int64, numpy=9680>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.final_metrics[\"monitoring_bytes_exchanged\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "76816a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=int64, numpy=80000>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.final_metrics[\"model_bytes_exchanged\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27a0a365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=int64, numpy=89680>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.final_metrics[\"total_communication_bytes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b832532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=int64, numpy=31285760>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.final_metrics[\"trained_in_bytes\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54450dae",
   "metadata": {},
   "source": [
    "1. Add input_spec everywhere to avoid tracing [here](https://stackoverflow.com/questions/52774351/how-to-run-parallel-map-fn-when-eager-execution-enabled#:~:text=First%2C%20using%20tf.,once%2C%20so%2C%20the%20time.)\n",
    "2. Read [graphs](https://www.tensorflow.org/guide/intro_to_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd7dad9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tff-py39] *",
   "language": "python",
   "name": "conda-env-tff-py39-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
