{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12f8f459-1a0e-4584-9a59-d0182ee9fdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079baeb4-3ff4-461c-97cd-2e033646a817",
   "metadata": {},
   "source": [
    "## Import EMNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2f5a9f2-a315-4167-b085-33c1df5961b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e1c6b01-7986-4d55-8d0e-37e2c47f60a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b19675f-ad59-4e03-91ef-d8bd949c6dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_BATCH_INPUT = (None, 28, 28) # EMNIST dataset (None is used for batch size, as it varies)\n",
    "CNN_INPUT_RESHAPE = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb30c89b-f085-4ce8-b783-ea5fb65b0d10",
   "metadata": {},
   "source": [
    "## Prepare data for Federated Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c18aaa3-647f-4eb1-b396-4c66ee9f930b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to TensorFlow Datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(256)\n",
    "\n",
    "del X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3f5543-ce86-4b35-ac58-598ff694e0d5",
   "metadata": {},
   "source": [
    "### Slice the Tensors for each Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ecdda90-668f-43cc-a247-6f25538b7cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_federated_data_for_clients(num_clients):\n",
    "    \n",
    "    # Shard the data across clients CLIENT LEVEL\n",
    "    client_datasets = [\n",
    "        train_dataset.shard(num_clients, i)\n",
    "        for i in range(num_clients)\n",
    "    ]\n",
    "    \n",
    "    return client_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a29fb3-00c2-4332-99aa-8cf3d8c8e700",
   "metadata": {},
   "source": [
    "### Prepare (and restart) Client Dataset - shuffling, batching, prefetching\n",
    "\n",
    "Proper use of `.prefetch` [explained](https://stackoverflow.com/questions/63796936/what-is-the-proper-use-of-tensorflow-dataset-prefetch-and-cache-options).\n",
    "\n",
    "Proper ordering `.shuffle` and `.batch` and `.repeat` [explained](https://stackoverflow.com/questions/50437234/tensorflow-dataset-shuffle-then-batch-or-batch-then-shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d52400eb-8916-4d11-8e0c-9791962ebe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_federated_data_for_test(federated_data, batch_size, num_steps_until_rtc_check, seed=None):\n",
    "    \n",
    "    def process_client_dataset(client_dataset, batch_size, num_steps_until_rtc_check, seed, shuffle_size=512):\n",
    "        return client_dataset.shuffle(shuffle_size, seed=seed).repeat().batch(batch_size)\\\n",
    "            .take(num_steps_until_rtc_check).prefetch(tf.data.AUTOTUNE)\n",
    "        \n",
    "    federated_dataset_prepared = [\n",
    "        process_client_dataset(client_dataset, batch_size, num_steps_until_rtc_check, seed)\n",
    "        for client_dataset in federated_data\n",
    "    ]\n",
    "    return federated_dataset_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0abac82-295e-4bdd-90a1-0bf65bf8152e",
   "metadata": {},
   "source": [
    "# Miscallenious"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cd81fb-92bd-4d26-860c-7af532479f48",
   "metadata": {},
   "source": [
    "TODO: Metrics Time series + Regular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab51e4b2-fb82-422e-bd30-d2751e3e5902",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Neural Net weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e7d31b3-74dd-4b1d-8f96-2b24bd465664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_weights(model):\n",
    "    total_params = 0\n",
    "    for layer in model.layers:\n",
    "        total_params += np.sum([np.prod(weight.shape) for weight in layer.trainable_weights])\n",
    "    return int(total_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c80d8f-5c08-4821-945d-8cf4f4fd91c0",
   "metadata": {},
   "source": [
    "## Reseting NN weights for Server-Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afc54958-80ea-4e0e-8db7-44c85072a5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_trainable_variables(server_cnn, client_cnns, starting_trainable_variables):\n",
    "    \n",
    "    server_cnn.set_trainable_variables(starting_trainable_variables)\n",
    "    \n",
    "    for client_cnn in client_cnns:\n",
    "        client_cnn.set_trainable_variables(starting_trainable_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64e0c33-a73f-42f2-ba2e-0c38e2ec0004",
   "metadata": {},
   "source": [
    "# Simple Convolutional Neural Net (CNN) - Medium Size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c1164e-7dde-4bf4-b518-fb59f2747f12",
   "metadata": {},
   "source": [
    "A simple Convolutional Neural Network with a single convolutional layer, followed by a max-pooling layer, and two dense layers for classification. Designed for 28x28 grayscale images. It has 692,352 weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "647bdd24-789a-4699-a1cd-02259dc067bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(tf.keras.Model):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        self.reshape = layers.Reshape(CNN_INPUT_RESHAPE)\n",
    "        self.conv1 = layers.Conv2D(32, 3, activation='relu')\n",
    "        self.max_pool = layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.dense1 = layers.Dense(128, activation='relu')\n",
    "        self.dense2 = layers.Dense(num_classes, activation='softmax')\n",
    "\n",
    "        \n",
    "    # Defines the computation from inputs to outputs\n",
    "    def call(self, inputs, training=None):\n",
    "        x = self.reshape(inputs)  # Add a channel dimension\n",
    "        x = self.conv1(x)\n",
    "        x = self.max_pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def step(self, batch):\n",
    "        \n",
    "        x_batch, y_batch = batch\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass: Compute predictions\n",
    "            y_batch_pred = self(x_batch, training=True)\n",
    "\n",
    "            # Compute the loss value\n",
    "            # (the loss function is configured in `compile()`)\n",
    "            loss = self.compiled_loss(\n",
    "                y_true=y_batch,\n",
    "                y_pred=y_batch_pred,\n",
    "                regularization_losses=self.losses\n",
    "            )\n",
    "\n",
    "        # Compute gradients\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        \n",
    "        # Apply gradients to the model's trainable variables (update weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        \n",
    "        # Update metrics (includes the metric that tracks the loss)\n",
    "        #self.compiled_metrics.update_state(y_batch, y_batch_pred)\n",
    "    \n",
    "    \n",
    "    def train(self, dataset):\n",
    "\n",
    "        for batch in dataset:\n",
    "            self.step(batch)\n",
    "            \n",
    "    \n",
    "    def set_trainable_variables(self, trainable_vars):\n",
    "        \"\"\" Given `trainable_vars` set our `self.trainable_vars` \"\"\"\n",
    "        for model_var, var in zip(self.trainable_variables, trainable_vars):\n",
    "            model_var.assign(var)\n",
    "\n",
    "            \n",
    "    def trainable_vars_as_vector(self):\n",
    "        return tf.concat([tf.reshape(var, [-1]) for var in self.trainable_variables], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb705b3-64f1-4e9b-80eb-f9ff312dd863",
   "metadata": {},
   "source": [
    "### Helper function to compile and return the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4960717e-6839-49c6-8c7f-911fc39cbd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_and_built_cnn():\n",
    "    cnn = CNN()\n",
    "    \n",
    "    cnn.compile(\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False), # we have softmax\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')]\n",
    "    )\n",
    "    \n",
    "    cnn.build(CNN_BATCH_INPUT)  # EMNIST dataset (None is used for batch size, as it varies)\n",
    "    \n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a550fe5a-5268-453b-9b71-332fa67fe947",
   "metadata": {},
   "source": [
    "# Advanced Convolutional Neural Net (CNN) - Large Size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1031fcc1-6679-4c39-b140-ea707665550f",
   "metadata": {},
   "source": [
    "A more complex Convolutional Neural Network with three sets of two convolutional layers, each followed by a max-pooling layer, and two dense layers with dropout for classification. Designed for 28x28 grayscale images. It has 2,592,202 weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3141d998-651e-46d4-8ef1-cf359d0f7f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedCNN(tf.keras.Model):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(AdvancedCNN, self).__init__()\n",
    "        \n",
    "        self.reshape = layers.Reshape(CNN_INPUT_RESHAPE)\n",
    "        \n",
    "        self.conv1 = layers.Conv2D(64, kernel_size=3, activation='relu', padding='same')\n",
    "        self.conv2 = layers.Conv2D(64, kernel_size=3, activation='relu', padding='same')\n",
    "        self.max_pool1 = layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        \n",
    "        self.conv3 = layers.Conv2D(128, kernel_size=3, activation='relu', padding='same')\n",
    "        self.conv4 = layers.Conv2D(128, kernel_size=3, activation='relu', padding='same')\n",
    "        self.max_pool2 = layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        \n",
    "        self.conv5 = layers.Conv2D(256, kernel_size=3, activation='relu', padding='same')\n",
    "        self.conv6 = layers.Conv2D(256, kernel_size=3, activation='relu', padding='same')\n",
    "        self.max_pool3 = layers.MaxPooling2D(pool_size=(2, 2))\n",
    "\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.dense1 = layers.Dense(512, activation='relu')\n",
    "        self.dropout1 = layers.Dropout(0.5)\n",
    "        self.dense2 = layers.Dense(512, activation='relu')\n",
    "        self.dropout2 = layers.Dropout(0.5)\n",
    "        self.dense3 = layers.Dense(num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        x = self.reshape(inputs)  # Add a channel dimension\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.max_pool1(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.max_pool2(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.max_pool3(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dropout1(x, training=training)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dropout2(x, training=training)\n",
    "        x = self.dense3(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def step(self, batch):\n",
    "        \n",
    "        x_batch, y_batch = batch\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass: Compute predictions\n",
    "            y_batch_pred = self(x_batch, training=True)\n",
    "\n",
    "            # Compute the loss value\n",
    "            # (the loss function is configured in `compile()`)\n",
    "            loss = self.compiled_loss(\n",
    "                y_true=y_batch,\n",
    "                y_pred=y_batch_pred,\n",
    "                regularization_losses=self.losses\n",
    "            )\n",
    "\n",
    "        # Compute gradients\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        \n",
    "        # Apply gradients to the model's trainable variables (update weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        \n",
    "        # Update metrics (includes the metric that tracks the loss)\n",
    "        #self.compiled_metrics.update_state(y_batch, y_batch_pred)\n",
    "    \n",
    "    \n",
    "    def train(self, dataset):\n",
    "\n",
    "        for batch in dataset:\n",
    "            self.step(batch)\n",
    "            \n",
    "    \n",
    "    def set_trainable_variables(self, trainable_vars):\n",
    "        \"\"\" Given `trainable_vars` set our `self.trainable_vars` \"\"\"\n",
    "        for model_var, var in zip(self.trainable_variables, trainable_vars):\n",
    "            model_var.assign(var)\n",
    "\n",
    "            \n",
    "    def trainable_vars_as_vector(self):\n",
    "        return tf.concat([tf.reshape(var, [-1]) for var in self.trainable_variables], axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25606540-c2a0-4e43-8ccb-d48f0bbbfcc4",
   "metadata": {},
   "source": [
    "### Helper function to compile and return the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f3a6d1d-772f-435f-8ef5-117999a85f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_and_built_advanced_cnn():\n",
    "    advanced_cnn = AdvancedCNN()\n",
    "    \n",
    "    advanced_cnn.compile(\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False), # we have softmax\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')]\n",
    "    )\n",
    "    \n",
    "    advanced_cnn.build(CNN_BATCH_INPUT)  # EMNIST dataset (None is used for batch size, as it varies)\n",
    "    \n",
    "    return advanced_cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ba9905-67f5-4c59-a089-6ce27c1cf147",
   "metadata": {},
   "source": [
    "### Average NN weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1417655-5196-4954-9942-dab9d2fb3bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_client_weights(client_models):\n",
    "    # client_weights[0] the trainable variables of Client 0 (a list of tf.Variable)\n",
    "    client_weights = [model.trainable_variables for model in client_models]\n",
    "\n",
    "    # concise solution. per layer. `layer_weight_tensors` corresponds to a list of tensors of a layer\n",
    "    avg_weights = [\n",
    "        tf.reduce_mean(layer_weight_tensors, axis=0)\n",
    "        for layer_weight_tensors in zip(*client_weights)\n",
    "    ]\n",
    "\n",
    "    return avg_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f3a35c-5182-4767-a5bb-ffd35b374c81",
   "metadata": {},
   "source": [
    "### Server - Clients synchronization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16d98a88-4393-4360-8ad1-e244c846e5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synchronize(server_cnn, client_cnns):\n",
    "    # server average\n",
    "    server_cnn.set_trainable_variables(average_client_weights(client_cnns))\n",
    "    \n",
    "    # synchronize clients\n",
    "    for client_cnn in client_cnns:\n",
    "        client_cnn.set_trainable_variables(server_cnn.trainable_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6fdb3e-c945-43ef-934b-97af4a8144cc",
   "metadata": {},
   "source": [
    "# Functional Dynamic Averaging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0a989e-89d0-4e71-af83-b9d6f3347070",
   "metadata": {},
   "source": [
    "We follow the Functional Dynamic Averaging (FDA) scheme. Let the mean model be\n",
    "\n",
    "$$ \\overline{w_t} = \\frac{1}{k} \\sum_{i=1}^{k} w_t^{(i)} $$\n",
    "\n",
    "where $ w_t^{(i)} $ is the model at time $ t $ in some round in the $i$-th learner.\n",
    "\n",
    "Local models are trained independently and cooperatively and we want to monitor the Round Terminating Conditon (**RTC**):\n",
    "\n",
    "$$ \\frac{1}{k} \\sum_{i=1}^{k} \\lVert w_t^{(i)} - \\overline{w_t} \\rVert_2^2  \\leq \\Theta $$\n",
    "\n",
    "where the left-hand side is the **model variance**, and threshold $\\Theta$ is a hyperparameter of the FDA, defined at the beginning of the round; it may change at each round. When the monitoring logic cannot guarantee the validity of RTC, the round terminates. All local models are pulled into `tff.SERVER`, and $\\bar{w_t}$ is set to their average. Then, another round begins."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea88e748-3b00-47a9-b128-5bbb53adfac5",
   "metadata": {},
   "source": [
    "### Monitoring the RTC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08446303-59c6-4251-9ae1-0ca859e6cf77",
   "metadata": {},
   "source": [
    "FDA monitors the RTC by applying techniques from Functionary [Functional Geometric Averaging](http://users.softnet.tuc.gr/~minos/Papers/edbt19.pdf). We first restate the problem of monitoring RTC into the standard distributed stream monitoring formulation. Let\n",
    "\n",
    "$$ S(t) =  \\frac{1}{k} \\sum_{i=1}^{k} S_i(t) $$\n",
    "\n",
    "where $ S(t) \\in \\mathbb{R}^n $ be the \"global state\" of the system and $ S_i(t) \\in \\mathbb{R}^n $ the \"local states\". The goal is to monitor the threshold condition on the global state in the form $ F(S(t)) \\leq \\Theta $ where $ F : \\mathbb{R}^n \\to \\mathbb{R} $ a non-linear function. Let\n",
    "\n",
    "$$ \\Delta_t^{(i)} = w_t^{(i)} - w_{t_0}^{(i)} $$\n",
    "\n",
    "be the update at the $ i $-th learner, that is, the change to the local model at time $t$ since the beginning of the current round at time $t_0$. Let the average update be\n",
    "\n",
    "$$ \\overline{\\Delta_t} = \\frac{1}{k} \\sum_{i=1}^{k} \\Delta_t^{(i)} $$\n",
    "\n",
    "it follows that the variance can be written as\n",
    "\n",
    "$$ \\frac{1}{k} \\sum_{i=1}^{k} \\lVert w_t^{(i)} - \\overline{w_t} \\rVert_2^2 = \\Big( \\frac{1}{k} \\sum_{i=1}^{k} \\lVert \\Delta_t^{(i)} \\rVert_2^2 \\Big) - \\lVert \\overline{\\Delta_t} \\rVert_2^2 $$\n",
    "\n",
    "So, conceptually, if we define\n",
    "$$ S_i(t) = \\begin{bmatrix}\n",
    "           \\lVert \\Delta_t^{(i)} \\rVert_2^2 \\\\\n",
    "           \\Delta_t^{(i)}\n",
    "         \\end{bmatrix} \\quad \\text{and} \\quad\n",
    "         F(\\begin{bmatrix}\n",
    "           v \\\\\n",
    "           \\bf{x}\n",
    "         \\end{bmatrix}) = v - \\lVert \\bf{x} \\rVert_2^2 $$\n",
    "\n",
    "The RTC is equivalent to condition $$ F(S(t)) \\leq \\Theta $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f8ced7-22ce-404d-bd78-55590cfdd478",
   "metadata": {},
   "source": [
    "## 1️⃣ Naive FDA\n",
    "\n",
    "In the naive approach, we eliminate the update vector from the local state (i.e. recuce the dimension to 0). Define local state as\n",
    "\n",
    "$$ S_i(t) = \\lVert \\Delta_t^{(i)} \\rVert_2^2 \\in \\mathbb{R}$$ \n",
    "\n",
    "and the identity function\n",
    "\n",
    "$$ F(v) = v $$\n",
    "\n",
    "It is trivial that $ F(S(t)) \\leq \\Theta $ implies the RTC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ab384b-e2b3-4470-9a7b-e8f555d0245d",
   "metadata": {},
   "source": [
    "### Client Train\n",
    "\n",
    "The number of steps depends on the dataset, i.e., `.take(num)` call on `tf.data.Dataset` creation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ebcfa211-c199-4f93-9b01-7ef9aeba1c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_train_naive(last_sync_cnn, client_cnn, client_dataset):\n",
    "    \"\"\" Returns Tensor shape=() dtype=tf.float32 \"\"\"\n",
    "    \n",
    "    # number of steps depend on `.take()` from `dataset`\n",
    "    client_cnn.train(client_dataset)\n",
    "    \n",
    "    Delta_i = client_cnn.trainable_vars_as_vector() - last_sync_cnn.trainable_vars_as_vector()\n",
    "    \n",
    "    Delta_i_euc_norm_squared = tf.reduce_sum(tf.square(Delta_i)) # ||D(t)_i||^2\n",
    "    \n",
    "    return Delta_i_euc_norm_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738965e0-2852-42aa-88ee-e8f558252948",
   "metadata": {},
   "source": [
    "### Train all Clients\n",
    "\n",
    "We will now create the training function given many client CNNs. It is essential to use `@tf.function` wrapper here to let Tensorflow create a Graph since each Client can be trained in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7b5e970d-f8f0-4870-80ad-f56c8d49fced",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def clients_train_naive(last_sync_cnn, client_cnns, federated_dataset):\n",
    "    \"\"\" Returns list of Tensors shape=() dtype=tf.float32 \"\"\"\n",
    "    \n",
    "    print(\"retrace `clients_train_naive`\")\n",
    "    S_i_clients = []\n",
    "\n",
    "    for client_cnn, client_dataset in zip(client_cnns, federated_dataset):\n",
    "        Delta_i_euc_norm_squared = client_train_naive(last_sync_cnn, client_cnn, client_dataset)\n",
    "        S_i_clients.append(Delta_i_euc_norm_squared)\n",
    "    \n",
    "    return S_i_clients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bc0988-882c-4c7c-8ab0-27b86363c000",
   "metadata": {},
   "source": [
    "### Identity Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "da9b7c4c-da11-4e04-ba64-b035030a57b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_naive(S_i_clients):\n",
    "    \"\"\" Returns Tensor shape=() dtype=tf.float32 \"\"\"\n",
    "    \n",
    "    S = tf.reduce_mean(S_i_clients)\n",
    "    \n",
    "    return S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc5f85d-c56b-4869-87f0-88fc31183f83",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dd3e0d-e0be-4be6-8321-31fae8983fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937138e5-0c9e-4687-a50d-83290724ee33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37233f86-6c30-46af-b01b-d6cf0a0d875f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8c96d5-861b-4f4e-85cd-36a4b500c094",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30956ec6-ec03-4f36-b851-80c6d2a5507e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e9aec1-6120-4201-9df4-1dad15374bfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0cff9ee0-f81a-41fe-9859-997c8e259e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_stuff():\n",
    "    NUM_CLIENTS = 5\n",
    "    NUM_EPOCHS = 1\n",
    "    BATCH_SIZE = 32\n",
    "    NUM_STEPS_UNTIL_RTC_CHECK = 1\n",
    "    seed = 7\n",
    "    \n",
    "    clients_federated_data = create_federated_data_for_clients(NUM_CLIENTS)\n",
    "            \n",
    "    server_cnn = get_compiled_and_built_advanced_cnn()\n",
    "    client_cnns = [get_compiled_and_built_advanced_cnn() for _ in range(NUM_CLIENTS)]\n",
    "    \n",
    "    synchronize(server_cnn, client_cnns)\n",
    "    \n",
    "    federated_dataset = prepare_federated_data_for_test(\n",
    "        federated_data=clients_federated_data, \n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_steps_until_rtc_check=NUM_STEPS_UNTIL_RTC_CHECK,\n",
    "        seed=seed\n",
    "    )\n",
    "    \n",
    "    return server_cnn, client_cnns, federated_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642c1dd8-85ea-46a9-a6b2-3beb834a1963",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-212] *",
   "language": "python",
   "name": "conda-env-tf-212-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
