{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b4bea7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "055b8db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.11.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313ca374",
   "metadata": {},
   "source": [
    "## Create Binary Classification data with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69940316",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "n = 10_000 # we want 200_00\n",
    "d = 1_00\n",
    "\n",
    "\n",
    "noise_factor = 0.02 # % of the labels are randomly flipped, DEFAULT=0.01\n",
    "test_size = 0.2 # % of n\n",
    "# The factor multiplying the hypercube size. Larger values spread out the \n",
    "# clusters/classes and make the classification task easier. DEFAULT=1\n",
    "class_sep = 2\n",
    "seed = 7 # `None` for no seed\n",
    "\n",
    "# Create (noisy) testing data for binary classification.\n",
    "X, y = make_classification(\n",
    "    n_samples=n, \n",
    "    n_features=d,\n",
    "    n_informative=d,\n",
    "    n_redundant=0, \n",
    "    n_classes=2,\n",
    "    class_sep=class_sep,\n",
    "    flip_y=noise_factor,\n",
    "    random_state=seed\n",
    ")\n",
    "\n",
    "# We will work with label values -1, +1 and not 0, +1 (convert)\n",
    "y[y == 0] = -1\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "681b7b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba160f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.943"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# PA-I regressor from sklearn\n",
    "pa1 = PassiveAggressiveClassifier(C=0.01, loss=\"hinge\", n_jobs=-1)\n",
    "pa1.fit(X_train, y_train)\n",
    "\n",
    "accuracy_score(y_test, pa1.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6bc2f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d7841b1",
   "metadata": {},
   "source": [
    "## Convert to Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c46d87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = tf.constant(X_train, dtype=tf.float32)\n",
    "del X_train\n",
    "\n",
    "y_train_tensor = tf.constant(y_train, dtype=tf.float32)\n",
    "del y_train\n",
    "\n",
    "X_test_tensor = tf.constant(X_test, dtype=tf.float32)\n",
    "del X_test\n",
    "\n",
    "y_test_tensor = tf.constant(y_test, dtype=tf.float32)\n",
    "del y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7779e542",
   "metadata": {},
   "source": [
    "## Prepare data for Federated Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a002f9cf",
   "metadata": {},
   "source": [
    "### Create centralized testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a351bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "slices_test = (X_test_tensor, y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dc0a0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_dataset_for_testing(batch_size):\n",
    "    return tf.data.Dataset.from_tensor_slices(slices_test).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5576ca5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = create_tf_dataset_for_testing(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4809df",
   "metadata": {},
   "source": [
    "### Slice the Tensors for each Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5792cb",
   "metadata": {},
   "source": [
    "We will cut the training data, i.e., (`X_train_tensor`, `y_train_tensor`) to equal parts, each part corresponding to one Client. We want to give the result back as a dictionary with key `client_id` and value the training tensor data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b21e4eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_for_clients(num_clients):\n",
    "    \n",
    "    client_slices_train = {}\n",
    "\n",
    "    n_test = int(n - n*test_size)\n",
    "\n",
    "    for i in range(num_clients):\n",
    "        # Compute the indices for this client's slice\n",
    "        start_idx = int(i * n_test / num_clients)\n",
    "        end_idx = int((i + 1) * n_test / num_clients)\n",
    "\n",
    "        # Get the slice for this client\n",
    "        X_client_train = X_train_tensor[start_idx:end_idx]\n",
    "        y_client_train = y_train_tensor[start_idx:end_idx]\n",
    "        \n",
    "        # Combine the slices into a single dataset\n",
    "        client_slices_train[f'client_{i}'] = (X_client_train, y_client_train)\n",
    "    \n",
    "    return client_slices_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28604a1c",
   "metadata": {},
   "source": [
    "### Create TF friendly data for each Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f351360",
   "metadata": {},
   "source": [
    "Given a Tensor slice (i.e. value of `client_slices_train[\"client_id\"]` we convert it to highly optimized `tf.data.Dataset` to prepare for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba400a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_dataset_for_client(client_tensor_slices, batch_size, shuffle_buffer_size, num_steps_until_rtc_check, seed):\n",
    "    \n",
    "        return tf.data.Dataset.from_tensor_slices(client_tensor_slices) \\\n",
    "            .shuffle(buffer_size=shuffle_buffer_size, seed=seed).batch(batch_size) \\\n",
    "            .prefetch(tf.data.AUTOTUNE).take(num_steps_until_rtc_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e16b23",
   "metadata": {},
   "source": [
    "### Create Federated Learning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16be409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_federated_data(client_slices_train, batch_size, shuffle_buffer_size, num_steps_until_rtc_check, seed=None):\n",
    "    \n",
    "    federated_dataset = [ \n",
    "        create_tf_dataset_for_client(client_tensor_slices, batch_size, shuffle_buffer_size, num_steps_until_rtc_check, seed)\n",
    "        for client, client_tensor_slices in client_slices_train.items()\n",
    "    ]\n",
    "    \n",
    "    return federated_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5115e0",
   "metadata": {},
   "source": [
    "# Miscallenious"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7329b0b",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6e6686f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metrics_dict(fda_name, n, d, test_size, seed, class_sep, noise_factor, epochs, num_clients, \n",
    "                        batch_size, steps_in_one_fda_step, theta, c, total_fda_steps, \n",
    "                        total_rounds, final_accuracy, sketch_width=None, sketch_depth=None):\n",
    "    metrics = {\n",
    "            \"fda_name\" : fda_name,\n",
    "            \"theta\" : theta,\n",
    "            \"n\" : n,\n",
    "            \"d\" : d,\n",
    "            \"seed\" : seed,\n",
    "            \"class_sep\" : class_sep,\n",
    "            \"noise_factor\" : noise_factor,\n",
    "            \"test_size\" : test_size,\n",
    "            \"epochs\" : epochs,\n",
    "            \"num_clients\" : num_clients,\n",
    "            \"batch_size\" : batch_size,\n",
    "            \"steps_in_one_fda_step\" : steps_in_one_fda_step,\n",
    "            \"sketch_width\" : sketch_width,\n",
    "            \"sketch_depth\" : sketch_depth,\n",
    "            \"c\" : c\n",
    "        }\n",
    "    \n",
    "    # one batch bytes\n",
    "    metrics[\"one_sample_bytes\"] = 4 * (metrics[\"d\"] + 1)\n",
    "    \n",
    "    # training dataset size\n",
    "    metrics[\"training_dataset_bytes\"] = metrics[\"one_sample_bytes\"] * (1 - metrics[\"test_size\"]) * metrics[\"n\"]\n",
    "    \n",
    "    # model bytes\n",
    "    metrics[\"model_bytes\"] = d * 4\n",
    "    \n",
    "    \n",
    "    # local state bytes (i.e. S_i), for one client\n",
    "    if fda_name == \"naive\":\n",
    "        metrics[\"local_state_bytes\"] = 4\n",
    "    elif fda_name == \"linear\":\n",
    "        metrics[\"local_state_bytes\"] = 8\n",
    "    else:\n",
    "        metrics[\"local_state_bytes\"] = sketch_width * sketch_depth * 4 + 4\n",
    "        \n",
    "    # accuracy (already computed in parameter)\n",
    "    metrics[\"final_accuracy\"] = final_accuracy\n",
    "    \n",
    "    # total fda steps from algo\n",
    "    metrics[\"total_fda_steps\"] = total_fda_steps\n",
    "    \n",
    "    # total steps (a single fda step might have many normal SGD steps, batch steps)\n",
    "    metrics[\"total_steps\"] = metrics[\"total_fda_steps\"] * metrics[\"steps_in_one_fda_step\"]\n",
    "    \n",
    "    # total rounds in algo. Reason why we differentiate from the hardcoded NUM_ROUNDS\n",
    "    # is because we might run less rounds in the future (i.e. stop on 10^7 samples idk)\n",
    "    metrics[\"total_rounds\"] = total_rounds\n",
    "    \n",
    "    # bytes exchanged for synchronizing weights (x2 because server sends back)\n",
    "    metrics[\"model_bytes_exchanged\"] = metrics[\"total_rounds\"] * metrics[\"model_bytes\"] \\\n",
    "        * metrics[\"num_clients\"] * 2\n",
    "    \n",
    "    # bytes exchanged for monitoring the variance (communication)\n",
    "    metrics[\"monitoring_bytes_exchanged\"] = metrics[\"local_state_bytes\"] * metrics[\"total_fda_steps\"] \\\n",
    "        * metrics[\"num_clients\"]\n",
    "    \n",
    "    # total communication bytes (for both monitoring and model synchronization)\n",
    "    metrics[\"total_communication_bytes\"] = metrics[\"model_bytes_exchanged\"] + metrics[\"monitoring_bytes_exchanged\"]\n",
    "    \n",
    "    # total seen dataset bytes (across all learning, i.e., all clients)\n",
    "    metrics[\"trained_in_bytes\"] = metrics[\"batch_size\"] * metrics[\"one_sample_bytes\"] \\\n",
    "        * metrics[\"total_steps\"] * metrics[\"num_clients\"]\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c54083",
   "metadata": {},
   "source": [
    "## Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ee83adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# = client_num\n",
    "w_spec = tf.TensorSpec(shape=(20, d, 1), dtype=tf.float32)\n",
    "\n",
    "@tf.function(input_signature=[w_spec, w_spec])\n",
    "def variance(w_t, w_sync):\n",
    "    # w_t , w_sync tensors with shape=(NUM_CLIENTS, d, 1)\n",
    "    \n",
    "    # tensor with shape=(NUM_CLIENTS, d, 1)\n",
    "    diff = w_t - w_sync\n",
    "    \n",
    "    # tensor with shape=(NUM_CLIENTS, 1) , For each client ||w_i_t - w_t||^2\n",
    "    dot = tf.reduce_sum(tf.square(diff), axis=1)\n",
    "    \n",
    "    # Variance shape=() , scalar\n",
    "    var = tf.reduce_mean(dot)\n",
    "    \n",
    "    return var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca41b7bc",
   "metadata": {},
   "source": [
    "## Accuracy testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d94157c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def accuracy(model, dataset):\n",
    "    \n",
    "    @tf.function\n",
    "    def _batch_accuracy(model, batch):\n",
    "        x_batch, y_batch = batch\n",
    "        # from shape (d,) make it (d,1)\n",
    "        y_batch = tf.expand_dims(y_batch, axis=1)\n",
    "\n",
    "        # dot(w, x) for the batch (each instance of x in x_batch) with with shape=(batchsize, 1)\n",
    "        weights_dot_x_batch = tf.matmul(x_batch, model)\n",
    "\n",
    "        # Prediction batch with shape=(batchsize, 1)\n",
    "        y_pred_batch = tf.sign(weights_dot_x_batch)\n",
    "\n",
    "        accuracy = tf.reduce_mean(tf.cast(tf.equal(y_pred_batch, y_batch), tf.float32))\n",
    "\n",
    "        return accuracy\n",
    "    \n",
    "    # We take advantage of AutoGraph (convert Python code to TensorFlow-compatible graph code automatically)\n",
    "    acc, num_batches = 0., 0.\n",
    "    for batch in dataset:\n",
    "        acc += _batch_accuracy(model, batch)\n",
    "        num_batches += 1\n",
    "        \n",
    "    acc = acc / num_batches\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6e7be4",
   "metadata": {},
   "source": [
    "## PA-Classiers (binary classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c37ce06",
   "metadata": {},
   "source": [
    "![PA](images/PA_binary_classifiers.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38f96baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def client_train(model, dataset, C):\n",
    "\n",
    "    @tf.function\n",
    "    def _train_on_batch(model, batch, C):\n",
    "\n",
    "        x_batch, y_batch = batch\n",
    "        \n",
    "        # from shape (d,) make it (d,1)\n",
    "        y_batch = tf.expand_dims(y_batch, axis=1)\n",
    "\n",
    "        # dot(w, x) for the batch (each instance of x in x_batch) with with shape=(batchsize, 1)\n",
    "        weights_dot_x_batch = tf.matmul(x_batch, model)\n",
    "\n",
    "        # Prediction batch with shape=(batchsize, 1)\n",
    "        y_pred_batch = tf.sign(weights_dot_x_batch)\n",
    "\n",
    "        # Suffer loss for each prediction (of instance) in the batch with shape=(batchsize,1)\n",
    "        loss_batch = tf.maximum(0., 1. - tf.multiply(y_batch, weights_dot_x_batch))\n",
    "\n",
    "        # shape=(batchsize,1) where each instance is ||x||^2, x in x_batch\n",
    "        norm_batch = tf.expand_dims(tf.reduce_sum(tf.square(x_batch), axis=1), axis=1)\n",
    "        \n",
    "        # PA-1 : Learning rate t for each instance x, with shape=(batchsize,1)\n",
    "        t_batch = tf.maximum(C, tf.divide(loss_batch, norm_batch))\n",
    "\n",
    "        # each instance is y*t*x, where y,t scalars and x in x_batch. shape=(batchsize,d)\n",
    "        t_y_x_batch = tf.multiply(t_batch, tf.multiply(y_batch, x_batch))\n",
    "\n",
    "        # !!!! Update with mean t*y*x\n",
    "        t_y_x_update = tf.expand_dims(tf.reduce_mean(t_y_x_batch, axis=0) ,axis=1)\n",
    "\n",
    "        # Update\n",
    "        model.assign_add(t_y_x_update)\n",
    "    \n",
    "    for batch in dataset:\n",
    "        _train_on_batch(model, batch, C)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93115f92",
   "metadata": {},
   "source": [
    "# Functional Dynamic Averaging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a2a6d7",
   "metadata": {},
   "source": [
    "We follow the Functional Dynamic Averaging (FDA) scheme. Let the mean model be\n",
    "\n",
    "$$ \\overline{w_t} = \\frac{1}{k} \\sum_{i=1}^{k} w_t^{(i)} $$\n",
    "\n",
    "where $ w_t^{(i)} $ is the model at time $ t $ in some round in the $i$-th learner.\n",
    "\n",
    "Local models are trained independently and cooperatively and we want to monitor the Round Terminating Conditon (**RTC**):\n",
    "\n",
    "$$ \\frac{1}{k} \\sum_{i=1}^{k} \\lVert w_t^{(i)} - \\overline{w_t} \\rVert_2^2  \\leq \\Theta $$\n",
    "\n",
    "where the left-hand side is the **model variance**, and threshold $\\Theta$ is a hyperparameter of the FDA, defined at the beginning of the round; it may change at each round. When the monitoring logic cannot guarantee the validity of RTC, the round terminates. All local models are pulled into `tff.SERVER`, and $\\bar{w_t}$ is set to their average. Then, another round begins."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003fe9e9",
   "metadata": {},
   "source": [
    "### Monitoring the RTC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c20ea38",
   "metadata": {},
   "source": [
    "FDA monitors the RTC by applying techniques from Functionary [Functional Geometric Averaging](http://users.softnet.tuc.gr/~minos/Papers/edbt19.pdf). We first restate the problem of monitoring RTC into the standard distributed stream monitoring formulation. Let\n",
    "\n",
    "$$ S(t) =  \\frac{1}{k} \\sum_{i=1}^{k} S_i(t) $$\n",
    "\n",
    "where $ S(t) \\in \\mathbb{R}^n $ be the \"global state\" of the system and $ S_i(t) \\in \\mathbb{R}^n $ the \"local states\". The goal is to monitor the threshold condition on the global state in the form $ F(S(t)) \\leq \\Theta $ where $ F : \\mathbb{R}^n \\to \\mathbb{R} $ a non-linear function. Let\n",
    "\n",
    "$$ \\Delta_t^{(i)} = w_t^{(i)} - w_{t_0}^{(i)} $$\n",
    "\n",
    "be the update at the $ i $-th learner, that is, the change to the local model at time $t$ since the beginning of the current round at time $t_0$. Let the average update be\n",
    "\n",
    "$$ \\overline{\\Delta_t} = \\frac{1}{k} \\sum_{i=1}^{k} \\Delta_t^{(i)} $$\n",
    "\n",
    "it follows that the variance can be written as\n",
    "\n",
    "$$ \\frac{1}{k} \\sum_{i=1}^{k} \\lVert w_t^{(i)} - \\overline{w_t} \\rVert_2^2 = \\Big( \\frac{1}{k} \\sum_{i=1}^{k} \\lVert \\Delta_t^{(i)} \\rVert_2^2 \\Big) - \\lVert \\overline{\\Delta_t} \\rVert_2^2 $$\n",
    "\n",
    "So, conceptually, if we define\n",
    "$$ S_i(t) = \\begin{bmatrix}\n",
    "           \\lVert \\Delta_t^{(i)} \\rVert_2^2 \\\\\n",
    "           \\Delta_t^{(i)}\n",
    "         \\end{bmatrix} \\quad \\text{and} \\quad\n",
    "         F(\\begin{bmatrix}\n",
    "           v \\\\\n",
    "           \\bf{x}\n",
    "         \\end{bmatrix}) = v - \\lVert \\bf{x} \\rVert_2^2 $$\n",
    "\n",
    "The RTC is equivalent to condition $$ F(S(t)) \\leq \\Theta $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5433a7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3f52bb",
   "metadata": {},
   "source": [
    "## 1️⃣ Naive FDA\n",
    "\n",
    "In the naive approach, we eliminate the update vector from the local state (i.e. recuce the dimension to 0). Define local state as\n",
    "\n",
    "$$ S_i(t) = \\lVert \\Delta_t^{(i)} \\rVert_2^2 \\in \\mathbb{R}$$ \n",
    "\n",
    "and the identity function\n",
    "\n",
    "$$ F(v) = v $$\n",
    "\n",
    "It is trivial that $ F(S(t)) \\leq \\Theta $ implies the RTC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ab590e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def steps_naive(last_sync_model, model, dataset, C):\n",
    "    # number of steps depend on `.take()` from `dataset`\n",
    "    client_train(model, dataset, C)\n",
    "    \n",
    "    Delta_i = model - last_sync_model\n",
    "    \n",
    "    Delta_i_euc_norm_squared = tf.reduce_sum(tf.square(Delta_i), axis=0) # ||D(t)_i||^2\n",
    "    \n",
    "    return Delta_i_euc_norm_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050f36f4",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ebb80a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_naive(S):\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3c94064",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def run_federated_simulation_naive(server_model, client_models, federated_dataset, C,\n",
    "                                   num_epochs, theta, epoch_fda_steps):\n",
    "    \n",
    "    print(\"retracing naive\")\n",
    "    \n",
    "    total_rounds = 0\n",
    "    total_fda_steps = 0\n",
    "    \n",
    "    round_fda_steps = tf.constant(0, shape=(), dtype=tf.int32)\n",
    "    epoch_count = tf.constant(0, shape=(), dtype=tf.int32)\n",
    "    \n",
    "    S = tf.constant(0., shape=(), dtype=tf.float32)\n",
    "    \n",
    "    while epoch_count < num_epochs:\n",
    "        \n",
    "        while F_naive(S) <= theta:\n",
    "            S_i_clients = []\n",
    "\n",
    "            # client steps (number depends on `federated_dataset`, i.e., `.take(num)`)\n",
    "            for client_model, client_dataset in zip(client_models, federated_dataset):\n",
    "                Delta_i_euc_norm_squared = steps_naive(server_model, client_model, client_dataset, C)\n",
    "                S_i_clients.append(Delta_i_euc_norm_squared)\n",
    "                \n",
    "            S = tf.reduce_mean(S_i_clients)\n",
    "            \n",
    "            round_fda_steps += 1\n",
    "            total_fda_steps += 1\n",
    "            \n",
    "            if round_fda_steps == epoch_fda_steps:\n",
    "                epoch_count += 1\n",
    "                round_fda_steps = tf.constant(0, shape=(), dtype=tf.int32)\n",
    "                \n",
    "                if epoch_count == num_epochs:\n",
    "                    break\n",
    "        \n",
    "        \n",
    "        \"\"\"------------------------------test--------------------------------------------\"\"\"\n",
    "        #tf.print(\"\\n sync : \", output_stream=sys.stdout)\n",
    "        #Delta_i_clients = [tf.subtract(client_model, server_model) for client_model in client_models] #test\n",
    "        #testing_approx_0 = tf.reduce_sum(tf.square(tf.reduce_mean(Delta_i_clients, axis=0)), axis=0) #test\n",
    "        #for client_model in client_models:\n",
    "        #        tf.print(\"acc : \", accuracy(client_model, test_dataset), output_stream=sys.stdout)\n",
    "        \"\"\"------------------------------test--------------------------------------------\"\"\"\n",
    "        \n",
    "        # server average\n",
    "        server_model.assign(tf.reduce_mean(client_models, axis=0))\n",
    "        \n",
    "        \"\"\"------------------------------test--------------------------------------------\"\"\"\n",
    "        #tf.print(\"acc (after) : \", accuracy(server_model, test_dataset), output_stream=sys.stdout)\n",
    "        #tf.print(\"Naive Epoch count: \", epoch_count, \" Round fda steps: \", round_fda_steps, \" Epoch fda steps:\", epoch_fda_steps, output_stream=sys.stdout)\n",
    "        #tf.print(\"Naive Epoch count: \", epoch_count, output_stream=sys.stdout)\n",
    "        #actual_var = variance(client_models, [server_model]*len(client_models)) #test\n",
    "        #tf.print(\"Est var: \", S, \" Actual var: \", actual_var, \" Total fda steps: \", total_fda_steps, output_stream=sys.stdout)\n",
    "        #tf.print(\"\\n\", output_stream=sys.stdout)\n",
    "        \"\"\"------------------------------test--------------------------------------------\"\"\"\n",
    "        \n",
    "        # reset variance approx\n",
    "        S = tf.constant(0., shape=(), dtype=tf.float32)\n",
    "\n",
    "        # synchronize clients\n",
    "        for client_model in client_models:\n",
    "            client_model.assign(server_model)\n",
    "            \n",
    "        total_rounds += 1\n",
    "    \n",
    "    return total_rounds, total_fda_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb4ed22",
   "metadata": {},
   "source": [
    "## 2️⃣ Linear FDA\n",
    "\n",
    "In the linear case, we reduce the update vector to a scalar, $ \\xi \\Delta_t^{(i)} \\in \\mathbb{R}$, where $ \\xi $ is any unit vector.\n",
    "\n",
    "Define the local state to be \n",
    "\n",
    "$$ S_i(t) = \\begin{bmatrix}\n",
    "           \\lVert \\Delta_t^{(i)} \\rVert_2^2 \\\\\n",
    "           \\xi \\Delta_t^{(i)}\n",
    "         \\end{bmatrix} \\in \\mathbb{R}^2 $$\n",
    "\n",
    "Also, define \n",
    "\n",
    "$$ F(v, x) = v - x^2 $$\n",
    "\n",
    "The RTC is equivalent to condition \n",
    "\n",
    "$$ F(S(t)) \\leq \\Theta $$\n",
    "\n",
    "A random choice of $ \\xi $ is likely to perform poorly (terminate round prematurely), as it wil likely be close to orthogonal to $ \\overline{\\Delta_t} $. A good choice would be a vector $ \\xi $ correlated to $ \\overline{\\Delta_t} $. A heuristic choice is to take $ \\overline{\\Delta_{t_0}} $ (after scaling it to norm 1), i.e., the update vector right before the current round started. All nodes can estimate this without communication, as $ \\overline{w_{t_0}} - \\overline{w_{t_{-1}}} $, the difference of the last two models pushed by the Server. Hence, \n",
    "\n",
    "$$ \\xi = \\frac{\\overline{w_{t_0}} - \\overline{w_{t_{-1}}}}{\\lVert \\overline{w_{t_0}} - \\overline{w_{t_{-1}}} \\rVert_2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0afcc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def ksi_unit_fn(w_t0, w_tminus1):\n",
    "    \n",
    "    if tf.reduce_all(tf.equal(w_t0, w_tminus1)):\n",
    "        # if equal then ksi becomes a random vector (will only happen in round 1)\n",
    "        ksi = tf.random.normal(shape=w_t0.shape)\n",
    "    else:\n",
    "        ksi = w_t0 - w_tminus1\n",
    "\n",
    "    # Normalize and return\n",
    "    return tf.divide(ksi, tf.norm(ksi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6e04fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def steps_linear(model_tminus, model_t0, model, dataset, C):\n",
    "    # number of steps depend on `.take()` from `dataset`\n",
    "    client_train(model, dataset, C)\n",
    "    \n",
    "    Delta_i = model - model_t0\n",
    "    \n",
    "    #||D(t)_i||^2 , shape = (1,) \n",
    "    Delta_i_euc_norm_squared = tf.reduce_sum(tf.square(Delta_i), axis=0)\n",
    "    \n",
    "    # heuristic unit vector ksi\n",
    "    ksi = ksi_unit_fn(model_t0, model_tminus)\n",
    "    \n",
    "    # ksi * Delta_i (* is dot) , shape = ()\n",
    "    ksi_Delta_i = tf.reduce_sum(tf.multiply(ksi, Delta_i))\n",
    "    \n",
    "    return Delta_i_euc_norm_squared, ksi_Delta_i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666cb80d",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ac60a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_linear(S_1, S_2):\n",
    "    return S_1 - S_2**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4fa017f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def run_federated_simulation_linear(previous_server_model, server_model,\n",
    "                                    client_models, federated_dataset, C, \n",
    "                                    num_epochs, theta, epoch_fda_steps):\n",
    "    \n",
    "    print(\"retracing linear\")\n",
    "    \n",
    "    total_rounds = 0\n",
    "    total_fda_steps = 0\n",
    "    \n",
    "    round_fda_steps = tf.constant(0, shape=(), dtype=tf.int32)\n",
    "    epoch_count = tf.constant(0, shape=(), dtype=tf.int32)\n",
    "    \n",
    "    S_1 = tf.constant(0., shape=(), dtype=tf.float32)\n",
    "    S_2 = tf.constant(0., shape=(), dtype=tf.float32)\n",
    "    \n",
    "    while epoch_count < num_epochs:\n",
    "        \n",
    "        while F_linear(S_1, S_2) <= theta:\n",
    "            euc_norm_squared_clients = []\n",
    "            ksi_delta_clients = []\n",
    "\n",
    "            # client steps (number depends on `federated_dataset`, i.e., `.take(num)`)\n",
    "            for client_model, client_dataset in zip(client_models, federated_dataset):\n",
    "                \n",
    "                Delta_i_euc_norm_squared, ksi_Delta_i  = steps_linear(\n",
    "                    previous_server_model, server_model, client_model, client_dataset, C\n",
    "                )\n",
    "                \n",
    "                euc_norm_squared_clients.append(Delta_i_euc_norm_squared)\n",
    "                ksi_delta_clients.append(ksi_Delta_i)\n",
    "                \n",
    "            S_1 = tf.reduce_mean(euc_norm_squared_clients)\n",
    "            S_2 = tf.reduce_mean(ksi_delta_clients)\n",
    "            \n",
    "            round_fda_steps += 1\n",
    "            total_fda_steps += 1\n",
    "            \n",
    "            if round_fda_steps == epoch_fda_steps:\n",
    "                epoch_count += 1\n",
    "                round_fda_steps = tf.constant(0, shape=(), dtype=tf.int32)\n",
    "                \n",
    "                if epoch_count == num_epochs:\n",
    "                    break\n",
    "        \n",
    "        # last server model (previous sync)\n",
    "        previous_server_model.assign(server_model)\n",
    "        \n",
    "        \"\"\"------------------------------test--------------------------------------------\"\"\"\n",
    "        #tf.print(\"\\n sync : \", output_stream=sys.stdout)\n",
    "        #Delta_i_clients = [tf.subtract(client_model, server_model) for client_model in client_models] #test\n",
    "        #testing_approx_0 = tf.reduce_sum(tf.square(tf.reduce_mean(Delta_i_clients, axis=0)), axis=0) #test\n",
    "        #for client_model in client_models:\n",
    "        #        tf.print(\"acc : \", accuracy(client_model, test_dataset), output_stream=sys.stdout)\n",
    "        \"\"\"------------------------------test--------------------------------------------\"\"\"\n",
    "        \n",
    "        # server average\n",
    "        server_model.assign(tf.reduce_mean(client_models, axis=0))\n",
    "        \n",
    "        \"\"\"------------------------------test--------------------------------------------\"\"\"\n",
    "        #tf.print(\"acc (after) : \", accuracy(server_model, test_dataset), output_stream=sys.stdout)\n",
    "        #tf.print(\"Linear Epoch count: \", epoch_count, \" Round fda steps: \", round_fda_steps, \" Epoch fda steps:\", epoch_fda_steps, output_stream=sys.stdout)\n",
    "        #tf.print(\"Linear Epoch count: \", epoch_count, output_stream=sys.stdout)\n",
    "        #actual_var = variance(client_models, [server_model]*len(client_models)) #test\n",
    "        #tf.print(\"Est left: \", S_1, \" Est S_2: \", S_2**2, \"Est var: \", S_1-S_2**2, \" Actual var: \", actual_var, \" Total fda steps: \", total_fda_steps, output_stream=sys.stdout)\n",
    "        #tf.print(\"\\n\", output_stream=sys.stdout)\n",
    "        \"\"\"------------------------------test--------------------------------------------\"\"\"\n",
    "        \n",
    "        \n",
    "        # reset variance approx\n",
    "        S_1 = tf.constant(0., shape=(), dtype=tf.float32)\n",
    "        S_2 = tf.constant(0., shape=(), dtype=tf.float32)\n",
    "\n",
    "        # synchronize clients\n",
    "        for client_model in client_models:\n",
    "            client_model.assign(server_model)\n",
    "            \n",
    "        total_rounds += 1\n",
    "    \n",
    "    return total_rounds, total_fda_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ce41db",
   "metadata": {},
   "source": [
    "## 3️⃣ Sketch FDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22930938",
   "metadata": {},
   "source": [
    "An optimal estimator for $ \\lVert \\overline{\\Delta_t} \\rVert_2^2  $ can be obtained by employing AMS sketches. An AMS sketch of a vector $ v \\in \\mathbb{R}^M $ is a $ d \\times m $ real matrix\n",
    "\n",
    "$$ \\Xi = \\text{sk}(v) = \\begin{bmatrix}\n",
    "           \\Xi_1 \\\\\n",
    "           \\Xi_2 \\\\\n",
    "           \\vdots \\\\\n",
    "           \\Xi_d \n",
    "         \\end{bmatrix} $$\n",
    "         \n",
    "where $ d \\cdot m \\ll M$. Operator sk($ \\cdot $) is linear, i.e., let $a, b \\in \\mathbb{R}$ and $v_1, v_2 \\in \\mathbb{R}^N$ then \n",
    "\n",
    "$$ \\text{sk}(a v_1 + b v_2) = a \\; \\text{sk}(v_1) + b \\; \\text{sk}(v_2)  $$\n",
    "\n",
    "Also, sk($ v $) can be computed in $ \\mathcal{O}(dN) $ steps.\n",
    "\n",
    "The interesting property of AMS sketches is that the function \n",
    "\n",
    "$$ M(sk(\\textbf{v})) = \\underset{i=1,...,d}{\\text{median}} \\; \\lVert \\boldsymbol{\\Xi}_i \\rVert_2^2  $$ \n",
    "\n",
    "is an excellent estimator of the Euclidean norm of **v** (within relative $\\epsilon$-error):\n",
    "\n",
    "$$ M(sk(\\textbf{v})) \\; \\in (1 \\pm \\epsilon) \\lVert \\textbf{v} \\rVert_2^2 \\; \\; \\text{with probability at least} \\; (1-\\delta) $$\n",
    "\n",
    "where $m = \\mathcal{O}(\\frac{1}{\\epsilon^2})$ and $d = \\mathcal{O}(\\log \\frac{1}{\\delta})$\n",
    "            \n",
    "Moreover, let $\\boldsymbol{\\Xi} \\in \\mathbb{R}^{d \\times m}$ and $ k \\in \\mathbb{R}$. It can be proven that\n",
    "\n",
    "$$ M( \\frac{1}{k} \\boldsymbol{\\Xi}) = \\frac{1}{k^2} M(\\boldsymbol{\\Xi}) $$\n",
    "\n",
    "Let's investigate a little further on how this helps us. The $i$-th client computes $ sk(\\Delta_t^{(i)}) $ and sends it to the server. Notice\n",
    "\n",
    "$$ M\\big(sk(\\Delta_t^{(1)}) + sk(\\Delta_t^{(2)}) + ... + sk(\\Delta_t^{(k)}) \\big) = M\\Big( \\text{sk}\\big( \\sum_{i=1}^{k} \\Delta_t^{(i)} \\big) \\Big)$$\n",
    "\n",
    "Remember that\n",
    "\n",
    "$$ \\overline{\\boldsymbol{\\Delta}}_t = \\frac{1}{k} \\sum_{i=1}^{k} \\boldsymbol{\\Delta}_t^{(i)} $$\n",
    "\n",
    "Then\n",
    "            \n",
    "$$ M\\Big( \\text{sk}\\big( \\overline{\\boldsymbol{\\Delta}}_t \\big) \\Big) = M\\Big( \\text{sk}\\big( \\frac{1}{k} \\sum_{i=1}^{k} \\boldsymbol{\\Delta}_t^{(i)} \\big) \\Big) = \\frac{1}{k^2} M\\Big( \\text{sk}\\big( \\sum_{i=1}^{k} \\boldsymbol{\\Delta}_t^{(i)} \\big) \\Big) $$\n",
    "\n",
    "\n",
    "Which means that \n",
    "\n",
    "$$ \\frac{1}{k^2} M\\Big( \\text{sk}\\big( \\sum_{i=1}^{k} \\boldsymbol{\\Delta}_t^{(i)} \\big) \\Big) \\in (1 \\pm \\epsilon) \\lVert \\overline{\\boldsymbol{\\Delta}}_t \\rVert_2^2 \\; \\; \\text{w.p. at least} \\; (1-\\delta) $$\n",
    "\n",
    "In the monitoring process it is essential that we do not overestimate $ \\lVert \\overline{\\Delta_t} \\rVert_2^2 $ because we would then underestimate the variance which would potentially result in actual varience exceeding $ \\Theta$ without us noticing it. With this in mind,\n",
    "\n",
    "$$ \\frac{1}{k^2} M\\Big( \\text{sk}\\big( \\sum_{i=1}^{k} \\Delta_t^{(i)} \\big) \\Big) \\leq (1+\\epsilon) \\lVert \\overline{\\Delta_t} \\rVert_2^2 \\quad \\text{with probability at least} \\; (1-\\delta)$$\n",
    "\n",
    "Which means\n",
    "\n",
    "$$ \\frac{1}{(1+\\epsilon)} \\frac{1}{k^2} M\\Big( \\text{sk}\\big( \\sum_{i=1}^{k} \\Delta_t^{(i)} \\big) \\Big) \\leq \\lVert \\overline{\\Delta_t} \\rVert_2^2 \\quad \\text{with probability at least} \\; (1-\\delta)$$\n",
    "\n",
    "Hence, the Server's estimation of $ \\lVert \\overline{\\Delta_t} \\rVert_2^2 $ is\n",
    "\n",
    "$$ \\frac{1}{(1+\\epsilon)} \\frac{1}{k^2} M\\Big( sk(\\Delta_t^{(1)}) + sk(\\Delta_t^{(2)}) + ... + sk(\\Delta_t^{(k)}) \\big) \\Big) $$\n",
    "\n",
    "Define the local state to be \n",
    "\n",
    "$$ S_i(t) = \\begin{bmatrix}\n",
    "           \\lVert \\Delta_t^{(i)} \\rVert_2^2 \\\\\n",
    "           sk(\\Delta_t^{(i)})\n",
    "         \\end{bmatrix} \\in \\mathbb{R}^{1+d \\times m} \\quad \\text{and} \\quad\n",
    "         F(\\begin{bmatrix}\n",
    "           v \\\\\n",
    "           \\Xi\n",
    "         \\end{bmatrix}) = v - \\frac{1}{(1+\\epsilon)} \\frac{1}{k^2} M(\\Xi) \\quad \\text{where} \\quad \\Xi = \\sum_{i=1}^{k} sk(\\Delta_t^{(i)}) $$\n",
    "\n",
    "It follows that $ F(S(t)) \\leq \\Theta $ implies that the variance is less or equal to $ \\Theta $ with probability at least $ 1-\\delta $.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3187f096",
   "metadata": {},
   "source": [
    "## AMS sketch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71ea2d6",
   "metadata": {},
   "source": [
    "We use `ExtensionType` which is the way to go in order to avoid unecessary graph retracing when passing around `AmsSketch` type 'objects'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ef4e9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.experimental import ExtensionType\n",
    "\n",
    "\n",
    "class AmsSketch(ExtensionType):\n",
    "    depth: int\n",
    "    width: int\n",
    "    F: tf.Tensor\n",
    "        \n",
    "    def __init__(self, depth=7, width=1500):\n",
    "        self.depth = depth\n",
    "        self.width = width\n",
    "        self.F = tf.random.uniform(shape=(6, depth), minval=0, maxval=(1 << 31) - 1, dtype=tf.int32)\n",
    "\n",
    "        \n",
    "    @tf.function\n",
    "    def hash31(self, x, a, b):\n",
    "\n",
    "        r = a * x + b\n",
    "        fold = tf.bitwise.bitwise_xor(tf.bitwise.right_shift(r, 31), r)\n",
    "        return tf.bitwise.bitwise_and(fold, 2147483647)\n",
    "    \n",
    "    \n",
    "    @tf.function\n",
    "    def tensor_hash31(self, x, a, b): # GOOD\n",
    "        \"\"\" Assumed that x is tensor shaped (d,) , i.e., a vector (for example, indices, i.e., tf.range(d)) \"\"\"\n",
    "\n",
    "        # Reshape x to have an extra dimension, resulting in a shape of (k, 1)\n",
    "        x_reshaped = tf.expand_dims(x, axis=-1)\n",
    "\n",
    "        # shape=(`v_dim`, 7)\n",
    "        r = tf.multiply(a, x_reshaped) + b\n",
    "\n",
    "        fold = tf.bitwise.bitwise_xor(tf.bitwise.right_shift(r, 31), r)\n",
    "        \n",
    "        return tf.bitwise.bitwise_and(fold, 2147483647)\n",
    "    \n",
    "    \n",
    "    @tf.function\n",
    "    def tensor_fourwise(self, x):\n",
    "        \"\"\" Assumed that x is tensor shaped (d,) , i.e., a vector (for example, indices, i.e., tf.range(d)) \"\"\"\n",
    "        # 1st use the tensor hash31\n",
    "        in1 = self.tensor_hash31(x, self.F[2], self.F[3])  # (`x_dim`, 7)\n",
    "        \n",
    "        # 2nd (notice we swap the first two params, no change really)\n",
    "        in2 = self.tensor_hash31(x, in1, self.F[4])  # (`x_dim`, 7)\n",
    "        \n",
    "        in3 = self.tensor_hash31(x, in2, self.F[5])  # (`x_dim`, 7)\n",
    "        \n",
    "        in4 = tf.bitwise.bitwise_and(in3, 32768)  # (`x_dim`, 7)\n",
    "        \n",
    "        return 2 * (tf.bitwise.right_shift(in4, 15)) - 1  # (`x_dim`, 7)\n",
    "        \n",
    "        \n",
    "    @tf.function\n",
    "    def fourwise(self, x):\n",
    "\n",
    "        result = 2 * (tf.bitwise.right_shift(tf.bitwise.bitwise_and(self.hash31(self.hash31(self.hash31(x, self.F[2], self.F[3]), x, self.F[4]), x, self.F[5]), 32768), 15)) - 1\n",
    "        return result\n",
    "    \n",
    "    \n",
    "    @tf.function\n",
    "    def sketch_for_vector(self, v):\n",
    "        \"\"\" Extremely efficient computation of sketch with only using tensors. \"\"\"\n",
    "        \n",
    "        sketch = tf.zeros(shape=(self.depth, self.width), dtype=tf.float32)\n",
    "        \n",
    "        len_v = v.shape[0]\n",
    "        \n",
    "        pos_tensor = self.tensor_hash31(tf.range(len_v), self.F[0], self.F[1]) % self.width\n",
    "        \n",
    "        v_expand = tf.expand_dims(v, axis=-1)\n",
    "        \n",
    "        deltas_tensor = tf.multiply(tf.cast(self.tensor_fourwise(tf.range(len_v)), dtype=tf.float32), v_expand)\n",
    "        \n",
    "        range_tensor = tf.range(self.depth)\n",
    "        \n",
    "        # Expand dimensions to create a 2D tensor with shape (1, depth)\n",
    "        range_tensor_expanded = tf.expand_dims(range_tensor, 0)\n",
    "\n",
    "        # Use tf.tile to repeat the tensor `len_v` times\n",
    "        repeated_range_tensor = tf.tile(range_tensor_expanded, [len_v, 1])\n",
    "        \n",
    "        # shape=(`len_v`, 7, 2)\n",
    "        indices = tf.stack([repeated_range_tensor, pos_tensor], axis=-1)\n",
    "        \n",
    "        sketch = tf.tensor_scatter_nd_add(sketch, indices, deltas_tensor)\n",
    "        \n",
    "        return sketch\n",
    "    \n",
    "    \n",
    "    @tf.function\n",
    "    def sketch_for_vector2(self, v):\n",
    "        \"\"\" Bad implementation for tensorflow. \"\"\"\n",
    "\n",
    "        sketch = tf.zeros(shape=(self.depth, self.width), dtype=tf.float32)\n",
    "\n",
    "        for i in tf.range(tf.shape(v)[0], dtype=tf.int32):\n",
    "            pos = self.hash31(i, self.F[0], self.F[1]) % self.width\n",
    "            delta = tf.cast(self.fourwise(i), dtype=tf.float32) * v[i]\n",
    "            indices_to_update = tf.stack([tf.range(self.depth, dtype=tf.int32), pos], axis=1)\n",
    "            sketch = tf.tensor_scatter_nd_add(sketch, indices_to_update, delta)\n",
    "\n",
    "        return sketch\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    @tf.function\n",
    "    def estimate_euc_norm_squared(sketch):\n",
    "\n",
    "        @tf.function\n",
    "        def _median(v):\n",
    "            \"\"\" Median of tensor `v` with shape=(n,). Note: Suboptimal O(nlogn) but it's ok bcz n = `depth`\"\"\"\n",
    "            length = tf.shape(v)[0]\n",
    "            sorted_v = tf.sort(v)\n",
    "            middle = length // 2\n",
    "\n",
    "            return tf.cond(\n",
    "                tf.equal(length % 2, 0),\n",
    "                lambda: (sorted_v[middle - 1] + sorted_v[middle]) / 2.0,\n",
    "                lambda: sorted_v[middle]\n",
    "            )\n",
    "\n",
    "        return _median(tf.reduce_sum(tf.square(sketch), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d4534f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def steps_sketch(last_sync_model, model, dataset, C, ams_sketch):\n",
    "    # number of steps depend on `.take()` from `dataset`\n",
    "    client_train(model, dataset, C)\n",
    "    \n",
    "    Delta_i = model - last_sync_model\n",
    "    \n",
    "    #||D(t)_i||^2 , shape = (1,) \n",
    "    Delta_i_euc_norm_squared = tf.reduce_sum(tf.square(Delta_i), axis=0)\n",
    "    \n",
    "    # sketch approx\n",
    "    sketch = ams_sketch.sketch_for_vector(tf.reshape(Delta_i, shape=[-1]))\n",
    "    \n",
    "    return Delta_i_euc_norm_squared, sketch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10244cae",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0142e982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_sketch(S_1, S_2, epsilon, num_clients):\n",
    "    \"\"\" `S_1` is mean || ||^2 as usual, S_2 is the `Ξ` as defined in the theoretical analysis above \"\"\"\n",
    "    one = tf.constant(1., shape=(), dtype=tf.float32)\n",
    "    \n",
    "    return S_1 - (one / (one + epsilon)) * (one / num_clients**2) * AmsSketch.estimate_euc_norm_squared(S_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "475908b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def run_federated_simulation_sketch(server_model, client_models, federated_dataset, C,\n",
    "                                    num_epochs, theta, epoch_fda_steps, \n",
    "                                    ams_sketch, epsilon, num_clients):\n",
    "    \n",
    "    print(\"retracing sketch\")\n",
    "    \n",
    "    total_rounds = 0\n",
    "    total_fda_steps = 0\n",
    "    \n",
    "    round_fda_steps = tf.constant(0, shape=(), dtype=tf.int32)\n",
    "    epoch_count = tf.constant(0, shape=(), dtype=tf.int32)\n",
    "    \n",
    "    S_1 = tf.constant(0., shape=(), dtype=tf.float32)\n",
    "    S_2 = tf.zeros(shape=(ams_sketch.depth, ams_sketch.width), dtype=tf.float32)\n",
    "    \n",
    "    while epoch_count < num_epochs:\n",
    "        \n",
    "        while F_sketch(S_1, S_2, epsilon, num_clients) <= theta:\n",
    "            euc_norm_squared_clients = []\n",
    "            sketch_clients = []\n",
    "\n",
    "            # client steps (number depends on `federated_dataset`, i.e., `.take(num)`)\n",
    "            for client_model, client_dataset in zip(client_models, federated_dataset):\n",
    "                \n",
    "                Delta_i_euc_norm_squared, sketch  = steps_sketch(\n",
    "                    server_model, client_model, client_dataset, C, ams_sketch\n",
    "                )\n",
    "                \n",
    "                euc_norm_squared_clients.append(Delta_i_euc_norm_squared)\n",
    "                sketch_clients.append(sketch)\n",
    "                \n",
    "            S_1 = tf.reduce_mean(euc_norm_squared_clients)\n",
    "            S_2 = tf.reduce_sum(sketch_clients, axis=0)  # shape=(`depth`, width`). See `Ξ` in theoretical analysis\n",
    "            \n",
    "            round_fda_steps += 1\n",
    "            total_fda_steps += 1\n",
    "            \n",
    "            if round_fda_steps == epoch_fda_steps:\n",
    "                epoch_count += 1\n",
    "                round_fda_steps = tf.constant(0, shape=(), dtype=tf.int32)\n",
    "                \n",
    "                if epoch_count == num_epochs:\n",
    "                    break\n",
    "        \n",
    "        \"\"\"------------------------------test--------------------------------------------\"\"\"\n",
    "        #tf.print(\"\\n sync : \", output_stream=sys.stdout)\n",
    "        #Delta_i_clients = [tf.subtract(client_model, server_model) for client_model in client_models] #test\n",
    "        #testing_approx_0 = tf.reduce_sum(tf.square(tf.reduce_mean(Delta_i_clients, axis=0)), axis=0) #test\n",
    "        #for client_model in client_models:\n",
    "        #        tf.print(\"acc : \", accuracy(client_model, test_dataset), output_stream=sys.stdout)\n",
    "        \"\"\"------------------------------test--------------------------------------------\"\"\"\n",
    "        \n",
    "        # server average\n",
    "        server_model.assign(tf.reduce_mean(client_models, axis=0))\n",
    "        \n",
    "        \"\"\"------------------------------test--------------------------------------------\"\"\"\n",
    "        #tf.print(\"acc (after) : \", accuracy(server_model, test_dataset), output_stream=sys.stdout)\n",
    "        #tf.print(\"Sketch Epoch count: \", epoch_count, \" Round fda steps: \", round_fda_steps, \" Epoch fda steps:\", epoch_fda_steps, output_stream=sys.stdout)\n",
    "        #tf.print(\"Sketch Epoch count: \", epoch_count, output_stream=sys.stdout)\n",
    "        #actual_var = variance(client_models, [server_model]*len(client_models)) #test\n",
    "        #tf.print(\"Est left: \", S_1, \"Est var: \", F_sketch(S_1, S_2, epsilon, num_clients), \" Actual var: \", actual_var, \" Total fda steps: \", total_fda_steps, output_stream=sys.stdout)\n",
    "        #tf.print(\"\\n\", output_stream=sys.stdout)\n",
    "        \"\"\"------------------------------test--------------------------------------------\"\"\"\n",
    "        \n",
    "        \n",
    "        # reset variance approx\n",
    "        S_1 = tf.constant(0., shape=(), dtype=tf.float32)\n",
    "        S_2 = tf.zeros(shape=(ams_sketch.depth, ams_sketch.width), dtype=tf.float32)\n",
    "\n",
    "        # synchronize clients\n",
    "        for client_model in client_models:\n",
    "            client_model.assign(server_model)\n",
    "            \n",
    "        total_rounds += 1\n",
    "    \n",
    "    return total_rounds, total_fda_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c459c7",
   "metadata": {},
   "source": [
    "# Simulation tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6f32451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_test(NUM_EPOCHS, C, NUM_STEPS_UNTIL_RTC_CHECK, NUM_CLIENTS,\n",
    "               BATCH_SIZE, THETA, EPSILON, ams_sketch, client_slices_train):\n",
    "    \n",
    "    \"\"\" One test for Naive,Linear,Sketch. Returns metrics \"\"\"\n",
    "    \n",
    "    c = tf.constant(C, shape=(), dtype=tf.float32)\n",
    "    num_epochs = tf.constant(NUM_EPOCHS, shape=(), dtype=tf.int32)\n",
    "    theta = tf.constant(THETA, shape=(), dtype=tf.float32)\n",
    "    \n",
    "    # for sketch\n",
    "    epsilon = tf.constant(EPSILON, shape=(), dtype=tf.float32) # new\n",
    "    num_clients = tf.constant(float(NUM_CLIENTS), shape=(), dtype=tf.float32) # new\n",
    "    \n",
    "    \n",
    "    epoch_client_batches = ((1-test_size)*n / BATCH_SIZE) / NUM_CLIENTS\n",
    "    epoch_max_fda_steps = epoch_client_batches / NUM_STEPS_UNTIL_RTC_CHECK\n",
    "    epoch_max_fda_steps = tf.constant(int(epoch_max_fda_steps), shape=(), dtype=tf.int32)\n",
    "    \n",
    "    basic_test_metrics = []\n",
    "    \n",
    "    \"\"\" --------------- Naive ----------------------------------\"\"\"\n",
    "        \n",
    "    # 1. tf.data.Dataset (we create it again because we want determinism)\n",
    "\n",
    "    federated_dataset = create_federated_data(\n",
    "        client_slices_train=client_slices_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle_buffer_size=int(n/NUM_CLIENTS),\n",
    "        num_steps_until_rtc_check=NUM_STEPS_UNTIL_RTC_CHECK,\n",
    "        seed=seed\n",
    "    )\n",
    "\n",
    "    # 2. Models init\n",
    "    \n",
    "    server_model = tf.Variable(tf.zeros(shape=(d, 1)), trainable=True, name='weights', dtype=tf.float32)\n",
    "\n",
    "    client_models = [\n",
    "        tf.Variable(tf.zeros(shape=(d, 1)), trainable=True, name='weights', dtype=tf.float32)\n",
    "        for _ in range(NUM_CLIENTS)\n",
    "    ]\n",
    "\n",
    "    # 3. Run \n",
    "    \n",
    "    total_rounds, total_fda_steps = run_federated_simulation_naive(\n",
    "        server_model, \n",
    "        client_models, \n",
    "        federated_dataset, \n",
    "        c,\n",
    "        num_epochs, \n",
    "        theta,\n",
    "        epoch_max_fda_steps\n",
    "    )\n",
    "\n",
    "    # 4. Compute metrics \n",
    "    \n",
    "    final_accuracy = accuracy(server_model, test_dataset)\n",
    "\n",
    "    metrics = create_metrics_dict(\n",
    "        fda_name=\"naive\", \n",
    "        n=n, \n",
    "        d=d, \n",
    "        test_size=test_size,\n",
    "        seed=seed,\n",
    "        class_sep=class_sep,\n",
    "        noise_factor=noise_factor,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        num_clients=NUM_CLIENTS, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        steps_in_one_fda_step=NUM_STEPS_UNTIL_RTC_CHECK, \n",
    "        theta=THETA, \n",
    "        c=C, \n",
    "        total_fda_steps=total_fda_steps.numpy(), \n",
    "        total_rounds=total_rounds.numpy(), \n",
    "        final_accuracy=final_accuracy.numpy(), \n",
    "        sketch_width=None, \n",
    "        sketch_depth=None\n",
    "    )\n",
    "\n",
    "    basic_test_metrics.append(metrics)\n",
    "\n",
    "    del federated_dataset, server_model, client_models, total_rounds, total_fda_steps\n",
    "\n",
    "    \"\"\" ----------------- Linear ----------------------------------\"\"\"\n",
    "\n",
    "    # 1. tf.data.Dataset (we create it again because we want determinism)\n",
    "\n",
    "    federated_dataset = create_federated_data(\n",
    "        client_slices_train=client_slices_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle_buffer_size=int(n/NUM_CLIENTS),\n",
    "        num_steps_until_rtc_check=NUM_STEPS_UNTIL_RTC_CHECK,\n",
    "        seed=seed\n",
    "    )\n",
    "\n",
    "    # 3. Model init\n",
    "    \n",
    "    server_model = tf.Variable(tf.zeros(shape=(d, 1)), trainable=True, name='weights', dtype=tf.float32)\n",
    "\n",
    "    client_models = [\n",
    "        tf.Variable(tf.zeros(shape=(d, 1)), trainable=True, name='weights', dtype=tf.float32)\n",
    "        for _ in range(NUM_CLIENTS)\n",
    "    ]\n",
    "\n",
    "    # for `ξ` approximation.\n",
    "    previous_server_model = tf.Variable(tf.zeros(shape=(d, 1)), trainable=True, name='weights', dtype=tf.float32)\n",
    "\n",
    "\n",
    "    # 3. Run\n",
    "    total_rounds, total_fda_steps = run_federated_simulation_linear(\n",
    "        previous_server_model,\n",
    "        server_model, \n",
    "        client_models, \n",
    "        federated_dataset, \n",
    "        c,\n",
    "        num_epochs, \n",
    "        theta,\n",
    "        epoch_max_fda_steps\n",
    "    )\n",
    "    \n",
    "    # 4. Compute metrics \n",
    "\n",
    "    final_accuracy = accuracy(server_model, test_dataset)\n",
    "\n",
    "    metrics = create_metrics_dict(\n",
    "        fda_name=\"linear\", \n",
    "        n=n, \n",
    "        d=d, \n",
    "        test_size=test_size, \n",
    "        seed=seed,\n",
    "        class_sep=class_sep,\n",
    "        noise_factor=noise_factor,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        num_clients=NUM_CLIENTS, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        steps_in_one_fda_step=NUM_STEPS_UNTIL_RTC_CHECK, \n",
    "        theta=THETA, \n",
    "        c=C, \n",
    "        total_fda_steps=total_fda_steps.numpy(), \n",
    "        total_rounds=total_rounds.numpy(), \n",
    "        final_accuracy=final_accuracy.numpy(), \n",
    "        sketch_width=None, \n",
    "        sketch_depth=None\n",
    "    )\n",
    "\n",
    "    basic_test_metrics.append(metrics)\n",
    "\n",
    "    del federated_dataset, server_model, client_models, previous_server_model, total_rounds, total_fda_steps\n",
    "    \n",
    "    \n",
    "    \"\"\" --------------- Sketch ----------------------------------\"\"\"\n",
    "    \n",
    "    # 1. tf.data.Dataset (we create it again because we want determinism)\n",
    "\n",
    "    federated_dataset = create_federated_data(\n",
    "        client_slices_train=client_slices_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle_buffer_size=int(n/NUM_CLIENTS),\n",
    "        num_steps_until_rtc_check=NUM_STEPS_UNTIL_RTC_CHECK,\n",
    "        seed=seed\n",
    "    )\n",
    "\n",
    "    # 2. Models init\n",
    "\n",
    "    server_model = tf.Variable(tf.zeros(shape=(d, 1)), trainable=True, name='weights', dtype=tf.float32)\n",
    "\n",
    "    client_models = [\n",
    "        tf.Variable(tf.zeros(shape=(d, 1)), trainable=True, name='weights', dtype=tf.float32)\n",
    "        for _ in range(NUM_CLIENTS)\n",
    "    ]\n",
    "\n",
    "    # 3. Run \n",
    "\n",
    "    total_rounds, total_fda_steps = run_federated_simulation_sketch(\n",
    "        server_model, \n",
    "        client_models, \n",
    "        federated_dataset, \n",
    "        c,\n",
    "        num_epochs, \n",
    "        theta,\n",
    "        epoch_max_fda_steps,\n",
    "        ams_sketch, # new\n",
    "        epsilon,  # new\n",
    "        num_clients # new\n",
    "    )\n",
    "\n",
    "    # 4. Compute metrics \n",
    "\n",
    "    final_accuracy = accuracy(server_model, test_dataset)\n",
    "\n",
    "    metrics = create_metrics_dict(\n",
    "        fda_name=\"sketch\", \n",
    "        n=n, \n",
    "        d=d, \n",
    "        test_size=test_size,\n",
    "        seed=seed,\n",
    "        class_sep=class_sep,\n",
    "        noise_factor=noise_factor,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        num_clients=NUM_CLIENTS, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        steps_in_one_fda_step=NUM_STEPS_UNTIL_RTC_CHECK, \n",
    "        theta=THETA, \n",
    "        c=C, \n",
    "        total_fda_steps=total_fda_steps.numpy(), \n",
    "        total_rounds=total_rounds.numpy(), \n",
    "        final_accuracy=final_accuracy.numpy(), \n",
    "        sketch_width=ams_sketch.width, \n",
    "        sketch_depth=ams_sketch.depth\n",
    "    )\n",
    "    \n",
    "    basic_test_metrics.append(metrics)\n",
    "    \n",
    "    del federated_dataset, server_model, client_models, total_rounds, total_fda_steps\n",
    "\n",
    "    return basic_test_metrics\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabe9149",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed1c38de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt # new\n",
    "\n",
    "def run_tests(NUM_EPOCHS_FIXED, C_FIXED, NUM_STEPS_UNTIL_RTC_CHECK_FIXED, \n",
    "              SKETCH_DEPTH, SKETCH_WIDTH, NUM_CLIENTS_LIST, BATCH_SIZE_LIST, THETA_LIST,\n",
    "              BATCH_SIZE_FIXED, THETA_FIXED, NUM_CLIENTS_FIXED):\n",
    "    \n",
    "    \"\"\" --------------- Fixed configurations -------------------\"\"\"\n",
    "\n",
    "    ams_sketch = AmsSketch(\n",
    "        depth=SKETCH_DEPTH,\n",
    "        width=SKETCH_WIDTH\n",
    "    )\n",
    "\n",
    "    EPSILON = 1. / sqrt(SKETCH_WIDTH)\n",
    "    \n",
    "    \n",
    "    \"\"\" --------------- Metrics list ----------------------\"\"\"\n",
    "    \n",
    "    all_metrics = []\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        \"\"\" --------------- Run tests -------------------\"\"\"\n",
    "\n",
    "        # Test /k nodes\n",
    "        # FIX: BATCH_SIZE, THETA\n",
    "\n",
    "        for NUM_CLIENTS in NUM_CLIENTS_LIST:\n",
    "            print()\n",
    "            print(f\"CLIENTS testing. Current NUM_CLIENTS : {NUM_CLIENTS}\")\n",
    "            \n",
    "            client_slices_train = create_data_for_clients(NUM_CLIENTS)  # new sliced dataset (diff NUM_CLIENTS)\n",
    "\n",
    "            basic_test_metrics = basic_test(\n",
    "                NUM_EPOCHS=NUM_EPOCHS_FIXED,\n",
    "                C=C_FIXED,\n",
    "                NUM_STEPS_UNTIL_RTC_CHECK=NUM_STEPS_UNTIL_RTC_CHECK_FIXED,\n",
    "                NUM_CLIENTS=NUM_CLIENTS,\n",
    "                BATCH_SIZE=BATCH_SIZE_FIXED,\n",
    "                THETA=THETA_FIXED,\n",
    "                EPSILON=EPSILON,\n",
    "                ams_sketch=ams_sketch,\n",
    "                client_slices_train=client_slices_train\n",
    "            )\n",
    "\n",
    "            all_metrics.extend(basic_test_metrics)\n",
    "            \n",
    "            del client_slices_train\n",
    "            \n",
    "\n",
    "        # Test /THETA : THETA tests will only retrance Graphs once!\n",
    "        \n",
    "        client_slices_train = create_data_for_clients(NUM_CLIENTS_FIXED)  # same sliced dataset (fixed NUM_CLIENTS)\n",
    "\n",
    "        for THETA in THETA_LIST:\n",
    "            print()\n",
    "            print(f\"THETA testing. Current THETA : {THETA}\")\n",
    "\n",
    "            basic_test_metrics = basic_test(\n",
    "                NUM_EPOCHS=NUM_EPOCHS_FIXED,\n",
    "                C=C_FIXED,\n",
    "                NUM_STEPS_UNTIL_RTC_CHECK=NUM_STEPS_UNTIL_RTC_CHECK_FIXED,\n",
    "                NUM_CLIENTS=NUM_CLIENTS_FIXED,\n",
    "                BATCH_SIZE=BATCH_SIZE_FIXED,\n",
    "                THETA=THETA,\n",
    "                EPSILON=EPSILON,\n",
    "                ams_sketch=ams_sketch,\n",
    "                client_slices_train=client_slices_train\n",
    "            )\n",
    "\n",
    "            all_metrics.extend(basic_test_metrics)\n",
    "\n",
    "        # Test /BATCHS_SIZE : THETA tests will only retrance Graphs once!\n",
    "        \n",
    "        client_slices_train = create_data_for_clients(NUM_CLIENTS_FIXED) # same sliced dataset (fixed NUM_CLIENTS)\n",
    "\n",
    "        for BATCH_SIZE in BATCH_SIZE_LIST:\n",
    "            print()\n",
    "            print(f\"BATCH_SIZE testing. Current BATCH_SIZE : {BATCH_SIZE}\")\n",
    "\n",
    "            basic_test_metrics = basic_test(\n",
    "                NUM_EPOCHS=NUM_EPOCHS_FIXED,\n",
    "                C=C_FIXED,\n",
    "                NUM_STEPS_UNTIL_RTC_CHECK=NUM_STEPS_UNTIL_RTC_CHECK_FIXED,\n",
    "                NUM_CLIENTS=NUM_CLIENTS_FIXED,\n",
    "                BATCH_SIZE=BATCH_SIZE,\n",
    "                THETA=THETA_FIXED,\n",
    "                EPSILON=EPSILON,\n",
    "                ams_sketch=ams_sketch,\n",
    "                client_slices_train=client_slices_train\n",
    "            )\n",
    "\n",
    "            all_metrics.extend(basic_test_metrics)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"shit\")\n",
    "    \n",
    "    finally:\n",
    "        return all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d469ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b33c0d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "THETA testing. Current THETA : 1.0\n",
      "retracing naive\n",
      "WARNING:tensorflow:From /home/miketheologitis/anaconda3/envs/tff-py39/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "retracing linear\n",
      "retracing sketch\n",
      "\n",
      "THETA testing. Current THETA : 5.0\n"
     ]
    }
   ],
   "source": [
    "all_metrics = run_tests(\n",
    "    NUM_EPOCHS_FIXED=3,\n",
    "    C_FIXED=0.01, \n",
    "    NUM_STEPS_UNTIL_RTC_CHECK_FIXED=1,\n",
    "    SKETCH_DEPTH=7, \n",
    "    SKETCH_WIDTH=1000, \n",
    "    NUM_CLIENTS_LIST=[], #[10, 20, 35, 50, 75, 100, 250, 500],\n",
    "    BATCH_SIZE_LIST=[], #[16, 32, 64, 126, 256, 512], \n",
    "    THETA_LIST=[1., 5.], #[10., 25., 50., 75., 100., 250., 500., 1000.],\n",
    "    BATCH_SIZE_FIXED=32,  # When testing THETA_LIST and NUM_CLIENTS_LIST\n",
    "    THETA_FIXED=5.,  # When testing BATCH_SIZE_LIST and NUM_CLIENTS_LIST\n",
    "    NUM_CLIENTS_FIXED=20  # When testing BATCH_SIZE_LIST and THETA_LIST\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "29ff1707",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "486dc175",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9aed2bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fda_name</th>\n",
       "      <th>theta</th>\n",
       "      <th>n</th>\n",
       "      <th>d</th>\n",
       "      <th>seed</th>\n",
       "      <th>class_sep</th>\n",
       "      <th>noise_factor</th>\n",
       "      <th>test_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>num_clients</th>\n",
       "      <th>...</th>\n",
       "      <th>model_bytes</th>\n",
       "      <th>local_state_bytes</th>\n",
       "      <th>final_accuracy</th>\n",
       "      <th>total_fda_steps</th>\n",
       "      <th>total_steps</th>\n",
       "      <th>total_rounds</th>\n",
       "      <th>model_bytes_exchanged</th>\n",
       "      <th>monitoring_bytes_exchanged</th>\n",
       "      <th>total_communication_bytes</th>\n",
       "      <th>trained_in_bytes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>naive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>400</td>\n",
       "      <td>4</td>\n",
       "      <td>0.951885</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>64000</td>\n",
       "      <td>2880</td>\n",
       "      <td>66880</td>\n",
       "      <td>9308160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>linear</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>400</td>\n",
       "      <td>8</td>\n",
       "      <td>0.951885</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>32000</td>\n",
       "      <td>5760</td>\n",
       "      <td>37760</td>\n",
       "      <td>9308160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sketch</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>400</td>\n",
       "      <td>28004</td>\n",
       "      <td>0.951885</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>32000</td>\n",
       "      <td>20162880</td>\n",
       "      <td>20194880</td>\n",
       "      <td>9308160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>naive</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>400</td>\n",
       "      <td>4</td>\n",
       "      <td>0.951885</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>32000</td>\n",
       "      <td>2880</td>\n",
       "      <td>34880</td>\n",
       "      <td>9308160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>linear</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>400</td>\n",
       "      <td>8</td>\n",
       "      <td>0.951885</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>32000</td>\n",
       "      <td>5760</td>\n",
       "      <td>37760</td>\n",
       "      <td>9308160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sketch</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>400</td>\n",
       "      <td>28004</td>\n",
       "      <td>0.951885</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>16000</td>\n",
       "      <td>20162880</td>\n",
       "      <td>20178880</td>\n",
       "      <td>9308160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  fda_name  theta      n    d  seed  class_sep  noise_factor  test_size  \\\n",
       "0    naive    1.0  10000  100     7          2          0.02        0.2   \n",
       "1   linear    1.0  10000  100     7          2          0.02        0.2   \n",
       "2   sketch    1.0  10000  100     7          2          0.02        0.2   \n",
       "3    naive    5.0  10000  100     7          2          0.02        0.2   \n",
       "4   linear    5.0  10000  100     7          2          0.02        0.2   \n",
       "5   sketch    5.0  10000  100     7          2          0.02        0.2   \n",
       "\n",
       "   epochs  num_clients  ...  model_bytes  local_state_bytes  final_accuracy  \\\n",
       "0       3           20  ...          400                  4        0.951885   \n",
       "1       3           20  ...          400                  8        0.951885   \n",
       "2       3           20  ...          400              28004        0.951885   \n",
       "3       3           20  ...          400                  4        0.951885   \n",
       "4       3           20  ...          400                  8        0.951885   \n",
       "5       3           20  ...          400              28004        0.951885   \n",
       "\n",
       "   total_fda_steps  total_steps  total_rounds  model_bytes_exchanged  \\\n",
       "0               36           36             4                  64000   \n",
       "1               36           36             2                  32000   \n",
       "2               36           36             2                  32000   \n",
       "3               36           36             2                  32000   \n",
       "4               36           36             2                  32000   \n",
       "5               36           36             1                  16000   \n",
       "\n",
       "   monitoring_bytes_exchanged  total_communication_bytes  trained_in_bytes  \n",
       "0                        2880                      66880           9308160  \n",
       "1                        5760                      37760           9308160  \n",
       "2                    20162880                   20194880           9308160  \n",
       "3                        2880                      34880           9308160  \n",
       "4                        5760                      37760           9308160  \n",
       "5                    20162880                   20178880           9308160  \n",
       "\n",
       "[6 rows x 27 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ce5cc0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test_results/results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a94bebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf667e7d",
   "metadata": {},
   "source": [
    "TODO:\n",
    "\n",
    "1. variance (follow NN approach) decouple `NUM_CLIENTS` fixed. Better approach plz\n",
    "2. for in : for in : for in: approach in testing. REMOVE FIXED SHIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a11ade8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tff-py39] *",
   "language": "python",
   "name": "conda-env-tff-py39-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
