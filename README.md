# Requirements
**TensorFlow** version: **v2.15**
```bash
conda create -n tf-2.15 python==3.9
```
```bash
conda activate tf-2.15
```

If you are planning on using GPU:
```bash
pip install --extra-index-url https://pypi.nvidia.com tensorrt-bindings==8.6.1 tensorrt-libs==8.6.1
```
```bash
pip install -U tensorflow[and-cuda]==2.15.0 pandas pyarrow
```
If you are planning on **not** using GPU:
```bash
pip install tensorflow==2.15.0 pandas pyarrow
```

# Clone repository
Clone.
```bash
git clone https://github.com/miketheologitis/FedL-Sync-FDA
```
Materialize LFS files (deep pre-trained models ~2GB).
```bash
cd FedL-Sync-FDA/
```
```bash
git lfs fetch --all
```
```bash
git lfs pull
```
# WorkFlow
1. Using the `create_combinations.py` script, create all the experiments you want to run.
2. Simulate the experiments you created utilizing GPUs, in **SLURM**, in a local machine, or in a server cluster provided they are visible to `nvidia-smi`. For the `Kafka` WorkFlow go to the end of this README.

## 1. Combination Script

### Example
Go to project directory `/FedL-Sync-FDA` and create a combinations file:
```bash
python -m fdavg.utils.create_combinations --fda linear sketch --nn DenseNet121 --ds_name CIFAR10 --b 32 --e 100 --th 350 400 --num_clients 5 10 15 20 --comb_file_id 0
```
**Output:**
```
OK! Created 16 combinations in 0.json, i.e., `n_sims` = 16.
```
**Help**:
```shell
python -m fdavg.utils.create_combinations --help
```

## 2. Simulation
Be careful to use the same `--comb_file_id` for both scripts and use the same number of simulations (`--n_sims`) 
as the number of combinations generated by the combinations script. 
\
\
When an experiment finishes you will see the `.csv` or `.parquet` file in `/metrics/tmp/epoch_metrcis/`.
### Local
If `--n_gpus` is given and no GPUs are found, we continue on CPUs.

**Example**: Go to project directory `/FedL-Sync-FDA` and run the following command:
```bash
python -m local_simulator --n_gpus 2 --n_sims 12 --comb_file_id 0
```
**Tip**: Press `enter` to send as many simulations on each GPU as possible. In parallel, monitor the GPUs with 
```nvidia-smi``` so you know that there is available RAM (wait 5 minutes so that each simulation has enough time to 
allocate the needed RAM).

**Help**:
```shell
python -m local_simulator --help
```
You will see the `.out` and `.err` files in `/metrics/tmp/local_out/` with the following convention: `cX_simY.out`, where 
`X` is the `comb_file_id` and `Y` is the simulation ID (out of `n_sims`).

### SLURM

**Example**: Go to project directory `/FedL-Sync-FDA` and run the following command:
```shell
python -m slurm_submitter --gpu_mem 5120 --gpus_per_node 2 --sims_per_gpu 2 --mem_per_sim 10240 --cpus_per_sim 2 --nodes_per_submit 2 --n_sims 16 --comb_file_id 0 --walltime 24:00:00
```
**Help**:
```shell
python -m slurm_submitter --help
```
You will see the `.out` and `.err` files in `/metrics/tmp/slurm_out/`.

## 3. Results

After each simulation ends, a `.parquet` or `.csv` file will be created in `/FedL-Sync-FDA/metrics/tmp/epoch_metrics`. Then,
we must move it to `/FedL-Sync-FDA/metrics/epoch_metrics` where all the metrics are kept.

If the files are `.parquet`:
```bash
cp /metrics/tmp/epoch_metrics/* /metrics/epoch_metrics
```
```bash
rm /metrics/tmp/epoch_metrics/*
```

If the files are `.csv`:
```bash
cd /metrics/
```
```bash
python from_csv_to_parquet.py
```
```bash
rm /metrics/tmp/epoch_metrics/*
```
Then, run the notebook `/FedL-Sync-FDA/notebooks/data_analysis/epoch_metrics_analysis.ipynb` to see the results (plots) in
`/FedL-Sync-FDA/metrics/plots`.


# Paper Experiments

We provide the workflow to run all of our experiments. Note that they required 200K GPU hours so hopefully there
are many available GPUs.

## 1. Create individual simulation combinations
We will create 5 combination files, one for each Neural Network - Dataset, encompassing all experiments of the paper.
1. **LeNet-5 - MNIST**: `0.json` with total of `612` unique simulations.
2. **VGG16\* - MNIST**: `1.json` with total of `612` unique simulations.
3. **DenseNet121 - CIFAR-10**: `2.json` with total of `96` unique simulations.
4. **DenseNet201 - CIFAR-10**: `3.json` with total of `96` unique simulations.
5. **ConvNeXtLarge - CIFAR-100** (fine-tuning): `4.json` with total of `18` unique simulations.

### LeNet-5

**IID:**
```bash
python -m fdavg.utils.create_combinations --fda linear sketch --nn LeNet-5 --ds_name MNIST --b 32 --e 300 --th 0.5 1 1.5 2 3 5 7 --num_clients 5 10 15 20 25 30 35 40 45 50 55 60 --comb_file_id 0
```
```bash
python -m fdavg.utils.create_combinations --fda synchronous --nn LeNet-5 --ds_name MNIST --b 32 --e 300 --th 0 --num_clients 5 10 15 20 25 30 35 40 45 50 55 60 --comb_file_id 0 --append_to
```
```bash
python -m fdavg.utils.create_combinations --fda synchronous FedAdam --nn LeNet-5 --ds_name MNIST --b 32 --e 1000 --th 0 --num_clients 5 10 15 20 25 30 35 40 45 50 55 60 --comb_file_id 0 --append_to
```
**Non-IID:**
```bash
python -m fdavg.utils.create_combinations --fda linear sketch --nn LeNet-5 --ds_name MNIST --b 32 --e 300 --th 0.5 1 1.5 2 3 5 7 --num_clients 5 10 15 20 25 30 35 40 45 50 55 60 --bias 0.6 -1 --comb_file_id 0 --append_to
```
```bash
python -m fdavg.utils.create_combinations --fda synchronous --nn LeNet-5 --ds_name MNIST --b 32 --e 300 --th 0 --num_clients 5 10 15 20 25 30 35 40 45 50 55 60 --bias 0.6 -1 --comb_file_id 0 --append_to
```
```bash
python -m fdavg.utils.create_combinations --fda synchronous FedAdam --nn LeNet-5 --ds_name MNIST --b 32 --e 1000 --th 0 --num_clients 5 10 15 20 25 30 35 40 45 50 55 60 --bias 0.6 -1 --comb_file_id 0 --append_to
```

### VGG16*

**IID:**
```bash
python -m fdavg.utils.create_combinations --fda linear sketch --nn AdvancedCNN --ds_name MNIST --b 32 --e 300 --th 20 25 30 50 75 90 100 --num_clients 5 10 15 20 25 30 35 40 45 50 55 60 --comb_file_id 1
```
```bash
python -m fdavg.utils.create_combinations --fda synchronous --nn AdvancedCNN --ds_name MNIST --b 32 --e 300 --th 0 --num_clients 5 10 15 20 25 30 35 40 45 50 55 60 --comb_file_id 1 --append_to
```
```bash
python -m fdavg.utils.create_combinations --fda synchronous FedAdam --nn AdvancedCNN --ds_name MNIST --b 32 --e 1000 --th 0 --num_clients 5 10 15 20 25 30 35 40 45 50 55 60 --comb_file_id 1 --append_to
```

**Non-IID:**
```bash
python -m fdavg.utils.create_combinations --fda linear sketch --nn AdvancedCNN --ds_name MNIST --b 32 --e 300 --th 20 25 30 50 75 90 100 --bias -1 -2 --num_clients 5 10 15 20 25 30 35 40 45 50 55 60 --comb_file_id 1 --append_to
```
```bash
python -m fdavg.utils.create_combinations --fda synchronous --nn AdvancedCNN --ds_name MNIST --b 32 --e 300 --th 0 --bias -1 -2 --num_clients 5 10 15 20 25 30 35 40 45 50 55 60 --comb_file_id 1 --append_to
```
```bash
python -m fdavg.utils.create_combinations --fda synchronous FedAdam --nn AdvancedCNN --ds_name MNIST --b 32 --e 1000 --th 0 --bias -1 -2 --num_clients 5 10 15 20 25 30 35 40 45 50 55 60 --comb_file_id 1 --append_to
```

### DenseNet121
```bash
python -m fdavg.utils.create_combinations --fda linear sketch --nn DenseNet121 --ds_name CIFAR-10 --b 32 --e 300 --th 200 250 275 300 325 350 400 --num_clients 5 10 15 20 25 30 --comb_file_id 2
```
```bash
python -m fdavg.utils.create_combinations --fda synchronous --nn DenseNet121 --ds_name CIFAR-10 --b 32 --e 300 --th 0 --num_clients 5 10 15 20 25 30 --comb_file_id 2 --append_to
```
```bash
python -m fdavg.utils.create_combinations --fda FedAvgM --nn DenseNet121 --ds_name CIFAR-10 --b 32 --e 1000 --th 0 --num_clients 5 10 15 20 25 30 --comb_file_id 2 --append_to
```

### DenseNet201
```bash
python -m fdavg.utils.create_combinations --fda linear sketch --nn DenseNet201 --ds_name CIFAR-10 --b 32 --e 300 --th 200 250 275 300 325 350 400 --num_clients 5 10 15 20 25 30 --comb_file_id 3
```
```bash
python -m fdavg.utils.create_combinations --fda synchronous --nn DenseNet201 --ds_name CIFAR-10 --b 32 --e 300 --th 0 --num_clients 5 10 15 20 25 30 --comb_file_id 3 --append_to
```
```bash
python -m fdavg.utils.create_combinations --fda FedAvgM --nn DenseNet201 --ds_name CIFAR-10 --b 32 --e 1000 --th 0 --num_clients 5 10 15 20 25 30 --comb_file_id 3 --append_to
```

### ConvNeXtLarge
```bash
python -m fdavg.utils.create_combinations --fda linear sketch --nn ConvNeXtLarge --ds_name CIFAR-100 --b 32 --e 30 --th 25 50 100 150 --num_clients 3 5 --comb_file_id 4
```
```bash
python -m fdavg.utils.create_combinations --fda synchronous --nn ConvNeXtLarge --ds_name CIFAR-100 --b 32 --e 30 --th 0 --num_clients 3 5 --comb_file_id 4 --append_to
```

## 2. Simulations
To streamline things, we will run experiments locally.
```bash
python -m local_simulator --n_sims 612 --comb_file_id 0 --n_gpus 2
```
```bash
python -m local_simulator --n_sims 612 --comb_file_id 1 --n_gpus 2
```
```bash
python -m local_simulator --n_sims 96 --comb_file_id 2 --n_gpus 2
```
```bash
python -m local_simulator --n_sims 96 --comb_file_id 3 --n_gpus 2
```
```bash
python -m local_simulator --n_sims 18 --comb_file_id 4 --n_gpus 2
```

# Kafka WorkFlow

```bash
cd FedL-Sync-FDA
```

```bash
python -m fdavg.utils.create_combinations --fda sketch --nn AdvancedCNN --ds_name MNIST --b 32 --e 300 --th 300 --num_clients 20 --comb_file_id 0
```

```bash
python -m kafka_submitter --n_gpus 2 --kafka_topic FedL --kafka_server localhost:9092
```

```bash
cd /FedL-Sync-FDA/metrics/tmp/combinations
```

```bash
kafka-console-producer.sh --bootstrap-server localhost:9092 --topic FedL < 0.json
```

```bash
cd /FedL-Sync-FDA/metrics/tmp/local_out
```

```bash
tail -f server_sim1.out
```