{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b4bea7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "055b8db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.11.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313ca374",
   "metadata": {},
   "source": [
    "## Create Binary Classification data with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69940316",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "n = 50_000\n",
    "d = 1_000\n",
    "\n",
    "\n",
    "noise_factor = 0.01 # % of the labels are randomly flipped, DEFAULT=0.01\n",
    "test_size = 0.2 # % of n\n",
    "# The factor multiplying the hypercube size. Larger values spread out the \n",
    "# clusters/classes and make the classification task easier. DEFAULT=1\n",
    "class_sep = -1\n",
    "seed = None # None for no seed 7\n",
    "\n",
    "# Create (noisy) testing data for binary classification.\n",
    "X, y = make_classification(\n",
    "    n_samples=n, \n",
    "    n_features=d,\n",
    "    n_informative=d,\n",
    "    n_redundant=0, \n",
    "    n_classes=2,\n",
    "    class_sep=class_sep,\n",
    "    flip_y=noise_factor,\n",
    "    random_state=seed\n",
    ")\n",
    "\n",
    "# We will work with label values -1, +1 and not 0, +1 (convert)\n",
    "y[y == 0] = -1\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba160f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7651"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# PA-I regressor from sklearn\n",
    "pa1 = PassiveAggressiveClassifier(C=0.01, loss=\"hinge\", n_jobs=-1)\n",
    "pa1.fit(X_train, y_train)\n",
    "\n",
    "accuracy_score(y_test, pa1.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7841b1",
   "metadata": {},
   "source": [
    "## Convert to Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c46d87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = tf.constant(X_train, dtype=tf.float32)\n",
    "y_train_tensor = tf.constant(y_train, dtype=tf.float32)\n",
    "X_test_tensor = tf.constant(X_test, dtype=tf.float32)\n",
    "y_test_tensor = tf.constant(y_test, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358adb8f",
   "metadata": {},
   "source": [
    "Delete sklearn type data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8626b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X, y, X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7779e542",
   "metadata": {},
   "source": [
    "## Prepare data for Federated Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a002f9cf",
   "metadata": {},
   "source": [
    "### Create centralized testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a351bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "slices_test = (X_test_tensor, y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dc0a0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_dataset_for_testing(batch_size):\n",
    "    return tf.data.Dataset.from_tensor_slices(slices_test).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5576ca5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = create_tf_dataset_for_testing(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4809df",
   "metadata": {},
   "source": [
    "### Slice the Tensors for each Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5792cb",
   "metadata": {},
   "source": [
    "We will cut the training data, i.e., (`X_train_tensor`, `y_train_tensor`) to equal parts, each part corresponding to one Client. We want to give the result back as a dictionary with key `client_id` and value the training tensor data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b21e4eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_for_clients(num_clients):\n",
    "    \n",
    "    client_slices_train = {}\n",
    "\n",
    "    n_test = int(n - n*test_size)\n",
    "\n",
    "    for i in range(num_clients):\n",
    "        # Compute the indices for this client's slice\n",
    "        start_idx = int(i * n_test / num_clients)\n",
    "        end_idx = int((i + 1) * n_test / num_clients)\n",
    "\n",
    "        # Get the slice for this client\n",
    "        X_client_train = X_train_tensor[start_idx:end_idx]\n",
    "        y_client_train = y_train_tensor[start_idx:end_idx]\n",
    "        \n",
    "        # Combine the slices into a single dataset\n",
    "        client_slices_train[f'client_{i}'] = (X_client_train, y_client_train)\n",
    "    \n",
    "    return client_slices_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28604a1c",
   "metadata": {},
   "source": [
    "### Create TF friendly data for each Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f351360",
   "metadata": {},
   "source": [
    "Given a Tensor slice (i.e. value of `client_slices_train[\"client_id\"]` we convert it to highly optimized `tf.data.Dataset` to prepare for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba400a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_dataset_for_client(client_tensor_slices, batch_size, shuffle_buffer_size, num_steps_until_rtc_check, seed):\n",
    "    \n",
    "        return tf.data.Dataset.from_tensor_slices(client_tensor_slices) \\\n",
    "            .shuffle(buffer_size=shuffle_buffer_size, seed=seed).batch(batch_size) \\\n",
    "            .prefetch(tf.data.AUTOTUNE).take(num_steps_until_rtc_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e16b23",
   "metadata": {},
   "source": [
    "### Create Federated Learning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16be409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_federated_data(client_slices_train, batch_size, shuffle_buffer_size, num_steps_until_rtc_check, seed=None):\n",
    "    \n",
    "    federated_dataset = [ \n",
    "        create_tf_dataset_for_client(client_tensor_slices, batch_size, shuffle_buffer_size, num_steps_until_rtc_check, seed)\n",
    "        for client, client_tensor_slices in client_slices_train.items()\n",
    "    ]\n",
    "    \n",
    "    return federated_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6e7be4",
   "metadata": {},
   "source": [
    "## PA-Classiers (binary classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c37ce06",
   "metadata": {},
   "source": [
    "![PA](images/PA_binary_classifiers.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38f96baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def client_train(model, dataset, C):\n",
    "\n",
    "    @tf.function\n",
    "    def _train_on_batch(model, batch, C):\n",
    "\n",
    "        x_batch, y_batch = batch\n",
    "        \n",
    "        # from shape (d,) make it (d,1)\n",
    "        y_batch = tf.expand_dims(y_batch, axis=1)\n",
    "\n",
    "        # dot(w, x) for the batch (each instance of x in x_batch) with with shape=(batchsize, 1)\n",
    "        weights_dot_x_batch = tf.matmul(x_batch, model)\n",
    "\n",
    "        # Prediction batch with shape=(batchsize, 1)\n",
    "        y_pred_batch = tf.sign(weights_dot_x_batch)\n",
    "\n",
    "        # Suffer loss for each prediction (of instance) in the batch with shape=(batchsize,1)\n",
    "        loss_batch = tf.maximum(0., 1. - tf.multiply(y_batch, weights_dot_x_batch))\n",
    "\n",
    "        # shape=(batchsize,1) where each instance is ||x||^2, x in x_batch\n",
    "        norm_batch = tf.expand_dims(tf.reduce_sum(tf.square(x_batch), axis=1), axis=1)\n",
    "        \n",
    "        # PA-1 : Learning rate t for each instance x, with shape=(batchsize,1)\n",
    "        t_batch = tf.maximum(C, tf.divide(loss_batch, norm_batch))\n",
    "\n",
    "        # each instance is y*t*x, where y,t scalars and x in x_batch. shape=(batchsize,d)\n",
    "        t_y_x_batch = tf.multiply(t_batch, tf.multiply(y_batch, x_batch))\n",
    "\n",
    "        # !!!! Update with mean t*y*x\n",
    "        t_y_x_update = tf.expand_dims(tf.reduce_mean(t_y_x_batch, axis=0) ,axis=1)\n",
    "\n",
    "        # Update\n",
    "        model.assign_add(t_y_x_update)\n",
    "    \n",
    "    for batch in dataset:\n",
    "        _train_on_batch(model, batch, C)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93115f92",
   "metadata": {},
   "source": [
    "# Functional Dynamic Averaging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a2a6d7",
   "metadata": {},
   "source": [
    "We follow the Functional Dynamic Averaging (FDA) scheme. Let the mean model be\n",
    "\n",
    "$$ \\overline{w_t} = \\frac{1}{k} \\sum_{i=1}^{k} w_t^{(i)} $$\n",
    "\n",
    "where $ w_t^{(i)} $ is the model at time $ t $ in some round in the $i$-th learner.\n",
    "\n",
    "Local models are trained independently and cooperatively and we want to monitor the Round Terminating Conditon (**RTC**):\n",
    "\n",
    "$$ \\frac{1}{k} \\sum_{i=1}^{k} \\lVert w_t^{(i)} - \\overline{w_t} \\rVert_2^2  \\leq \\Theta $$\n",
    "\n",
    "where the left-hand side is the **model variance**, and threshold $\\Theta$ is a hyperparameter of the FDA, defined at the beginning of the round; it may change at each round. When the monitoring logic cannot guarantee the validity of RTC, the round terminates. All local models are pulled into `tff.SERVER`, and $\\bar{w_t}$ is set to their average. Then, another round begins."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003fe9e9",
   "metadata": {},
   "source": [
    "### Monitoring the RTC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c20ea38",
   "metadata": {},
   "source": [
    "FDA monitors the RTC by applying techniques from Functionary [Functional Geometric Averaging](http://users.softnet.tuc.gr/~minos/Papers/edbt19.pdf). We first restate the problem of monitoring RTC into the standard distributed stream monitoring formulation. Let\n",
    "\n",
    "$$ S(t) =  \\frac{1}{k} \\sum_{i=1}^{k} S_i(t) $$\n",
    "\n",
    "where $ S(t) \\in \\mathbb{R}^n $ be the \"global state\" of the system and $ S_i(t) \\in \\mathbb{R}^n $ the \"local states\". The goal is to monitor the threshold condition on the global state in the form $ F(S(t)) \\leq \\Theta $ where $ F : \\mathbb{R}^n \\to \\mathbb{R} $ a non-linear function. Let\n",
    "\n",
    "$$ \\Delta_t^{(i)} = w_t^{(i)} - w_{t_0}^{(i)} $$\n",
    "\n",
    "be the update at the $ i $-th learner, that is, the change to the local model at time $t$ since the beginning of the current round at time $t_0$. Let the average update be\n",
    "\n",
    "$$ \\overline{\\Delta_t} = \\frac{1}{k} \\sum_{i=1}^{k} \\Delta_t^{(i)} $$\n",
    "\n",
    "it follows that the variance can be written as\n",
    "\n",
    "$$ \\frac{1}{k} \\sum_{i=1}^{k} \\lVert w_t^{(i)} - \\overline{w_t} \\rVert_2^2 = \\Big( \\frac{1}{k} \\sum_{i=1}^{k} \\lVert \\Delta_t^{(i)} \\rVert_2^2 \\Big) - \\lVert \\overline{\\Delta_t} \\rVert_2^2 $$\n",
    "\n",
    "So, conceptually, if we define\n",
    "$$ S_i(t) = \\begin{bmatrix}\n",
    "           \\lVert \\Delta_t^{(i)} \\rVert_2^2 \\\\\n",
    "           \\Delta_t^{(i)}\n",
    "         \\end{bmatrix} \\quad \\text{and} \\quad\n",
    "         F(\\begin{bmatrix}\n",
    "           v \\\\\n",
    "           \\bf{x}\n",
    "         \\end{bmatrix}) = v - \\lVert \\bf{x} \\rVert_2^2 $$\n",
    "\n",
    "The RTC is equivalent to condition $$ F(S(t)) \\leq \\Theta $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3f52bb",
   "metadata": {},
   "source": [
    "## 2️⃣ Linear FDA\n",
    "\n",
    "In the linear case, we reduce the update vector to a scalar, $ \\xi \\Delta_t^{(i)} \\in \\mathbb{R}$, where $ \\xi $ is any unit vector.\n",
    "\n",
    "Define the local state to be \n",
    "\n",
    "$$ S_i(t) = \\begin{bmatrix}\n",
    "           \\lVert \\Delta_t^{(i)} \\rVert_2^2 \\\\\n",
    "           \\xi \\Delta_t^{(i)}\n",
    "         \\end{bmatrix} \\in \\mathbb{R}^2 $$\n",
    "\n",
    "Also, define \n",
    "\n",
    "$$ F(v, x) = v - x^2 $$\n",
    "\n",
    "The RTC is equivalent to condition \n",
    "\n",
    "$$ F(S(t)) \\leq \\Theta $$\n",
    "\n",
    "A random choice of $ \\xi $ is likely to perform poorly (terminate round prematurely), as it wil likely be close to orthogonal to $ \\overline{\\Delta_t} $. A good choice would be a vector $ \\xi $ correlated to $ \\overline{\\Delta_t} $. A heuristic choice is to take $ \\overline{\\Delta_{t_0}} $ (after scaling it to norm 1), i.e., the update vector right before the current round started. All nodes can estimate this without communication, as $ \\overline{w_{t_0}} - \\overline{w_{t_{-1}}} $, the difference of the last two models pushed by the Server. Hence, \n",
    "\n",
    "$$ \\xi = \\frac{\\overline{w_{t_0}} - \\overline{w_{t_{-1}}}}{\\lVert \\overline{w_{t_0}} - \\overline{w_{t_{-1}}} \\rVert_2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15a97fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def ksi_unit_fn(w_t0, w_tminus1):\n",
    "    \n",
    "    if tf.reduce_all(tf.equal(w_t0, w_tminus1)):\n",
    "        # if equal then ksi becomes a random vector (will only happen in round 1)\n",
    "        ksi = tf.random.normal(shape=w_t0.shape)\n",
    "    else:\n",
    "        ksi = w_t0 - w_tminus1\n",
    "\n",
    "    # Normalize and return\n",
    "    return tf.divide(ksi, tf.norm(ksi))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ab590e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def steps_linear(model_tminus, model_t0, model, dataset, C):\n",
    "    # number of steps depend on `.take()` from `dataset`\n",
    "    client_train(model, dataset, C)\n",
    "    \n",
    "    Delta_i = model - model_t0\n",
    "    \n",
    "    #||D(t)_i||^2 , shape = (1,) \n",
    "    Delta_i_euc_norm_squared = tf.reduce_sum(tf.square(Delta_i), axis=0)\n",
    "    \n",
    "    # heuristic unit vector ksi\n",
    "    ksi = ksi_unit_fn(model_t0, model_tminus)\n",
    "    \n",
    "    # ksi * Delta_i (* is dot) , shape = ()\n",
    "    ksi_Delta_i = tf.reduce_sum(tf.multiply(ksi, Delta_i))\n",
    "    \n",
    "    return Delta_i_euc_norm_squared, ksi_Delta_i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31896e11",
   "metadata": {},
   "source": [
    "## Accuracy Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2459aeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def accuracy(model, dataset):\n",
    "    \n",
    "    @tf.function\n",
    "    def _batch_accuracy(model, batch):\n",
    "        x_batch, y_batch = batch\n",
    "        # from shape (d,) make it (d,1)\n",
    "        y_batch = tf.expand_dims(y_batch, axis=1)\n",
    "\n",
    "        # dot(w, x) for the batch (each instance of x in x_batch) with with shape=(batchsize, 1)\n",
    "        weights_dot_x_batch = tf.matmul(x_batch, model)\n",
    "\n",
    "        # Prediction batch with shape=(batchsize, 1)\n",
    "        y_pred_batch = tf.sign(weights_dot_x_batch)\n",
    "\n",
    "        accuracy = tf.reduce_mean(tf.cast(tf.equal(y_pred_batch, y_batch), tf.float32))\n",
    "\n",
    "        return accuracy\n",
    "    \n",
    "    # We take advantage of AutoGraph (convert Python code to TensorFlow-compatible graph code automatically)\n",
    "    acc, num_batches = 0., 0.\n",
    "    for batch in dataset:\n",
    "        acc += _batch_accuracy(model, batch)\n",
    "        num_batches += 1\n",
    "        \n",
    "    acc = acc / num_batches\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050f36f4",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "019b121d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metrics_dict(fda_name, n, d, test_size, num_clients, batch_size, \n",
    "                        steps_in_one_fda_step, theta, c, total_fda_steps, \n",
    "                        total_rounds, final_accuracy, sketch_width=None, sketch_depth=None):\n",
    "    metrics = {\n",
    "            \"fda_name\" : fda_name,\n",
    "            \"theta\" : theta,\n",
    "            \"n\" : n,\n",
    "            \"d\" : d,\n",
    "            \"test_size\" : test_size,\n",
    "            \"num_clients\" : num_clients,\n",
    "            \"batch_size\" : batch_size,\n",
    "            \"steps_in_one_fda_step\" : steps_in_one_fda_step,\n",
    "            \"sketch_width\" : sketch_width,\n",
    "            \"sketch_depth\" : sketch_depth,\n",
    "            \"c\" : c\n",
    "        }\n",
    "    \n",
    "    # one batch bytes\n",
    "    metrics[\"one_sample_bytes\"] = 4 * (metrics[\"d\"] + 1)\n",
    "    \n",
    "    # training dataset size\n",
    "    metrics[\"training_dataset_bytes\"] = metrics[\"one_sample_bytes\"] * (1 - metrics[\"test_size\"]) * metrics[\"n\"]\n",
    "    \n",
    "    # model bytes\n",
    "    metrics[\"model_bytes\"] = d * 4\n",
    "    \n",
    "    \n",
    "    # local state bytes (i.e. S_i), for one client\n",
    "    if fda_name == \"naive\":\n",
    "        metrics[\"local_state_bytes\"] = 4\n",
    "    elif fda_name == \"linear\":\n",
    "        metrics[\"local_state_bytes\"] = 8\n",
    "    else:\n",
    "        metrics[\"local_state_bytes\"] = sketch_width * sketch_depth * 4 + 4\n",
    "        \n",
    "    # accuracy (already computed in parameter)\n",
    "    metrics[\"final_accuracy\"] = final_accuracy\n",
    "    \n",
    "    # total fda steps from algo\n",
    "    metrics[\"total_fda_steps\"] = total_fda_steps\n",
    "    \n",
    "    # total steps (a single fda step might have many normal SGD steps, batch steps)\n",
    "    metrics[\"total_steps\"] = metrics[\"total_fda_steps\"] * metrics[\"steps_in_one_fda_step\"]\n",
    "    \n",
    "    # total rounds in algo. Reason why we differentiate from the hardcoded NUM_ROUNDS\n",
    "    # is because we might run less rounds in the future (i.e. stop on 10^7 samples idk)\n",
    "    metrics[\"total_rounds\"] = total_rounds\n",
    "    \n",
    "    # bytes exchanged for synchronizing weights (x2 because server sends back)\n",
    "    metrics[\"model_bytes_exchanged\"] = metrics[\"total_rounds\"] * metrics[\"model_bytes\"] \\\n",
    "        * metrics[\"num_clients\"] * 2\n",
    "    \n",
    "    # bytes exchanged for monitoring the variance (communication)\n",
    "    metrics[\"monitoring_bytes_exchanged\"] = metrics[\"local_state_bytes\"] * metrics[\"total_fda_steps\"] \\\n",
    "        * metrics[\"num_clients\"]\n",
    "    \n",
    "    # total communication bytes (for both monitoring and model synchronization)\n",
    "    metrics[\"total_communication_bytes\"] = metrics[\"model_bytes_exchanged\"] + metrics[\"monitoring_bytes_exchanged\"]\n",
    "    \n",
    "    # total seen dataset bytes (across all learning, i.e., all clients)\n",
    "    metrics[\"trained_in_bytes\"] = metrics[\"batch_size\"] * metrics[\"one_sample_bytes\"] \\\n",
    "        * metrics[\"total_steps\"] * metrics[\"num_clients\"]\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aeccaf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_spec = tf.TensorSpec(shape=(20, d, 1), dtype=tf.float32)\n",
    "\n",
    "@tf.function(input_signature=[w_spec, w_spec])\n",
    "def variance(w_t, w_sync):\n",
    "    # w_t , w_sync tensors with shape=(NUM_CLIENTS, d, 1)\n",
    "    \n",
    "    # tensor with shape=(NUM_CLIENTS, d, 1)\n",
    "    diff = w_t - w_sync\n",
    "    \n",
    "    # tensor with shape=(NUM_CLIENTS, 1) , For each client ||w_i_t - w_t||^2\n",
    "    dot = tf.reduce_sum(tf.square(diff), axis=1)\n",
    "    \n",
    "    # Variance shape=() , scalar\n",
    "    var = tf.reduce_mean(dot)\n",
    "    \n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e57ba2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8ebb80a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_linear(S_1, S_2):\n",
    "    return S_1 - S_2**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e3c94064",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def run_federated_simulation_linear(previous_server_model, server_model, client_models, federated_dataset, C, num_rounds, theta):\n",
    "    \n",
    "    print(\"retracing\")\n",
    "    \n",
    "    total_rounds = 0\n",
    "    total_fda_steps = 0\n",
    "    \n",
    "    S_1 = tf.constant(0., shape=(), dtype=tf.float32)\n",
    "    S_2 = tf.constant(0., shape=(), dtype=tf.float32)\n",
    "    \n",
    "    for r in range(num_rounds):\n",
    "        \n",
    "        while F_linear(S_1, S_2) <= theta:\n",
    "            euc_norm_squared_clients = []\n",
    "            ksi_delta_clients = []\n",
    "\n",
    "            # client steps (number depends on `federated_dataset`, i.e., `.take(num)`)\n",
    "            for client_model, client_dataset in zip(client_models, federated_dataset):\n",
    "                \n",
    "                Delta_i_euc_norm_squared, ksi_Delta_i  = steps_linear(\n",
    "                    previous_server_model, server_model, client_model, client_dataset, C\n",
    "                )\n",
    "                \n",
    "                euc_norm_squared_clients.append(Delta_i_euc_norm_squared)\n",
    "                ksi_delta_clients.append(ksi_Delta_i)\n",
    "                \n",
    "            S_1 = tf.reduce_mean(euc_norm_squared_clients)\n",
    "            S_2 = tf.reduce_mean(ksi_delta_clients)\n",
    "            \n",
    "            total_fda_steps += 1\n",
    "        \n",
    "        # last server model (previous sync)\n",
    "        previous_server_model.assign(server_model)\n",
    "        \n",
    "        \"\"\"------------------------------test--------------------------------------------\"\"\"\n",
    "        #Delta_i_clients = [tf.subtract(client_model, server_model) for client_model in client_models] #test\n",
    "        #testing_approx_0 = tf.reduce_sum(tf.square(tf.reduce_mean(Delta_i_clients, axis=0)), axis=0) #test\n",
    "        \"\"\"------------------------------test--------------------------------------------\"\"\"\n",
    "        \n",
    "        # server average\n",
    "        server_model.assign(tf.reduce_mean(client_models, axis=0))\n",
    "        \n",
    "        \"\"\"------------------------------test--------------------------------------------\"\"\"\n",
    "        actual_var = variance(client_models, [server_model]*len(client_models)) #test\n",
    "        tf.print(\"Est left: \", S_1, \" Est S_2: \", S_2**2, \"Est var: \", S_1-S_2**2, \" Actual var: \", actual_var, \" Total fda steps: \", total_fda_steps, output_stream=sys.stdout)\n",
    "        #tf.print(\"Est var: \", S_1-S_2, \" Actual var: \", actual_var, \" Missing: \", testing_approx_0, \" Total fda steps: \", total_fda_steps, output_stream=sys.stdout)\n",
    "        \"\"\"------------------------------test--------------------------------------------\"\"\"\n",
    "        \n",
    "        \n",
    "        # reset variance approx\n",
    "        S_1 = tf.constant(0., shape=(), dtype=tf.float32)\n",
    "        S_2 = tf.constant(0., shape=(), dtype=tf.float32)\n",
    "\n",
    "        # synchronize clients\n",
    "        for client_model in client_models:\n",
    "            client_model.assign(server_model)\n",
    "            \n",
    "        total_rounds += 1\n",
    "    \n",
    "    return total_rounds, total_fda_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00df981e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0e97780f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tests():\n",
    "    \"\"\" --------------- Test configurations -------------------\"\"\"\n",
    "    \n",
    "    NUM_CLIENTS = 20  # dataset\n",
    "    BATCH_SIZE = 32 # dataset !\n",
    "    NUM_STEPS_UNTIL_RTC_CHECK = 1 # dataset !  ALONE NO RETRACING\n",
    "    NUM_ROUNDS = 10 # ! WE WANT !~~50~~!\n",
    "    C = 0.01  # model, GOOD\n",
    "    THETA = 100. # ALONE NO RETRACING (/ 10 of d)  WE WANT !~~100.~~!\n",
    "    \n",
    "    # Convert to tensors to avoid retracing where we can in `run_federated_simulation`\n",
    "    c = tf.constant(C, shape=(), dtype=tf.float32)\n",
    "    num_rounds = tf.constant(NUM_ROUNDS, shape=(), dtype=tf.int32)\n",
    "    theta = tf.constant(THETA, shape=(), dtype=tf.float32)\n",
    "    \n",
    "    \n",
    "    \"\"\" --------------- Initializations -------------------\"\"\"\n",
    "    \n",
    "    # 1. Dataset\n",
    "\n",
    "    client_slices_train = create_data_for_clients(NUM_CLIENTS)\n",
    "\n",
    "    federated_dataset = create_federated_data(\n",
    "        client_slices_train=client_slices_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle_buffer_size=int(n/20),\n",
    "        num_steps_until_rtc_check=NUM_STEPS_UNTIL_RTC_CHECK,\n",
    "        seed=seed\n",
    "    )\n",
    "    \n",
    "    # 2. Models\n",
    "    \n",
    "    server_model = tf.Variable(tf.zeros(shape=(d, 1)), trainable=True, name='weights', dtype=tf.float32)\n",
    "    \n",
    "    # for `ξ` approximation.\n",
    "    previous_server_model = tf.Variable(tf.zeros(shape=(d, 1)), trainable=True, name='weights', dtype=tf.float32)\n",
    "\n",
    "    client_models = [\n",
    "        tf.Variable(tf.zeros(shape=(d, 1)), trainable=True, name='weights', dtype=tf.float32)\n",
    "        for _ in range(NUM_CLIENTS)\n",
    "    ]\n",
    "    \n",
    "    \"\"\" --------------- Test -------------------\"\"\"\n",
    "    \n",
    "    c = tf.constant(C, shape=(), dtype=tf.float32)\n",
    "    num_rounds = tf.constant(NUM_ROUNDS, shape=(), dtype=tf.int32)\n",
    "    theta = tf.constant(THETA, shape=(), dtype=tf.float32)\n",
    "    \n",
    "    total_rounds, total_fda_steps = run_federated_simulation_linear(\n",
    "        previous_server_model,\n",
    "        server_model, \n",
    "        client_models, \n",
    "        federated_dataset, \n",
    "        c,\n",
    "        num_rounds, \n",
    "        theta\n",
    "    )\n",
    "    \n",
    "    final_accuracy = accuracy(server_model, test_dataset)\n",
    "    \n",
    "    metrics = create_metrics_dict(\n",
    "        fda_name=\"linear\", \n",
    "        n=n, \n",
    "        d=d, \n",
    "        test_size=test_size, \n",
    "        num_clients=NUM_CLIENTS, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        steps_in_one_fda_step=NUM_STEPS_UNTIL_RTC_CHECK, \n",
    "        theta=THETA, \n",
    "        c=C, \n",
    "        total_fda_steps=total_fda_steps.numpy(), \n",
    "        total_rounds=total_rounds.numpy(), \n",
    "        final_accuracy=final_accuracy.numpy(), \n",
    "        sketch_width=None, \n",
    "        sketch_depth=None\n",
    "    )\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eac45662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retracing\n",
      "Est left:  100.837708  Est S_2:  0.00222611311 Est var:  100.83548  Actual var:  61.9981918  Total fda steps:  39\n",
      "Est left:  166.342834  Est S_2:  65.936058 Est var:  100.406776  Actual var:  95.1428833  Total fda steps:  92\n",
      "Est left:  165.646515  Est S_2:  64.9602432 Est var:  100.686272  Actual var:  95.8189545  Total fda steps:  145\n",
      "Est left:  169.5784  Est S_2:  66.6086044 Est var:  102.969795  Actual var:  97.5546494  Total fda steps:  199\n",
      "Est left:  170.323105  Est S_2:  68.0853195 Est var:  102.237785  Actual var:  96.7513275  Total fda steps:  253\n",
      "Est left:  167.947067  Est S_2:  66.0359879 Est var:  101.911079  Actual var:  96.3050232  Total fda steps:  306\n",
      "Est left:  164.681519  Est S_2:  64.2349701 Est var:  100.446548  Actual var:  95.0593567  Total fda steps:  359\n",
      "Est left:  164.217392  Est S_2:  64.147728 Est var:  100.069664  Actual var:  94.6075  Total fda steps:  412\n",
      "Est left:  168.502411  Est S_2:  67.6123428 Est var:  100.890068  Actual var:  95.4260712  Total fda steps:  466\n",
      "Est left:  165.837112  Est S_2:  64.6187363 Est var:  101.218376  Actual var:  95.8377228  Total fda steps:  519\n"
     ]
    }
   ],
   "source": [
    "metrics = run_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4f1af048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fda_name': 'linear',\n",
       " 'theta': 100.0,\n",
       " 'n': 50000,\n",
       " 'd': 1000,\n",
       " 'test_size': 0.2,\n",
       " 'num_clients': 20,\n",
       " 'batch_size': 32,\n",
       " 'steps_in_one_fda_step': 1,\n",
       " 'sketch_width': None,\n",
       " 'sketch_depth': None,\n",
       " 'c': 0.01,\n",
       " 'one_sample_bytes': 4004,\n",
       " 'training_dataset_bytes': 160160000.0,\n",
       " 'model_bytes': 4000,\n",
       " 'local_state_bytes': 8,\n",
       " 'final_accuracy': 0.8034145,\n",
       " 'total_fda_steps': 519,\n",
       " 'total_steps': 519,\n",
       " 'total_rounds': 10,\n",
       " 'model_bytes_exchanged': 1600000,\n",
       " 'monitoring_bytes_exchanged': 83040,\n",
       " 'total_communication_bytes': 1683040,\n",
       " 'trained_in_bytes': 1329968640}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17b62529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160.16"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics[\"training_dataset_bytes\"]/1_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "474ce20d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1329.96864"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics[\"trained_in_bytes\"]/1_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8676108b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5e165f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b242464a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [metrics, metrics, metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e4028e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "168c3556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fda_name</th>\n",
       "      <th>theta</th>\n",
       "      <th>n</th>\n",
       "      <th>d</th>\n",
       "      <th>test_size</th>\n",
       "      <th>num_clients</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>steps_in_one_fda_step</th>\n",
       "      <th>sketch_width</th>\n",
       "      <th>sketch_depth</th>\n",
       "      <th>...</th>\n",
       "      <th>model_bytes</th>\n",
       "      <th>local_state_bytes</th>\n",
       "      <th>final_accuracy</th>\n",
       "      <th>total_fda_steps</th>\n",
       "      <th>total_steps</th>\n",
       "      <th>total_rounds</th>\n",
       "      <th>model_bytes_exchanged</th>\n",
       "      <th>monitoring_bytes_exchanged</th>\n",
       "      <th>total_communication_bytes</th>\n",
       "      <th>trained_in_bytes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear</td>\n",
       "      <td>10.0</td>\n",
       "      <td>50000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>4000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.797424</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>5</td>\n",
       "      <td>800000</td>\n",
       "      <td>7040</td>\n",
       "      <td>807040</td>\n",
       "      <td>112752640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>linear</td>\n",
       "      <td>10.0</td>\n",
       "      <td>50000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>4000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.797424</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>5</td>\n",
       "      <td>800000</td>\n",
       "      <td>7040</td>\n",
       "      <td>807040</td>\n",
       "      <td>112752640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>linear</td>\n",
       "      <td>10.0</td>\n",
       "      <td>50000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>4000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.797424</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>5</td>\n",
       "      <td>800000</td>\n",
       "      <td>7040</td>\n",
       "      <td>807040</td>\n",
       "      <td>112752640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  fda_name  theta      n     d  test_size  num_clients  batch_size  \\\n",
       "0   linear   10.0  50000  1000        0.2           20          32   \n",
       "1   linear   10.0  50000  1000        0.2           20          32   \n",
       "2   linear   10.0  50000  1000        0.2           20          32   \n",
       "\n",
       "   steps_in_one_fda_step sketch_width sketch_depth  ...  model_bytes  \\\n",
       "0                      1         None         None  ...         4000   \n",
       "1                      1         None         None  ...         4000   \n",
       "2                      1         None         None  ...         4000   \n",
       "\n",
       "   local_state_bytes  final_accuracy  total_fda_steps  total_steps  \\\n",
       "0                  8        0.797424               44           44   \n",
       "1                  8        0.797424               44           44   \n",
       "2                  8        0.797424               44           44   \n",
       "\n",
       "   total_rounds  model_bytes_exchanged  monitoring_bytes_exchanged  \\\n",
       "0             5                 800000                        7040   \n",
       "1             5                 800000                        7040   \n",
       "2             5                 800000                        7040   \n",
       "\n",
       "   total_communication_bytes  trained_in_bytes  \n",
       "0                     807040         112752640  \n",
       "1                     807040         112752640  \n",
       "2                     807040         112752640  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "03091788",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test_results/naive.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d412cb79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117b1f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3f1385e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DataFrame from a CSV file\n",
    "df_from_csv = pd.read_csv('test_results/naive.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc81c8b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>fda_name</th>\n",
       "      <th>theta</th>\n",
       "      <th>n</th>\n",
       "      <th>d</th>\n",
       "      <th>test_size</th>\n",
       "      <th>num_clients</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>steps_in_one_fda_step</th>\n",
       "      <th>sketch_width</th>\n",
       "      <th>...</th>\n",
       "      <th>model_bytes</th>\n",
       "      <th>local_state_bytes</th>\n",
       "      <th>final_accuracy</th>\n",
       "      <th>total_fda_steps</th>\n",
       "      <th>total_steps</th>\n",
       "      <th>total_rounds</th>\n",
       "      <th>model_bytes_exchanged</th>\n",
       "      <th>monitoring_bytes_exchanged</th>\n",
       "      <th>total_communication_bytes</th>\n",
       "      <th>trained_in_bytes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>linear</td>\n",
       "      <td>10.0</td>\n",
       "      <td>50000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.797424</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>5</td>\n",
       "      <td>800000</td>\n",
       "      <td>7040</td>\n",
       "      <td>807040</td>\n",
       "      <td>112752640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>10.0</td>\n",
       "      <td>50000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.797424</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>5</td>\n",
       "      <td>800000</td>\n",
       "      <td>7040</td>\n",
       "      <td>807040</td>\n",
       "      <td>112752640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>linear</td>\n",
       "      <td>10.0</td>\n",
       "      <td>50000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.797424</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>5</td>\n",
       "      <td>800000</td>\n",
       "      <td>7040</td>\n",
       "      <td>807040</td>\n",
       "      <td>112752640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 fda_name  theta      n     d  test_size  num_clients  \\\n",
       "0           0   linear   10.0  50000  1000        0.2           20   \n",
       "1           1   linear   10.0  50000  1000        0.2           20   \n",
       "2           2   linear   10.0  50000  1000        0.2           20   \n",
       "\n",
       "   batch_size  steps_in_one_fda_step  sketch_width  ...  model_bytes  \\\n",
       "0          32                      1           NaN  ...         4000   \n",
       "1          32                      1           NaN  ...         4000   \n",
       "2          32                      1           NaN  ...         4000   \n",
       "\n",
       "   local_state_bytes  final_accuracy  total_fda_steps  total_steps  \\\n",
       "0                  8        0.797424               44           44   \n",
       "1                  8        0.797424               44           44   \n",
       "2                  8        0.797424               44           44   \n",
       "\n",
       "   total_rounds  model_bytes_exchanged  monitoring_bytes_exchanged  \\\n",
       "0             5                 800000                        7040   \n",
       "1             5                 800000                        7040   \n",
       "2             5                 800000                        7040   \n",
       "\n",
       "   total_communication_bytes  trained_in_bytes  \n",
       "0                     807040         112752640  \n",
       "1                     807040         112752640  \n",
       "2                     807040         112752640  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_from_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8c2632",
   "metadata": {},
   "source": [
    "1. check which changes produce new graph. We want "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tff-py39] *",
   "language": "python",
   "name": "conda-env-tff-py39-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
