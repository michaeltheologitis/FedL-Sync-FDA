{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16945920",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5666e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.50.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tff.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70db373c",
   "metadata": {},
   "source": [
    "## Create Binary Classification data with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8936c1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "n = 10000\n",
    "d = 8\n",
    "noise_factor = 0.\n",
    "\n",
    "# Create (noisy) testing data for binary classification.\n",
    "X, y = make_classification(\n",
    "    n_samples=n, \n",
    "    n_features=d,\n",
    "    n_informative=d,\n",
    "    n_redundant=0, \n",
    "    n_classes=2,\n",
    "    class_sep=-1,\n",
    "    flip_y=noise_factor\n",
    ")\n",
    "\n",
    "# We will work with label values -1, +1 and not 0, +1 (convert)\n",
    "y[y == 0] = -1\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b180164a",
   "metadata": {},
   "source": [
    "## Convert to Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29d1b71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert the data to TensorFlow tensors\n",
    "X_train_tensor = tf.constant(X_train, dtype=tf.float32)\n",
    "y_train_tensor = tf.constant(y_train, dtype=tf.float32)\n",
    "X_test_tensor = tf.constant(X_test, dtype=tf.float32)\n",
    "y_test_tensor = tf.constant(y_test, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc001d5",
   "metadata": {},
   "source": [
    "## Prepare data for Tensorflow Federated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2921d7d",
   "metadata": {},
   "source": [
    "We have the training and testing Tensors holding our data. TFF expects for each client an `OrderedDict` containing `y` and `x` data. Hence, we preprocess our Tensors to follow this convention."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5825d1",
   "metadata": {},
   "source": [
    "**Note**: Cross-device federated learning does not use client IDs or perform any tracking of clients. However in simulation experiments using centralized test data the experimenter may select specific clients to be processed per round. The concept of a client ID is only available at the preprocessing stage when preparing input data for the simulation and is not part of the TensorFlow Federated core APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53e2091a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NUM_CLIENTS = 10\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99a285bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import collections\n",
    "\n",
    "# Create a dictionary with the slices for each client\n",
    "client_slices_train = {}\n",
    "\n",
    "for i in range(NUM_CLIENTS):\n",
    "    # Compute the indices for this client's slice\n",
    "    start_idx = int(i * n / NUM_CLIENTS)\n",
    "    end_idx = int((i + 1) * n / NUM_CLIENTS)\n",
    "\n",
    "    # Get the slice for this client\n",
    "    X_client_train = X_train_tensor[start_idx:end_idx]\n",
    "    y_client_train = y_train_tensor[start_idx:end_idx]\n",
    "    \n",
    "    \n",
    "    client_data_train = collections.OrderedDict([('y', y_client_train), ('x', X_client_train)])\n",
    "    \n",
    "    # Combine the slices into a single dataset\n",
    "    client_slices_train[f'client_{i}'] = client_data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef737537",
   "metadata": {},
   "source": [
    "We need to construct `tff.simulation.datasets.ClientData`. We can use the `from_clients_and_tf_fn` function that takes as argument the `client_ids` : a list of strings to use as input to `create_dataset_fn`, and a `serializable_dataset_fn` : a function that takes a `client_id` from the above list, and returns a `tf.data.Dataset`, this function must be serializable and usable within the context of a `tf.function` and `tff.Computation`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72350d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def create_tf_dataset_for_client(client_data):\n",
    "    return tf.data.Dataset.from_tensor_slices(client_data).batch(BATCH_SIZE)#.shuffle()\n",
    "\n",
    "train_federated_dataset = tff.simulation.datasets.ClientData.from_clients_and_tf_fn(\n",
    "    client_ids=list(client_slices_train.keys()),\n",
    "    serializable_dataset_fn=lambda client_id: create_tf_dataset_for_client(\n",
    "        client_slices_train[client_id]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1acb22b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['client_0',\n",
       " 'client_1',\n",
       " 'client_2',\n",
       " 'client_3',\n",
       " 'client_4',\n",
       " 'client_5',\n",
       " 'client_6',\n",
       " 'client_7',\n",
       " 'client_8',\n",
       " 'client_9']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_federated_dataset.client_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee538970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('y', TensorSpec(shape=(None,), dtype=tf.float32, name=None)),\n",
       "             ('x', TensorSpec(shape=(None, 8), dtype=tf.float32, name=None))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_federated_dataset.element_type_structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d3c683",
   "metadata": {},
   "source": [
    "First, let's define the type of input as a TFF named tuple. Since the size of data batches may vary, we set the batch dimension to None to indicate that the size of this dimension is unknown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47b88ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BATCH_SPEC = collections.OrderedDict(\n",
    "    y=tf.TensorSpec(shape=[None], dtype=tf.float32),\n",
    "    x=tf.TensorSpec(shape=[None, d], dtype=tf.float32)\n",
    ")\n",
    "BATCH_TYPE = tff.to_type(BATCH_SPEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d69a37d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<y=float32[?],x=float32[?,8]>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(BATCH_TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dedbfb",
   "metadata": {},
   "source": [
    "Let's now define the TFF type of the model which is simply a `tf.Variable` with shape (d, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1625384b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODEL_TYPE = tff.TensorType(dtype=tf.float32, shape=(d, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4db97c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'float32[8,1]'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "7ffca0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tff.tf_computation(MODEL_TYPE, BATCH_TYPE)\n",
    "def batch_accuracy_fn(model, batch):\n",
    "    \n",
    "    @tf.function\n",
    "    def _batch_accuracy(model, batch):\n",
    "        x_batch, y_batch = batch['x'], tf.expand_dims(batch['y'], axis=1)\n",
    "\n",
    "        # dot(w, x) for the batch (each instance of x in x_batch) with with shape=(batchsize, 1)\n",
    "        weights_dot_x_batch = tf.matmul(x_batch, model)\n",
    "\n",
    "        # Prediction batch with shape=(batchsize, 1)\n",
    "        y_pred_batch = tf.sign(weights_dot_x_batch)\n",
    "\n",
    "        accuracy = tf.reduce_mean(tf.cast(tf.equal(y_pred_batch, y_batch), tf.float32))\n",
    "\n",
    "        return accuracy\n",
    "    \n",
    "    return _batch_accuracy(model, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bab9c42c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(<model=float32[8,1],batch=<y=float32[?],x=float32[?,8]>> -> float32)'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(batch_accuracy.type_signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3b2c6967",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LOCAL_DATA_TYPE = tff.SequenceType(BATCH_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "35b3fe11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<y=float32[?],x=float32[?,8]>*'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(LOCAL_DATA_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2427e37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def client_accuracy(model, dataset):\n",
    "    \n",
    "    @tf.function\n",
    "    def _batch_accuracy(model, batch):\n",
    "        x_batch, y_batch = batch['x'], tf.expand_dims(batch['y'], axis=1)\n",
    "\n",
    "        # dot(w, x) for the batch (each instance of x in x_batch) with with shape=(batchsize, 1)\n",
    "        weights_dot_x_batch = tf.matmul(x_batch, model)\n",
    "\n",
    "        # Prediction batch with shape=(batchsize, 1)\n",
    "        y_pred_batch = tf.sign(weights_dot_x_batch)\n",
    "\n",
    "        accuracy = tf.reduce_mean(tf.cast(tf.equal(y_pred_batch, y_batch), tf.float32))\n",
    "\n",
    "        return accuracy\n",
    "    \n",
    "    # We take advantage of AutoGraph (convert Python code to TensorFlow-compatible graph code automatically)\n",
    "    acc, num_batches = 0., 0.\n",
    "    for batch in dataset:\n",
    "        acc += _batch_accuracy(model, batch)\n",
    "        num_batches += 1\n",
    "        \n",
    "    acc = acc / num_batches\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "7db2f5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tff.tf_computation(MODEL_TYPE, LOCAL_DATA_TYPE)\n",
    "def client_accuracy_fn(client_model, dataset):\n",
    "    model = tf.Variable(initial_value=client_model)\n",
    "    return client_accuracy(model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ecea1204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(<client_model=float32[8,1],dataset=<y=float32[?],x=float32[?,8]>*> -> float32)'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(client_accuracy_fn.type_signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "dc8b1db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tf.function\n",
    "def client_train(model, dataset):\n",
    "    \n",
    "    @tf.function\n",
    "    def _train_on_batch(model, batch, C=0.01):\n",
    "\n",
    "        x_batch, y_batch = batch['x'], tf.expand_dims(batch['y'], axis=1)\n",
    "\n",
    "        # dot(w, x) for the batch (each instance of x in x_batch) with with shape=(batchsize, 1)\n",
    "        weights_dot_x_batch = tf.matmul(x_batch, model)\n",
    "\n",
    "        # Prediction batch with shape=(batchsize, 1)\n",
    "        y_pred_batch = tf.sign(weights_dot_x_batch)\n",
    "\n",
    "        # Suffer loss for each prediction (of instance) in the batch with shape=(batchsize,1)\n",
    "        loss_batch = tf.maximum(0., 1. - tf.multiply(y_batch, weights_dot_x_batch))\n",
    "\n",
    "        # shape=(batchsize,1) where each instance is ||x||^2, x in x_batch\n",
    "        norm_batch = tf.expand_dims(tf.reduce_sum(tf.square(x_batch), axis=1), axis=1)\n",
    "\n",
    "        # PA-1 : Learning rate t for each instance x, with shape=(batchsize,1)\n",
    "        t_batch = tf.maximum(C, tf.divide(loss_batch, norm_batch))\n",
    "\n",
    "        # each instance is y*t*x, where y,t scalars and x in x_batch. shape=(batchsize,d)\n",
    "        t_y_x_batch = tf.multiply(t_batch, tf.multiply(y_batch, x_batch))\n",
    "\n",
    "        # !!!! Update with mean t*y*x\n",
    "        t_y_x_update = tf.expand_dims(tf.reduce_mean(t_y_x_batch, axis=0) ,axis=1)\n",
    "\n",
    "        # Update\n",
    "        model.assign_add(t_y_x_update)\n",
    "    \n",
    "    for batch in dataset:\n",
    "        _train_on_batch(model, batch)\n",
    "        \n",
    "    return model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "888be5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tff.tf_computation(MODEL_TYPE, LOCAL_DATA_TYPE)\n",
    "def client_train_fn(initial_model, dataset):\n",
    "    model = tf.Variable(initial_value=initial_model)\n",
    "    return client_train(model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "349b9ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(<initial_model=float32[8,1],dataset=<y=float32[?],x=float32[?,8]>*> -> float32[8,1])'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(client_train_fn.type_signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "8ac5354f",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_model = tf.Variable(tf.zeros(shape=(d, 1)), trainable=True, name='weights', dtype=tf.float32)\n",
    "first_client_dataset = train_federated_dataset.create_tf_dataset_for_client('client_0')\n",
    "second_client_dataset = train_federated_dataset.create_tf_dataset_for_client('client_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "34aee272",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = client_train_fn(initial_model, first_client_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "1518ec5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86816406"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_accuracy_fn(trained_model, first_client_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "d747e058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8378906"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_accuracy_fn(trained_model, second_client_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14c5c75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tff-py39] *",
   "language": "python",
   "name": "conda-env-tff-py39-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
